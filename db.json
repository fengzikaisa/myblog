{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/hexo-theme-tangyuxian/source/css/other.styl","path":"css/other.styl","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/css/webapp.css","path":"css/webapp.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/js/app.js","path":"js/app.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/js/clock.js","path":"js/clock.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/js/postcover.js","path":"js/postcover.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/js/webapp.js","path":"js/webapp.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/cangshu.png","path":"images/background/cangshu.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/background.png","path":"images/background/background.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/chichi.jpg","path":"images/background/chichi.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/cat.png","path":"images/background/cat.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/xiaomai.jpg","path":"images/background/xiaomai.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/lihui.png","path":"images/background/lihui.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/papa.jpg","path":"images/background/papa.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/100.gif","path":"images/emoji/100.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/101.gif","path":"images/emoji/101.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/102.gif","path":"images/emoji/102.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/103.gif","path":"images/emoji/103.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/105.gif","path":"images/emoji/105.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/104.gif","path":"images/emoji/104.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/106.gif","path":"images/emoji/106.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/107.gif","path":"images/emoji/107.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/108.gif","path":"images/emoji/108.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/109.gif","path":"images/emoji/109.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/110.gif","path":"images/emoji/110.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/111.gif","path":"images/emoji/111.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/112.gif","path":"images/emoji/112.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/113.gif","path":"images/emoji/113.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/114.gif","path":"images/emoji/114.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/115.gif","path":"images/emoji/115.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/116.gif","path":"images/emoji/116.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/117.gif","path":"images/emoji/117.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/118.gif","path":"images/emoji/118.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/119.gif","path":"images/emoji/119.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/120.gif","path":"images/emoji/120.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/121.gif","path":"images/emoji/121.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/122.gif","path":"images/emoji/122.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/123.gif","path":"images/emoji/123.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/124.gif","path":"images/emoji/124.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/125.gif","path":"images/emoji/125.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/126.gif","path":"images/emoji/126.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/127.gif","path":"images/emoji/127.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/128.gif","path":"images/emoji/128.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/129.gif","path":"images/emoji/129.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/130.gif","path":"images/emoji/130.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/131.gif","path":"images/emoji/131.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/132.gif","path":"images/emoji/132.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/133.gif","path":"images/emoji/133.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/134.gif","path":"images/emoji/134.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/135.gif","path":"images/emoji/135.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/136.gif","path":"images/emoji/136.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/137.gif","path":"images/emoji/137.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/138.gif","path":"images/emoji/138.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/139.gif","path":"images/emoji/139.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/140.gif","path":"images/emoji/140.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/141.gif","path":"images/emoji/141.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/142.gif","path":"images/emoji/142.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/143.gif","path":"images/emoji/143.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/144.gif","path":"images/emoji/144.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/145.gif","path":"images/emoji/145.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/146.gif","path":"images/emoji/146.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/147.gif","path":"images/emoji/147.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/148.gif","path":"images/emoji/148.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/149.gif","path":"images/emoji/149.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/150.gif","path":"images/emoji/150.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/151.gif","path":"images/emoji/151.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/152.gif","path":"images/emoji/152.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/153.gif","path":"images/emoji/153.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/154.gif","path":"images/emoji/154.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/155.gif","path":"images/emoji/155.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/156.gif","path":"images/emoji/156.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/157.gif","path":"images/emoji/157.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/158.gif","path":"images/emoji/158.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/159.gif","path":"images/emoji/159.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/160.gif","path":"images/emoji/160.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/161.gif","path":"images/emoji/161.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/162.gif","path":"images/emoji/162.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/163.gif","path":"images/emoji/163.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/164.gif","path":"images/emoji/164.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/165.gif","path":"images/emoji/165.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/166.gif","path":"images/emoji/166.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/167.gif","path":"images/emoji/167.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/168.gif","path":"images/emoji/168.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/169.gif","path":"images/emoji/169.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/170.gif","path":"images/emoji/170.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/171.gif","path":"images/emoji/171.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/172.gif","path":"images/emoji/172.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/173.gif","path":"images/emoji/173.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/174.gif","path":"images/emoji/174.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/175.gif","path":"images/emoji/175.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/176.gif","path":"images/emoji/176.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/177.gif","path":"images/emoji/177.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/178.gif","path":"images/emoji/178.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/179.gif","path":"images/emoji/179.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/180.gif","path":"images/emoji/180.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/181.gif","path":"images/emoji/181.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/182.gif","path":"images/emoji/182.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/183.gif","path":"images/emoji/183.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/184.gif","path":"images/emoji/184.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/185.gif","path":"images/emoji/185.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/186.gif","path":"images/emoji/186.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/187.gif","path":"images/emoji/187.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/188.gif","path":"images/emoji/188.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/190.gif","path":"images/emoji/190.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/189.gif","path":"images/emoji/189.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/191.gif","path":"images/emoji/191.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/192.gif","path":"images/emoji/192.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/194.gif","path":"images/emoji/194.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/193.gif","path":"images/emoji/193.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/195.gif","path":"images/emoji/195.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/196.gif","path":"images/emoji/196.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/197.gif","path":"images/emoji/197.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/198.gif","path":"images/emoji/198.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/199.gif","path":"images/emoji/199.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/200.png","path":"images/emoji/200.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/201.png","path":"images/emoji/201.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/202.png","path":"images/emoji/202.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/203.png","path":"images/emoji/203.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/204.png","path":"images/emoji/204.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/205.png","path":"images/emoji/205.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/206.png","path":"images/emoji/206.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/207.png","path":"images/emoji/207.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/208.png","path":"images/emoji/208.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/209.png","path":"images/emoji/209.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/210.png","path":"images/emoji/210.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/211.png","path":"images/emoji/211.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/212.png","path":"images/emoji/212.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/213.png","path":"images/emoji/213.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/214.png","path":"images/emoji/214.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/215.png","path":"images/emoji/215.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/219.png","path":"images/emoji/219.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/call.jpg","path":"images/head/call.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/head.jpg","path":"images/head/head.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/uniapp.jpg","path":"images/head/uniapp.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/vue.jpg","path":"images/head/vue.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/JavaScript.jpg","path":"images/post/JavaScript.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/216.png","path":"images/emoji/216.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/217.png","path":"images/emoji/217.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/218.png","path":"images/emoji/218.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/TypeScript.jpg","path":"images/post/TypeScript.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/algorithm.jpg","path":"images/post/algorithm.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/beautify.jpg","path":"images/post/beautify.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/database.jpg","path":"images/post/database.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/browser.jpg","path":"images/post/browser.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/css.jpg","path":"images/post/css.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/editor.jpg","path":"images/post/editor.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/elasticsearch.jpg","path":"images/post/elasticsearch.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/es6.jpg","path":"images/post/es6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/git.jpg","path":"images/post/git.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/hexo.jpg","path":"images/post/hexo.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/internet.jpg","path":"images/post/internet.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/java.jpg","path":"images/post/java.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/markerdown.jpg","path":"images/post/markerdown.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/nodejs.jpg","path":"images/post/nodejs.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/phantomjs.png","path":"images/post/phantomjs.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/redis.png","path":"images/post/redis.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/data.jpg","path":"images/post/data.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/development_tool.jpg","path":"images/post/development_tool.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/docker.jpg","path":"images/post/docker.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/ui.jpg","path":"images/post/ui.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/weifuwu.png","path":"images/post/weifuwu.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/view/render_tree.png","path":"images/view/render_tree.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeBlockFuction.js","path":"lib/codeBlock/codeBlockFuction.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeCopy.js","path":"lib/codeBlock/codeCopy.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeLang.js","path":"lib/codeBlock/codeLang.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeShrink.js","path":"lib/codeBlock/codeShrink.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/matery.css","path":"lib/codeBlock/matery.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/demo.css","path":"lib/iconfont/demo.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/demo_index.html","path":"lib/iconfont/demo_index.html","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.css","path":"lib/iconfont/iconfont.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/vue.jpg","path":"images/post/vue.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/webpack.jpg","path":"images/post/webpack.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/wechat_applet.jpg","path":"images/post/wechat_applet.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.eot","path":"lib/iconfont/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.ttf","path":"lib/iconfont/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.woff","path":"lib/iconfont/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.woff2","path":"lib/iconfont/iconfont.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.js","path":"lib/iconfont/iconfont.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.json","path":"lib/iconfont/iconfont.json","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.svg","path":"lib/iconfont/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/fancybox/css/jquery.fancybox.min.css","path":"lib/fancybox/css/jquery.fancybox.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/fancybox/js/jquery.fancybox.min.js","path":"lib/fancybox/js/jquery.fancybox.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/mdui_043tiny/css/mdui.css","path":"lib/mdui_043tiny/css/mdui.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-tangyuxian/source/lib/mdui_043tiny/js/mdui.js","path":"lib/mdui_043tiny/js/mdui.js","modified":0,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0}],"Cache":[{"_id":"themes/hexo-theme-tangyuxian/_config.yml","hash":"0edd8221a3838a0ebbc32d069b3108b1a0fb35c0","modified":1664415723207},{"_id":"themes/hexo-theme-tangyuxian/_config.styl","hash":"27fdf4a7e387f1fa940c1da7c3c5ae734345b5e2","modified":1664257727404},{"_id":"themes/hexo-theme-tangyuxian/package.json","hash":"e703a5efa3ae7b46791a048177ea5211361b0e09","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/languages/default.yml","hash":"e9e6d033d90d7a407e587208dd5536e5650626db","modified":1664257727406},{"_id":"themes/hexo-theme-tangyuxian/languages/en.yml","hash":"658b68a0aaf4bf0711b5749da910aee13a7565a4","modified":1664257727406},{"_id":"themes/hexo-theme-tangyuxian/languages/ja.yml","hash":"18d42a4413bb9cfef0472d19ae7cb070e0bf36f1","modified":1664257727406},{"_id":"themes/hexo-theme-tangyuxian/languages/zh-CN.yml","hash":"148d4f78719eef47d4930eb168a5eaeb93570567","modified":1664257727406},{"_id":"themes/hexo-theme-tangyuxian/languages/zh-HK.yml","hash":"85fda43f723651db4f07a88484c57f13dda41757","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/languages/zh-TW.yml","hash":"85fda43f723651db4f07a88484c57f13dda41757","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/archives.ejs","hash":"3f9f5e8c6a3580b6ea54b4bafad978f6a5cd9df5","modified":1664257727416},{"_id":"themes/hexo-theme-tangyuxian/layout/index.ejs","hash":"cdbb668c28a4a0220369da45316f353c12a8d841","modified":1664257727416},{"_id":"themes/hexo-theme-tangyuxian/layout/post.ejs","hash":"baf68c503dd582dc25f317ea4a9264ba491d46a3","modified":1664257727416},{"_id":"themes/hexo-theme-tangyuxian/layout/layout.ejs","hash":"f0bc2accb836a72453d9d4a3f8df91bbea9444a4","modified":1664257727416},{"_id":"themes/hexo-theme-tangyuxian/layout/py.ejs","hash":"7d877186e87fa9a9eb1175e980c18407a6955f61","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/analytics.ejs","hash":"e53883f2bb9921cb08437f433d5d4d5cf52ab297","modified":1664257727413},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/after-footer.ejs","hash":"064fa99e08935098e0ed150f020d069e33ec393a","modified":1664415663245},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/comment.ejs","hash":"6e48ae4a79ad9e14d00244c15cd6e9ad04b99eb4","modified":1664257727413},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/header.ejs","hash":"3a9324caee4f2df0350563c42ede0068ca6c0a3b","modified":1664267406385},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/copyright.ejs","hash":"512f67959aa507006fe34ed0f85f603471f0f518","modified":1664257727413},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/paginator.ejs","hash":"20caf7c8ab390cfd125a12cbc71e51f868899050","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/sidebar.ejs","hash":"58c53d620cc0695b68c1e18a9f0d97fc888357cc","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/site-verification.ejs","hash":"600319729da09e366c05e104fe68a821b087c027","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_pendant/clock.ejs","hash":"d462a9558b4d343705b1bda379b1785f32345932","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_pendant/pendant.ejs","hash":"7ca489d04edf5a050530355056a21f570d8b28a2","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_pendant/qweather.ejs","hash":"f56e63d3d34cb020ad87a1a660c1a1ba4443d5fb","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/archive.ejs","hash":"b6c6fa5d3a80c5eb0ccb27fcd1b67494e6715dee","modified":1664257727414},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/category.ejs","hash":"add8fe5a94437019685f6e01b6a3357a77dd09a5","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/link.ejs","hash":"d9104aa53f57a99d59ed1a06b3e1abca93082945","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/recent_posts.ejs","hash":"7d9eaf8228eda803aa4956e55432f78e056d6a01","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/search.ejs","hash":"f2c784f32bd356d9f5cacd62fc44ecc54e7dacaa","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/social.ejs","hash":"d0f2a8386de1a08deb431a6fa9a3f4a299d0cd1a","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/tag.ejs","hash":"ddf844f08124454bea2a30f8349b63f3cb63ac16","modified":1664257727415},{"_id":"themes/hexo-theme-tangyuxian/layout/_widget/tagcloud.ejs","hash":"6636a70e3ed871f2e90550d37b773c951817f143","modified":1664257727416},{"_id":"themes/hexo-theme-tangyuxian/scripts/clock/clockLink.js","hash":"3de8d76129ae5b9240a9f22dcd46e10deab06854","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/scripts/codeBlock/codeBlock.js","hash":"b2a23633177bbb01403aa68d56b4da77c64a0d71","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/scripts/helper/cover_auto_post.js","hash":"07a82e4d0e35a06519b2dbb0b1465cd9e46746b1","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/scripts/helper/css_auto_version.js","hash":"63c90dac6ad0a102ef302bf9fd9e030d521a8232","modified":1664257727417},{"_id":"themes/hexo-theme-tangyuxian/scripts/helper/image_auto_lazyload.js","hash":"3f87969ab6988bde342e87472749686e02b4014e","modified":1664257727418},{"_id":"themes/hexo-theme-tangyuxian/scripts/helper/js_auto_version.js","hash":"338cb31ea975bbcb00a7fa5afb0294dbdc385165","modified":1664257727418},{"_id":"themes/hexo-theme-tangyuxian/scripts/search/searchLink.js","hash":"8cd28f1483fe572fd6915edfbc4ed86790250370","modified":1664257727418},{"_id":"themes/hexo-theme-tangyuxian/scripts/tag/gallery.js","hash":"a359add30a0106f06cc4bd6b997abc107d751f00","modified":1664257727418},{"_id":"themes/hexo-theme-tangyuxian/scripts/webapp/webappLink.js","hash":"14fa0165ebbaf3c3abb1df31ad4044fca734e212","modified":1664257727418},{"_id":"themes/hexo-theme-tangyuxian/source/css/other.styl","hash":"9a4d2b59792e73c41744bd0fed097498705eeb50","modified":1664257727419},{"_id":"themes/hexo-theme-tangyuxian/source/css/style.styl","hash":"eda32a3f7b7a371857e622b8a381c361553d3384","modified":1664257727419},{"_id":"themes/hexo-theme-tangyuxian/.gitignore","hash":"3cc8fa8c3fe29546b38050deb8f7d5cfb5fb601f","modified":1664257727404},{"_id":"themes/hexo-theme-tangyuxian/source/js/app.js","hash":"4744fd883b665f6f06054197fb96b144b5aab104","modified":1664257727463},{"_id":"themes/hexo-theme-tangyuxian/source/js/clock.js","hash":"5cc9643c1c8fdfc742ee5d1f2ef39b4939200df8","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/source/js/postcover.js","hash":"0bdd1584be3ca9097c611641219b5a91e266e5fe","modified":1664349514409},{"_id":"themes/hexo-theme-tangyuxian/source/js/search.js","hash":"86c41ea703eeaac6b9f50f7328efcd2e91ae842d","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/source/js/webapp.js","hash":"f7146257296f064177d4e006ce966a747a4e3818","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/baidu.ejs","hash":"cc782e1363c8bbb6277c3825bb9eac83762bc26d","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/cnzz.ejs","hash":"345ed559b76930bed05e1b393c12f09d42c2312e","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/google.ejs","hash":"97f3a717495c8cc71d5d3c7ab69ddd589a69a038","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/gtags.ejs","hash":"2c429eef83e712531a08de370b06f1f00ac7398b","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/gtm-body.ejs","hash":"1471e3a49ad6c93fd33b18545b43805c48695e23","modified":1664257727407},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/la.ejs","hash":"e08b1f111068c62e625b6790e66d8a5f625246ba","modified":1664257727408},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/tencent.ejs","hash":"6f7d514f157fbdb505e52dda2dc4f35dcdb2685e","modified":1664257727408},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_analytics/gtm-head.ejs","hash":"5638bed9cfe2e86aeee77adc883b2a3e1ecd76ff","modified":1664257727408},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/changyan.ejs","hash":"8a520fd9a9704208c23abcb689bae33acd1167db","modified":1664257727411},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/DiscussBot.ejs","hash":"92fb25b5204b325eb18eea0c15ddb4f4116e35e2","modified":1664257727411},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/disqus.ejs","hash":"e1e70a619cf3499ef8b054c8fb4b23865a554b6b","modified":1664257727411},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/disqusjs.ejs","hash":"7518e88f2504b9844f71190e079df07f51847472","modified":1664257727411},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/gitalk.ejs","hash":"a3a33112234fee49646a9c11fcbdf2ed1a7777a8","modified":1664257727412},{"_id":"themes/hexo-theme-tangyuxian/source/css/webapp.css","hash":"7a70ea62dddf0fe63d9f198ac33c1c59b7134118","modified":1664257727419},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/gitment.ejs","hash":"d4a99db9f2daf7bcdbcf637f478d925d5d840fe4","modified":1664257727412},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/livere.ejs","hash":"e96e1510ba2a8ccb1edebc378c566fadaed09e50","modified":1664257727412},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_comment/valine.ejs","hash":"a56abbf2fa249ab60121d6c3e0fb9bf008098009","modified":1664257727412},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_post/meta.ejs","hash":"1a6d6facbe095031341ccfe186b272d2c851a373","modified":1664257727412},{"_id":"themes/hexo-theme-tangyuxian/layout/_partial/_post/tag.ejs","hash":"c265ae74f31bb046922a052bb7d5eef4416d1357","modified":1664257727413},{"_id":"themes/hexo-theme-tangyuxian/source/css/_partial/archives.styl","hash":"f6b6579907a8368440013737734598248291a972","modified":1664257727419},{"_id":"themes/hexo-theme-tangyuxian/source/css/_partial/article.styl","hash":"0d7159e3456e8e4a33cbc8d1cfc429089373426b","modified":1664415674708},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/cangshu.png","hash":"79566fdd8d4b29971f84bcf7678b1cd451827534","modified":1664257727430},{"_id":"themes/hexo-theme-tangyuxian/source/css/_partial/py.styl","hash":"d471e21a503687f6449d0585e4c9997ecb1e883a","modified":1664257727419},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/chichi.jpg","hash":"e364c38f02bf9c1b74110e4e7cb5915dfeefc89e","modified":1664257727431},{"_id":"themes/hexo-theme-tangyuxian/README.md","hash":"152d3068cd8d09eadae43f490789cbe23e1895f8","modified":1664257727404},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/papa.jpg","hash":"10d778fbed199c56e986e3d22ad80c18a06db5f2","modified":1664257727433},{"_id":"themes/hexo-theme-tangyuxian/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1664257727404},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/cat.png","hash":"ccda3c9f0c85dfc457c723cf24e7868e72314c2a","modified":1664257727431},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/100.gif","hash":"08e13e2f9a57713cac0bb3570472601ad3b64cd4","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/101.gif","hash":"a49210c9d99f5e1663a7b3ee1836c603866fe703","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/102.gif","hash":"b22c01184c47b80c25841ab3dd74525af506132b","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/103.gif","hash":"5a67c38c03c501dd3cc762bd475a2f952a8eb967","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/105.gif","hash":"e70bca66a53a5d5a2633cd806c9e75968ac8df48","modified":1664257727436},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/106.gif","hash":"951441561cf6dc97d90db2e32db95d2ac81e0803","modified":1664257727436},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/107.gif","hash":"8f55b9a520a5daeeb874f18e3a0ff5e8e7a5b7bb","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/104.gif","hash":"ecb730525f4bbab66a2f7d1a0beb4c5a33024c4d","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/108.gif","hash":"8f2e77f259f99cbf81b3ae8e6f5bad08d3c233e8","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/109.gif","hash":"d26731f3ac47eef724940225fdc7cc4b32df0fc9","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/111.gif","hash":"efd4e92387b3d2adaa6aafa539b64b94e384e751","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/112.gif","hash":"ead851113876e9ca8b34bb9e14ea795e231ad4c3","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/110.gif","hash":"b0011c024457e3fd56151ec6d7a083d9b60824f0","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/113.gif","hash":"30f300ea0255b5e2d526e26c7b13cb2a9aca986a","modified":1664257727437},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/115.gif","hash":"112ed4f86a19b83a89fb032bc9b0e045f0f501d2","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/114.gif","hash":"38469b26c1e59718b5bc0d11fb770944ffdff6cc","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/116.gif","hash":"fd48dd300d810035667999dd4471d1788fecb3ae","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/117.gif","hash":"f6528fe54ba1e8e9511ddf70689bcdc65bb3015b","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/118.gif","hash":"eae431af35aaada000bac3bf1169c8522b305ee1","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/119.gif","hash":"a896b477bd134ae30fb49c826841ce0a0ad0709a","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/120.gif","hash":"be94dcfd79af6b2b0a1934bb3b3a0808134fe9d1","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/121.gif","hash":"db18cc01ddaa4668ad1faffc9f5f62eb4452e325","modified":1664257727438},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/122.gif","hash":"e3f7e0d4aa2cffd8b8d48ae25a5250501c4916c9","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/123.gif","hash":"ae6d19d7f175180b8311ab49fbe0a9ee27115713","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/124.gif","hash":"97e045b79958302955e00ceb2ca3eae29e558a87","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/125.gif","hash":"3cca520648813a9223de9e7c40348739db1e2167","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/126.gif","hash":"11834b77f4b20383aeeda4e53c32834ad62b35e2","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/127.gif","hash":"2c24c9b755703a656af6983767d9c76e319b3054","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/128.gif","hash":"53baf1a3eaf8bee92c0376d35d7f504199d52fdb","modified":1664257727439},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/129.gif","hash":"aed1ac54764de1604f1e2f803af91c5400dd12c0","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/130.gif","hash":"a53accded36281c55e3299c635e1f5c47093ead5","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/131.gif","hash":"efc4648182d11ac7f77f5d0f6f5a9fdaac8c3d02","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/132.gif","hash":"f77fe2749048668ca424b7a691e128c9353ed2d0","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/133.gif","hash":"3004a4ca69e73e535fea208e42cbad2d37cbac30","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/134.gif","hash":"08c8dc4fd6f9018f7c9af1a90c671defe8bbeafd","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/135.gif","hash":"114d709fb33e9bc1ff694e3974b9aa249e859e27","modified":1664257727440},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/137.gif","hash":"55d89284defe7617b17813a65f1b65c12f509749","modified":1664257727441},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/138.gif","hash":"13cefa1d39ac3ebb77845d21ad817a20557182a0","modified":1664257727441},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/139.gif","hash":"f1a8196f58a2e95c2fc376d65b3362e2f3b360e8","modified":1664257727441},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/140.gif","hash":"14694d0c7e7dd0a87cc83cef5e4064f956618544","modified":1664257727441},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/141.gif","hash":"9de2fa2aef63cf8e6096ad2c0c8ca19bf9bf1409","modified":1664257727442},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/142.gif","hash":"71c99c8d90fee2e92ab8ebd843d11c884e7a83b2","modified":1664257727442},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/143.gif","hash":"bb33a375ec6cf4b301a858316d991d690dc4694a","modified":1664257727442},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/144.gif","hash":"8b487eae23ec61ae136ed82ba46347d9fdc740aa","modified":1664257727442},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/145.gif","hash":"c29cb928fa3982042687a3f0d800f636b5dcce88","modified":1664257727443},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/146.gif","hash":"23ef2d150adb840a57e629a3b8d89a3cdb566b4c","modified":1664257727443},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/147.gif","hash":"776285d4af925fe51c9fa179c0c5f499e5bc1009","modified":1664257727443},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/148.gif","hash":"addae76a66cf12d64f6fe38bb6e83101cfc8cf5c","modified":1664257727443},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/149.gif","hash":"08230e3085ca3d657c27eee81048bd3049df0be1","modified":1664257727443},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/150.gif","hash":"c7a403b5e33b7c45501ef600ea91066e60e25619","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/151.gif","hash":"e79d25fc8730714f7625aae411dda011c39e11ed","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/153.gif","hash":"505d8bb3f2b51cac729f8b6602bb1a1d329c8eff","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/136.gif","hash":"f55bdf318dfff07a009f27802f2e6492d299a9d5","modified":1664257727441},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/154.gif","hash":"e3180081f65ed3f2f02cd9910578f3864003feb9","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/152.gif","hash":"9e8e1a602549a5daa86a60cd2b932feda12cd856","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/155.gif","hash":"54b4e482b857437e7d4168ae3dc42aeee0041b03","modified":1664257727444},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/156.gif","hash":"67e7ae5690c35528796678fae0307bc6cd8b7139","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/158.gif","hash":"5acb07481f05bc084b8142d2c3149b497f3d9a43","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/157.gif","hash":"a942190d6ca4ed6707300f0df551a5e9a3559818","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/159.gif","hash":"b2d4b7a39b901cf4c3ee263266d45220d2a8d023","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/161.gif","hash":"04552d20fc832b0d4b4a0fe7d8ee9bfc2de493ab","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/160.gif","hash":"2f62eb4c5f0756547e09bc259c41d8c0b69b8a4c","modified":1664257727445},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/162.gif","hash":"4b7e2723c14404478bf590e5c10dff34fe95c126","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/165.gif","hash":"d89054c0aa501c23b0dc3b6cdd4d2a3465040d4c","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/166.gif","hash":"af2fee57afe72d6e3162ab04dcd15ac96223b642","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/167.gif","hash":"df1d3e8e957e3bfcc722fd2b04e6ea201bacdb5d","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/168.gif","hash":"cbf5294928cbe64e547f299b066aa92fd879cdc7","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/169.gif","hash":"65150b00b3f002d2a35e36b05108869e248945a4","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/170.gif","hash":"0f7cf27e866ae6226967add3cb8e2c54e18044f3","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/171.gif","hash":"78572a3d820aa5460f051a03d9c8171957c96044","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/172.gif","hash":"f1db06ec39eed83eed6253037bfe49e3fb70eab3","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/173.gif","hash":"530ed8b5671e78c91432ea2002cac85c9411795f","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/174.gif","hash":"e8582ecde37573ca8a4c237fb6ee8d8c8309eb2b","modified":1664257727447},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/176.gif","hash":"cd19cc59c65b97621d4d02387941858604709d36","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/175.gif","hash":"d7e7f75f7a3e708e548f139240b7d1cf8b0b12e3","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/163.gif","hash":"a3cd050714583290f5aaa2b03a7821911ca7133f","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/164.gif","hash":"f27481a27a18420f256911763e1bd2bc21bb6692","modified":1664257727446},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/177.gif","hash":"32c95ad1721fc143df5e1795388d4f0b2ceab739","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/178.gif","hash":"ab6f3d3e6cfd080af48f5acf02b0544634e5b8f9","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/179.gif","hash":"e74435eb9ef411becedeaf17d380aa0c76c0ff0c","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/180.gif","hash":"2c5247fe32b396b411a02853a3d8177c1acc501a","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/181.gif","hash":"3555eae56a92a6d592e84b7b40b20da6d5cff8da","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/182.gif","hash":"8dfc6421e5d68e9a12867d5c6605edff4b345124","modified":1664257727448},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/183.gif","hash":"a87911529020e62f399902e4290b8e4325378f93","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/184.gif","hash":"1030d1242670e2f541a2c7ef0e94ae00f4401536","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/185.gif","hash":"062280ba4b67e2053d625680578776ce2bd3e748","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/186.gif","hash":"cafff6b96491d24e8c7f87d7bad0b4c8d6df7c2f","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/187.gif","hash":"4265f098e55cfd4a075cb303b12442e02de40b28","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/188.gif","hash":"48c34728a802c10da59c6ece07cf12e4e6fa2f2d","modified":1664257727449},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/190.gif","hash":"c112e7a0fd8a2ae0ea01442d13a21cb26aab78c6","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/192.gif","hash":"3a8fc60f3a8a9592fe4826b7ec01c11973b32818","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/194.gif","hash":"d4fa1dfc51723eaaaa351e44afcd90e9f8ed2329","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/193.gif","hash":"c4100e61798f46ce432488391fb850c0d85915d7","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/195.gif","hash":"d12ecb9031ec2747941054297d542fac3c263b86","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/196.gif","hash":"dd999e90afd8a1779b08923ed9a1aa4e725b6a43","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/197.gif","hash":"6b4ddde064fd31f76f0f16bab4328fe337668391","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/198.gif","hash":"9e20eb98f55781c4f260b078529d3c1b852c553f","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/199.gif","hash":"c4aafef4b734516b0c6fd2d2f344ca383a04e7f3","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/191.gif","hash":"d27dce702731088be15d440abf36e16790eda893","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/189.gif","hash":"707e3552c8b086dfcc627a2e8843405a5cddacec","modified":1664257727450},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/200.png","hash":"11e4c96f09209016c88d9c99c1c884db6abdd0d8","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/201.png","hash":"2e4e9b89539588a65a80ca4d8a246e1a38cfdc34","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/202.png","hash":"9ff2f7dd6c0da725007ede6befd2a3a36c3079c9","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/203.png","hash":"2aec6517e1b8203d3d4b2acddc8fb7b37c5bf64b","modified":1664257727451},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/206.png","hash":"a8e73d095313fe0372eca4e72e92961cf9022f07","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/205.png","hash":"b934b7a27869b7f37fffac441540104cba1c29d2","modified":1664257727452},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/207.png","hash":"f48194a896768596845c77dcb1f78205b12c8b79","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/204.png","hash":"39a4705bfae18f5e312997797869888bb4bc447a","modified":1664257727452},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/208.png","hash":"8f5fd728b5a605a1eeb4c475ac7584e810513347","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/211.png","hash":"cac7341d040a6b7c6747f14c53b630f76101d226","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/210.png","hash":"510508062daaaf95a3e66d85b777911c59518f29","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/209.png","hash":"367a93350236149c874138b920cbf2c0e6d29176","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/212.png","hash":"135435d8b921c1f1bc4843355f88a6ced3901037","modified":1664257727453},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/215.png","hash":"c43d2eb06da33d356f8d519e7f9fd37a97e7b8be","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/head.jpg","hash":"ddb660a97661cfbad9958440311061203d102323","modified":1664257727455},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/call.jpg","hash":"045628c7e5cde14e50d10cc2db57c503cef8c932","modified":1664257727455},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/214.png","hash":"25b4e208a518e9993e293025faddd9239893eed3","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/213.png","hash":"8d83b0b6815b1a69bcd6d4da9ee287c1c2a13972","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/JavaScript.jpg","hash":"6933428537582f4ea97c7fe0460e13716dbc13d7","modified":1664257727456},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/219.png","hash":"14b60d99208719b8953c4630397495640c0d8f16","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/uniapp.jpg","hash":"6ea306a5ff9b0cccc3b0c23db8ff2a70bef6221c","modified":1664257727455},{"_id":"themes/hexo-theme-tangyuxian/source/images/head/vue.jpg","hash":"a054b7f6da951ead22c2e5454c5357151c3b62a2","modified":1664257727455},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/216.png","hash":"0011363a9816758f46d831d6353e58e4d19f1180","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/TypeScript.jpg","hash":"d1330ba7733b6b53993a435fedf1d56ea8d6d0bd","modified":1664257727456},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/218.png","hash":"4ae0ba0b3b6500c20645fe189036c2e2b35d6583","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/emoji/217.png","hash":"843311fc87f67bc6bd357c2439d70f25e3d0f5f2","modified":1664257727454},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/algorithm.jpg","hash":"a22350c34e87a2877c7ad797601add67d57ef1fd","modified":1664257727456},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/browser.jpg","hash":"112c9ac27e9c64900c7b015ebd881ec5c69ebc82","modified":1664257727456},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/css.jpg","hash":"8c2650dfb926e9ec19ae515da44cb5257ce09387","modified":1664257727457},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/elasticsearch.jpg","hash":"cb9a4c990bc4248fcb5d35e50b4825375e601e07","modified":1664348663008},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/beautify.jpg","hash":"2a07d7e9c70332e134c36f5b14e1f37505939756","modified":1664257727456},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/es6.jpg","hash":"2b3301404f555ca66fbba208970ecf18bd755566","modified":1664257727459},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/git.jpg","hash":"8b3ff9dd6d500ad2feaf899bb70380f9467a87cd","modified":1664257727459},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/internet.jpg","hash":"1460f2cb6908f4b0c7f3b48d75ebf8379056b222","modified":1664257727459},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/markerdown.jpg","hash":"632c5ca83b95c742be114c522c2dd779f9b296f5","modified":1664257727460},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/hexo.jpg","hash":"067ccbce47ebbbc9112dd67edb9a1b37f39b4edd","modified":1664345146596},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/nodejs.jpg","hash":"a6cedb5889544d26ebb0e9683b28ba52f6aab450","modified":1664257727460},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/data.jpg","hash":"c51b02dd57aa59357a4385bc4e0e7c7bef8c4c69","modified":1664257727457},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/development_tool.jpg","hash":"79304751390001a95d8eb9d014ff0050fe8b47c3","modified":1664257727458},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/docker.jpg","hash":"caebb3795b800df635bd89a77a335d5f466975ea","modified":1664257727458},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeBlockFuction.js","hash":"02c3310d91fb93ca9975dcca92caf41ee057fb63","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeCopy.js","hash":"668f50efb6870379bab0eaadfb3ebe5b3f5f9362","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeLang.js","hash":"e538722a763dba71af7176a507e89c6a9ff715ff","modified":1664257727464},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/codeShrink.js","hash":"709874a0a5c4eb639ea5fb755e8a2f90a01c6633","modified":1664257727465},{"_id":"themes/hexo-theme-tangyuxian/source/lib/codeBlock/matery.css","hash":"3faa03693272adcf27db326835b0bb7d340416ec","modified":1664257727465},{"_id":"themes/hexo-theme-tangyuxian/source/images/view/render_tree.png","hash":"86409dfcf8b9366bc973cae95a0a03446277e9fc","modified":1664257727463},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.css","hash":"63586544063643542bdbea6939bc3a418952e8d6","modified":1664257727466},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/demo.css","hash":"53456972a11d52af67187fc17999e6665f9f06fe","modified":1664257727466},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/webpack.jpg","hash":"ba36ac97f844f9d2b9df6239a5f7292b19030425","modified":1664257727462},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/vue.jpg","hash":"26ad5c5ad634347aac9d5bc85fcb217ed980bd4a","modified":1664257727462},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/wechat_applet.jpg","hash":"5760cc1715e5930339c6b7d14f5f20c69f2389ad","modified":1664257727463},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.eot","hash":"465966dac936ddff3e7313dea360f59c43fab804","modified":1664257727466},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.ttf","hash":"1b497f21aff9732f4e9f66881b028c3eb0e0763e","modified":1664257727468},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.woff","hash":"15f15f4b1219ba1bc08267f2e70d2cac5bb3d496","modified":1664257727468},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.woff2","hash":"d966e8fdd11265e4e7d84bbff903e89aa778bd18","modified":1664257727469},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/demo_index.html","hash":"83a1dd51b3edf9ce44354b57ce109de5a3d38a90","modified":1664257727466},{"_id":"themes/hexo-theme-tangyuxian/source/lib/fancybox/css/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1664257727465},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.json","hash":"a6045f33dfb7a4ade26c5ed8e9c952b785aed305","modified":1664257727467},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.js","hash":"bcd569bf13e40a6d49f55aa8f4e488ab89e1041a","modified":1664257727467},{"_id":"themes/hexo-theme-tangyuxian/source/lib/iconfont/iconfont.svg","hash":"d2e821043a7754603ff9aaed3b8cae934a15a4a0","modified":1664257727468},{"_id":"source/_posts/Lucene和ES的前世今生.md","hash":"1ccf265948d3fd4c6dd6164d03e3c79bae02d7fd","modified":1664348907188},{"_id":"source/_posts/about.md","hash":"44b33a962605b54e8dc788add30bd78a66ce199e","modified":1664270776324},{"_id":"source/CNAME","hash":"6cddd062af8766aa850b7636dc7da50936b2a56b","modified":1663928200825},{"_id":"source/_posts/JAVA核心知识点.md","hash":"ad509e22ee9825882b323909e4e19182085e9d9e","modified":1664354181412},{"_id":"source/_posts/archives.md","hash":"4966654514de102eb0c4e551be052a51cfcb83da","modified":1664258526476},{"_id":"source/_posts/hexo常用命令.md","hash":"4984704ce9a30d9186a183259e7c30f1820e8046","modified":1664345258922},{"_id":"source/_posts/分库分表之后的id主键如何处理.md","hash":"4a2dd1070dc998dc1ca9c0a9f64ca76fff39d521","modified":1664347946300},{"_id":"source/_posts/分库分表.md","hash":"33ac1b0bae8a57e5078bc7fb8b25fd2b83298f28","modified":1664347533402},{"_id":"source/_posts/可以动态扩容缩容的分库分表方案.md","hash":"f821dc2fc9450792e1a23168940d9359ecdfdae4","modified":1664347533421},{"_id":"source/_posts/Lucene和ES的前世今生/es-cluster-0.png","hash":"49c56c0ddb2d51c88b90f7d09b2c71517fbae823","modified":1663922463087},{"_id":"source/_posts/限流.md","hash":"df32be75ab3b00c17053310adad23003f8a9a6c7","modified":1664270031578},{"_id":"source/_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？.md","hash":"e72c125fbf4c5dc753ca54931bf8b808a5aa6c9d","modified":1664348505165},{"_id":"source/_posts/redis知识点整理/lru-cache.png","hash":"bb19432c0df3e7d9bb55d8712cf72f67df205094","modified":1663922463092},{"_id":"source/_posts/redis知识点整理.md","hash":"5a2e1a96ea439225b41a6b00ce9a4818c9135455","modified":1664357194485},{"_id":"source/_posts/redis知识点整理/lru.png","hash":"32a214c8166a70f35473b312feeb3ad3795b5cc7","modified":1663922463093},{"_id":"source/_posts/redis知识点整理/redis-caching-avalanche-solution.png","hash":"40a7dcfdd8f032d3063b54ddb98c68d921d21eaf","modified":1663922463098},{"_id":"source/_posts/redis知识点整理/async-replication-data-lose-case.png","hash":"23829a3ef283251aa9042e73717843a33d692105","modified":1663922463081},{"_id":"source/_posts/redis知识点整理/redis-master-slave-replication-detail.png","hash":"0d21d98d555a16e61b41411a686d48cd680fa1b2","modified":1663922463099},{"_id":"source/_posts/redis知识点整理/redis-master-slave.png","hash":"8411c6c19514e77f81efd1ba6ebf4a90345a508c","modified":1663922463100},{"_id":"source/_posts/redis知识点整理/redis-master-slave-replication.png","hash":"a99355e06d206c7e113e13ab14536991d2279219","modified":1663922463099},{"_id":"source/_posts/分库分表/database-split-horizon.png","hash":"99d3ae7d9589a99531fadd9fb478bb334c4c0641","modified":1663922463084},{"_id":"source/_posts/分库分表/database-split-vertically.png","hash":"3b806fa11b06445ba0a3603479d664ce9689c655","modified":1663922463084},{"_id":"source/_posts/分库分表之后的id主键如何处理/database-id-sequence-step.png","hash":"2c15829b2ad752d641226f2444b6f1ca13686708","modified":1663922463082},{"_id":"source/_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-1.png","hash":"6ac851f110875b5bc3b56815aa5ba617a0b57a36","modified":1663922463083},{"_id":"source/_posts/redis知识点整理/redis-caching-avalanche.png","hash":"3104a3ade8b0a852a0122ac18f89a4dd0aa42156","modified":1663922463098},{"_id":"source/_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-2.png","hash":"04e7714fbd44d91b08c5c428f74be0e0522f5086","modified":1663922463083},{"_id":"source/_posts/redis知识点整理/redis-caching-avoid-penetration.png","hash":"9f65a6a927656d20d00d2f9000f6bff913713b99","modified":1663922463098},{"_id":"source/_posts/redis知识点整理/redis-single-thread-model.png","hash":"99aa744eb5db308d0601c6e600c8a3c449b435a9","modified":1663922463100},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/database.jpg","hash":"5074ce5c61158bfb272d693f1a57f05687934a40","modified":1664345860711},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/java.jpg","hash":"2a0cbd5d80a679a400b66d2ede2d3a03e3f6e27e","modified":1664257727460},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/redis.png","hash":"39a8584dcff54d5573894971edf73d4077043ad5","modified":1664349487063},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/weifuwu.png","hash":"633864eea636cb58ff2d9a6e8046e707e766277c","modified":1664344996592},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/phantomjs.png","hash":"5dade79e59d099fe1b7e6ab40e294d40ecf9bc1e","modified":1664257727461},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/ui.jpg","hash":"caff3b70d12b1e66e4fabc399086467fc04340dd","modified":1664257727462},{"_id":"themes/hexo-theme-tangyuxian/source/lib/fancybox/js/jquery.fancybox.min.js","hash":"eef46b6fb2e460838cd7328a6e13ecda0cb1e194","modified":1664257727466},{"_id":"source/_posts/微服务技术栈.md","hash":"d39ddd10c7aa79b8c3c6e6010e4b973ba8bccaeb","modified":1664345558207},{"_id":"source/_posts/redis知识点整理/redis-caching-penetration.png","hash":"84d3860ce4ce59e842ac00f7d3a3741e4fdcd2ac","modified":1663922463098},{"_id":"source/_posts/redis知识点整理/redis-cluster-split-brain.png","hash":"e8482c1c48615713d5d1a64f871afe74904624bf","modified":1663922463098},{"_id":"source/_posts/阿里巴巴java开发手册-嵩山版.md","hash":"b8120e785dede07cf9d5875e024bc2e713948312","modified":1664331552015},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/xiaomai.jpg","hash":"382a4746f7fba1820f82da78f0dd02ce0a6b9627","modified":1664257727435},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/lihui.png","hash":"9fc8d5b24020428cdc492ddbe82d44e5a6abd9ee","modified":1664257727432},{"_id":"source/_posts/redis知识点整理/redis-junior-inconsistent.png","hash":"de10d689fcf6d56e97f23e1899102fbd0fd5576a","modified":1663922463099},{"_id":"themes/hexo-theme-tangyuxian/source/lib/mdui_043tiny/css/mdui.css","hash":"1500b5d27b8ce2e7c543bb6d7205de43059378db","modified":1664257727470},{"_id":"themes/hexo-theme-tangyuxian/source/lib/mdui_043tiny/js/mdui.js","hash":"1b3f4e4b7d1b944dd2a8ca09cc60614435195c67","modified":1664257727471},{"_id":"themes/hexo-theme-tangyuxian/source/images/post/editor.jpg","hash":"f988f11f5aee24e549551aff9912ae547cb1ab1e","modified":1664257727459},{"_id":"themes/hexo-theme-tangyuxian/source/images/background/background.png","hash":"26a72e8fad4f27d502e8b5016ebe94e3c9b51371","modified":1664257727430},{"_id":"source/_posts/JAVA核心知识点/JAVA核心知识点.pdf","hash":"39d26d01c4291289334f1c9f4e37be0048c7d855","modified":1664331651877},{"_id":"public/2022/09/28/redis知识点整理/index.html","hash":"109c3ae39c9593f7f4d22139d42bc067fcb32fbc","modified":1664415749288},{"_id":"public/2022/09/28/Lucene和ES的前世今生/index.html","hash":"491887d3f62def48531b1419b055a128035f4b66","modified":1664415749288},{"_id":"public/2022/09/28/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/index.html","hash":"09a9c02ce27a85e8f7c4b40b8b7bb7870aff255f","modified":1664415749288},{"_id":"public/2022/09/28/分库分表之后的id主键如何处理/index.html","hash":"c4b0c7c7aa0115539cdc35a3e18744165b140092","modified":1664415749288},{"_id":"public/2022/09/28/可以动态扩容缩容的分库分表方案/index.html","hash":"3e1d79134c6bd318c4e5ba60638cd7d7f591ddb7","modified":1664415749288},{"_id":"public/2022/09/28/分库分表/index.html","hash":"cc8ea310d11d1072b2ac57dd14796c7d97cce3eb","modified":1664415749288},{"_id":"public/2022/09/28/JAVA核心知识点/index.html","hash":"6079c0fcef5178972ffba31a0e117a214ac84dc1","modified":1664415749288},{"_id":"public/2022/09/28/微服务技术栈/index.html","hash":"87980535b672b034b7234728a180c1848f53c677","modified":1664415749288},{"_id":"public/about.html","hash":"319b2308eef08ff6413055d258472fe536cced02","modified":1664415749288},{"_id":"public/archives.html","hash":"8e5520dbea772aecd88c090c1d3e626993f95f99","modified":1664415749288},{"_id":"public/2022/09/28/阿里巴巴java开发手册-嵩山版/index.html","hash":"f88686603745119458d92e3ec687b2ac9b07512f","modified":1664415749288},{"_id":"public/2022/09/27/限流/index.html","hash":"cd4c59bcb4940ebddd7525c2727802c4bd8a5575","modified":1664415749288},{"_id":"public/2022/09/27/hexo常用命令/index.html","hash":"099894322d9be1076f31a718fbe59bdaad8f46e6","modified":1664415749288},{"_id":"public/categories/笔记/index.html","hash":"2d29f9dbf5c671cc287b4c3ffadde7da59e966e5","modified":1664415749288},{"_id":"public/archives/index.html","hash":"76eff28941748238e681c658b7d2a085d59e9c3d","modified":1664415749288},{"_id":"public/archives/page/2/index.html","hash":"3ec27212bc07eddd4a79c6072b4faf5373262908","modified":1664415749288},{"_id":"public/archives/2022/index.html","hash":"caef511584837c03b64c1edafcc87679c65f297d","modified":1664415749288},{"_id":"public/archives/2022/page/2/index.html","hash":"1549b995829ded01a591fe5ca4891705f75ae422","modified":1664415749288},{"_id":"public/index.html","hash":"4ae3c1de979e51026a3071b0b6f9c9719a8e35fe","modified":1664415749288},{"_id":"public/archives/2022/09/index.html","hash":"8c95dbef49058b1edcade5074443442de120569d","modified":1664415749288},{"_id":"public/archives/2022/09/page/2/index.html","hash":"b2e86e355ca576cc2ca1efa6b2e0da062bd863e7","modified":1664415749288},{"_id":"public/page/2/index.html","hash":"a3259d88ead0951b61564668e61a39a952e5601a","modified":1664415749288},{"_id":"public/tags/ElasticSearch/index.html","hash":"cf74652b31f3c615225173504363d0ca6e6c784a","modified":1664415749288},{"_id":"public/tags/java/index.html","hash":"95cd34a6f1a085d6419bb5945d06ac78477da59c","modified":1664415749288},{"_id":"public/tags/hexo/index.html","hash":"77865838c3543a633568120270f763583441b3b3","modified":1664415749288},{"_id":"public/tags/数据库/index.html","hash":"1bc6d6e23768a1d4bbc6d9d1eb760cb8c3766606","modified":1664415749288},{"_id":"public/tags/分库分表/index.html","hash":"133b767e44ac245d728ef9db9f340c039d5404f0","modified":1664415749288},{"_id":"public/tags/微服务/index.html","hash":"1138ba88c42a4f72ecdb195545955253b34ba083","modified":1664415749288},{"_id":"public/tags/redis/index.html","hash":"22142b8741bf816874555d686d4ec815ed675cc6","modified":1664415749288},{"_id":"public/tags/限流/index.html","hash":"f94c6880f75534e5f0099ffe932a7aad4b067216","modified":1664415749288},{"_id":"public/images/background/chichi.jpg","hash":"e364c38f02bf9c1b74110e4e7cb5915dfeefc89e","modified":1664361027271},{"_id":"public/images/background/cangshu.png","hash":"79566fdd8d4b29971f84bcf7678b1cd451827534","modified":1664361027271},{"_id":"public/images/background/cat.png","hash":"ccda3c9f0c85dfc457c723cf24e7868e72314c2a","modified":1664361027271},{"_id":"public/images/emoji/100.gif","hash":"08e13e2f9a57713cac0bb3570472601ad3b64cd4","modified":1664361027271},{"_id":"public/images/emoji/101.gif","hash":"a49210c9d99f5e1663a7b3ee1836c603866fe703","modified":1664361027271},{"_id":"public/images/background/papa.jpg","hash":"10d778fbed199c56e986e3d22ad80c18a06db5f2","modified":1664361027271},{"_id":"public/images/emoji/102.gif","hash":"b22c01184c47b80c25841ab3dd74525af506132b","modified":1664361027271},{"_id":"public/images/emoji/103.gif","hash":"5a67c38c03c501dd3cc762bd475a2f952a8eb967","modified":1664361027271},{"_id":"public/images/emoji/104.gif","hash":"ecb730525f4bbab66a2f7d1a0beb4c5a33024c4d","modified":1664361027271},{"_id":"public/images/emoji/107.gif","hash":"8f55b9a520a5daeeb874f18e3a0ff5e8e7a5b7bb","modified":1664361027271},{"_id":"public/images/emoji/105.gif","hash":"e70bca66a53a5d5a2633cd806c9e75968ac8df48","modified":1664361027271},{"_id":"public/images/emoji/108.gif","hash":"8f2e77f259f99cbf81b3ae8e6f5bad08d3c233e8","modified":1664361027271},{"_id":"public/images/emoji/106.gif","hash":"951441561cf6dc97d90db2e32db95d2ac81e0803","modified":1664361027271},{"_id":"public/images/emoji/109.gif","hash":"d26731f3ac47eef724940225fdc7cc4b32df0fc9","modified":1664361027271},{"_id":"public/images/emoji/111.gif","hash":"efd4e92387b3d2adaa6aafa539b64b94e384e751","modified":1664361027271},{"_id":"public/images/emoji/110.gif","hash":"b0011c024457e3fd56151ec6d7a083d9b60824f0","modified":1664361027271},{"_id":"public/images/emoji/112.gif","hash":"ead851113876e9ca8b34bb9e14ea795e231ad4c3","modified":1664361027271},{"_id":"public/images/emoji/113.gif","hash":"30f300ea0255b5e2d526e26c7b13cb2a9aca986a","modified":1664361027271},{"_id":"public/images/emoji/114.gif","hash":"38469b26c1e59718b5bc0d11fb770944ffdff6cc","modified":1664361027271},{"_id":"public/images/emoji/116.gif","hash":"fd48dd300d810035667999dd4471d1788fecb3ae","modified":1664361027271},{"_id":"public/images/emoji/115.gif","hash":"112ed4f86a19b83a89fb032bc9b0e045f0f501d2","modified":1664361027271},{"_id":"public/images/emoji/117.gif","hash":"f6528fe54ba1e8e9511ddf70689bcdc65bb3015b","modified":1664361027271},{"_id":"public/images/emoji/118.gif","hash":"eae431af35aaada000bac3bf1169c8522b305ee1","modified":1664361027271},{"_id":"public/images/emoji/119.gif","hash":"a896b477bd134ae30fb49c826841ce0a0ad0709a","modified":1664361027271},{"_id":"public/images/emoji/120.gif","hash":"be94dcfd79af6b2b0a1934bb3b3a0808134fe9d1","modified":1664361027271},{"_id":"public/images/emoji/122.gif","hash":"e3f7e0d4aa2cffd8b8d48ae25a5250501c4916c9","modified":1664361027271},{"_id":"public/images/emoji/121.gif","hash":"db18cc01ddaa4668ad1faffc9f5f62eb4452e325","modified":1664361027271},{"_id":"public/images/emoji/123.gif","hash":"ae6d19d7f175180b8311ab49fbe0a9ee27115713","modified":1664361027271},{"_id":"public/images/emoji/125.gif","hash":"3cca520648813a9223de9e7c40348739db1e2167","modified":1664361027271},{"_id":"public/images/emoji/124.gif","hash":"97e045b79958302955e00ceb2ca3eae29e558a87","modified":1664361027271},{"_id":"public/images/emoji/126.gif","hash":"11834b77f4b20383aeeda4e53c32834ad62b35e2","modified":1664361027271},{"_id":"public/images/emoji/128.gif","hash":"53baf1a3eaf8bee92c0376d35d7f504199d52fdb","modified":1664361027271},{"_id":"public/images/emoji/127.gif","hash":"2c24c9b755703a656af6983767d9c76e319b3054","modified":1664361027271},{"_id":"public/images/emoji/129.gif","hash":"aed1ac54764de1604f1e2f803af91c5400dd12c0","modified":1664361027271},{"_id":"public/images/emoji/130.gif","hash":"a53accded36281c55e3299c635e1f5c47093ead5","modified":1664361027271},{"_id":"public/images/emoji/132.gif","hash":"f77fe2749048668ca424b7a691e128c9353ed2d0","modified":1664361027271},{"_id":"public/images/emoji/131.gif","hash":"efc4648182d11ac7f77f5d0f6f5a9fdaac8c3d02","modified":1664361027271},{"_id":"public/images/emoji/133.gif","hash":"3004a4ca69e73e535fea208e42cbad2d37cbac30","modified":1664361027271},{"_id":"public/images/emoji/135.gif","hash":"114d709fb33e9bc1ff694e3974b9aa249e859e27","modified":1664361027271},{"_id":"public/images/emoji/134.gif","hash":"08c8dc4fd6f9018f7c9af1a90c671defe8bbeafd","modified":1664361027271},{"_id":"public/images/emoji/137.gif","hash":"55d89284defe7617b17813a65f1b65c12f509749","modified":1664361027271},{"_id":"public/images/emoji/139.gif","hash":"f1a8196f58a2e95c2fc376d65b3362e2f3b360e8","modified":1664361027271},{"_id":"public/images/emoji/138.gif","hash":"13cefa1d39ac3ebb77845d21ad817a20557182a0","modified":1664361027271},{"_id":"public/images/emoji/136.gif","hash":"f55bdf318dfff07a009f27802f2e6492d299a9d5","modified":1664361027271},{"_id":"public/images/emoji/140.gif","hash":"14694d0c7e7dd0a87cc83cef5e4064f956618544","modified":1664361027271},{"_id":"public/images/emoji/141.gif","hash":"9de2fa2aef63cf8e6096ad2c0c8ca19bf9bf1409","modified":1664361027271},{"_id":"public/images/emoji/142.gif","hash":"71c99c8d90fee2e92ab8ebd843d11c884e7a83b2","modified":1664361027271},{"_id":"public/images/emoji/143.gif","hash":"bb33a375ec6cf4b301a858316d991d690dc4694a","modified":1664361027271},{"_id":"public/images/emoji/145.gif","hash":"c29cb928fa3982042687a3f0d800f636b5dcce88","modified":1664361027271},{"_id":"public/images/emoji/146.gif","hash":"23ef2d150adb840a57e629a3b8d89a3cdb566b4c","modified":1664361027271},{"_id":"public/images/emoji/144.gif","hash":"8b487eae23ec61ae136ed82ba46347d9fdc740aa","modified":1664361027271},{"_id":"public/images/emoji/147.gif","hash":"776285d4af925fe51c9fa179c0c5f499e5bc1009","modified":1664361027271},{"_id":"public/images/emoji/148.gif","hash":"addae76a66cf12d64f6fe38bb6e83101cfc8cf5c","modified":1664361027271},{"_id":"public/images/emoji/149.gif","hash":"08230e3085ca3d657c27eee81048bd3049df0be1","modified":1664361027271},{"_id":"public/images/emoji/151.gif","hash":"e79d25fc8730714f7625aae411dda011c39e11ed","modified":1664361027271},{"_id":"public/images/emoji/152.gif","hash":"9e8e1a602549a5daa86a60cd2b932feda12cd856","modified":1664361027271},{"_id":"public/images/emoji/150.gif","hash":"c7a403b5e33b7c45501ef600ea91066e60e25619","modified":1664361027271},{"_id":"public/images/emoji/154.gif","hash":"e3180081f65ed3f2f02cd9910578f3864003feb9","modified":1664361027271},{"_id":"public/images/emoji/153.gif","hash":"505d8bb3f2b51cac729f8b6602bb1a1d329c8eff","modified":1664361027271},{"_id":"public/images/emoji/155.gif","hash":"54b4e482b857437e7d4168ae3dc42aeee0041b03","modified":1664361027271},{"_id":"public/images/emoji/156.gif","hash":"67e7ae5690c35528796678fae0307bc6cd8b7139","modified":1664361027271},{"_id":"public/images/emoji/157.gif","hash":"a942190d6ca4ed6707300f0df551a5e9a3559818","modified":1664361027271},{"_id":"public/images/emoji/158.gif","hash":"5acb07481f05bc084b8142d2c3149b497f3d9a43","modified":1664361027271},{"_id":"public/images/emoji/160.gif","hash":"2f62eb4c5f0756547e09bc259c41d8c0b69b8a4c","modified":1664361027271},{"_id":"public/images/emoji/159.gif","hash":"b2d4b7a39b901cf4c3ee263266d45220d2a8d023","modified":1664361027271},{"_id":"public/images/emoji/161.gif","hash":"04552d20fc832b0d4b4a0fe7d8ee9bfc2de493ab","modified":1664361027271},{"_id":"public/images/emoji/162.gif","hash":"4b7e2723c14404478bf590e5c10dff34fe95c126","modified":1664361027271},{"_id":"public/images/emoji/163.gif","hash":"a3cd050714583290f5aaa2b03a7821911ca7133f","modified":1664361027271},{"_id":"public/images/emoji/164.gif","hash":"f27481a27a18420f256911763e1bd2bc21bb6692","modified":1664361027271},{"_id":"public/images/emoji/165.gif","hash":"d89054c0aa501c23b0dc3b6cdd4d2a3465040d4c","modified":1664361027271},{"_id":"public/images/emoji/166.gif","hash":"af2fee57afe72d6e3162ab04dcd15ac96223b642","modified":1664361027271},{"_id":"public/images/emoji/167.gif","hash":"df1d3e8e957e3bfcc722fd2b04e6ea201bacdb5d","modified":1664361027271},{"_id":"public/images/emoji/168.gif","hash":"cbf5294928cbe64e547f299b066aa92fd879cdc7","modified":1664361027271},{"_id":"public/images/emoji/170.gif","hash":"0f7cf27e866ae6226967add3cb8e2c54e18044f3","modified":1664361027271},{"_id":"public/images/emoji/169.gif","hash":"65150b00b3f002d2a35e36b05108869e248945a4","modified":1664361027271},{"_id":"public/images/emoji/171.gif","hash":"78572a3d820aa5460f051a03d9c8171957c96044","modified":1664361027271},{"_id":"public/images/emoji/172.gif","hash":"f1db06ec39eed83eed6253037bfe49e3fb70eab3","modified":1664361027271},{"_id":"public/images/emoji/173.gif","hash":"530ed8b5671e78c91432ea2002cac85c9411795f","modified":1664361027271},{"_id":"public/images/emoji/174.gif","hash":"e8582ecde37573ca8a4c237fb6ee8d8c8309eb2b","modified":1664361027271},{"_id":"public/images/emoji/175.gif","hash":"d7e7f75f7a3e708e548f139240b7d1cf8b0b12e3","modified":1664361027271},{"_id":"public/images/emoji/176.gif","hash":"cd19cc59c65b97621d4d02387941858604709d36","modified":1664361027271},{"_id":"public/images/emoji/177.gif","hash":"32c95ad1721fc143df5e1795388d4f0b2ceab739","modified":1664361027271},{"_id":"public/images/emoji/178.gif","hash":"ab6f3d3e6cfd080af48f5acf02b0544634e5b8f9","modified":1664361027271},{"_id":"public/images/emoji/179.gif","hash":"e74435eb9ef411becedeaf17d380aa0c76c0ff0c","modified":1664361027271},{"_id":"public/images/emoji/180.gif","hash":"2c5247fe32b396b411a02853a3d8177c1acc501a","modified":1664361027271},{"_id":"public/images/emoji/181.gif","hash":"3555eae56a92a6d592e84b7b40b20da6d5cff8da","modified":1664361027271},{"_id":"public/images/emoji/182.gif","hash":"8dfc6421e5d68e9a12867d5c6605edff4b345124","modified":1664361027271},{"_id":"public/images/emoji/183.gif","hash":"a87911529020e62f399902e4290b8e4325378f93","modified":1664361027271},{"_id":"public/images/emoji/184.gif","hash":"1030d1242670e2f541a2c7ef0e94ae00f4401536","modified":1664361027271},{"_id":"public/images/emoji/185.gif","hash":"062280ba4b67e2053d625680578776ce2bd3e748","modified":1664361027271},{"_id":"public/images/emoji/186.gif","hash":"cafff6b96491d24e8c7f87d7bad0b4c8d6df7c2f","modified":1664361027271},{"_id":"public/images/emoji/187.gif","hash":"4265f098e55cfd4a075cb303b12442e02de40b28","modified":1664361027271},{"_id":"public/images/emoji/188.gif","hash":"48c34728a802c10da59c6ece07cf12e4e6fa2f2d","modified":1664361027271},{"_id":"public/images/emoji/190.gif","hash":"c112e7a0fd8a2ae0ea01442d13a21cb26aab78c6","modified":1664361027271},{"_id":"public/images/emoji/189.gif","hash":"707e3552c8b086dfcc627a2e8843405a5cddacec","modified":1664361027271},{"_id":"public/images/emoji/191.gif","hash":"d27dce702731088be15d440abf36e16790eda893","modified":1664361027271},{"_id":"public/images/emoji/192.gif","hash":"3a8fc60f3a8a9592fe4826b7ec01c11973b32818","modified":1664361027271},{"_id":"public/images/emoji/194.gif","hash":"d4fa1dfc51723eaaaa351e44afcd90e9f8ed2329","modified":1664361027271},{"_id":"public/images/emoji/193.gif","hash":"c4100e61798f46ce432488391fb850c0d85915d7","modified":1664361027271},{"_id":"public/images/emoji/196.gif","hash":"dd999e90afd8a1779b08923ed9a1aa4e725b6a43","modified":1664361027271},{"_id":"public/images/emoji/197.gif","hash":"6b4ddde064fd31f76f0f16bab4328fe337668391","modified":1664361027271},{"_id":"public/images/emoji/195.gif","hash":"d12ecb9031ec2747941054297d542fac3c263b86","modified":1664361027271},{"_id":"public/images/emoji/198.gif","hash":"9e20eb98f55781c4f260b078529d3c1b852c553f","modified":1664361027271},{"_id":"public/images/emoji/199.gif","hash":"c4aafef4b734516b0c6fd2d2f344ca383a04e7f3","modified":1664361027271},{"_id":"public/images/emoji/202.png","hash":"9ff2f7dd6c0da725007ede6befd2a3a36c3079c9","modified":1664361027271},{"_id":"public/images/emoji/201.png","hash":"2e4e9b89539588a65a80ca4d8a246e1a38cfdc34","modified":1664361027271},{"_id":"public/images/emoji/200.png","hash":"11e4c96f09209016c88d9c99c1c884db6abdd0d8","modified":1664361027271},{"_id":"public/images/emoji/204.png","hash":"39a4705bfae18f5e312997797869888bb4bc447a","modified":1664361027271},{"_id":"public/images/emoji/203.png","hash":"2aec6517e1b8203d3d4b2acddc8fb7b37c5bf64b","modified":1664361027271},{"_id":"public/images/emoji/206.png","hash":"a8e73d095313fe0372eca4e72e92961cf9022f07","modified":1664361027271},{"_id":"public/images/emoji/207.png","hash":"f48194a896768596845c77dcb1f78205b12c8b79","modified":1664361027271},{"_id":"public/images/emoji/208.png","hash":"8f5fd728b5a605a1eeb4c475ac7584e810513347","modified":1664361027271},{"_id":"public/images/emoji/205.png","hash":"b934b7a27869b7f37fffac441540104cba1c29d2","modified":1664361027271},{"_id":"public/images/emoji/209.png","hash":"367a93350236149c874138b920cbf2c0e6d29176","modified":1664361027271},{"_id":"public/images/emoji/210.png","hash":"510508062daaaf95a3e66d85b777911c59518f29","modified":1664361027271},{"_id":"public/images/emoji/214.png","hash":"25b4e208a518e9993e293025faddd9239893eed3","modified":1664361027271},{"_id":"public/images/emoji/212.png","hash":"135435d8b921c1f1bc4843355f88a6ced3901037","modified":1664361027271},{"_id":"public/images/emoji/211.png","hash":"cac7341d040a6b7c6747f14c53b630f76101d226","modified":1664361027271},{"_id":"public/images/emoji/213.png","hash":"8d83b0b6815b1a69bcd6d4da9ee287c1c2a13972","modified":1664361027271},{"_id":"public/images/emoji/215.png","hash":"c43d2eb06da33d356f8d519e7f9fd37a97e7b8be","modified":1664361027271},{"_id":"public/images/emoji/219.png","hash":"14b60d99208719b8953c4630397495640c0d8f16","modified":1664361027271},{"_id":"public/images/head/head.jpg","hash":"ddb660a97661cfbad9958440311061203d102323","modified":1664361027271},{"_id":"public/images/head/call.jpg","hash":"045628c7e5cde14e50d10cc2db57c503cef8c932","modified":1664361027271},{"_id":"public/images/head/uniapp.jpg","hash":"6ea306a5ff9b0cccc3b0c23db8ff2a70bef6221c","modified":1664361027271},{"_id":"public/images/head/vue.jpg","hash":"a054b7f6da951ead22c2e5454c5357151c3b62a2","modified":1664361027271},{"_id":"public/images/emoji/216.png","hash":"0011363a9816758f46d831d6353e58e4d19f1180","modified":1664361027271},{"_id":"public/images/post/JavaScript.jpg","hash":"6933428537582f4ea97c7fe0460e13716dbc13d7","modified":1664361027271},{"_id":"public/images/emoji/218.png","hash":"4ae0ba0b3b6500c20645fe189036c2e2b35d6583","modified":1664361027271},{"_id":"public/images/emoji/217.png","hash":"843311fc87f67bc6bd357c2439d70f25e3d0f5f2","modified":1664361027271},{"_id":"public/images/post/TypeScript.jpg","hash":"d1330ba7733b6b53993a435fedf1d56ea8d6d0bd","modified":1664361027271},{"_id":"public/images/post/algorithm.jpg","hash":"a22350c34e87a2877c7ad797601add67d57ef1fd","modified":1664361027271},{"_id":"public/images/post/beautify.jpg","hash":"2a07d7e9c70332e134c36f5b14e1f37505939756","modified":1664361027271},{"_id":"public/images/post/browser.jpg","hash":"112c9ac27e9c64900c7b015ebd881ec5c69ebc82","modified":1664361027271},{"_id":"public/images/post/css.jpg","hash":"8c2650dfb926e9ec19ae515da44cb5257ce09387","modified":1664361027271},{"_id":"public/images/post/es6.jpg","hash":"2b3301404f555ca66fbba208970ecf18bd755566","modified":1664361027271},{"_id":"public/images/post/elasticsearch.jpg","hash":"cb9a4c990bc4248fcb5d35e50b4825375e601e07","modified":1664361027271},{"_id":"public/images/post/hexo.jpg","hash":"067ccbce47ebbbc9112dd67edb9a1b37f39b4edd","modified":1664361027271},{"_id":"public/images/post/markerdown.jpg","hash":"632c5ca83b95c742be114c522c2dd779f9b296f5","modified":1664361027271},{"_id":"public/images/post/git.jpg","hash":"8b3ff9dd6d500ad2feaf899bb70380f9467a87cd","modified":1664361027271},{"_id":"public/images/post/internet.jpg","hash":"1460f2cb6908f4b0c7f3b48d75ebf8379056b222","modified":1664361027271},{"_id":"public/images/post/nodejs.jpg","hash":"a6cedb5889544d26ebb0e9683b28ba52f6aab450","modified":1664361027271},{"_id":"public/images/post/data.jpg","hash":"c51b02dd57aa59357a4385bc4e0e7c7bef8c4c69","modified":1664361027271},{"_id":"public/images/post/development_tool.jpg","hash":"79304751390001a95d8eb9d014ff0050fe8b47c3","modified":1664361027271},{"_id":"public/images/post/docker.jpg","hash":"caebb3795b800df635bd89a77a335d5f466975ea","modified":1664361027271},{"_id":"public/images/view/render_tree.png","hash":"86409dfcf8b9366bc973cae95a0a03446277e9fc","modified":1664361027271},{"_id":"public/images/post/webpack.jpg","hash":"ba36ac97f844f9d2b9df6239a5f7292b19030425","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.eot","hash":"465966dac936ddff3e7313dea360f59c43fab804","modified":1664361027271},{"_id":"public/images/post/wechat_applet.jpg","hash":"5760cc1715e5930339c6b7d14f5f20c69f2389ad","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.woff","hash":"15f15f4b1219ba1bc08267f2e70d2cac5bb3d496","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.ttf","hash":"1b497f21aff9732f4e9f66881b028c3eb0e0763e","modified":1664361027271},{"_id":"public/images/post/vue.jpg","hash":"26ad5c5ad634347aac9d5bc85fcb217ed980bd4a","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.svg","hash":"d2e821043a7754603ff9aaed3b8cae934a15a4a0","modified":1664361027271},{"_id":"public/CNAME","hash":"6cddd062af8766aa850b7636dc7da50936b2a56b","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.woff2","hash":"d966e8fdd11265e4e7d84bbff903e89aa778bd18","modified":1664361027271},{"_id":"public/2022/09/28/分库分表/database-split-horizon.png","hash":"99d3ae7d9589a99531fadd9fb478bb334c4c0641","modified":1664361027271},{"_id":"public/2022/09/28/Lucene和ES的前世今生/es-cluster-0.png","hash":"49c56c0ddb2d51c88b90f7d09b2c71517fbae823","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/async-replication-data-lose-case.png","hash":"23829a3ef283251aa9042e73717843a33d692105","modified":1664361027271},{"_id":"public/2022/09/28/分库分表/database-split-vertically.png","hash":"3b806fa11b06445ba0a3603479d664ce9689c655","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/lru-cache.png","hash":"bb19432c0df3e7d9bb55d8712cf72f67df205094","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-caching-avalanche-solution.png","hash":"40a7dcfdd8f032d3063b54ddb98c68d921d21eaf","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/lru.png","hash":"32a214c8166a70f35473b312feeb3ad3795b5cc7","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-caching-avalanche.png","hash":"3104a3ade8b0a852a0122ac18f89a4dd0aa42156","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-caching-avoid-penetration.png","hash":"9f65a6a927656d20d00d2f9000f6bff913713b99","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-caching-penetration.png","hash":"84d3860ce4ce59e842ac00f7d3a3741e4fdcd2ac","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-cluster-split-brain.png","hash":"e8482c1c48615713d5d1a64f871afe74904624bf","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-master-slave-replication-detail.png","hash":"0d21d98d555a16e61b41411a686d48cd680fa1b2","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-master-slave-replication.png","hash":"a99355e06d206c7e113e13ab14536991d2279219","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-junior-inconsistent.png","hash":"de10d689fcf6d56e97f23e1899102fbd0fd5576a","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-single-thread-model.png","hash":"99aa744eb5db308d0601c6e600c8a3c449b435a9","modified":1664361027271},{"_id":"public/2022/09/28/redis知识点整理/redis-master-slave.png","hash":"8411c6c19514e77f81efd1ba6ebf4a90345a508c","modified":1664361027271},{"_id":"public/2022/09/28/分库分表之后的id主键如何处理/database-id-sequence-step.png","hash":"2c15829b2ad752d641226f2444b6f1ca13686708","modified":1664361027271},{"_id":"public/2022/09/28/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-1.png","hash":"6ac851f110875b5bc3b56815aa5ba617a0b57a36","modified":1664361027271},{"_id":"public/2022/09/28/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-2.png","hash":"04e7714fbd44d91b08c5c428f74be0e0522f5086","modified":1664361027271},{"_id":"public/live2dw/assets/exp/f01.exp.json","hash":"84073a497ddb6e56c6cfc244a0fb217ba473abf9","modified":1664361027271},{"_id":"public/live2dw/assets/exp/f02.exp.json","hash":"241b6afafa2e25c6d7a54692a8b5aa060a137ab1","modified":1664361027271},{"_id":"public/live2dw/assets/exp/f03.exp.json","hash":"fbf7729e504f14f83f976827fcf62301a6579a34","modified":1664361027271},{"_id":"public/live2dw/assets/exp/f04.exp.json","hash":"35e746ede62e7090e7dfb08561d77772f58b4153","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/flickHead_00.mtn","hash":"f64c79c9171660db5c440bef229ac2e35a1597d5","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/flickHead_02.mtn","hash":"d3c9c0acb4dc25a2274f3b9faa71e5ce60ad92e4","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/flickHead_01.mtn","hash":"a1011d6bf397bcd3c3c968d9616f88fe1ffbc83c","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/idle_01.mtn","hash":"88c2494655dbb712b842f03232b619f381753d52","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/idle_00.mtn","hash":"378b4577217c604c9d28ab4edf8b707c8d8c2fbb","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchIn_01.mtn","hash":"a5fefb45115695db72b9499e627a51b2b9394f2c","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/idle_02.mtn","hash":"7f5d2cf8706007c8659938eba132a68c470a4c26","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchIn_00.mtn","hash":"70978b4c983f6a9fd6d3d9c24571586f7d6eac30","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchIn_02.mtn","hash":"aa0d66ca9b06c374577fd7e64e89756de1e1f2ae","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchOut_00.mtn","hash":"e07fe8fd8c2810e3c1d28b730bd49c8c25849bad","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchOut_02.mtn","hash":"b323fd350d334b33bbdfb31194ae664089986c27","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/pinchOut_01.mtn","hash":"e05df948d08b17f34c993a9c1f901190509d5db0","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/shake_00.mtn","hash":"5185d02c7ab9f0bec3d4a890b54b2378e553373d","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/shake_02.mtn","hash":"2702970805e07777974c383613e631730982bcff","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/shake_01.mtn","hash":"e812985a56796e122018f9d57d1606a4866ff7d1","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/tapBody_00.mtn","hash":"835aa3d4a8fbd26c0bb66b164a19464fa3f17a99","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/tapBody_01.mtn","hash":"78fca17436ab5e065e27f419f135aa6c0a0b52ef","modified":1664361027271},{"_id":"public/live2dw/assets/mtn/tapBody_02.mtn","hash":"a75acb51c1191ce5050d3ee1af6f2dcc787c7c5e","modified":1664361027271},{"_id":"public/live2dw/assets/shizuku.model.json","hash":"19a05bd41b806a935cea42c2000626fc82da2536","modified":1664361027271},{"_id":"public/live2dw/assets/shizuku.pose.json","hash":"ac5505efbf80ba0a2e5783d67fe232bc5c6f1f80","modified":1664361027271},{"_id":"public/live2dw/assets/shizuku.physics.json","hash":"6484d646e79a44c83784c6ae434cf7349746c5c8","modified":1664361027271},{"_id":"public/live2dw/assets/snd/flickHead_00.mp3","hash":"356388d939006b03cf9e6158c603b58d4800bec1","modified":1664361027271},{"_id":"public/live2dw/assets/snd/flickHead_01.mp3","hash":"436d0bbccf6e7a2744447554947eee4563608970","modified":1664361027271},{"_id":"public/live2dw/assets/snd/flickHead_02.mp3","hash":"5f63477ce63f2073e24d68fea906fe136fe6349e","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchIn_00.mp3","hash":"f9baa3b7cadec20b714135fc49cfab3ff6adeeb4","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchIn_01.mp3","hash":"d5c8cc6f61b56222a83a5174f75006f83c3b88da","modified":1664361027271},{"_id":"public/css/webapp.css","hash":"1abbf605a0074dad66830ef3bb70360840505020","modified":1664361027271},{"_id":"public/css/other.css","hash":"6dd626aae23c33700ad33de9be660be78c403214","modified":1664361027271},{"_id":"public/js/postcover.js","hash":"f390a3869b8d69545a920d71d8bb6d6ee3c372c2","modified":1664361027271},{"_id":"public/js/search.js","hash":"d95b9f04a7c11fb66fea422f137d7fe3188c5a5d","modified":1664361027271},{"_id":"public/js/webapp.js","hash":"2759b867dde5a506f92ebe2c4ae6a2f2fd8b31b8","modified":1664361027271},{"_id":"public/js/clock.js","hash":"6902df918c8e5211e875c56429201d564a87a1b8","modified":1664361027271},{"_id":"public/js/app.js","hash":"0886cef5b4decc17e21ac70fb8f1d56d61ef1d29","modified":1664361027271},{"_id":"public/css/style.css","hash":"d789696cd08dea923448f3712c09adb5ae2cbf84","modified":1664361027271},{"_id":"public/live2dw/assets/snd/shake_01.mp3","hash":"c1e0e8a07ff268ee06c2b7825d1b645e193f21b9","modified":1664361027271},{"_id":"public/live2dw/assets/snd/shake_00.mp3","hash":"f65dd58e7b44ec5c865d13c190316070b625b5fe","modified":1664361027271},{"_id":"public/live2dw/assets/snd/shake_02.mp3","hash":"8882b94bce00f09232588b7301badb105fa8acab","modified":1664361027271},{"_id":"public/live2dw/assets/snd/tapBody_00.mp3","hash":"003e68a59a9c8392e230f34c91860efbd946277a","modified":1664361027271},{"_id":"public/live2dw/assets/snd/tapBody_01.mp3","hash":"5314b50f153df71559e51e2586581c006df00722","modified":1664361027271},{"_id":"public/live2dw/assets/snd/tapBody_02.mp3","hash":"15e7815ed0a0e5164e18e0c53b97aedc742a134d","modified":1664361027271},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1664361027271},{"_id":"public/images/post/database.jpg","hash":"5074ce5c61158bfb272d693f1a57f05687934a40","modified":1664361027271},{"_id":"public/images/post/java.jpg","hash":"2a0cbd5d80a679a400b66d2ede2d3a03e3f6e27e","modified":1664361027271},{"_id":"public/images/post/phantomjs.png","hash":"5dade79e59d099fe1b7e6ab40e294d40ecf9bc1e","modified":1664361027271},{"_id":"public/images/post/redis.png","hash":"39a8584dcff54d5573894971edf73d4077043ad5","modified":1664361027271},{"_id":"public/images/post/ui.jpg","hash":"caff3b70d12b1e66e4fabc399086467fc04340dd","modified":1664361027271},{"_id":"public/images/post/weifuwu.png","hash":"633864eea636cb58ff2d9a6e8046e707e766277c","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_00.png","hash":"21bdb28b31783e23b26b3aa061e90be4088665aa","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_03.png","hash":"07f568a2bb8045b6bdff7783fb4daf62c821f9ab","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_05.png","hash":"0cd00007fb8bff62a2eb08e1d7c43abab8722224","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchIn_02.mp3","hash":"5b63e02607571ac601c500995e836e6c861b1c62","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchOut_00.mp3","hash":"0654f38f6e9fd623eaf8be11b5d58c9d12991949","modified":1664361027271},{"_id":"public/lib/codeBlock/codeBlockFuction.js","hash":"b48efab08a0856094ec67b56b91e8eb5075490f9","modified":1664361027271},{"_id":"public/lib/codeBlock/codeLang.js","hash":"fc584a7cf615eaa8a26f05b8efd6653225c748d7","modified":1664361027271},{"_id":"public/lib/codeBlock/codeCopy.js","hash":"e590db81151ce9f63e810338bf350ef571e5769f","modified":1664361027271},{"_id":"public/lib/codeBlock/codeShrink.js","hash":"6db05ce6baeee604ca5c68e0a731eb90153d6fef","modified":1664361027271},{"_id":"public/lib/codeBlock/matery.css","hash":"a001f7c96966924412c3d5bfed40487a18360979","modified":1664361027271},{"_id":"public/lib/iconfont/demo.css","hash":"65c50db528a5abe06426b1a20735feaf1f2a0d9b","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.css","hash":"f77481ef899d42d1f07d009332e92f58a8adcf95","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.json","hash":"03e829ff4d38d43953051e0639e5700629df3c5d","modified":1664361027271},{"_id":"public/lib/fancybox/css/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1664361027271},{"_id":"public/lib/iconfont/demo_index.html","hash":"77a7fde76271989fb498422f582f29d2ba61b90d","modified":1664361027271},{"_id":"public/lib/iconfont/iconfont.js","hash":"bcd569bf13e40a6d49f55aa8f4e488ab89e1041a","modified":1664361027271},{"_id":"public/lib/fancybox/js/jquery.fancybox.min.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1664361027271},{"_id":"public/lib/mdui_043tiny/css/mdui.css","hash":"b79ef94d2b11f8ce05ba048f5d74a3bd09f12e4d","modified":1664361027271},{"_id":"public/lib/mdui_043tiny/js/mdui.js","hash":"9feeebf8c11d8ce8549ec94896c630ba2334613c","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchOut_02.mp3","hash":"554edb2f3838cbdc27d1a9c6b8a9cb6eb465cbdd","modified":1664361027271},{"_id":"public/live2dw/assets/snd/pinchOut_01.mp3","hash":"8a081030fd53c07bffe3edd48f87a371ca77296b","modified":1664361027271},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1664361027271},{"_id":"public/images/background/xiaomai.jpg","hash":"382a4746f7fba1820f82da78f0dd02ce0a6b9627","modified":1664361027271},{"_id":"public/images/background/lihui.png","hash":"9fc8d5b24020428cdc492ddbe82d44e5a6abd9ee","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_01.png","hash":"3d0e745f3e560071ee08beeecde186e5ea35d99e","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_04.png","hash":"f764d594841905db8b2998dd61c329866125ad97","modified":1664361027271},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1664361027271},{"_id":"public/images/post/editor.jpg","hash":"f988f11f5aee24e549551aff9912ae547cb1ab1e","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.1024/texture_02.png","hash":"055eb2da9c13e9116be93a1e60c0ea2b660af864","modified":1664361027271},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1664361027271},{"_id":"public/live2dw/assets/moc/shizuku.moc","hash":"c2670a0f75830edc89d7fe6d074de4ee67e8dc5d","modified":1664361027271},{"_id":"public/images/background/background.png","hash":"26a72e8fad4f27d502e8b5016ebe94e3c9b51371","modified":1664361027271},{"_id":"public/2022/09/28/JAVA核心知识点/JAVA核心知识点.pdf","hash":"39d26d01c4291289334f1c9f4e37be0048c7d855","modified":1664361027271},{"_id":"themes/hexo-theme-tangyuxian/source/js/script.js","hash":"5b2650ac164dca0bb50049f95237b19378467069","modified":1664415392200},{"_id":"public/js/script.js","hash":"e489da62528406e015910e230d0f915bcf35599b","modified":1664415407087}],"Category":[{"name":"笔记","_id":"cl8lhl0kv0009ekwe6sjd1vea"}],"Data":[],"Page":[],"Post":[{"title":"Lucene和ES的前世今生","date":"2022-09-28T07:06:37.000Z","_content":"Lucene 和 ES 的前世今生\n<!--more-->\n## Lucene 和 ES 的前世今生\n\nLucene 是最先进、功能最强大的搜索库。如果直接基于 Lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。\n\nElasticSearch 基于 Lucene，隐藏了 lucene 的复杂性，提供了简单易用的 RESTful api / Java api 接口（另外还有其他语言的 api 接口）。\n\n- 分布式的文档存储引擎\n- 分布式的搜索引擎和分析引擎\n- 分布式，支持 PB 级数据\n\n## ES 的核心概念\n\n### Near Realtime\n\n近实时，有两层意思：\n\n- 从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）\n- 基于 ES 执行搜索和分析可以达到秒级\n\n### Cluster 集群\n\n集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。\n\n### Node 节点\n\nNode 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 `elasticsearch` 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。\n\n### Document & field\n\n文档是 ES 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。\n\n```json\n{\n  \"product_id\": \"1\",\n  \"product_name\": \"iPhone X\",\n  \"product_desc\": \"苹果手机\",\n  \"category_id\": \"2\",\n  \"category_name\": \"电子产品\"\n}\n```\n\n### Index\n\n索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 document。\n\n### Type\n\n类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。\n\n### shard\n\n单台机器无法存储大量数据，ES 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。\n\n### replica\n\n任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5 个 replica shard，最小的高可用配置，是 2 台服务器。\n\n这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。\n\n![Lucene和ES的前世今生](es-cluster-0.png)\n\n## ES 核心概念 vs. DB 核心概念\n\n| ES       | DB       |\n| -------- | -------- |\n| index    | 数据库   |\n| type     | 数据表   |\n| document | 一行数据 |\n\n以上是一个简单的类比。\n\n","source":"_posts/Lucene和ES的前世今生.md","raw":"---\ntitle: Lucene和ES的前世今生\ndate: 2022-09-28 15:06:37\ntags:\n- ElasticSearch\n---\nLucene 和 ES 的前世今生\n<!--more-->\n## Lucene 和 ES 的前世今生\n\nLucene 是最先进、功能最强大的搜索库。如果直接基于 Lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。\n\nElasticSearch 基于 Lucene，隐藏了 lucene 的复杂性，提供了简单易用的 RESTful api / Java api 接口（另外还有其他语言的 api 接口）。\n\n- 分布式的文档存储引擎\n- 分布式的搜索引擎和分析引擎\n- 分布式，支持 PB 级数据\n\n## ES 的核心概念\n\n### Near Realtime\n\n近实时，有两层意思：\n\n- 从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）\n- 基于 ES 执行搜索和分析可以达到秒级\n\n### Cluster 集群\n\n集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。\n\n### Node 节点\n\nNode 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 `elasticsearch` 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。\n\n### Document & field\n\n文档是 ES 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。\n\n```json\n{\n  \"product_id\": \"1\",\n  \"product_name\": \"iPhone X\",\n  \"product_desc\": \"苹果手机\",\n  \"category_id\": \"2\",\n  \"category_name\": \"电子产品\"\n}\n```\n\n### Index\n\n索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 document。\n\n### Type\n\n类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。\n\n### shard\n\n单台机器无法存储大量数据，ES 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。\n\n### replica\n\n任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5 个 replica shard，最小的高可用配置，是 2 台服务器。\n\n这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。\n\n![Lucene和ES的前世今生](es-cluster-0.png)\n\n## ES 核心概念 vs. DB 核心概念\n\n| ES       | DB       |\n| -------- | -------- |\n| index    | 数据库   |\n| type     | 数据表   |\n| document | 一行数据 |\n\n以上是一个简单的类比。\n\n","slug":"Lucene和ES的前世今生","published":1,"updated":"2022-09-28T07:08:27.188Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0k60000ekwe39nf24oh","content":"<p>Lucene 和 ES 的前世今生</p>\n<span id=\"more\"></span>\n<h2 id=\"Lucene-和-ES-的前世今生\"><a href=\"#Lucene-和-ES-的前世今生\" class=\"headerlink\" title=\"Lucene 和 ES 的前世今生\"></a>Lucene 和 ES 的前世今生</h2><p>Lucene 是最先进、功能最强大的搜索库。如果直接基于 Lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。</p>\n<p>ElasticSearch 基于 Lucene，隐藏了 lucene 的复杂性，提供了简单易用的 RESTful api / Java api 接口（另外还有其他语言的 api 接口）。</p>\n<ul>\n<li>分布式的文档存储引擎</li>\n<li>分布式的搜索引擎和分析引擎</li>\n<li>分布式，支持 PB 级数据</li>\n</ul>\n<h2 id=\"ES-的核心概念\"><a href=\"#ES-的核心概念\" class=\"headerlink\" title=\"ES 的核心概念\"></a>ES 的核心概念</h2><h3 id=\"Near-Realtime\"><a href=\"#Near-Realtime\" class=\"headerlink\" title=\"Near Realtime\"></a>Near Realtime</h3><p>近实时，有两层意思：</p>\n<ul>\n<li>从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）</li>\n<li>基于 ES 执行搜索和分析可以达到秒级</li>\n</ul>\n<h3 id=\"Cluster-集群\"><a href=\"#Cluster-集群\" class=\"headerlink\" title=\"Cluster 集群\"></a>Cluster 集群</h3><p>集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。</p>\n<h3 id=\"Node-节点\"><a href=\"#Node-节点\" class=\"headerlink\" title=\"Node 节点\"></a>Node 节点</h3><p>Node 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 <code>elasticsearch</code> 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。</p>\n<h3 id=\"Document-amp-field\"><a href=\"#Document-amp-field\" class=\"headerlink\" title=\"Document &amp; field\"></a>Document &amp; field</h3><p>文档是 ES 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。</p>\n<pre><code class=\"json\">&#123;\n  &quot;product_id&quot;: &quot;1&quot;,\n  &quot;product_name&quot;: &quot;iPhone X&quot;,\n  &quot;product_desc&quot;: &quot;苹果手机&quot;,\n  &quot;category_id&quot;: &quot;2&quot;,\n  &quot;category_name&quot;: &quot;电子产品&quot;\n&#125;\n</code></pre>\n<h3 id=\"Index\"><a href=\"#Index\" class=\"headerlink\" title=\"Index\"></a>Index</h3><p>索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 document。</p>\n<h3 id=\"Type\"><a href=\"#Type\" class=\"headerlink\" title=\"Type\"></a>Type</h3><p>类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。</p>\n<h3 id=\"shard\"><a href=\"#shard\" class=\"headerlink\" title=\"shard\"></a>shard</h3><p>单台机器无法存储大量数据，ES 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。</p>\n<h3 id=\"replica\"><a href=\"#replica\" class=\"headerlink\" title=\"replica\"></a>replica</h3><p>任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5 个 replica shard，最小的高可用配置，是 2 台服务器。</p>\n<p>这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。</p>\n<p><img src=\"es-cluster-0.png\" alt=\"Lucene和ES的前世今生\"></p>\n<h2 id=\"ES-核心概念-vs-DB-核心概念\"><a href=\"#ES-核心概念-vs-DB-核心概念\" class=\"headerlink\" title=\"ES 核心概念 vs. DB 核心概念\"></a>ES 核心概念 vs. DB 核心概念</h2><table>\n<thead>\n<tr>\n<th>ES</th>\n<th>DB</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>index</td>\n<td>数据库</td>\n</tr>\n<tr>\n<td>type</td>\n<td>数据表</td>\n</tr>\n<tr>\n<td>document</td>\n<td>一行数据</td>\n</tr>\n</tbody></table>\n<p>以上是一个简单的类比。</p>\n","site":{"data":{}},"excerpt":"<p>Lucene 和 ES 的前世今生</p>","more":"<h2 id=\"Lucene-和-ES-的前世今生\"><a href=\"#Lucene-和-ES-的前世今生\" class=\"headerlink\" title=\"Lucene 和 ES 的前世今生\"></a>Lucene 和 ES 的前世今生</h2><p>Lucene 是最先进、功能最强大的搜索库。如果直接基于 Lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。</p>\n<p>ElasticSearch 基于 Lucene，隐藏了 lucene 的复杂性，提供了简单易用的 RESTful api / Java api 接口（另外还有其他语言的 api 接口）。</p>\n<ul>\n<li>分布式的文档存储引擎</li>\n<li>分布式的搜索引擎和分析引擎</li>\n<li>分布式，支持 PB 级数据</li>\n</ul>\n<h2 id=\"ES-的核心概念\"><a href=\"#ES-的核心概念\" class=\"headerlink\" title=\"ES 的核心概念\"></a>ES 的核心概念</h2><h3 id=\"Near-Realtime\"><a href=\"#Near-Realtime\" class=\"headerlink\" title=\"Near Realtime\"></a>Near Realtime</h3><p>近实时，有两层意思：</p>\n<ul>\n<li>从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）</li>\n<li>基于 ES 执行搜索和分析可以达到秒级</li>\n</ul>\n<h3 id=\"Cluster-集群\"><a href=\"#Cluster-集群\" class=\"headerlink\" title=\"Cluster 集群\"></a>Cluster 集群</h3><p>集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。</p>\n<h3 id=\"Node-节点\"><a href=\"#Node-节点\" class=\"headerlink\" title=\"Node 节点\"></a>Node 节点</h3><p>Node 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 <code>elasticsearch</code> 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。</p>\n<h3 id=\"Document-amp-field\"><a href=\"#Document-amp-field\" class=\"headerlink\" title=\"Document &amp; field\"></a>Document &amp; field</h3><p>文档是 ES 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。</p>\n<pre><code class=\"json\">&#123;\n  &quot;product_id&quot;: &quot;1&quot;,\n  &quot;product_name&quot;: &quot;iPhone X&quot;,\n  &quot;product_desc&quot;: &quot;苹果手机&quot;,\n  &quot;category_id&quot;: &quot;2&quot;,\n  &quot;category_name&quot;: &quot;电子产品&quot;\n&#125;\n</code></pre>\n<h3 id=\"Index\"><a href=\"#Index\" class=\"headerlink\" title=\"Index\"></a>Index</h3><p>索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 document。</p>\n<h3 id=\"Type\"><a href=\"#Type\" class=\"headerlink\" title=\"Type\"></a>Type</h3><p>类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。</p>\n<h3 id=\"shard\"><a href=\"#shard\" class=\"headerlink\" title=\"shard\"></a>shard</h3><p>单台机器无法存储大量数据，ES 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。</p>\n<h3 id=\"replica\"><a href=\"#replica\" class=\"headerlink\" title=\"replica\"></a>replica</h3><p>任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5 个 replica shard，最小的高可用配置，是 2 台服务器。</p>\n<p>这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。</p>\n<p><img src=\"es-cluster-0.png\" alt=\"Lucene和ES的前世今生\"></p>\n<h2 id=\"ES-核心概念-vs-DB-核心概念\"><a href=\"#ES-核心概念-vs-DB-核心概念\" class=\"headerlink\" title=\"ES 核心概念 vs. DB 核心概念\"></a>ES 核心概念 vs. DB 核心概念</h2><table>\n<thead>\n<tr>\n<th>ES</th>\n<th>DB</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>index</td>\n<td>数据库</td>\n</tr>\n<tr>\n<td>type</td>\n<td>数据表</td>\n</tr>\n<tr>\n<td>document</td>\n<td>一行数据</td>\n</tr>\n</tbody></table>\n<p>以上是一个简单的类比。</p>"},{"title":"JAVA核心知识点","date":"2022-09-28T03:16:38.000Z","_content":"JAVA核心知识点整理<!--more-->\n{% pdf  JAVA核心知识点.pdf %}","source":"_posts/JAVA核心知识点.md","raw":"---\ntitle: JAVA核心知识点\ndate: 2022-09-28 11:16:38\ntags: java\n---\nJAVA核心知识点整理<!--more-->\n{% pdf  JAVA核心知识点.pdf %}","slug":"JAVA核心知识点","published":1,"updated":"2022-09-28T08:36:21.412Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0kq0001ekweabkl0bvx","content":"<p>JAVA核心知识点整理<span id=\"more\"></span></p>\n\n\n\t<div class=\"row\">\n    <embed src=\"JAVA核心知识点.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>\n\n\n","site":{"data":{}},"excerpt":"<p>JAVA核心知识点整理","more":"</p>\n\n\n\t<div class=\"row\">\n    <embed src=\"JAVA核心知识点.pdf\" width=\"100%\" height=\"550\" type=\"application/pdf\">\n\t</div>"},{"title":"文章归档","layout":"archives","_content":"","source":"_posts/archives.md","raw":"---\ntitle: 文章归档\nlayout: archives\npermalink: archives.html\n---","slug":"archives","published":1,"date":"2022-09-27T06:01:59.118Z","updated":"2022-09-27T06:02:06.476Z","__permalink":"archives.html","comments":1,"photos":[],"link":"","_id":"cl8lhl0ks0003ekwe9s7o2ake","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"关于","layout":"about","_content":"博主是一名奋斗在职场的小码农,后端研发,建立个人网站的初衷是希望拥有一个能够有一个随时展示自己,同时记录各种技术文章<!--more-->,总结工作学习内容和分享个人经历的个人小笔记;网站主内容覆盖关于前端,后端,服务器相关技术文章,同时也会更新发布一些个人兴趣爱好的文章\n","source":"_posts/about.md","raw":"---\ntitle: 关于\nlayout: about\npermalink: about.html\n---\n博主是一名奋斗在职场的小码农,后端研发,建立个人网站的初衷是希望拥有一个能够有一个随时展示自己,同时记录各种技术文章<!--more-->,总结工作学习内容和分享个人经历的个人小笔记;网站主内容覆盖关于前端,后端,服务器相关技术文章,同时也会更新发布一些个人兴趣爱好的文章\n","slug":"about","published":1,"date":"2022-09-27T06:47:45.884Z","updated":"2022-09-27T09:26:16.324Z","__permalink":"about.html","comments":1,"photos":[],"link":"","_id":"cl8lhl0ks0004ekwef3f9944p","content":"<p>博主是一名奋斗在职场的小码农,后端研发,建立个人网站的初衷是希望拥有一个能够有一个随时展示自己,同时记录各种技术文章<span id=\"more\"></span>,总结工作学习内容和分享个人经历的个人小笔记;网站主内容覆盖关于前端,后端,服务器相关技术文章,同时也会更新发布一些个人兴趣爱好的文章</p>\n","site":{"data":{}},"excerpt":"<p>博主是一名奋斗在职场的小码农,后端研发,建立个人网站的初衷是希望拥有一个能够有一个随时展示自己,同时记录各种技术文章","more":",总结工作学习内容和分享个人经历的个人小笔记;网站主内容覆盖关于前端,后端,服务器相关技术文章,同时也会更新发布一些个人兴趣爱好的文章</p>"},{"title":"hexo常用命令","date":"2022-09-26T16:00:00.000Z","_content":"hexo常用命令\n<!--more-->\n1 hexo n #写文章\n2 hexo g #生成\n3 hexo d #部署 #可与hexo g合并为 hexo d -g","source":"_posts/hexo常用命令.md","raw":"---\ntitle: hexo常用命令\ndate: 2022-09-27\ntags:\n- hexo\ncategories:\n- 笔记\n# cover: /images/post/markerdown.jpg\n# coverWidth: 1200\n# coverHeight: 320\n# author: 王恺\n# from: 笔记\n---\nhexo常用命令\n<!--more-->\n1 hexo n #写文章\n2 hexo g #生成\n3 hexo d #部署 #可与hexo g合并为 hexo d -g","slug":"hexo常用命令","published":1,"updated":"2022-09-28T06:07:38.922Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0kt0005ekweci6f6tye","content":"<p>hexo常用命令</p>\n<span id=\"more\"></span>\n<p>1 hexo n #写文章<br>2 hexo g #生成<br>3 hexo d #部署 #可与hexo g合并为 hexo d -g</p>\n","site":{"data":{}},"excerpt":"<p>hexo常用命令</p>","more":"<p>1 hexo n #写文章<br>2 hexo g #生成<br>3 hexo d #部署 #可与hexo g合并为 hexo d -g</p>"},{"title":"分库分表","date":"2022-09-28T06:16:21.000Z","_content":"\n为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\n<!--more-->\n\n### 为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\n\n说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。\n\n我先给大家抛出来一个场景。\n\n假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。\n\n结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！\n\n好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢......\n\n再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。\n\n但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 `5000~8000` ！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！\n\n好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。\n\n#### 分表\n\n比如你单表都几千万数据了，你确定你能扛住么？绝对不行，**单表数据量太大**，会极大影响你的 sql **执行的性能**，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。\n\n分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。\n\n#### 分库\n\n分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。\n\n这就是所谓的**分库分表**，为啥要分库分表？你明白了吧。\n\n| #            | 分库分表前                   | 分库分表后                                   |\n| ------------ | ---------------------------- | -------------------------------------------- |\n| 并发支撑情况 | MySQL 单机部署，扛不住高并发 | MySQL 从单机到多机，能承受的并发增加了多倍   |\n| 磁盘使用情况 | MySQL 单机磁盘容量几乎撑满   | 拆分为多个库，数据库服务器磁盘使用率大大降低 |\n| SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升         |\n\n### 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\n\n这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。\n\n比较常见的包括：\n\n- Cobar\n- TDDL\n- Atlas\n- Sharding-jdbc\n- Mycat\n\n#### Cobar\n\n阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。\n\n#### TDDL\n\n淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。\n\n#### Atlas\n\n360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。\n\n#### Sharding-jdbc\n\n当当开源的，属于 client 层方案，是[ `ShardingSphere` ](https://shardingsphere.apache.org)的 client 层方案，[ `ShardingSphere` ](https://shardingsphere.apache.org)还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1` 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。\n\n#### Mycat\n\n基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。\n\n#### 总结\n\n综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。\n\nSharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；\n\nMycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。\n\n通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。\n\n### 你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\n\n**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。\n\n![分库分表](database-split-horizon.png)\n\n**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。\n\n![分库分表](database-split-vertically.png)\n\n这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。\n\n还有**表层面的拆分**，就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的 SQL 越复杂，就最好让单表行数越少。\n\n好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，**中间件可以根据你指定的某个字段值**，比如说 userid，**自动路由到对应的库上去，然后再自动路由到对应的表里去**。\n\n你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。\n\n而且这儿还有两种**分库分表的方式**：\n\n- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。\n- 或者是按照某个字段 hash 一下均匀分散，这个较为常用。\n\nrange 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。\n\nhash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。\n\n","source":"_posts/分库分表.md","raw":"---\ntitle: 分库分表\ndate: 2022-09-28 14:16:21\ntags: \n- 数据库\n- 分库分表\n---\n\n为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\n<!--more-->\n\n### 为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\n\n说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。\n\n我先给大家抛出来一个场景。\n\n假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。\n\n结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！\n\n好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢......\n\n再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。\n\n但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 `5000~8000` ！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！\n\n好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。\n\n#### 分表\n\n比如你单表都几千万数据了，你确定你能扛住么？绝对不行，**单表数据量太大**，会极大影响你的 sql **执行的性能**，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。\n\n分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。\n\n#### 分库\n\n分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。\n\n这就是所谓的**分库分表**，为啥要分库分表？你明白了吧。\n\n| #            | 分库分表前                   | 分库分表后                                   |\n| ------------ | ---------------------------- | -------------------------------------------- |\n| 并发支撑情况 | MySQL 单机部署，扛不住高并发 | MySQL 从单机到多机，能承受的并发增加了多倍   |\n| 磁盘使用情况 | MySQL 单机磁盘容量几乎撑满   | 拆分为多个库，数据库服务器磁盘使用率大大降低 |\n| SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升         |\n\n### 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\n\n这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。\n\n比较常见的包括：\n\n- Cobar\n- TDDL\n- Atlas\n- Sharding-jdbc\n- Mycat\n\n#### Cobar\n\n阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。\n\n#### TDDL\n\n淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。\n\n#### Atlas\n\n360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。\n\n#### Sharding-jdbc\n\n当当开源的，属于 client 层方案，是[ `ShardingSphere` ](https://shardingsphere.apache.org)的 client 层方案，[ `ShardingSphere` ](https://shardingsphere.apache.org)还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1` 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。\n\n#### Mycat\n\n基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。\n\n#### 总结\n\n综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。\n\nSharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；\n\nMycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。\n\n通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。\n\n### 你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\n\n**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。\n\n![分库分表](database-split-horizon.png)\n\n**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。\n\n![分库分表](database-split-vertically.png)\n\n这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。\n\n还有**表层面的拆分**，就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的 SQL 越复杂，就最好让单表行数越少。\n\n好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，**中间件可以根据你指定的某个字段值**，比如说 userid，**自动路由到对应的库上去，然后再自动路由到对应的表里去**。\n\n你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。\n\n而且这儿还有两种**分库分表的方式**：\n\n- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。\n- 或者是按照某个字段 hash 一下均匀分散，这个较为常用。\n\nrange 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。\n\nhash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。\n\n","slug":"分库分表","published":1,"updated":"2022-09-28T06:45:33.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0ku0008ekwe5d620dp3","content":"<p>为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</p>\n<span id=\"more\"></span>\n\n<h3 id=\"为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\"><a href=\"#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\" class=\"headerlink\" title=\"为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\"></a>为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</h3><p>说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。</p>\n<p>我先给大家抛出来一个场景。</p>\n<p>假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。</p>\n<p>结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！</p>\n<p>好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢……</p>\n<p>再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。</p>\n<p>但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 <code>5000~8000</code> ！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！</p>\n<p>好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。</p>\n<h4 id=\"分表\"><a href=\"#分表\" class=\"headerlink\" title=\"分表\"></a>分表</h4><p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，<strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p>\n<p>分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p>\n<h4 id=\"分库\"><a href=\"#分库\" class=\"headerlink\" title=\"分库\"></a>分库</h4><p>分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p>\n<p>这就是所谓的<strong>分库分表</strong>，为啥要分库分表？你明白了吧。</p>\n<table>\n<thead>\n<tr>\n<th>#</th>\n<th>分库分表前</th>\n<th>分库分表后</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>并发支撑情况</td>\n<td>MySQL 单机部署，扛不住高并发</td>\n<td>MySQL 从单机到多机，能承受的并发增加了多倍</td>\n</tr>\n<tr>\n<td>磁盘使用情况</td>\n<td>MySQL 单机磁盘容量几乎撑满</td>\n<td>拆分为多个库，数据库服务器磁盘使用率大大降低</td>\n</tr>\n<tr>\n<td>SQL 执行性能</td>\n<td>单表数据量太大，SQL 越跑越慢</td>\n<td>单表数据量减少，SQL 执行效率明显提升</td>\n</tr>\n</tbody></table>\n<h3 id=\"用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\"><a href=\"#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\" class=\"headerlink\" title=\"用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\"></a>用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h3><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p>\n<p>比较常见的包括：</p>\n<ul>\n<li>Cobar</li>\n<li>TDDL</li>\n<li>Atlas</li>\n<li>Sharding-jdbc</li>\n<li>Mycat</li>\n</ul>\n<h4 id=\"Cobar\"><a href=\"#Cobar\" class=\"headerlink\" title=\"Cobar\"></a>Cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p>\n<h4 id=\"TDDL\"><a href=\"#TDDL\" class=\"headerlink\" title=\"TDDL\"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p>\n<h4 id=\"Atlas\"><a href=\"#Atlas\" class=\"headerlink\" title=\"Atlas\"></a>Atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p>\n<h4 id=\"Sharding-jdbc\"><a href=\"#Sharding-jdbc\" class=\"headerlink\" title=\"Sharding-jdbc\"></a>Sharding-jdbc</h4><p>当当开源的，属于 client 层方案，是<a href=\"https://shardingsphere.apache.org/\"> <code>ShardingSphere</code> </a>的 client 层方案，<a href=\"https://shardingsphere.apache.org/\"> <code>ShardingSphere</code> </a>还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 <code>4.0.0-RC1</code> 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p>\n<h4 id=\"Mycat\"><a href=\"#Mycat\" class=\"headerlink\" title=\"Mycat\"></a>Mycat</h4><p>基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。</p>\n<p>Sharding-jdbc 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖；</p>\n<p>Mycat 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</p>\n<p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。</p>\n<h3 id=\"你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\"><a href=\"#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\" class=\"headerlink\" title=\"你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\"></a>你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</h3><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</p>\n<p><img src=\"database-split-horizon.png\" alt=\"分库分表\"></p>\n<p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p>\n<p><img src=\"database-split-vertically.png\" alt=\"分库分表\"></p>\n<p>这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。</p>\n<p>还有<strong>表层面的拆分</strong>，就是分表，将一个表变成 N 个表，就是<strong>让每个表的数据量控制在一定范围内</strong>，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的 SQL 越复杂，就最好让单表行数越少。</p>\n<p>好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，<strong>中间件可以根据你指定的某个字段值</strong>，比如说 userid，<strong>自动路由到对应的库上去，然后再自动路由到对应的表里去</strong>。</p>\n<p>你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。</p>\n<p>而且这儿还有两种<strong>分库分表的方式</strong>：</p>\n<ul>\n<li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li>\n<li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。</li>\n</ul>\n<p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p>\n<p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</p>\n","site":{"data":{}},"excerpt":"<p>为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</p>","more":"<h3 id=\"为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\"><a href=\"#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\" class=\"headerlink\" title=\"为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）\"></a>为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</h3><p>说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。</p>\n<p>我先给大家抛出来一个场景。</p>\n<p>假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。</p>\n<p>结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！</p>\n<p>好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢……</p>\n<p>再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。</p>\n<p>但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 <code>5000~8000</code> ！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！</p>\n<p>好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。</p>\n<h4 id=\"分表\"><a href=\"#分表\" class=\"headerlink\" title=\"分表\"></a>分表</h4><p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，<strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p>\n<p>分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p>\n<h4 id=\"分库\"><a href=\"#分库\" class=\"headerlink\" title=\"分库\"></a>分库</h4><p>分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p>\n<p>这就是所谓的<strong>分库分表</strong>，为啥要分库分表？你明白了吧。</p>\n<table>\n<thead>\n<tr>\n<th>#</th>\n<th>分库分表前</th>\n<th>分库分表后</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>并发支撑情况</td>\n<td>MySQL 单机部署，扛不住高并发</td>\n<td>MySQL 从单机到多机，能承受的并发增加了多倍</td>\n</tr>\n<tr>\n<td>磁盘使用情况</td>\n<td>MySQL 单机磁盘容量几乎撑满</td>\n<td>拆分为多个库，数据库服务器磁盘使用率大大降低</td>\n</tr>\n<tr>\n<td>SQL 执行性能</td>\n<td>单表数据量太大，SQL 越跑越慢</td>\n<td>单表数据量减少，SQL 执行效率明显提升</td>\n</tr>\n</tbody></table>\n<h3 id=\"用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\"><a href=\"#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\" class=\"headerlink\" title=\"用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？\"></a>用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h3><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p>\n<p>比较常见的包括：</p>\n<ul>\n<li>Cobar</li>\n<li>TDDL</li>\n<li>Atlas</li>\n<li>Sharding-jdbc</li>\n<li>Mycat</li>\n</ul>\n<h4 id=\"Cobar\"><a href=\"#Cobar\" class=\"headerlink\" title=\"Cobar\"></a>Cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p>\n<h4 id=\"TDDL\"><a href=\"#TDDL\" class=\"headerlink\" title=\"TDDL\"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p>\n<h4 id=\"Atlas\"><a href=\"#Atlas\" class=\"headerlink\" title=\"Atlas\"></a>Atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p>\n<h4 id=\"Sharding-jdbc\"><a href=\"#Sharding-jdbc\" class=\"headerlink\" title=\"Sharding-jdbc\"></a>Sharding-jdbc</h4><p>当当开源的，属于 client 层方案，是<a href=\"https://shardingsphere.apache.org/\"> <code>ShardingSphere</code> </a>的 client 层方案，<a href=\"https://shardingsphere.apache.org/\"> <code>ShardingSphere</code> </a>还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 <code>4.0.0-RC1</code> 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p>\n<h4 id=\"Mycat\"><a href=\"#Mycat\" class=\"headerlink\" title=\"Mycat\"></a>Mycat</h4><p>基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。</p>\n<p>Sharding-jdbc 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖；</p>\n<p>Mycat 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</p>\n<p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。</p>\n<h3 id=\"你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\"><a href=\"#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\" class=\"headerlink\" title=\"你们具体是如何对数据库如何进行垂直拆分或水平拆分的？\"></a>你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</h3><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</p>\n<p><img src=\"database-split-horizon.png\" alt=\"分库分表\"></p>\n<p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p>\n<p><img src=\"database-split-vertically.png\" alt=\"分库分表\"></p>\n<p>这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。</p>\n<p>还有<strong>表层面的拆分</strong>，就是分表，将一个表变成 N 个表，就是<strong>让每个表的数据量控制在一定范围内</strong>，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的 SQL 越复杂，就最好让单表行数越少。</p>\n<p>好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，<strong>中间件可以根据你指定的某个字段值</strong>，比如说 userid，<strong>自动路由到对应的库上去，然后再自动路由到对应的表里去</strong>。</p>\n<p>你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。</p>\n<p>而且这儿还有两种<strong>分库分表的方式</strong>：</p>\n<ul>\n<li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li>\n<li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。</li>\n</ul>\n<p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p>\n<p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</p>"},{"title":"微服务技术栈","date":"2022-09-27T16:00:00.000Z","_content":"微服务技术栈<!--more-->\n# 微服务技术栈\n\n## 技术栈\n\n### 微服务开发\n\n作用：快速开发服务。\n\n- Spring\n- Spring MVC\n- Spring Boot\n\n[Spring](https://spring.io/) 目前是 JavaWeb 开发人员必不可少的一个框架，SpringBoot 简化了 Spring 开发的配置目前也是业内主流开发框架。\n\n### 微服务注册发现\n\n作用：发现服务，注册服务，集中管理服务。\n\n#### Eureka\n\n- Eureka Server : 提供服务注册服务, 各个节点启动后，会在 Eureka Server 中进行注册。\n- Eureka Client : 简化与 Eureka Server 的交互操作。\n- Spring Cloud Netflix : [GitHub](https://github.com/spring-cloud/spring-cloud-netflix)，[文档](https://cloud.spring.io/spring-cloud-netflix/reference/html/)\n\n#### Zookeeper\n\n> ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.\n\n[Zookeeper](https://github.com/apache/zookeeper) 是一个集中的服务, 用于维护配置信息、命名、提供分布式同步和提供组服务。\n\n#### Zookeeper 和 Eureka 区别\n\nZookeeper 保证 CP，Eureka 保证 AP：\n\n- C：数据一致性；\n- A：服务可用性；\n- P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。\n\n#### nacos\n\n\n### 微服务配置管理\n\n作用：统一管理一个或多个服务的配置信息, 集中管理。\n\n#### [Disconf](https://github.com/knightliao/disconf)\n\nDistributed Configuration Management Platform(分布式配置管理平台) , 它是专注于各种分布式系统配置管理 的通用组件/通用平台, 提供统一的配置管理服务, 是一套完整的基于 zookeeper 的分布式配置统一解决方案。\n\n#### [SpringCloudConfig](https://github.com/spring-cloud/spring-cloud-config)\n\n#### [Apollo](https://github.com/ctripcorp/apollo)\n\nApollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，用于微服务配置管理场景。\n\n### 权限认证\n\n作用：根据系统设置的安全规则或者安全策略, 用户可以访问而且只能访问自己被授权的资源，不多不少。\n\n#### [Spring Security](https://spring.io/projects/spring-security)\n\n#### [Apache Shiro](http://shiro.apache.org/)\n\n> Apache Shiro™ is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. With Shiro’s easy-to-understand API, you can quickly and easily secure any application – from the smallest mobile applications to the largest web and enterprise applications.\n\n### 批处理\n\n作用: 批量处理同类型数据或事物\n\n#### [Spring Batch](https://spring.io/projects/spring-batch)\n\n### 定时任务\n\n> 作用: 定时做什么。\n\n#### [Quartz](http://www.quartz-scheduler.org/)\n\n### 微服务调用 (协议)\n\n> 通讯协议\n\n#### Rest\n\n- 通过 HTTP/HTTPS 发送 Rest 请求进行数据交互\n\n#### RPC\n\n- Remote Procedure Call\n- 它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。\n\n#### [gRPC](https://www.grpc.io/)\n\n> A high-performance, open-source universal RPC framework\n\n所谓 RPC(remote procedure call 远程过程调用) 框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从 server/client 模型。使用的时候客户端调用 server 端提供的接口就像是调用本地的函数一样。\n\n#### RMI\n\n- Remote Method Invocation\n- 纯 Java 调用\n\n### 服务接口调用\n\n> 作用：多个服务之间的通讯\n\n#### [Feign(HTTP)](https://github.com/OpenFeign/feign)\n\nSpring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。\n\n### 服务熔断\n\n> 作用: 当请求到达一定阈值时不让请求继续.\n\n#### [Hystrix](https://github.com/Netflix/Hystrix)\n\n> Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable.\n\n#### [Sentinel](https://github.com/alibaba/Sentinel)\n\n> A lightweight powerful flow control component enabling reliability and monitoring for microservices. (轻量级的流量控制、熔断降级 Java 库)\n\n### 服务的负载均衡\n\n> 作用：降低服务压力, 增加吞吐量\n\n#### [Ribbon](https://github.com/Netflix/ribbon)\n\n> Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具, 它基于 Netflix Ribbon 实现\n\n#### [Nginx](https://github.com/nginx/nginx)\n\nNginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器, 同时也提供了 IMAP/POP3/SMTP 服务\n\n#### Nginx 与 Ribbon 区别\n\nNginx 属于服务端负载均衡，Ribbon 属于客户端负载均衡。Nginx 作用与 Tomcat，Ribbon 作用与各个服务之间的调用 (RPC)。\n\n### 消息队列\n\n> 作用: 解耦业务, 异步化处理数据\n\n#### [Kafka](http://kafka.apache.org/)\n\n#### [RabbitMQ](https://www.rabbitmq.com/)\n\n#### [RocketMQ](http://rocketmq.apache.org/)\n\n#### [activeMQ](http://activemq.apache.org/)\n\n### 日志采集 (elk)\n\n> 作用: 收集各服务日志提供日志分析、用户画像等\n\n#### [Elasticsearch](https://github.com/elastic/elasticsearch)\n\n#### [Logstash](https://github.com/elastic/logstash)\n\n#### [Kibana](https://github.com/elastic/kibana)\n\n### API 网关\n\n> 作用: 外部请求通过 API 网关进行拦截处理, 再转发到真正的服务\n\n#### [Zuul](https://github.com/Netflix/zuul)\n\n> Zuul is a gateway service that provides dynamic routing, monitoring, resiliency, security, and more.\n\n### 服务监控\n\n> 作用: 以可视化或非可视化的形式展示出各个服务的运行情况 (CPU、内存、访问量等)\n\n#### [Zabbix](https://github.com/jjmartres/Zabbix)\n\n#### [Nagios](https://www.nagios.org/)\n\n#### [Metrics](https://metrics.dropwizard.io)\n\n### 服务链路追踪\n\n> 作用: 明确服务之间的调用关系\n\n#### [Zipkin](https://github.com/openzipkin/zipkin)\n\n#### [Brave](https://github.com/openzipkin/brave)\n\n### 数据存储\n\n> 作用: 存储数据\n\n#### 关系型数据库\n\n##### [MySql](https://www.mysql.com/)\n\n##### [Oracle](https://www.oracle.com/index.html)\n\n##### [MsSQL](https://docs.microsoft.com/zh-cn/sql/?view=sql-server-ver15)\n\n##### [PostgreSql](https://www.postgresql.org/)\n\n#### 非关系型数据库\n\n##### [Mongodb](https://www.mongodb.com/)\n\n##### [Elasticsearch](https://github.com/elastic/elasticsearch)\n\n### 缓存\n\n> 作用: 存储数据\n\n#### [redis](https://redis.io/)\n\n### 分库分表\n\n> 作用: 数据库分库分表方案.\n\n#### [ShardingSphere](http://shardingsphere.apache.org/)\n\n#### [Mycat](http://www.mycat.io/)\n\n### 服务部署\n\n> 作用: 将项目快速部署、上线、持续集成.\n\n#### [Docker](http://www.docker.com/)\n\n#### [Jenkins](https://jenkins.io/zh/)\n\n#### [Kubernetes(K8s)](https://kubernetes.io/)\n\n#### [Mesos](http://mesos.apache.org/)\n","source":"_posts/微服务技术栈.md","raw":"---\ntitle: 微服务技术栈\ndate: 2022-09-28\ntags:\n- 微服务\ncategories:\n- 笔记\n# cover: /images/post/markerdown.jpg\n# coverWidth: 1200\n# coverHeight: 320\n# author: 王恺\n# from: 笔记\n---\n微服务技术栈<!--more-->\n# 微服务技术栈\n\n## 技术栈\n\n### 微服务开发\n\n作用：快速开发服务。\n\n- Spring\n- Spring MVC\n- Spring Boot\n\n[Spring](https://spring.io/) 目前是 JavaWeb 开发人员必不可少的一个框架，SpringBoot 简化了 Spring 开发的配置目前也是业内主流开发框架。\n\n### 微服务注册发现\n\n作用：发现服务，注册服务，集中管理服务。\n\n#### Eureka\n\n- Eureka Server : 提供服务注册服务, 各个节点启动后，会在 Eureka Server 中进行注册。\n- Eureka Client : 简化与 Eureka Server 的交互操作。\n- Spring Cloud Netflix : [GitHub](https://github.com/spring-cloud/spring-cloud-netflix)，[文档](https://cloud.spring.io/spring-cloud-netflix/reference/html/)\n\n#### Zookeeper\n\n> ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.\n\n[Zookeeper](https://github.com/apache/zookeeper) 是一个集中的服务, 用于维护配置信息、命名、提供分布式同步和提供组服务。\n\n#### Zookeeper 和 Eureka 区别\n\nZookeeper 保证 CP，Eureka 保证 AP：\n\n- C：数据一致性；\n- A：服务可用性；\n- P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。\n\n#### nacos\n\n\n### 微服务配置管理\n\n作用：统一管理一个或多个服务的配置信息, 集中管理。\n\n#### [Disconf](https://github.com/knightliao/disconf)\n\nDistributed Configuration Management Platform(分布式配置管理平台) , 它是专注于各种分布式系统配置管理 的通用组件/通用平台, 提供统一的配置管理服务, 是一套完整的基于 zookeeper 的分布式配置统一解决方案。\n\n#### [SpringCloudConfig](https://github.com/spring-cloud/spring-cloud-config)\n\n#### [Apollo](https://github.com/ctripcorp/apollo)\n\nApollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，用于微服务配置管理场景。\n\n### 权限认证\n\n作用：根据系统设置的安全规则或者安全策略, 用户可以访问而且只能访问自己被授权的资源，不多不少。\n\n#### [Spring Security](https://spring.io/projects/spring-security)\n\n#### [Apache Shiro](http://shiro.apache.org/)\n\n> Apache Shiro™ is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. With Shiro’s easy-to-understand API, you can quickly and easily secure any application – from the smallest mobile applications to the largest web and enterprise applications.\n\n### 批处理\n\n作用: 批量处理同类型数据或事物\n\n#### [Spring Batch](https://spring.io/projects/spring-batch)\n\n### 定时任务\n\n> 作用: 定时做什么。\n\n#### [Quartz](http://www.quartz-scheduler.org/)\n\n### 微服务调用 (协议)\n\n> 通讯协议\n\n#### Rest\n\n- 通过 HTTP/HTTPS 发送 Rest 请求进行数据交互\n\n#### RPC\n\n- Remote Procedure Call\n- 它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。\n\n#### [gRPC](https://www.grpc.io/)\n\n> A high-performance, open-source universal RPC framework\n\n所谓 RPC(remote procedure call 远程过程调用) 框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从 server/client 模型。使用的时候客户端调用 server 端提供的接口就像是调用本地的函数一样。\n\n#### RMI\n\n- Remote Method Invocation\n- 纯 Java 调用\n\n### 服务接口调用\n\n> 作用：多个服务之间的通讯\n\n#### [Feign(HTTP)](https://github.com/OpenFeign/feign)\n\nSpring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。\n\n### 服务熔断\n\n> 作用: 当请求到达一定阈值时不让请求继续.\n\n#### [Hystrix](https://github.com/Netflix/Hystrix)\n\n> Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable.\n\n#### [Sentinel](https://github.com/alibaba/Sentinel)\n\n> A lightweight powerful flow control component enabling reliability and monitoring for microservices. (轻量级的流量控制、熔断降级 Java 库)\n\n### 服务的负载均衡\n\n> 作用：降低服务压力, 增加吞吐量\n\n#### [Ribbon](https://github.com/Netflix/ribbon)\n\n> Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具, 它基于 Netflix Ribbon 实现\n\n#### [Nginx](https://github.com/nginx/nginx)\n\nNginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器, 同时也提供了 IMAP/POP3/SMTP 服务\n\n#### Nginx 与 Ribbon 区别\n\nNginx 属于服务端负载均衡，Ribbon 属于客户端负载均衡。Nginx 作用与 Tomcat，Ribbon 作用与各个服务之间的调用 (RPC)。\n\n### 消息队列\n\n> 作用: 解耦业务, 异步化处理数据\n\n#### [Kafka](http://kafka.apache.org/)\n\n#### [RabbitMQ](https://www.rabbitmq.com/)\n\n#### [RocketMQ](http://rocketmq.apache.org/)\n\n#### [activeMQ](http://activemq.apache.org/)\n\n### 日志采集 (elk)\n\n> 作用: 收集各服务日志提供日志分析、用户画像等\n\n#### [Elasticsearch](https://github.com/elastic/elasticsearch)\n\n#### [Logstash](https://github.com/elastic/logstash)\n\n#### [Kibana](https://github.com/elastic/kibana)\n\n### API 网关\n\n> 作用: 外部请求通过 API 网关进行拦截处理, 再转发到真正的服务\n\n#### [Zuul](https://github.com/Netflix/zuul)\n\n> Zuul is a gateway service that provides dynamic routing, monitoring, resiliency, security, and more.\n\n### 服务监控\n\n> 作用: 以可视化或非可视化的形式展示出各个服务的运行情况 (CPU、内存、访问量等)\n\n#### [Zabbix](https://github.com/jjmartres/Zabbix)\n\n#### [Nagios](https://www.nagios.org/)\n\n#### [Metrics](https://metrics.dropwizard.io)\n\n### 服务链路追踪\n\n> 作用: 明确服务之间的调用关系\n\n#### [Zipkin](https://github.com/openzipkin/zipkin)\n\n#### [Brave](https://github.com/openzipkin/brave)\n\n### 数据存储\n\n> 作用: 存储数据\n\n#### 关系型数据库\n\n##### [MySql](https://www.mysql.com/)\n\n##### [Oracle](https://www.oracle.com/index.html)\n\n##### [MsSQL](https://docs.microsoft.com/zh-cn/sql/?view=sql-server-ver15)\n\n##### [PostgreSql](https://www.postgresql.org/)\n\n#### 非关系型数据库\n\n##### [Mongodb](https://www.mongodb.com/)\n\n##### [Elasticsearch](https://github.com/elastic/elasticsearch)\n\n### 缓存\n\n> 作用: 存储数据\n\n#### [redis](https://redis.io/)\n\n### 分库分表\n\n> 作用: 数据库分库分表方案.\n\n#### [ShardingSphere](http://shardingsphere.apache.org/)\n\n#### [Mycat](http://www.mycat.io/)\n\n### 服务部署\n\n> 作用: 将项目快速部署、上线、持续集成.\n\n#### [Docker](http://www.docker.com/)\n\n#### [Jenkins](https://jenkins.io/zh/)\n\n#### [Kubernetes(K8s)](https://kubernetes.io/)\n\n#### [Mesos](http://mesos.apache.org/)\n","slug":"微服务技术栈","published":1,"updated":"2022-09-28T06:12:38.207Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0kv000aekwecdyhe5h4","content":"<p>微服务技术栈<span id=\"more\"></span></p>\n<h1 id=\"微服务技术栈\"><a href=\"#微服务技术栈\" class=\"headerlink\" title=\"微服务技术栈\"></a>微服务技术栈</h1><h2 id=\"技术栈\"><a href=\"#技术栈\" class=\"headerlink\" title=\"技术栈\"></a>技术栈</h2><h3 id=\"微服务开发\"><a href=\"#微服务开发\" class=\"headerlink\" title=\"微服务开发\"></a>微服务开发</h3><p>作用：快速开发服务。</p>\n<ul>\n<li>Spring</li>\n<li>Spring MVC</li>\n<li>Spring Boot</li>\n</ul>\n<p><a href=\"https://spring.io/\">Spring</a> 目前是 JavaWeb 开发人员必不可少的一个框架，SpringBoot 简化了 Spring 开发的配置目前也是业内主流开发框架。</p>\n<h3 id=\"微服务注册发现\"><a href=\"#微服务注册发现\" class=\"headerlink\" title=\"微服务注册发现\"></a>微服务注册发现</h3><p>作用：发现服务，注册服务，集中管理服务。</p>\n<h4 id=\"Eureka\"><a href=\"#Eureka\" class=\"headerlink\" title=\"Eureka\"></a>Eureka</h4><ul>\n<li>Eureka Server : 提供服务注册服务, 各个节点启动后，会在 Eureka Server 中进行注册。</li>\n<li>Eureka Client : 简化与 Eureka Server 的交互操作。</li>\n<li>Spring Cloud Netflix : <a href=\"https://github.com/spring-cloud/spring-cloud-netflix\">GitHub</a>，<a href=\"https://cloud.spring.io/spring-cloud-netflix/reference/html/\">文档</a></li>\n</ul>\n<h4 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h4><blockquote>\n<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.</p>\n</blockquote>\n<p><a href=\"https://github.com/apache/zookeeper\">Zookeeper</a> 是一个集中的服务, 用于维护配置信息、命名、提供分布式同步和提供组服务。</p>\n<h4 id=\"Zookeeper-和-Eureka-区别\"><a href=\"#Zookeeper-和-Eureka-区别\" class=\"headerlink\" title=\"Zookeeper 和 Eureka 区别\"></a>Zookeeper 和 Eureka 区别</h4><p>Zookeeper 保证 CP，Eureka 保证 AP：</p>\n<ul>\n<li>C：数据一致性；</li>\n<li>A：服务可用性；</li>\n<li>P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。</li>\n</ul>\n<h4 id=\"nacos\"><a href=\"#nacos\" class=\"headerlink\" title=\"nacos\"></a>nacos</h4><h3 id=\"微服务配置管理\"><a href=\"#微服务配置管理\" class=\"headerlink\" title=\"微服务配置管理\"></a>微服务配置管理</h3><p>作用：统一管理一个或多个服务的配置信息, 集中管理。</p>\n<h4 id=\"Disconf\"><a href=\"#Disconf\" class=\"headerlink\" title=\"Disconf\"></a><a href=\"https://github.com/knightliao/disconf\">Disconf</a></h4><p>Distributed Configuration Management Platform(分布式配置管理平台) , 它是专注于各种分布式系统配置管理 的通用组件/通用平台, 提供统一的配置管理服务, 是一套完整的基于 zookeeper 的分布式配置统一解决方案。</p>\n<h4 id=\"SpringCloudConfig\"><a href=\"#SpringCloudConfig\" class=\"headerlink\" title=\"SpringCloudConfig\"></a><a href=\"https://github.com/spring-cloud/spring-cloud-config\">SpringCloudConfig</a></h4><h4 id=\"Apollo\"><a href=\"#Apollo\" class=\"headerlink\" title=\"Apollo\"></a><a href=\"https://github.com/ctripcorp/apollo\">Apollo</a></h4><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，用于微服务配置管理场景。</p>\n<h3 id=\"权限认证\"><a href=\"#权限认证\" class=\"headerlink\" title=\"权限认证\"></a>权限认证</h3><p>作用：根据系统设置的安全规则或者安全策略, 用户可以访问而且只能访问自己被授权的资源，不多不少。</p>\n<h4 id=\"Spring-Security\"><a href=\"#Spring-Security\" class=\"headerlink\" title=\"Spring Security\"></a><a href=\"https://spring.io/projects/spring-security\">Spring Security</a></h4><h4 id=\"Apache-Shiro\"><a href=\"#Apache-Shiro\" class=\"headerlink\" title=\"Apache Shiro\"></a><a href=\"http://shiro.apache.org/\">Apache Shiro</a></h4><blockquote>\n<p>Apache Shiro™ is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. With Shiro’s easy-to-understand API, you can quickly and easily secure any application – from the smallest mobile applications to the largest web and enterprise applications.</p>\n</blockquote>\n<h3 id=\"批处理\"><a href=\"#批处理\" class=\"headerlink\" title=\"批处理\"></a>批处理</h3><p>作用: 批量处理同类型数据或事物</p>\n<h4 id=\"Spring-Batch\"><a href=\"#Spring-Batch\" class=\"headerlink\" title=\"Spring Batch\"></a><a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a></h4><h3 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h3><blockquote>\n<p>作用: 定时做什么。</p>\n</blockquote>\n<h4 id=\"Quartz\"><a href=\"#Quartz\" class=\"headerlink\" title=\"Quartz\"></a><a href=\"http://www.quartz-scheduler.org/\">Quartz</a></h4><h3 id=\"微服务调用-协议\"><a href=\"#微服务调用-协议\" class=\"headerlink\" title=\"微服务调用 (协议)\"></a>微服务调用 (协议)</h3><blockquote>\n<p>通讯协议</p>\n</blockquote>\n<h4 id=\"Rest\"><a href=\"#Rest\" class=\"headerlink\" title=\"Rest\"></a>Rest</h4><ul>\n<li>通过 HTTP/HTTPS 发送 Rest 请求进行数据交互</li>\n</ul>\n<h4 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h4><ul>\n<li>Remote Procedure Call</li>\n<li>它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。</li>\n</ul>\n<h4 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a><a href=\"https://www.grpc.io/\">gRPC</a></h4><blockquote>\n<p>A high-performance, open-source universal RPC framework</p>\n</blockquote>\n<p>所谓 RPC(remote procedure call 远程过程调用) 框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从 server/client 模型。使用的时候客户端调用 server 端提供的接口就像是调用本地的函数一样。</p>\n<h4 id=\"RMI\"><a href=\"#RMI\" class=\"headerlink\" title=\"RMI\"></a>RMI</h4><ul>\n<li>Remote Method Invocation</li>\n<li>纯 Java 调用</li>\n</ul>\n<h3 id=\"服务接口调用\"><a href=\"#服务接口调用\" class=\"headerlink\" title=\"服务接口调用\"></a>服务接口调用</h3><blockquote>\n<p>作用：多个服务之间的通讯</p>\n</blockquote>\n<h4 id=\"Feign-HTTP\"><a href=\"#Feign-HTTP\" class=\"headerlink\" title=\"Feign(HTTP)\"></a><a href=\"https://github.com/OpenFeign/feign\">Feign(HTTP)</a></h4><p>Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。</p>\n<h3 id=\"服务熔断\"><a href=\"#服务熔断\" class=\"headerlink\" title=\"服务熔断\"></a>服务熔断</h3><blockquote>\n<p>作用: 当请求到达一定阈值时不让请求继续.</p>\n</blockquote>\n<h4 id=\"Hystrix\"><a href=\"#Hystrix\" class=\"headerlink\" title=\"Hystrix\"></a><a href=\"https://github.com/Netflix/Hystrix\">Hystrix</a></h4><blockquote>\n<p>Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable.</p>\n</blockquote>\n<h4 id=\"Sentinel\"><a href=\"#Sentinel\" class=\"headerlink\" title=\"Sentinel\"></a><a href=\"https://github.com/alibaba/Sentinel\">Sentinel</a></h4><blockquote>\n<p>A lightweight powerful flow control component enabling reliability and monitoring for microservices. (轻量级的流量控制、熔断降级 Java 库)</p>\n</blockquote>\n<h3 id=\"服务的负载均衡\"><a href=\"#服务的负载均衡\" class=\"headerlink\" title=\"服务的负载均衡\"></a>服务的负载均衡</h3><blockquote>\n<p>作用：降低服务压力, 增加吞吐量</p>\n</blockquote>\n<h4 id=\"Ribbon\"><a href=\"#Ribbon\" class=\"headerlink\" title=\"Ribbon\"></a><a href=\"https://github.com/Netflix/ribbon\">Ribbon</a></h4><blockquote>\n<p>Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具, 它基于 Netflix Ribbon 实现</p>\n</blockquote>\n<h4 id=\"Nginx\"><a href=\"#Nginx\" class=\"headerlink\" title=\"Nginx\"></a><a href=\"https://github.com/nginx/nginx\">Nginx</a></h4><p>Nginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器, 同时也提供了 IMAP/POP3/SMTP 服务</p>\n<h4 id=\"Nginx-与-Ribbon-区别\"><a href=\"#Nginx-与-Ribbon-区别\" class=\"headerlink\" title=\"Nginx 与 Ribbon 区别\"></a>Nginx 与 Ribbon 区别</h4><p>Nginx 属于服务端负载均衡，Ribbon 属于客户端负载均衡。Nginx 作用与 Tomcat，Ribbon 作用与各个服务之间的调用 (RPC)。</p>\n<h3 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h3><blockquote>\n<p>作用: 解耦业务, 异步化处理数据</p>\n</blockquote>\n<h4 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a><a href=\"http://kafka.apache.org/\">Kafka</a></h4><h4 id=\"RabbitMQ\"><a href=\"#RabbitMQ\" class=\"headerlink\" title=\"RabbitMQ\"></a><a href=\"https://www.rabbitmq.com/\">RabbitMQ</a></h4><h4 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ\"></a><a href=\"http://rocketmq.apache.org/\">RocketMQ</a></h4><h4 id=\"activeMQ\"><a href=\"#activeMQ\" class=\"headerlink\" title=\"activeMQ\"></a><a href=\"http://activemq.apache.org/\">activeMQ</a></h4><h3 id=\"日志采集-elk\"><a href=\"#日志采集-elk\" class=\"headerlink\" title=\"日志采集 (elk)\"></a>日志采集 (elk)</h3><blockquote>\n<p>作用: 收集各服务日志提供日志分析、用户画像等</p>\n</blockquote>\n<h4 id=\"Elasticsearch\"><a href=\"#Elasticsearch\" class=\"headerlink\" title=\"Elasticsearch\"></a><a href=\"https://github.com/elastic/elasticsearch\">Elasticsearch</a></h4><h4 id=\"Logstash\"><a href=\"#Logstash\" class=\"headerlink\" title=\"Logstash\"></a><a href=\"https://github.com/elastic/logstash\">Logstash</a></h4><h4 id=\"Kibana\"><a href=\"#Kibana\" class=\"headerlink\" title=\"Kibana\"></a><a href=\"https://github.com/elastic/kibana\">Kibana</a></h4><h3 id=\"API-网关\"><a href=\"#API-网关\" class=\"headerlink\" title=\"API 网关\"></a>API 网关</h3><blockquote>\n<p>作用: 外部请求通过 API 网关进行拦截处理, 再转发到真正的服务</p>\n</blockquote>\n<h4 id=\"Zuul\"><a href=\"#Zuul\" class=\"headerlink\" title=\"Zuul\"></a><a href=\"https://github.com/Netflix/zuul\">Zuul</a></h4><blockquote>\n<p>Zuul is a gateway service that provides dynamic routing, monitoring, resiliency, security, and more.</p>\n</blockquote>\n<h3 id=\"服务监控\"><a href=\"#服务监控\" class=\"headerlink\" title=\"服务监控\"></a>服务监控</h3><blockquote>\n<p>作用: 以可视化或非可视化的形式展示出各个服务的运行情况 (CPU、内存、访问量等)</p>\n</blockquote>\n<h4 id=\"Zabbix\"><a href=\"#Zabbix\" class=\"headerlink\" title=\"Zabbix\"></a><a href=\"https://github.com/jjmartres/Zabbix\">Zabbix</a></h4><h4 id=\"Nagios\"><a href=\"#Nagios\" class=\"headerlink\" title=\"Nagios\"></a><a href=\"https://www.nagios.org/\">Nagios</a></h4><h4 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a><a href=\"https://metrics.dropwizard.io/\">Metrics</a></h4><h3 id=\"服务链路追踪\"><a href=\"#服务链路追踪\" class=\"headerlink\" title=\"服务链路追踪\"></a>服务链路追踪</h3><blockquote>\n<p>作用: 明确服务之间的调用关系</p>\n</blockquote>\n<h4 id=\"Zipkin\"><a href=\"#Zipkin\" class=\"headerlink\" title=\"Zipkin\"></a><a href=\"https://github.com/openzipkin/zipkin\">Zipkin</a></h4><h4 id=\"Brave\"><a href=\"#Brave\" class=\"headerlink\" title=\"Brave\"></a><a href=\"https://github.com/openzipkin/brave\">Brave</a></h4><h3 id=\"数据存储\"><a href=\"#数据存储\" class=\"headerlink\" title=\"数据存储\"></a>数据存储</h3><blockquote>\n<p>作用: 存储数据</p>\n</blockquote>\n<h4 id=\"关系型数据库\"><a href=\"#关系型数据库\" class=\"headerlink\" title=\"关系型数据库\"></a>关系型数据库</h4><h5 id=\"MySql\"><a href=\"#MySql\" class=\"headerlink\" title=\"MySql\"></a><a href=\"https://www.mysql.com/\">MySql</a></h5><h5 id=\"Oracle\"><a href=\"#Oracle\" class=\"headerlink\" title=\"Oracle\"></a><a href=\"https://www.oracle.com/index.html\">Oracle</a></h5><h5 id=\"MsSQL\"><a href=\"#MsSQL\" class=\"headerlink\" title=\"MsSQL\"></a><a href=\"https://docs.microsoft.com/zh-cn/sql/?view=sql-server-ver15\">MsSQL</a></h5><h5 id=\"PostgreSql\"><a href=\"#PostgreSql\" class=\"headerlink\" title=\"PostgreSql\"></a><a href=\"https://www.postgresql.org/\">PostgreSql</a></h5><h4 id=\"非关系型数据库\"><a href=\"#非关系型数据库\" class=\"headerlink\" title=\"非关系型数据库\"></a>非关系型数据库</h4><h5 id=\"Mongodb\"><a href=\"#Mongodb\" class=\"headerlink\" title=\"Mongodb\"></a><a href=\"https://www.mongodb.com/\">Mongodb</a></h5><h5 id=\"Elasticsearch-1\"><a href=\"#Elasticsearch-1\" class=\"headerlink\" title=\"Elasticsearch\"></a><a href=\"https://github.com/elastic/elasticsearch\">Elasticsearch</a></h5><h3 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h3><blockquote>\n<p>作用: 存储数据</p>\n</blockquote>\n<h4 id=\"redis\"><a href=\"#redis\" class=\"headerlink\" title=\"redis\"></a><a href=\"https://redis.io/\">redis</a></h4><h3 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h3><blockquote>\n<p>作用: 数据库分库分表方案.</p>\n</blockquote>\n<h4 id=\"ShardingSphere\"><a href=\"#ShardingSphere\" class=\"headerlink\" title=\"ShardingSphere\"></a><a href=\"http://shardingsphere.apache.org/\">ShardingSphere</a></h4><h4 id=\"Mycat\"><a href=\"#Mycat\" class=\"headerlink\" title=\"Mycat\"></a><a href=\"http://www.mycat.io/\">Mycat</a></h4><h3 id=\"服务部署\"><a href=\"#服务部署\" class=\"headerlink\" title=\"服务部署\"></a>服务部署</h3><blockquote>\n<p>作用: 将项目快速部署、上线、持续集成.</p>\n</blockquote>\n<h4 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a><a href=\"http://www.docker.com/\">Docker</a></h4><h4 id=\"Jenkins\"><a href=\"#Jenkins\" class=\"headerlink\" title=\"Jenkins\"></a><a href=\"https://jenkins.io/zh/\">Jenkins</a></h4><h4 id=\"Kubernetes-K8s\"><a href=\"#Kubernetes-K8s\" class=\"headerlink\" title=\"Kubernetes(K8s)\"></a><a href=\"https://kubernetes.io/\">Kubernetes(K8s)</a></h4><h4 id=\"Mesos\"><a href=\"#Mesos\" class=\"headerlink\" title=\"Mesos\"></a><a href=\"http://mesos.apache.org/\">Mesos</a></h4>","site":{"data":{}},"excerpt":"<p>微服务技术栈","more":"</p>\n<h1 id=\"微服务技术栈\"><a href=\"#微服务技术栈\" class=\"headerlink\" title=\"微服务技术栈\"></a>微服务技术栈</h1><h2 id=\"技术栈\"><a href=\"#技术栈\" class=\"headerlink\" title=\"技术栈\"></a>技术栈</h2><h3 id=\"微服务开发\"><a href=\"#微服务开发\" class=\"headerlink\" title=\"微服务开发\"></a>微服务开发</h3><p>作用：快速开发服务。</p>\n<ul>\n<li>Spring</li>\n<li>Spring MVC</li>\n<li>Spring Boot</li>\n</ul>\n<p><a href=\"https://spring.io/\">Spring</a> 目前是 JavaWeb 开发人员必不可少的一个框架，SpringBoot 简化了 Spring 开发的配置目前也是业内主流开发框架。</p>\n<h3 id=\"微服务注册发现\"><a href=\"#微服务注册发现\" class=\"headerlink\" title=\"微服务注册发现\"></a>微服务注册发现</h3><p>作用：发现服务，注册服务，集中管理服务。</p>\n<h4 id=\"Eureka\"><a href=\"#Eureka\" class=\"headerlink\" title=\"Eureka\"></a>Eureka</h4><ul>\n<li>Eureka Server : 提供服务注册服务, 各个节点启动后，会在 Eureka Server 中进行注册。</li>\n<li>Eureka Client : 简化与 Eureka Server 的交互操作。</li>\n<li>Spring Cloud Netflix : <a href=\"https://github.com/spring-cloud/spring-cloud-netflix\">GitHub</a>，<a href=\"https://cloud.spring.io/spring-cloud-netflix/reference/html/\">文档</a></li>\n</ul>\n<h4 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h4><blockquote>\n<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.</p>\n</blockquote>\n<p><a href=\"https://github.com/apache/zookeeper\">Zookeeper</a> 是一个集中的服务, 用于维护配置信息、命名、提供分布式同步和提供组服务。</p>\n<h4 id=\"Zookeeper-和-Eureka-区别\"><a href=\"#Zookeeper-和-Eureka-区别\" class=\"headerlink\" title=\"Zookeeper 和 Eureka 区别\"></a>Zookeeper 和 Eureka 区别</h4><p>Zookeeper 保证 CP，Eureka 保证 AP：</p>\n<ul>\n<li>C：数据一致性；</li>\n<li>A：服务可用性；</li>\n<li>P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。</li>\n</ul>\n<h4 id=\"nacos\"><a href=\"#nacos\" class=\"headerlink\" title=\"nacos\"></a>nacos</h4><h3 id=\"微服务配置管理\"><a href=\"#微服务配置管理\" class=\"headerlink\" title=\"微服务配置管理\"></a>微服务配置管理</h3><p>作用：统一管理一个或多个服务的配置信息, 集中管理。</p>\n<h4 id=\"Disconf\"><a href=\"#Disconf\" class=\"headerlink\" title=\"Disconf\"></a><a href=\"https://github.com/knightliao/disconf\">Disconf</a></h4><p>Distributed Configuration Management Platform(分布式配置管理平台) , 它是专注于各种分布式系统配置管理 的通用组件/通用平台, 提供统一的配置管理服务, 是一套完整的基于 zookeeper 的分布式配置统一解决方案。</p>\n<h4 id=\"SpringCloudConfig\"><a href=\"#SpringCloudConfig\" class=\"headerlink\" title=\"SpringCloudConfig\"></a><a href=\"https://github.com/spring-cloud/spring-cloud-config\">SpringCloudConfig</a></h4><h4 id=\"Apollo\"><a href=\"#Apollo\" class=\"headerlink\" title=\"Apollo\"></a><a href=\"https://github.com/ctripcorp/apollo\">Apollo</a></h4><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，用于微服务配置管理场景。</p>\n<h3 id=\"权限认证\"><a href=\"#权限认证\" class=\"headerlink\" title=\"权限认证\"></a>权限认证</h3><p>作用：根据系统设置的安全规则或者安全策略, 用户可以访问而且只能访问自己被授权的资源，不多不少。</p>\n<h4 id=\"Spring-Security\"><a href=\"#Spring-Security\" class=\"headerlink\" title=\"Spring Security\"></a><a href=\"https://spring.io/projects/spring-security\">Spring Security</a></h4><h4 id=\"Apache-Shiro\"><a href=\"#Apache-Shiro\" class=\"headerlink\" title=\"Apache Shiro\"></a><a href=\"http://shiro.apache.org/\">Apache Shiro</a></h4><blockquote>\n<p>Apache Shiro™ is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. With Shiro’s easy-to-understand API, you can quickly and easily secure any application – from the smallest mobile applications to the largest web and enterprise applications.</p>\n</blockquote>\n<h3 id=\"批处理\"><a href=\"#批处理\" class=\"headerlink\" title=\"批处理\"></a>批处理</h3><p>作用: 批量处理同类型数据或事物</p>\n<h4 id=\"Spring-Batch\"><a href=\"#Spring-Batch\" class=\"headerlink\" title=\"Spring Batch\"></a><a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a></h4><h3 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h3><blockquote>\n<p>作用: 定时做什么。</p>\n</blockquote>\n<h4 id=\"Quartz\"><a href=\"#Quartz\" class=\"headerlink\" title=\"Quartz\"></a><a href=\"http://www.quartz-scheduler.org/\">Quartz</a></h4><h3 id=\"微服务调用-协议\"><a href=\"#微服务调用-协议\" class=\"headerlink\" title=\"微服务调用 (协议)\"></a>微服务调用 (协议)</h3><blockquote>\n<p>通讯协议</p>\n</blockquote>\n<h4 id=\"Rest\"><a href=\"#Rest\" class=\"headerlink\" title=\"Rest\"></a>Rest</h4><ul>\n<li>通过 HTTP/HTTPS 发送 Rest 请求进行数据交互</li>\n</ul>\n<h4 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h4><ul>\n<li>Remote Procedure Call</li>\n<li>它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。</li>\n</ul>\n<h4 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a><a href=\"https://www.grpc.io/\">gRPC</a></h4><blockquote>\n<p>A high-performance, open-source universal RPC framework</p>\n</blockquote>\n<p>所谓 RPC(remote procedure call 远程过程调用) 框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从 server/client 模型。使用的时候客户端调用 server 端提供的接口就像是调用本地的函数一样。</p>\n<h4 id=\"RMI\"><a href=\"#RMI\" class=\"headerlink\" title=\"RMI\"></a>RMI</h4><ul>\n<li>Remote Method Invocation</li>\n<li>纯 Java 调用</li>\n</ul>\n<h3 id=\"服务接口调用\"><a href=\"#服务接口调用\" class=\"headerlink\" title=\"服务接口调用\"></a>服务接口调用</h3><blockquote>\n<p>作用：多个服务之间的通讯</p>\n</blockquote>\n<h4 id=\"Feign-HTTP\"><a href=\"#Feign-HTTP\" class=\"headerlink\" title=\"Feign(HTTP)\"></a><a href=\"https://github.com/OpenFeign/feign\">Feign(HTTP)</a></h4><p>Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。</p>\n<h3 id=\"服务熔断\"><a href=\"#服务熔断\" class=\"headerlink\" title=\"服务熔断\"></a>服务熔断</h3><blockquote>\n<p>作用: 当请求到达一定阈值时不让请求继续.</p>\n</blockquote>\n<h4 id=\"Hystrix\"><a href=\"#Hystrix\" class=\"headerlink\" title=\"Hystrix\"></a><a href=\"https://github.com/Netflix/Hystrix\">Hystrix</a></h4><blockquote>\n<p>Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable.</p>\n</blockquote>\n<h4 id=\"Sentinel\"><a href=\"#Sentinel\" class=\"headerlink\" title=\"Sentinel\"></a><a href=\"https://github.com/alibaba/Sentinel\">Sentinel</a></h4><blockquote>\n<p>A lightweight powerful flow control component enabling reliability and monitoring for microservices. (轻量级的流量控制、熔断降级 Java 库)</p>\n</blockquote>\n<h3 id=\"服务的负载均衡\"><a href=\"#服务的负载均衡\" class=\"headerlink\" title=\"服务的负载均衡\"></a>服务的负载均衡</h3><blockquote>\n<p>作用：降低服务压力, 增加吞吐量</p>\n</blockquote>\n<h4 id=\"Ribbon\"><a href=\"#Ribbon\" class=\"headerlink\" title=\"Ribbon\"></a><a href=\"https://github.com/Netflix/ribbon\">Ribbon</a></h4><blockquote>\n<p>Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具, 它基于 Netflix Ribbon 实现</p>\n</blockquote>\n<h4 id=\"Nginx\"><a href=\"#Nginx\" class=\"headerlink\" title=\"Nginx\"></a><a href=\"https://github.com/nginx/nginx\">Nginx</a></h4><p>Nginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器, 同时也提供了 IMAP/POP3/SMTP 服务</p>\n<h4 id=\"Nginx-与-Ribbon-区别\"><a href=\"#Nginx-与-Ribbon-区别\" class=\"headerlink\" title=\"Nginx 与 Ribbon 区别\"></a>Nginx 与 Ribbon 区别</h4><p>Nginx 属于服务端负载均衡，Ribbon 属于客户端负载均衡。Nginx 作用与 Tomcat，Ribbon 作用与各个服务之间的调用 (RPC)。</p>\n<h3 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h3><blockquote>\n<p>作用: 解耦业务, 异步化处理数据</p>\n</blockquote>\n<h4 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a><a href=\"http://kafka.apache.org/\">Kafka</a></h4><h4 id=\"RabbitMQ\"><a href=\"#RabbitMQ\" class=\"headerlink\" title=\"RabbitMQ\"></a><a href=\"https://www.rabbitmq.com/\">RabbitMQ</a></h4><h4 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ\"></a><a href=\"http://rocketmq.apache.org/\">RocketMQ</a></h4><h4 id=\"activeMQ\"><a href=\"#activeMQ\" class=\"headerlink\" title=\"activeMQ\"></a><a href=\"http://activemq.apache.org/\">activeMQ</a></h4><h3 id=\"日志采集-elk\"><a href=\"#日志采集-elk\" class=\"headerlink\" title=\"日志采集 (elk)\"></a>日志采集 (elk)</h3><blockquote>\n<p>作用: 收集各服务日志提供日志分析、用户画像等</p>\n</blockquote>\n<h4 id=\"Elasticsearch\"><a href=\"#Elasticsearch\" class=\"headerlink\" title=\"Elasticsearch\"></a><a href=\"https://github.com/elastic/elasticsearch\">Elasticsearch</a></h4><h4 id=\"Logstash\"><a href=\"#Logstash\" class=\"headerlink\" title=\"Logstash\"></a><a href=\"https://github.com/elastic/logstash\">Logstash</a></h4><h4 id=\"Kibana\"><a href=\"#Kibana\" class=\"headerlink\" title=\"Kibana\"></a><a href=\"https://github.com/elastic/kibana\">Kibana</a></h4><h3 id=\"API-网关\"><a href=\"#API-网关\" class=\"headerlink\" title=\"API 网关\"></a>API 网关</h3><blockquote>\n<p>作用: 外部请求通过 API 网关进行拦截处理, 再转发到真正的服务</p>\n</blockquote>\n<h4 id=\"Zuul\"><a href=\"#Zuul\" class=\"headerlink\" title=\"Zuul\"></a><a href=\"https://github.com/Netflix/zuul\">Zuul</a></h4><blockquote>\n<p>Zuul is a gateway service that provides dynamic routing, monitoring, resiliency, security, and more.</p>\n</blockquote>\n<h3 id=\"服务监控\"><a href=\"#服务监控\" class=\"headerlink\" title=\"服务监控\"></a>服务监控</h3><blockquote>\n<p>作用: 以可视化或非可视化的形式展示出各个服务的运行情况 (CPU、内存、访问量等)</p>\n</blockquote>\n<h4 id=\"Zabbix\"><a href=\"#Zabbix\" class=\"headerlink\" title=\"Zabbix\"></a><a href=\"https://github.com/jjmartres/Zabbix\">Zabbix</a></h4><h4 id=\"Nagios\"><a href=\"#Nagios\" class=\"headerlink\" title=\"Nagios\"></a><a href=\"https://www.nagios.org/\">Nagios</a></h4><h4 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a><a href=\"https://metrics.dropwizard.io/\">Metrics</a></h4><h3 id=\"服务链路追踪\"><a href=\"#服务链路追踪\" class=\"headerlink\" title=\"服务链路追踪\"></a>服务链路追踪</h3><blockquote>\n<p>作用: 明确服务之间的调用关系</p>\n</blockquote>\n<h4 id=\"Zipkin\"><a href=\"#Zipkin\" class=\"headerlink\" title=\"Zipkin\"></a><a href=\"https://github.com/openzipkin/zipkin\">Zipkin</a></h4><h4 id=\"Brave\"><a href=\"#Brave\" class=\"headerlink\" title=\"Brave\"></a><a href=\"https://github.com/openzipkin/brave\">Brave</a></h4><h3 id=\"数据存储\"><a href=\"#数据存储\" class=\"headerlink\" title=\"数据存储\"></a>数据存储</h3><blockquote>\n<p>作用: 存储数据</p>\n</blockquote>\n<h4 id=\"关系型数据库\"><a href=\"#关系型数据库\" class=\"headerlink\" title=\"关系型数据库\"></a>关系型数据库</h4><h5 id=\"MySql\"><a href=\"#MySql\" class=\"headerlink\" title=\"MySql\"></a><a href=\"https://www.mysql.com/\">MySql</a></h5><h5 id=\"Oracle\"><a href=\"#Oracle\" class=\"headerlink\" title=\"Oracle\"></a><a href=\"https://www.oracle.com/index.html\">Oracle</a></h5><h5 id=\"MsSQL\"><a href=\"#MsSQL\" class=\"headerlink\" title=\"MsSQL\"></a><a href=\"https://docs.microsoft.com/zh-cn/sql/?view=sql-server-ver15\">MsSQL</a></h5><h5 id=\"PostgreSql\"><a href=\"#PostgreSql\" class=\"headerlink\" title=\"PostgreSql\"></a><a href=\"https://www.postgresql.org/\">PostgreSql</a></h5><h4 id=\"非关系型数据库\"><a href=\"#非关系型数据库\" class=\"headerlink\" title=\"非关系型数据库\"></a>非关系型数据库</h4><h5 id=\"Mongodb\"><a href=\"#Mongodb\" class=\"headerlink\" title=\"Mongodb\"></a><a href=\"https://www.mongodb.com/\">Mongodb</a></h5><h5 id=\"Elasticsearch-1\"><a href=\"#Elasticsearch-1\" class=\"headerlink\" title=\"Elasticsearch\"></a><a href=\"https://github.com/elastic/elasticsearch\">Elasticsearch</a></h5><h3 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h3><blockquote>\n<p>作用: 存储数据</p>\n</blockquote>\n<h4 id=\"redis\"><a href=\"#redis\" class=\"headerlink\" title=\"redis\"></a><a href=\"https://redis.io/\">redis</a></h4><h3 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h3><blockquote>\n<p>作用: 数据库分库分表方案.</p>\n</blockquote>\n<h4 id=\"ShardingSphere\"><a href=\"#ShardingSphere\" class=\"headerlink\" title=\"ShardingSphere\"></a><a href=\"http://shardingsphere.apache.org/\">ShardingSphere</a></h4><h4 id=\"Mycat\"><a href=\"#Mycat\" class=\"headerlink\" title=\"Mycat\"></a><a href=\"http://www.mycat.io/\">Mycat</a></h4><h3 id=\"服务部署\"><a href=\"#服务部署\" class=\"headerlink\" title=\"服务部署\"></a>服务部署</h3><blockquote>\n<p>作用: 将项目快速部署、上线、持续集成.</p>\n</blockquote>\n<h4 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a><a href=\"http://www.docker.com/\">Docker</a></h4><h4 id=\"Jenkins\"><a href=\"#Jenkins\" class=\"headerlink\" title=\"Jenkins\"></a><a href=\"https://jenkins.io/zh/\">Jenkins</a></h4><h4 id=\"Kubernetes-K8s\"><a href=\"#Kubernetes-K8s\" class=\"headerlink\" title=\"Kubernetes(K8s)\"></a><a href=\"https://kubernetes.io/\">Kubernetes(K8s)</a></h4><h4 id=\"Mesos\"><a href=\"#Mesos\" class=\"headerlink\" title=\"Mesos\"></a><a href=\"http://mesos.apache.org/\">Mesos</a></h4>"},{"title":"redis知识点整理","date":"2022-09-28T07:19:02.000Z","_content":"redis知识点整理\n<!--more-->\n## 面试题\n\n了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？\n\n## 面试官心理分析\n\n其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。\n\n## 面试题剖析\n\n### 缓存雪崩(Cache Avalanche)\n\n对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。\n\n这就是缓存雪崩。\n\n![redis知识点整理](redis-caching-avalanche.png)\n\n大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。\n\n缓存雪崩的事前事中事后的解决方案如下：\n\n- 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。\n- 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。\n- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n![redis知识点整理](redis-caching-avalanche-solution.png)\n\n用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。\n\n限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？**走降级**！可以返回一些默认的值，或者友情提示，或者空值。\n\n好处：\n\n- 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。\n- 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。\n- 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。\n\n### 缓存穿透(Cache Penetration)\n\n对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。\n\n黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。\n\n举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“**视缓存于无物**”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。\n\n![redis知识点整理](redis-caching-penetration.png)\n\n解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN` 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。\n\n当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：\n\n- 请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。\n- 请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。\n\n使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。\n\n![redis知识点整理](redis-caching-avoid-penetration.png)\n\n### 缓存击穿(Hotspot Invalid)\n\n缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。\n\n不同场景下的解决方式可如下：\n\n- 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。\n- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。\n- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。\n\n## 面试题\n\n如何保证缓存与数据库的双写一致性？\n\n## 面试官心理分析\n\n你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？\n\n## 面试题剖析\n\n一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统**不是严格要求** “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：**读请求和写请求串行化**，串到一个**内存队列**里去。\n\n串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。\n\n### Cache Aside Pattern\n\n最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。\n\n- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。\n- 更新的时候，**先更新数据库，然后再删除缓存**。\n\n**为什么是删除缓存，而不是更新缓存？**\n\n原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。\n\n比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。\n\n另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**\n\n举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**\n\n其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。\n\n### 最初级的缓存不一致问题及解决方案\n\n问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。\n\n![redis知识点整理](redis-junior-inconsistent.png)\n\n解决思路 1：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。\n\n解决思路 2：延时双删。依旧是先更新数据库，再删除缓存，唯一不同的是，我们把这个删除的动作，在不久之后再执行一次，比如 5s 之后。\n\n```java\npublic void set(key, value) {\n    putToDb(key, value);\n    deleteFromRedis(key);\n\n    // ... a few seconds later\n    deleteFromRedis(key);\n}\n```\n\n删除的动作，可以有多种选择，比如：1. 使用 `DelayQueue`，会随着 JVM 进程的死亡，丢失更新的风险；2. 放在 `MQ`，但编码复杂度为增加。总之，我们需要综合各种因素去做设计，选择一个最合理的解决方案。\n\n### 比较复杂的数据不一致问题分析\n\n数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据**，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...\n\n**为什么上亿流量高并发场景下，缓存会出现这个问题？**\n\n只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就**可能会出现上述的数据库+缓存不一致的情况**。\n\n**解决方案如下：**\n\n更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。\n\n一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。\n\n这里有一个**优化点**，一个队列中，其实**多个更新缓存请求串在一起是没意义的**，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。\n\n待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。\n\n如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。\n\n高并发的场景下，该解决方案要注意的问题：\n\n- 读请求长时阻塞\n\n由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。\n\n该解决方案，最大的风险点在于说，**可能数据更新很频繁**，导致队列中积压了大量更新操作在里面，然后**读请求会发生大量的超时**，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。\n\n另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要**部署多个服务**，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 \\* 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致**读请求的长时阻塞**。\n\n一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。\n\n**如果一个内存队列中可能积压的更新操作特别多**，那么你就要**加机器**，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。\n\n其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。\n\n我们来**实际粗略测算一下**。\n\n如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。\n\n经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。\n\n- 读请求并发量过高\n\n这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。\n\n但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。\n\n- 多服务实例部署的请求路由\n\n可能这个服务部署了多个实例，那么必须**保证**说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器**路由到相同的服务实例上**。\n\n比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。\n\n- 热点商品的路由问题，导致请求的倾斜\n\n万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。\n\n\n## 面试题\n\nRedis 都有哪些数据类型？分别在哪些场景下使用比较合适？\n\n## 面试官心理分析\n\n除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。\n\n其实问这个问题，主要有两个原因：\n\n- 看看你到底有没有全面的了解 Redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；\n- 看看你在实际项目里都怎么玩儿过 Redis。\n\n要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。\n\n## 面试题剖析\n\nRedis 主要有以下几种数据类型：\n\n- Strings\n- Hashes\n- Lists\n- Sets\n- Sorted Sets\n\n> Redis 除了这 5 种数据类型之外，还有 Bitmaps、HyperLogLogs、Streams 等。\n\n### Strings\n\n这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。\n\n```bash\nset college szu\n```\n\n### Hashes\n\n这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的**某个字段**。\n\n```bash\nhset person name bingo\nhset person age 20\nhset person id 1\nhget person name\n```\n\n```json\n(person = {\n  \"name\": \"bingo\",\n  \"age\": 20,\n  \"id\": 1\n})\n```\n\n### Lists\n\nLists 是有序列表，这个可以玩儿出很多花样。\n\n比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。\n\n比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。\n\n```bash\n# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n```\n\n比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。\n\n```bash\nlpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n```\n\n### Sets\n\nSets 是无序集合，自动去重。\n\n直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。\n\n可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。\n\n把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。\n\n```bash\n#-------操作一个set-------\n# 添加元素\nsadd mySet 1\n\n# 查看全部元素\nsmembers mySet\n\n# 判断是否包含某个值\nsismember mySet 3\n\n# 删除某个/些元素\nsrem mySet 1\nsrem mySet 2 4\n\n# 查看元素个数\nscard mySet\n\n# 随机删除一个元素\nspop mySet\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourSet mySet 2\n\n# 求两set的交集\nsinter yourSet mySet\n\n# 求两set的并集\nsunion yourSet mySet\n\n# 求在yourSet中而不在mySet中的元素\nsdiff yourSet mySet\n```\n\n### Sorted Sets\n\nSorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。\n\n```bash\nzadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n```\n## 面试题\n\nRedis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？\n\n## 面试官心理分析\n\n如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 Redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？\n\n常见的有两个问题：\n\n- 往 Redis 写入的数据怎么没了？\n\n可能有同学会遇到，在生产环境的 Redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 Redis 你就没用对啊。Redis 是缓存，你给当存储了是吧？\n\n啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。Redis 主要是基于内存来进行高性能、高并发的读写操作的。\n\n那既然内存是有限的，比如 Redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。\n\n- 数据明明过期了，怎么还占用着内存？\n\n这是由 Redis 的过期策略来决定。\n\n## 面试题剖析\n\n### Redis 过期策略\n\nRedis 过期策略是：**定期删除+惰性删除**。\n\n所谓**定期删除**，指的是 Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。\n\n假设 Redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 Redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的**灾难**。实际上 Redis 是每隔 100ms **随机抽取**一些 key 来检查和删除的。\n\n但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，Redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。\n\n> 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。\n\n但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 Redis 内存块耗尽了，咋整？\n\n答案是：**走内存淘汰机制**。\n\n### 内存淘汰机制\n\nRedis 内存淘汰机制有以下几个：\n\n- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。\n- **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）。\n- allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。\n- volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）。\n- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。\n- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除。\n\n### 手写一个 LRU 算法\n\nLRU 就是 Least Recently Used 的缩写，翻译过来就是“最近最少使用”。也就是说 LRU 算法会将最近最少用的缓存移除，让给最新使用的缓存。而往往最常读取的，也就是读取次数最多的，所以利用好 LRU 算法，我们能够提供对热点数据的缓存效率，能够提高缓存服务的内存使用率。\n\n那么如何实现呢？\n\n其实，实现的思路非常简单，就像下面这张图种描述的一样。\n\n![redis知识点整理](lru.png)\n\n你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。\n\n不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。\n\n![redis知识点整理](lru-cache.png)\n\n```java\npublic class LRUCache<K, V> extends LinkedHashMap<K, V> {\n    private int capacity;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param capacity 缓存大小\n     */\n    public LRUCache(int capacity) {\n        super(capacity, 0.75f, true);\n        this.capacity = capacity;\n    }\n\n    /**\n     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据\n     *\n     * @param eldest 最老的数据项\n     * @return true则移除最老的数据\n     */\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {\n        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据\n        return size() > capacity;\n    }\n}\n```\n\n## Redis 主从架构\n\n单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑**读高并发**的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的**读请求全部走从节点**。这样也可以很轻松实现水平扩容，**支撑读高并发**。\n\n![redis知识点整理](redis-master-slave.png)\n\nRedis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发\n\n## Redis replication 的核心机制\n\n- Redis 采用**异步方式**复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；\n- 一个 master node 是可以配置多个 slave node 的；\n- slave node 也可以连接其他的 slave node；\n- slave node 做复制的时候，不会 block master node 的正常工作；\n- slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；\n- slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。\n\n注意，如果采用了主从架构，那么建议必须**开启** master node 的 [持久化](#Redis的持久化有哪几种方式)，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。\n\n另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能**确保启动的时候，是有数据的**，即使采用了后续讲解的[高可用机制](#Redis-哨兵集群实现高可用)，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。\n\n## Redis 主从复制的核心原理\n\n当启动一个 slave node 的时候，它会发送一个 `PSYNC` 命令给 master node。\n\n如果这是 slave node 初次连接到 master node，那么会触发一次 `full resynchronization` 全量复制。此时 master 会启动一个后台线程，开始生成一份 `RDB` 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 `RDB` 文件生成完毕后， master 会将这个 `RDB` 发送给 slave，slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存**中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。\n\n![redis知识点整理](redis-master-slave-replication.png)\n\n### 主从复制的断点续传\n\n从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。\n\nmaster node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 `resynchronization` 。\n\n> 如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。\n\n### 无磁盘化复制\n\nmaster 在内存中直接创建 `RDB` ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 `repl-diskless-sync yes` 即可。\n\n```bash\nrepl-diskless-sync yes\n\n# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来\nrepl-diskless-sync-delay 5\n```\n\n### 过期 key 处理\n\nslave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。\n\n## 复制的完整流程\n\nslave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 `host` 和 `ip` ，但是复制流程没开始。\n\nslave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 `ping` 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node **第一次执行全量复制**，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。\n\n![redis知识点整理](redis-master-slave-replication-detail.png)\n\n### 全量复制\n\n- master 执行 bgsave ，在本地生成一份 rdb 快照文件。\n- master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)\n- master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。\n- 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。\n\n```bash\nclient-output-buffer-limit slave 256MB 64MB 60\n```\n\n- slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中。注意，在清空旧数据之前，slave node 依然会**基于旧的数据版本**对外提供服务。\n- 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。\n\n### 增量复制\n\n- 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。\n- master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。\n- master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。\n\n### heartbeat\n\n主从节点互相都会发送 heartbeat 信息。\n\nmaster 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。\n\n### 异步复制\n\nmaster 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。\n\n## Redis 如何才能做到高可用\n\n如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。\n\n一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。\n\n但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。\n\nRedis 的高可用架构，叫做 `failover` **故障转移**，也可以叫做主备切换。\n\nmaster node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用。\n\n\n## Redis的持久化有哪几种方式\n\nRedis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？\n\n## 面试官心理分析\n\nRedis 如果仅仅只是将数据缓存在内存里面，如果 Redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 Redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。\n\n如果 Redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。\n\n这个其实一样，针对的都是 Redis 的生产环境可能遇到的一些问题，就是 Redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？\n\n## 面试题剖析\n\n持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 Redis 整个挂了，然后 Redis 就不可用了，你要做的事情就是让 Redis 变得可用，尽快变得可用。\n\n重启 Redis，尽快让它对外提供服务，如果没做数据备份，这时候 Redis 启动了，也不可用啊，数据都没了。\n\n很可能说，大量的请求过来，缓存全部无法命中，在 Redis 里根本找不到数据，这个时候就死定了，出现**缓存雪崩**问题。所有请求没有在 Redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了...\n\n如果你把 Redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 Redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。\n\n### Redis 持久化的两种方式\n\n- RDB：RDB 持久化机制，是对 Redis 中的数据执行**周期性**的持久化。\n- AOF：AOF 机制对每条写入命令作为日志，以 `append-only` 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过**回放** AOF 日志中的写入指令来重新构建整个数据集。\n\n通过 RDB 或 AOF，都可以将 Redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。\n\n如果 Redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 Redis，Redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。\n\n如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。\n\n#### RDB 优缺点\n\n- RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，**非常适合做冷备**，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 Redis 中的数据。\n- RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis **保持高性能**，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。\n- 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。\n- 如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟（甚至更长时间）的数据。\n- RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。\n\n#### AOF 优缺点\n\n- AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。\n- AOF 日志文件以 `append-only` 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。\n- AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 `rewrite` log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。\n- AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常**适合做灾难性的误删除的紧急恢复**。比如某人不小心用 `flushall` 命令清空了所有数据，只要这个时候后台 `rewrite` 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 `flushall` 命令给删了，然后再将该 `AOF` 文件放回去，就可以通过恢复机制，自动恢复所有数据。\n- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。\n- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 `fsync` 一次日志文件，当然，每秒一次 `fsync` ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）\n- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 `merge` 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是**基于当时内存中的数据进行指令的重新构建**，这样健壮性会好很多。\n\n### RDB 和 AOF 到底该如何选择\n\n- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；\n- 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；\n- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。\n\n## Redis 哨兵集群实现高可用\n\n## 哨兵的介绍\n\nsentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：\n\n- 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。\n- 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。\n- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。\n- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。\n\n哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。\n\n- 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。\n- 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。\n\n## 哨兵的核心知识\n\n- 哨兵至少需要 3 个实例，来保证自己的健壮性。\n- 哨兵 + Redis 主从的部署架构，是**不保证数据零丢失**的，只能保证 Redis 集群的高可用性。\n- 对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。\n\n哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。\n\n```\n+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n```\n\n配置 `quorum=1` ，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。\n\n```\n2 个哨兵，majority=2\n3 个哨兵，majority=2\n4 个哨兵，majority=2\n5 个哨兵，majority=3\n...\n```\n\n如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。\n\n经典的 3 节点哨兵集群是这样的：\n\n```\n       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n```\n\n配置 `quorum=2` ，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。\n\n## Redis 哨兵主备切换的数据丢失问题\n\n### 导致数据丢失的两种情况\n\n主备切换的过程，可能会导致数据丢失：\n\n- 异步复制导致的数据丢失\n\n因为 master->slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。\n\n![redis知识点整理](async-replication-data-lose-case.png)\n\n- 脑裂导致的数据丢失\n\n脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。\n\n此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。\n\n![redis知识点整理](redis-cluster-split-brain.png)\n\n### 数据丢失问题的解决方案\n\n进行如下配置：\n\n```bash\nmin-slaves-to-write 1\nmin-slaves-max-lag 10\n```\n\n表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。\n\n如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。\n\n- 减少异步复制数据的丢失\n\n有了 `min-slaves-max-lag` 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。\n\n- 减少脑裂的数据丢失\n\n如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。\n\n## sdown 和 odown 转换机制\n\n- sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机\n- odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机\n\nsdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 `is-master-down-after-milliseconds` 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。\n\n## 哨兵集群的自动发现机制\n\n哨兵互相之间的发现，是通过 Redis 的 `pub/sub` 系统实现的，每个哨兵都会往 `__sentinel__:hello` 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。\n\n每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 `__sentinel__:hello` channel 里**发送一个消息**，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。\n\n每个哨兵也会去**监听**自己监控的每个 master+slaves 对应的 `__sentinel__:hello` channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。\n\n每个哨兵还会跟其他哨兵交换对 `master` 的监控配置，互相进行监控配置的同步。\n\n## slave 配置的自动纠正\n\n哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。\n\n## slave->master 选举算法\n\n如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：\n\n- 跟 master 断开连接的时长\n- slave 优先级\n- 复制 offset\n- run id\n\n如果一个 slave 跟 master 断开连接的时间已经超过了 `down-after-milliseconds` 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。\n\n```\n(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n```\n\n接下来会对 slave 进行排序：\n\n- 按照 slave 优先级进行排序，slave priority 越低，优先级就越高。\n- 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。\n- 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。\n\n## quorum 和 majority\n\n每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。\n\n如果 quorum < majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。\n\n但是如果 quorum >= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。\n\n## configuration epoch\n\n哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。\n\n执行切换的那个哨兵，会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。\n\n如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。\n\n## configuration 传播\n\n哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 `pub/sub` 消息机制。\n\n这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。\n\n## 面试题\n\nRedis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么 Redis 单线程却能支撑高并发？\n\n## 面试官心理分析\n\n这个是问 Redis 的时候，最基本的问题吧，Redis 最基本的一个内部原理和特点，就是 Redis 实际上是个**单线程工作模型**，你要是这个都不知道，那后面玩儿 Redis 的时候，出了问题岂不是什么都不知道？\n\n还有可能面试官会问问你 Redis 和 Memcached 的区别，但是 Memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 Redis，没什么公司用 Memcached 了。\n\n## 面试题剖析\n\n### Redis 和 Memcached 有啥区别？\n\n#### Redis 支持复杂的数据结构\n\nRedis 相比 Memcached 来说，拥有[更多的数据结构](Redis-都有哪些数据类型)，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。\n\n#### Redis 原生支持集群模式\n\n在 Redis3.x 版本中，便能支持 cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。\n\n#### 性能对比\n\n由于 Redis 只使用**单核**，而 Memcached 可以使用**多核**，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。\n\n### Redis 的线程模型\n\nRedis 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。\n\n文件事件处理器的结构包含 4 个部分：\n\n- 多个 socket\n- IO 多路复用程序\n- 文件事件分派器\n- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。\n\n来看客户端与 Redis 的一次通信过程：\n\n![redis知识点整理](redis-single-thread-model.png)\n\n要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。\n\n首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。\n\n客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。\n\n假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。\n\n如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。\n\n这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《[Redis 设计与实现——黄健宏](https://github.com/doocs/technical-books#database)》进行系统学习。\n\n### 为啥 Redis 单线程模型也能效率这么高？\n\n- 纯内存操作。\n- 核心是基于非阻塞的 IO 多路复用机制。\n- C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。\n- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。\n\n### Redis 6.0 开始引入多线程\n\n**注意！** Redis 6.0 之后的版本抛弃了单线程模型这一设计，**原本使用单线程运行的 Redis 也开始选择性地使用多线程模型**。\n\n前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。\n\n**Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。** 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。\n\n### 总结\n\nRedis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间(释放操作不会阻塞网络 IO 读写,因为网络 IO 读写与释放的命令执行不是同一个线程)也能减少对 Redis 主线程阻塞的时间，提高执行的效率。\n","source":"_posts/redis知识点整理.md","raw":"---\ntitle: redis知识点整理\ndate: 2022-09-28 15:19:02\ntags:\n- redis\n---\nredis知识点整理\n<!--more-->\n## 面试题\n\n了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？\n\n## 面试官心理分析\n\n其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。\n\n## 面试题剖析\n\n### 缓存雪崩(Cache Avalanche)\n\n对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。\n\n这就是缓存雪崩。\n\n![redis知识点整理](redis-caching-avalanche.png)\n\n大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。\n\n缓存雪崩的事前事中事后的解决方案如下：\n\n- 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。\n- 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。\n- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n![redis知识点整理](redis-caching-avalanche-solution.png)\n\n用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。\n\n限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？**走降级**！可以返回一些默认的值，或者友情提示，或者空值。\n\n好处：\n\n- 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。\n- 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。\n- 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。\n\n### 缓存穿透(Cache Penetration)\n\n对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。\n\n黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。\n\n举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“**视缓存于无物**”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。\n\n![redis知识点整理](redis-caching-penetration.png)\n\n解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN` 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。\n\n当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：\n\n- 请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。\n- 请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。\n\n使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。\n\n![redis知识点整理](redis-caching-avoid-penetration.png)\n\n### 缓存击穿(Hotspot Invalid)\n\n缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。\n\n不同场景下的解决方式可如下：\n\n- 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。\n- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。\n- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。\n\n## 面试题\n\n如何保证缓存与数据库的双写一致性？\n\n## 面试官心理分析\n\n你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？\n\n## 面试题剖析\n\n一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统**不是严格要求** “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：**读请求和写请求串行化**，串到一个**内存队列**里去。\n\n串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。\n\n### Cache Aside Pattern\n\n最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。\n\n- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。\n- 更新的时候，**先更新数据库，然后再删除缓存**。\n\n**为什么是删除缓存，而不是更新缓存？**\n\n原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。\n\n比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。\n\n另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**\n\n举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**\n\n其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。\n\n### 最初级的缓存不一致问题及解决方案\n\n问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。\n\n![redis知识点整理](redis-junior-inconsistent.png)\n\n解决思路 1：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。\n\n解决思路 2：延时双删。依旧是先更新数据库，再删除缓存，唯一不同的是，我们把这个删除的动作，在不久之后再执行一次，比如 5s 之后。\n\n```java\npublic void set(key, value) {\n    putToDb(key, value);\n    deleteFromRedis(key);\n\n    // ... a few seconds later\n    deleteFromRedis(key);\n}\n```\n\n删除的动作，可以有多种选择，比如：1. 使用 `DelayQueue`，会随着 JVM 进程的死亡，丢失更新的风险；2. 放在 `MQ`，但编码复杂度为增加。总之，我们需要综合各种因素去做设计，选择一个最合理的解决方案。\n\n### 比较复杂的数据不一致问题分析\n\n数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据**，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...\n\n**为什么上亿流量高并发场景下，缓存会出现这个问题？**\n\n只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就**可能会出现上述的数据库+缓存不一致的情况**。\n\n**解决方案如下：**\n\n更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。\n\n一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。\n\n这里有一个**优化点**，一个队列中，其实**多个更新缓存请求串在一起是没意义的**，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。\n\n待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。\n\n如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。\n\n高并发的场景下，该解决方案要注意的问题：\n\n- 读请求长时阻塞\n\n由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。\n\n该解决方案，最大的风险点在于说，**可能数据更新很频繁**，导致队列中积压了大量更新操作在里面，然后**读请求会发生大量的超时**，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。\n\n另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要**部署多个服务**，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 \\* 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致**读请求的长时阻塞**。\n\n一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。\n\n**如果一个内存队列中可能积压的更新操作特别多**，那么你就要**加机器**，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。\n\n其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。\n\n我们来**实际粗略测算一下**。\n\n如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。\n\n经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。\n\n- 读请求并发量过高\n\n这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。\n\n但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。\n\n- 多服务实例部署的请求路由\n\n可能这个服务部署了多个实例，那么必须**保证**说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器**路由到相同的服务实例上**。\n\n比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。\n\n- 热点商品的路由问题，导致请求的倾斜\n\n万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。\n\n\n## 面试题\n\nRedis 都有哪些数据类型？分别在哪些场景下使用比较合适？\n\n## 面试官心理分析\n\n除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。\n\n其实问这个问题，主要有两个原因：\n\n- 看看你到底有没有全面的了解 Redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；\n- 看看你在实际项目里都怎么玩儿过 Redis。\n\n要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。\n\n## 面试题剖析\n\nRedis 主要有以下几种数据类型：\n\n- Strings\n- Hashes\n- Lists\n- Sets\n- Sorted Sets\n\n> Redis 除了这 5 种数据类型之外，还有 Bitmaps、HyperLogLogs、Streams 等。\n\n### Strings\n\n这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。\n\n```bash\nset college szu\n```\n\n### Hashes\n\n这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的**某个字段**。\n\n```bash\nhset person name bingo\nhset person age 20\nhset person id 1\nhget person name\n```\n\n```json\n(person = {\n  \"name\": \"bingo\",\n  \"age\": 20,\n  \"id\": 1\n})\n```\n\n### Lists\n\nLists 是有序列表，这个可以玩儿出很多花样。\n\n比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。\n\n比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。\n\n```bash\n# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n```\n\n比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。\n\n```bash\nlpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n```\n\n### Sets\n\nSets 是无序集合，自动去重。\n\n直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。\n\n可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。\n\n把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。\n\n```bash\n#-------操作一个set-------\n# 添加元素\nsadd mySet 1\n\n# 查看全部元素\nsmembers mySet\n\n# 判断是否包含某个值\nsismember mySet 3\n\n# 删除某个/些元素\nsrem mySet 1\nsrem mySet 2 4\n\n# 查看元素个数\nscard mySet\n\n# 随机删除一个元素\nspop mySet\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourSet mySet 2\n\n# 求两set的交集\nsinter yourSet mySet\n\n# 求两set的并集\nsunion yourSet mySet\n\n# 求在yourSet中而不在mySet中的元素\nsdiff yourSet mySet\n```\n\n### Sorted Sets\n\nSorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。\n\n```bash\nzadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n```\n## 面试题\n\nRedis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？\n\n## 面试官心理分析\n\n如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 Redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？\n\n常见的有两个问题：\n\n- 往 Redis 写入的数据怎么没了？\n\n可能有同学会遇到，在生产环境的 Redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 Redis 你就没用对啊。Redis 是缓存，你给当存储了是吧？\n\n啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。Redis 主要是基于内存来进行高性能、高并发的读写操作的。\n\n那既然内存是有限的，比如 Redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。\n\n- 数据明明过期了，怎么还占用着内存？\n\n这是由 Redis 的过期策略来决定。\n\n## 面试题剖析\n\n### Redis 过期策略\n\nRedis 过期策略是：**定期删除+惰性删除**。\n\n所谓**定期删除**，指的是 Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。\n\n假设 Redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 Redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的**灾难**。实际上 Redis 是每隔 100ms **随机抽取**一些 key 来检查和删除的。\n\n但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，Redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。\n\n> 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。\n\n但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 Redis 内存块耗尽了，咋整？\n\n答案是：**走内存淘汰机制**。\n\n### 内存淘汰机制\n\nRedis 内存淘汰机制有以下几个：\n\n- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。\n- **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）。\n- allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。\n- volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）。\n- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。\n- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除。\n\n### 手写一个 LRU 算法\n\nLRU 就是 Least Recently Used 的缩写，翻译过来就是“最近最少使用”。也就是说 LRU 算法会将最近最少用的缓存移除，让给最新使用的缓存。而往往最常读取的，也就是读取次数最多的，所以利用好 LRU 算法，我们能够提供对热点数据的缓存效率，能够提高缓存服务的内存使用率。\n\n那么如何实现呢？\n\n其实，实现的思路非常简单，就像下面这张图种描述的一样。\n\n![redis知识点整理](lru.png)\n\n你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。\n\n不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。\n\n![redis知识点整理](lru-cache.png)\n\n```java\npublic class LRUCache<K, V> extends LinkedHashMap<K, V> {\n    private int capacity;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param capacity 缓存大小\n     */\n    public LRUCache(int capacity) {\n        super(capacity, 0.75f, true);\n        this.capacity = capacity;\n    }\n\n    /**\n     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据\n     *\n     * @param eldest 最老的数据项\n     * @return true则移除最老的数据\n     */\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {\n        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据\n        return size() > capacity;\n    }\n}\n```\n\n## Redis 主从架构\n\n单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑**读高并发**的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的**读请求全部走从节点**。这样也可以很轻松实现水平扩容，**支撑读高并发**。\n\n![redis知识点整理](redis-master-slave.png)\n\nRedis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发\n\n## Redis replication 的核心机制\n\n- Redis 采用**异步方式**复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；\n- 一个 master node 是可以配置多个 slave node 的；\n- slave node 也可以连接其他的 slave node；\n- slave node 做复制的时候，不会 block master node 的正常工作；\n- slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；\n- slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。\n\n注意，如果采用了主从架构，那么建议必须**开启** master node 的 [持久化](#Redis的持久化有哪几种方式)，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。\n\n另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能**确保启动的时候，是有数据的**，即使采用了后续讲解的[高可用机制](#Redis-哨兵集群实现高可用)，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。\n\n## Redis 主从复制的核心原理\n\n当启动一个 slave node 的时候，它会发送一个 `PSYNC` 命令给 master node。\n\n如果这是 slave node 初次连接到 master node，那么会触发一次 `full resynchronization` 全量复制。此时 master 会启动一个后台线程，开始生成一份 `RDB` 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 `RDB` 文件生成完毕后， master 会将这个 `RDB` 发送给 slave，slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存**中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。\n\n![redis知识点整理](redis-master-slave-replication.png)\n\n### 主从复制的断点续传\n\n从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。\n\nmaster node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 `resynchronization` 。\n\n> 如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。\n\n### 无磁盘化复制\n\nmaster 在内存中直接创建 `RDB` ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 `repl-diskless-sync yes` 即可。\n\n```bash\nrepl-diskless-sync yes\n\n# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来\nrepl-diskless-sync-delay 5\n```\n\n### 过期 key 处理\n\nslave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。\n\n## 复制的完整流程\n\nslave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 `host` 和 `ip` ，但是复制流程没开始。\n\nslave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 `ping` 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node **第一次执行全量复制**，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。\n\n![redis知识点整理](redis-master-slave-replication-detail.png)\n\n### 全量复制\n\n- master 执行 bgsave ，在本地生成一份 rdb 快照文件。\n- master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)\n- master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。\n- 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。\n\n```bash\nclient-output-buffer-limit slave 256MB 64MB 60\n```\n\n- slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中。注意，在清空旧数据之前，slave node 依然会**基于旧的数据版本**对外提供服务。\n- 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。\n\n### 增量复制\n\n- 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。\n- master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。\n- master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。\n\n### heartbeat\n\n主从节点互相都会发送 heartbeat 信息。\n\nmaster 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。\n\n### 异步复制\n\nmaster 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。\n\n## Redis 如何才能做到高可用\n\n如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。\n\n一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。\n\n但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。\n\nRedis 的高可用架构，叫做 `failover` **故障转移**，也可以叫做主备切换。\n\nmaster node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用。\n\n\n## Redis的持久化有哪几种方式\n\nRedis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？\n\n## 面试官心理分析\n\nRedis 如果仅仅只是将数据缓存在内存里面，如果 Redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 Redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。\n\n如果 Redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。\n\n这个其实一样，针对的都是 Redis 的生产环境可能遇到的一些问题，就是 Redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？\n\n## 面试题剖析\n\n持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 Redis 整个挂了，然后 Redis 就不可用了，你要做的事情就是让 Redis 变得可用，尽快变得可用。\n\n重启 Redis，尽快让它对外提供服务，如果没做数据备份，这时候 Redis 启动了，也不可用啊，数据都没了。\n\n很可能说，大量的请求过来，缓存全部无法命中，在 Redis 里根本找不到数据，这个时候就死定了，出现**缓存雪崩**问题。所有请求没有在 Redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了...\n\n如果你把 Redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 Redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。\n\n### Redis 持久化的两种方式\n\n- RDB：RDB 持久化机制，是对 Redis 中的数据执行**周期性**的持久化。\n- AOF：AOF 机制对每条写入命令作为日志，以 `append-only` 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过**回放** AOF 日志中的写入指令来重新构建整个数据集。\n\n通过 RDB 或 AOF，都可以将 Redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。\n\n如果 Redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 Redis，Redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。\n\n如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。\n\n#### RDB 优缺点\n\n- RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，**非常适合做冷备**，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 Redis 中的数据。\n- RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis **保持高性能**，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。\n- 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。\n- 如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟（甚至更长时间）的数据。\n- RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。\n\n#### AOF 优缺点\n\n- AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。\n- AOF 日志文件以 `append-only` 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。\n- AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 `rewrite` log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。\n- AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常**适合做灾难性的误删除的紧急恢复**。比如某人不小心用 `flushall` 命令清空了所有数据，只要这个时候后台 `rewrite` 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 `flushall` 命令给删了，然后再将该 `AOF` 文件放回去，就可以通过恢复机制，自动恢复所有数据。\n- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。\n- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 `fsync` 一次日志文件，当然，每秒一次 `fsync` ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）\n- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 `merge` 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是**基于当时内存中的数据进行指令的重新构建**，这样健壮性会好很多。\n\n### RDB 和 AOF 到底该如何选择\n\n- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；\n- 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；\n- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。\n\n## Redis 哨兵集群实现高可用\n\n## 哨兵的介绍\n\nsentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：\n\n- 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。\n- 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。\n- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。\n- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。\n\n哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。\n\n- 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。\n- 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。\n\n## 哨兵的核心知识\n\n- 哨兵至少需要 3 个实例，来保证自己的健壮性。\n- 哨兵 + Redis 主从的部署架构，是**不保证数据零丢失**的，只能保证 Redis 集群的高可用性。\n- 对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。\n\n哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。\n\n```\n+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n```\n\n配置 `quorum=1` ，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。\n\n```\n2 个哨兵，majority=2\n3 个哨兵，majority=2\n4 个哨兵，majority=2\n5 个哨兵，majority=3\n...\n```\n\n如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。\n\n经典的 3 节点哨兵集群是这样的：\n\n```\n       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n```\n\n配置 `quorum=2` ，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。\n\n## Redis 哨兵主备切换的数据丢失问题\n\n### 导致数据丢失的两种情况\n\n主备切换的过程，可能会导致数据丢失：\n\n- 异步复制导致的数据丢失\n\n因为 master->slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。\n\n![redis知识点整理](async-replication-data-lose-case.png)\n\n- 脑裂导致的数据丢失\n\n脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。\n\n此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。\n\n![redis知识点整理](redis-cluster-split-brain.png)\n\n### 数据丢失问题的解决方案\n\n进行如下配置：\n\n```bash\nmin-slaves-to-write 1\nmin-slaves-max-lag 10\n```\n\n表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。\n\n如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。\n\n- 减少异步复制数据的丢失\n\n有了 `min-slaves-max-lag` 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。\n\n- 减少脑裂的数据丢失\n\n如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。\n\n## sdown 和 odown 转换机制\n\n- sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机\n- odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机\n\nsdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 `is-master-down-after-milliseconds` 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。\n\n## 哨兵集群的自动发现机制\n\n哨兵互相之间的发现，是通过 Redis 的 `pub/sub` 系统实现的，每个哨兵都会往 `__sentinel__:hello` 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。\n\n每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 `__sentinel__:hello` channel 里**发送一个消息**，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。\n\n每个哨兵也会去**监听**自己监控的每个 master+slaves 对应的 `__sentinel__:hello` channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。\n\n每个哨兵还会跟其他哨兵交换对 `master` 的监控配置，互相进行监控配置的同步。\n\n## slave 配置的自动纠正\n\n哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。\n\n## slave->master 选举算法\n\n如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：\n\n- 跟 master 断开连接的时长\n- slave 优先级\n- 复制 offset\n- run id\n\n如果一个 slave 跟 master 断开连接的时间已经超过了 `down-after-milliseconds` 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。\n\n```\n(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n```\n\n接下来会对 slave 进行排序：\n\n- 按照 slave 优先级进行排序，slave priority 越低，优先级就越高。\n- 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。\n- 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。\n\n## quorum 和 majority\n\n每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。\n\n如果 quorum < majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。\n\n但是如果 quorum >= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。\n\n## configuration epoch\n\n哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。\n\n执行切换的那个哨兵，会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。\n\n如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。\n\n## configuration 传播\n\n哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 `pub/sub` 消息机制。\n\n这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。\n\n## 面试题\n\nRedis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么 Redis 单线程却能支撑高并发？\n\n## 面试官心理分析\n\n这个是问 Redis 的时候，最基本的问题吧，Redis 最基本的一个内部原理和特点，就是 Redis 实际上是个**单线程工作模型**，你要是这个都不知道，那后面玩儿 Redis 的时候，出了问题岂不是什么都不知道？\n\n还有可能面试官会问问你 Redis 和 Memcached 的区别，但是 Memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 Redis，没什么公司用 Memcached 了。\n\n## 面试题剖析\n\n### Redis 和 Memcached 有啥区别？\n\n#### Redis 支持复杂的数据结构\n\nRedis 相比 Memcached 来说，拥有[更多的数据结构](Redis-都有哪些数据类型)，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。\n\n#### Redis 原生支持集群模式\n\n在 Redis3.x 版本中，便能支持 cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。\n\n#### 性能对比\n\n由于 Redis 只使用**单核**，而 Memcached 可以使用**多核**，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。\n\n### Redis 的线程模型\n\nRedis 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。\n\n文件事件处理器的结构包含 4 个部分：\n\n- 多个 socket\n- IO 多路复用程序\n- 文件事件分派器\n- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。\n\n来看客户端与 Redis 的一次通信过程：\n\n![redis知识点整理](redis-single-thread-model.png)\n\n要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。\n\n首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。\n\n客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。\n\n假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。\n\n如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。\n\n这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《[Redis 设计与实现——黄健宏](https://github.com/doocs/technical-books#database)》进行系统学习。\n\n### 为啥 Redis 单线程模型也能效率这么高？\n\n- 纯内存操作。\n- 核心是基于非阻塞的 IO 多路复用机制。\n- C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。\n- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。\n\n### Redis 6.0 开始引入多线程\n\n**注意！** Redis 6.0 之后的版本抛弃了单线程模型这一设计，**原本使用单线程运行的 Redis 也开始选择性地使用多线程模型**。\n\n前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。\n\n**Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。** 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。\n\n### 总结\n\nRedis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间(释放操作不会阻塞网络 IO 读写,因为网络 IO 读写与释放的命令执行不是同一个线程)也能减少对 Redis 主线程阻塞的时间，提高执行的效率。\n","slug":"redis知识点整理","published":1,"updated":"2022-09-28T09:26:34.485Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0kw000cekwe9s337wt6","content":"<p>redis知识点整理</p>\n<span id=\"more\"></span>\n<h2 id=\"面试题\"><a href=\"#面试题\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？</p>\n<h2 id=\"面试官心理分析\"><a href=\"#面试官心理分析\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。</p>\n<h2 id=\"面试题剖析\"><a href=\"#面试题剖析\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"缓存雪崩-Cache-Avalanche\"><a href=\"#缓存雪崩-Cache-Avalanche\" class=\"headerlink\" title=\"缓存雪崩(Cache Avalanche)\"></a>缓存雪崩(Cache Avalanche)</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p>\n<p>这就是缓存雪崩。</p>\n<p><img src=\"redis-caching-avalanche.png\" alt=\"redis知识点整理\"></p>\n<p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p>\n<p>缓存雪崩的事前事中事后的解决方案如下：</p>\n<ul>\n<li>事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。</li>\n<li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li>\n<li>事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li>\n</ul>\n<p><img src=\"redis-caching-avalanche-solution.png\" alt=\"redis知识点整理\"></p>\n<p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。</p>\n<p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p>\n<p>好处：</p>\n<ul>\n<li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li>\n<li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li>\n<li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li>\n</ul>\n<h3 id=\"缓存穿透-Cache-Penetration\"><a href=\"#缓存穿透-Cache-Penetration\" class=\"headerlink\" title=\"缓存穿透(Cache Penetration)\"></a>缓存穿透(Cache Penetration)</h3><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p>\n<p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p>\n<p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p>\n<p><img src=\"redis-caching-penetration.png\" alt=\"redis知识点整理\"></p>\n<p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code> 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p>\n<p>当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：</p>\n<ul>\n<li>请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。</li>\n<li>请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。</li>\n</ul>\n<p>使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。</p>\n<p><img src=\"redis-caching-avoid-penetration.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"缓存击穿-Hotspot-Invalid\"><a href=\"#缓存击穿-Hotspot-Invalid\" class=\"headerlink\" title=\"缓存击穿(Hotspot Invalid)\"></a>缓存击穿(Hotspot Invalid)</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p>\n<p>不同场景下的解决方式可如下：</p>\n<ul>\n<li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li>\n<li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li>\n<li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li>\n</ul>\n<h2 id=\"面试题-1\"><a href=\"#面试题-1\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>如何保证缓存与数据库的双写一致性？</p>\n<h2 id=\"面试官心理分析-1\"><a href=\"#面试官心理分析-1\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>\n<h2 id=\"面试题剖析-1\"><a href=\"#面试题剖析-1\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p>\n<p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>\n<h3 id=\"Cache-Aside-Pattern\"><a href=\"#Cache-Aside-Pattern\" class=\"headerlink\" title=\"Cache Aside Pattern\"></a>Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p>\n<ul>\n<li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li>\n<li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li>\n</ul>\n<p><strong>为什么是删除缓存，而不是更新缓存？</strong></p>\n<p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p>\n<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p>\n<p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p>\n<p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p>\n<p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p>\n<h3 id=\"最初级的缓存不一致问题及解决方案\"><a href=\"#最初级的缓存不一致问题及解决方案\" class=\"headerlink\" title=\"最初级的缓存不一致问题及解决方案\"></a>最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p>\n<p><img src=\"redis-junior-inconsistent.png\" alt=\"redis知识点整理\"></p>\n<p>解决思路 1：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p>\n<p>解决思路 2：延时双删。依旧是先更新数据库，再删除缓存，唯一不同的是，我们把这个删除的动作，在不久之后再执行一次，比如 5s 之后。</p>\n<pre><code class=\"java\">public void set(key, value) &#123;\n    putToDb(key, value);\n    deleteFromRedis(key);\n\n    // ... a few seconds later\n    deleteFromRedis(key);\n&#125;\n</code></pre>\n<p>删除的动作，可以有多种选择，比如：1. 使用 <code>DelayQueue</code>，会随着 JVM 进程的死亡，丢失更新的风险；2. 放在 <code>MQ</code>，但编码复杂度为增加。总之，我们需要综合各种因素去做设计，选择一个最合理的解决方案。</p>\n<h3 id=\"比较复杂的数据不一致问题分析\"><a href=\"#比较复杂的数据不一致问题分析\" class=\"headerlink\" title=\"比较复杂的数据不一致问题分析\"></a>比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了…</p>\n<p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p>\n<p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p>\n<p><strong>解决方案如下：</strong></p>\n<p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。</p>\n<p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p>\n<p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p>\n<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p>\n<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p>\n<p>高并发的场景下，该解决方案要注意的问题：</p>\n<ul>\n<li>读请求长时阻塞</li>\n</ul>\n<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p>\n<p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p>\n<p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<strong>读请求的长时阻塞</strong>。</p>\n<p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p>\n<p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p>\n<p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p>\n<p>我们来<strong>实际粗略测算一下</strong>。</p>\n<p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p>\n<p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p>\n<ul>\n<li>读请求并发量过高</li>\n</ul>\n<p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p>\n<p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p>\n<ul>\n<li>多服务实例部署的请求路由</li>\n</ul>\n<p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p>\n<p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p>\n<ul>\n<li>热点商品的路由问题，导致请求的倾斜</li>\n</ul>\n<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p>\n<h2 id=\"面试题-2\"><a href=\"#面试题-2\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？</p>\n<h2 id=\"面试官心理分析-2\"><a href=\"#面试官心理分析-2\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。</p>\n<p>其实问这个问题，主要有两个原因：</p>\n<ul>\n<li>看看你到底有没有全面的了解 Redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；</li>\n<li>看看你在实际项目里都怎么玩儿过 Redis。</li>\n</ul>\n<p>要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。</p>\n<h2 id=\"面试题剖析-2\"><a href=\"#面试题剖析-2\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>Redis 主要有以下几种数据类型：</p>\n<ul>\n<li>Strings</li>\n<li>Hashes</li>\n<li>Lists</li>\n<li>Sets</li>\n<li>Sorted Sets</li>\n</ul>\n<blockquote>\n<p>Redis 除了这 5 种数据类型之外，还有 Bitmaps、HyperLogLogs、Streams 等。</p>\n</blockquote>\n<h3 id=\"Strings\"><a href=\"#Strings\" class=\"headerlink\" title=\"Strings\"></a>Strings</h3><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p>\n<pre><code class=\"bash\">set college szu\n</code></pre>\n<h3 id=\"Hashes\"><a href=\"#Hashes\" class=\"headerlink\" title=\"Hashes\"></a>Hashes</h3><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p>\n<pre><code class=\"bash\">hset person name bingo\nhset person age 20\nhset person id 1\nhget person name\n</code></pre>\n<pre><code class=\"json\">(person = &#123;\n  &quot;name&quot;: &quot;bingo&quot;,\n  &quot;age&quot;: 20,\n  &quot;id&quot;: 1\n&#125;)\n</code></pre>\n<h3 id=\"Lists\"><a href=\"#Lists\" class=\"headerlink\" title=\"Lists\"></a>Lists</h3><p>Lists 是有序列表，这个可以玩儿出很多花样。</p>\n<p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p>\n<p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p>\n<pre><code class=\"bash\"># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n</code></pre>\n<p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。</p>\n<pre><code class=\"bash\">lpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n</code></pre>\n<h3 id=\"Sets\"><a href=\"#Sets\" class=\"headerlink\" title=\"Sets\"></a>Sets</h3><p>Sets 是无序集合，自动去重。</p>\n<p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。</p>\n<p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p>\n<p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。</p>\n<pre><code class=\"bash\">#-------操作一个set-------\n# 添加元素\nsadd mySet 1\n\n# 查看全部元素\nsmembers mySet\n\n# 判断是否包含某个值\nsismember mySet 3\n\n# 删除某个/些元素\nsrem mySet 1\nsrem mySet 2 4\n\n# 查看元素个数\nscard mySet\n\n# 随机删除一个元素\nspop mySet\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourSet mySet 2\n\n# 求两set的交集\nsinter yourSet mySet\n\n# 求两set的并集\nsunion yourSet mySet\n\n# 求在yourSet中而不在mySet中的元素\nsdiff yourSet mySet\n</code></pre>\n<h3 id=\"Sorted-Sets\"><a href=\"#Sorted-Sets\" class=\"headerlink\" title=\"Sorted Sets\"></a>Sorted Sets</h3><p>Sorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p>\n<pre><code class=\"bash\">zadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n</code></pre>\n<h2 id=\"面试题-3\"><a href=\"#面试题-3\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？</p>\n<h2 id=\"面试官心理分析-3\"><a href=\"#面试官心理分析-3\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 Redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？</p>\n<p>常见的有两个问题：</p>\n<ul>\n<li>往 Redis 写入的数据怎么没了？</li>\n</ul>\n<p>可能有同学会遇到，在生产环境的 Redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 Redis 你就没用对啊。Redis 是缓存，你给当存储了是吧？</p>\n<p>啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。Redis 主要是基于内存来进行高性能、高并发的读写操作的。</p>\n<p>那既然内存是有限的，比如 Redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。</p>\n<ul>\n<li>数据明明过期了，怎么还占用着内存？</li>\n</ul>\n<p>这是由 Redis 的过期策略来决定。</p>\n<h2 id=\"面试题剖析-3\"><a href=\"#面试题剖析-3\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"Redis-过期策略\"><a href=\"#Redis-过期策略\" class=\"headerlink\" title=\"Redis 过期策略\"></a>Redis 过期策略</h3><p>Redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p>\n<p>所谓<strong>定期删除</strong>，指的是 Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。</p>\n<p>假设 Redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 Redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的<strong>灾难</strong>。实际上 Redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p>\n<p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，Redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p>\n<blockquote>\n<p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p>\n</blockquote>\n<p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 Redis 内存块耗尽了，咋整？</p>\n<p>答案是：<strong>走内存淘汰机制</strong>。</p>\n<h3 id=\"内存淘汰机制\"><a href=\"#内存淘汰机制\" class=\"headerlink\" title=\"内存淘汰机制\"></a>内存淘汰机制</h3><p>Redis 内存淘汰机制有以下几个：</p>\n<ul>\n<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li>\n<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li>\n<li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li>\n<li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li>\n<li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li>\n<li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li>\n</ul>\n<h3 id=\"手写一个-LRU-算法\"><a href=\"#手写一个-LRU-算法\" class=\"headerlink\" title=\"手写一个 LRU 算法\"></a>手写一个 LRU 算法</h3><p>LRU 就是 Least Recently Used 的缩写，翻译过来就是“最近最少使用”。也就是说 LRU 算法会将最近最少用的缓存移除，让给最新使用的缓存。而往往最常读取的，也就是读取次数最多的，所以利用好 LRU 算法，我们能够提供对热点数据的缓存效率，能够提高缓存服务的内存使用率。</p>\n<p>那么如何实现呢？</p>\n<p>其实，实现的思路非常简单，就像下面这张图种描述的一样。</p>\n<p><img src=\"lru.png\" alt=\"redis知识点整理\"></p>\n<p>你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。</p>\n<p>不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。</p>\n<p><img src=\"lru-cache.png\" alt=\"redis知识点整理\"></p>\n<pre><code class=\"java\">public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;\n    private int capacity;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param capacity 缓存大小\n     */\n    public LRUCache(int capacity) &#123;\n        super(capacity, 0.75f, true);\n        this.capacity = capacity;\n    &#125;\n\n    /**\n     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据\n     *\n     * @param eldest 最老的数据项\n     * @return true则移除最老的数据\n     */\n    @Override\n    protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;\n        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据\n        return size() &gt; capacity;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"Redis-主从架构\"><a href=\"#Redis-主从架构\" class=\"headerlink\" title=\"Redis 主从架构\"></a>Redis 主从架构</h2><p>单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现水平扩容，<strong>支撑读高并发</strong>。</p>\n<p><img src=\"redis-master-slave.png\" alt=\"redis知识点整理\"></p>\n<p>Redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>\n<h2 id=\"Redis-replication-的核心机制\"><a href=\"#Redis-replication-的核心机制\" class=\"headerlink\" title=\"Redis replication 的核心机制\"></a>Redis replication 的核心机制</h2><ul>\n<li>Redis 采用<strong>异步方式</strong>复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；</li>\n<li>一个 master node 是可以配置多个 slave node 的；</li>\n<li>slave node 也可以连接其他的 slave node；</li>\n<li>slave node 做复制的时候，不会 block master node 的正常工作；</li>\n<li>slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</li>\n<li>slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</li>\n</ul>\n<p>注意，如果采用了主从架构，那么建议必须<strong>开启</strong> master node 的 <a href=\"#Redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F\">持久化</a>，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。</p>\n<p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能<strong>确保启动的时候，是有数据的</strong>，即使采用了后续讲解的<a href=\"#Redis-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8\">高可用机制</a>，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p>\n<h2 id=\"Redis-主从复制的核心原理\"><a href=\"#Redis-主从复制的核心原理\" class=\"headerlink\" title=\"Redis 主从复制的核心原理\"></a>Redis 主从复制的核心原理</h2><p>当启动一个 slave node 的时候，它会发送一个 <code>PSYNC</code> 命令给 master node。</p>\n<p>如果这是 slave node 初次连接到 master node，那么会触发一次 <code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 <code>RDB</code> 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 <code>RDB</code> 文件生成完毕后， master 会将这个 <code>RDB</code> 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存</strong>中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p>\n<p><img src=\"redis-master-slave-replication.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"主从复制的断点续传\"><a href=\"#主从复制的断点续传\" class=\"headerlink\" title=\"主从复制的断点续传\"></a>主从复制的断点续传</h3><p>从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p>\n<p>master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 <code>resynchronization</code> 。</p>\n<blockquote>\n<p>如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。</p>\n</blockquote>\n<h3 id=\"无磁盘化复制\"><a href=\"#无磁盘化复制\" class=\"headerlink\" title=\"无磁盘化复制\"></a>无磁盘化复制</h3><p>master 在内存中直接创建 <code>RDB</code> ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 <code>repl-diskless-sync yes</code> 即可。</p>\n<pre><code class=\"bash\">repl-diskless-sync yes\n\n# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来\nrepl-diskless-sync-delay 5\n</code></pre>\n<h3 id=\"过期-key-处理\"><a href=\"#过期-key-处理\" class=\"headerlink\" title=\"过期 key 处理\"></a>过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p>\n<h2 id=\"复制的完整流程\"><a href=\"#复制的完整流程\" class=\"headerlink\" title=\"复制的完整流程\"></a>复制的完整流程</h2><p>slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 <code>host</code> 和 <code>ip</code> ，但是复制流程没开始。</p>\n<p>slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 <code>ping</code> 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node <strong>第一次执行全量复制</strong>，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。</p>\n<p><img src=\"redis-master-slave-replication-detail.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"全量复制\"><a href=\"#全量复制\" class=\"headerlink\" title=\"全量复制\"></a>全量复制</h3><ul>\n<li>master 执行 bgsave ，在本地生成一份 rdb 快照文件。</li>\n<li>master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)</li>\n<li>master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。</li>\n<li>如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。</li>\n</ul>\n<pre><code class=\"bash\">client-output-buffer-limit slave 256MB 64MB 60\n</code></pre>\n<ul>\n<li>slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中。注意，在清空旧数据之前，slave node 依然会<strong>基于旧的数据版本</strong>对外提供服务。</li>\n<li>如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。</li>\n</ul>\n<h3 id=\"增量复制\"><a href=\"#增量复制\" class=\"headerlink\" title=\"增量复制\"></a>增量复制</h3><ul>\n<li>如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。</li>\n<li>master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。</li>\n<li>master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。</li>\n</ul>\n<h3 id=\"heartbeat\"><a href=\"#heartbeat\" class=\"headerlink\" title=\"heartbeat\"></a>heartbeat</h3><p>主从节点互相都会发送 heartbeat 信息。</p>\n<p>master 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。</p>\n<h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><p>master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。</p>\n<h2 id=\"Redis-如何才能做到高可用\"><a href=\"#Redis-如何才能做到高可用\" class=\"headerlink\" title=\"Redis 如何才能做到高可用\"></a>Redis 如何才能做到高可用</h2><p>如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。</p>\n<p>一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。</p>\n<p>但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。</p>\n<p>Redis 的高可用架构，叫做 <code>failover</code> <strong>故障转移</strong>，也可以叫做主备切换。</p>\n<p>master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用。</p>\n<h2 id=\"Redis的持久化有哪几种方式\"><a href=\"#Redis的持久化有哪几种方式\" class=\"headerlink\" title=\"Redis的持久化有哪几种方式\"></a>Redis的持久化有哪几种方式</h2><p>Redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？</p>\n<h2 id=\"面试官心理分析-4\"><a href=\"#面试官心理分析-4\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>Redis 如果仅仅只是将数据缓存在内存里面，如果 Redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 Redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。</p>\n<p>如果 Redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。</p>\n<p>这个其实一样，针对的都是 Redis 的生产环境可能遇到的一些问题，就是 Redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？</p>\n<h2 id=\"面试题剖析-4\"><a href=\"#面试题剖析-4\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 Redis 整个挂了，然后 Redis 就不可用了，你要做的事情就是让 Redis 变得可用，尽快变得可用。</p>\n<p>重启 Redis，尽快让它对外提供服务，如果没做数据备份，这时候 Redis 启动了，也不可用啊，数据都没了。</p>\n<p>很可能说，大量的请求过来，缓存全部无法命中，在 Redis 里根本找不到数据，这个时候就死定了，出现<strong>缓存雪崩</strong>问题。所有请求没有在 Redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了…</p>\n<p>如果你把 Redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 Redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。</p>\n<h3 id=\"Redis-持久化的两种方式\"><a href=\"#Redis-持久化的两种方式\" class=\"headerlink\" title=\"Redis 持久化的两种方式\"></a>Redis 持久化的两种方式</h3><ul>\n<li>RDB：RDB 持久化机制，是对 Redis 中的数据执行<strong>周期性</strong>的持久化。</li>\n<li>AOF：AOF 机制对每条写入命令作为日志，以 <code>append-only</code> 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过<strong>回放</strong> AOF 日志中的写入指令来重新构建整个数据集。</li>\n</ul>\n<p>通过 RDB 或 AOF，都可以将 Redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。</p>\n<p>如果 Redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 Redis，Redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。</p>\n<p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 <strong>AOF</strong> 来重新构建数据，因为 AOF 中的<strong>数据更加完整</strong>。</p>\n<h4 id=\"RDB-优缺点\"><a href=\"#RDB-优缺点\" class=\"headerlink\" title=\"RDB 优缺点\"></a>RDB 优缺点</h4><ul>\n<li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，<strong>非常适合做冷备</strong>，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 Redis 中的数据。</li>\n<li>RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis <strong>保持高性能</strong>，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li>\n<li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。</li>\n<li>如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟（甚至更长时间）的数据。</li>\n<li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li>\n</ul>\n<h4 id=\"AOF-优缺点\"><a href=\"#AOF-优缺点\" class=\"headerlink\" title=\"AOF 优缺点\"></a>AOF 优缺点</h4><ul>\n<li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 <code>fsync</code> 操作，最多丢失 1 秒钟的数据。</li>\n<li>AOF 日志文件以 <code>append-only</code> 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li>\n<li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 <code>rewrite</code> log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li>\n<li>AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常<strong>适合做灾难性的误删除的紧急恢复</strong>。比如某人不小心用 <code>flushall</code> 命令清空了所有数据，只要这个时候后台 <code>rewrite</code> 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 <code>flushall</code> 命令给删了，然后再将该 <code>AOF</code> 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li>\n<li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li>\n<li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 <code>fsync</code> 一次日志文件，当然，每秒一次 <code>fsync</code> ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）</li>\n<li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 <code>merge</code> 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是<strong>基于当时内存中的数据进行指令的重新构建</strong>，这样健壮性会好很多。</li>\n</ul>\n<h3 id=\"RDB-和-AOF-到底该如何选择\"><a href=\"#RDB-和-AOF-到底该如何选择\" class=\"headerlink\" title=\"RDB 和 AOF 到底该如何选择\"></a>RDB 和 AOF 到底该如何选择</h3><ul>\n<li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li>\n<li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li>\n<li>Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li>\n</ul>\n<h2 id=\"Redis-哨兵集群实现高可用\"><a href=\"#Redis-哨兵集群实现高可用\" class=\"headerlink\" title=\"Redis 哨兵集群实现高可用\"></a>Redis 哨兵集群实现高可用</h2><h2 id=\"哨兵的介绍\"><a href=\"#哨兵的介绍\" class=\"headerlink\" title=\"哨兵的介绍\"></a>哨兵的介绍</h2><p>sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：</p>\n<ul>\n<li>集群监控：负责监控 Redis master 和 slave 进程是否正常工作。</li>\n<li>消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>\n<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>\n<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>\n</ul>\n<p>哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>\n<ul>\n<li>故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</li>\n<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</li>\n</ul>\n<h2 id=\"哨兵的核心知识\"><a href=\"#哨兵的核心知识\" class=\"headerlink\" title=\"哨兵的核心知识\"></a>哨兵的核心知识</h2><ul>\n<li>哨兵至少需要 3 个实例，来保证自己的健壮性。</li>\n<li>哨兵 + Redis 主从的部署架构，是<strong>不保证数据零丢失</strong>的，只能保证 Redis 集群的高可用性。</li>\n<li>对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。</li>\n</ul>\n<p>哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。</p>\n<pre><code>+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n</code></pre>\n<p>配置 <code>quorum=1</code> ，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。</p>\n<pre><code>2 个哨兵，majority=2\n3 个哨兵，majority=2\n4 个哨兵，majority=2\n5 个哨兵，majority=3\n...\n</code></pre>\n<p>如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。</p>\n<p>经典的 3 节点哨兵集群是这样的：</p>\n<pre><code>       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n</code></pre>\n<p>配置 <code>quorum=2</code> ，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。</p>\n<h2 id=\"Redis-哨兵主备切换的数据丢失问题\"><a href=\"#Redis-哨兵主备切换的数据丢失问题\" class=\"headerlink\" title=\"Redis 哨兵主备切换的数据丢失问题\"></a>Redis 哨兵主备切换的数据丢失问题</h2><h3 id=\"导致数据丢失的两种情况\"><a href=\"#导致数据丢失的两种情况\" class=\"headerlink\" title=\"导致数据丢失的两种情况\"></a>导致数据丢失的两种情况</h3><p>主备切换的过程，可能会导致数据丢失：</p>\n<ul>\n<li>异步复制导致的数据丢失</li>\n</ul>\n<p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。</p>\n<p><img src=\"async-replication-data-lose-case.png\" alt=\"redis知识点整理\"></p>\n<ul>\n<li>脑裂导致的数据丢失</li>\n</ul>\n<p>脑裂，也就是说，某个 master 所在机器突然<strong>脱离了正常的网络</strong>，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会<strong>认为</strong> master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p>\n<p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p>\n<p><img src=\"redis-cluster-split-brain.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"数据丢失问题的解决方案\"><a href=\"#数据丢失问题的解决方案\" class=\"headerlink\" title=\"数据丢失问题的解决方案\"></a>数据丢失问题的解决方案</h3><p>进行如下配置：</p>\n<pre><code class=\"bash\">min-slaves-to-write 1\nmin-slaves-max-lag 10\n</code></pre>\n<p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p>\n<p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p>\n<ul>\n<li>减少异步复制数据的丢失</li>\n</ul>\n<p>有了 <code>min-slaves-max-lag</code> 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p>\n<ul>\n<li>减少脑裂的数据丢失</li>\n</ul>\n<p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。</p>\n<h2 id=\"sdown-和-odown-转换机制\"><a href=\"#sdown-和-odown-转换机制\" class=\"headerlink\" title=\"sdown 和 odown 转换机制\"></a>sdown 和 odown 转换机制</h2><ul>\n<li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li>\n<li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li>\n</ul>\n<p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 <code>is-master-down-after-milliseconds</code> 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p>\n<h2 id=\"哨兵集群的自动发现机制\"><a href=\"#哨兵集群的自动发现机制\" class=\"headerlink\" title=\"哨兵集群的自动发现机制\"></a>哨兵集群的自动发现机制</h2><p>哨兵互相之间的发现，是通过 Redis 的 <code>pub/sub</code> 系统实现的，每个哨兵都会往 <code>__sentinel__:hello</code> 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p>\n<p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <code>__sentinel__:hello</code> channel 里<strong>发送一个消息</strong>，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p>\n<p>每个哨兵也会去<strong>监听</strong>自己监控的每个 master+slaves 对应的 <code>__sentinel__:hello</code> channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p>\n<p>每个哨兵还会跟其他哨兵交换对 <code>master</code> 的监控配置，互相进行监控配置的同步。</p>\n<h2 id=\"slave-配置的自动纠正\"><a href=\"#slave-配置的自动纠正\" class=\"headerlink\" title=\"slave 配置的自动纠正\"></a>slave 配置的自动纠正</h2><p>哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。</p>\n<h2 id=\"slave-gt-master-选举算法\"><a href=\"#slave-gt-master-选举算法\" class=\"headerlink\" title=\"slave-&gt;master 选举算法\"></a>slave-&gt;master 选举算法</h2><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p>\n<ul>\n<li>跟 master 断开连接的时长</li>\n<li>slave 优先级</li>\n<li>复制 offset</li>\n<li>run id</li>\n</ul>\n<p>如果一个 slave 跟 master 断开连接的时间已经超过了 <code>down-after-milliseconds</code> 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p>\n<pre><code>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n</code></pre>\n<p>接下来会对 slave 进行排序：</p>\n<ul>\n<li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li>\n<li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li>\n<li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li>\n</ul>\n<h2 id=\"quorum-和-majority\"><a href=\"#quorum-和-majority\" class=\"headerlink\" title=\"quorum 和 majority\"></a>quorum 和 majority</h2><p>每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。</p>\n<p>如果 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。</p>\n<p>但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。</p>\n<h2 id=\"configuration-epoch\"><a href=\"#configuration-epoch\" class=\"headerlink\" title=\"configuration epoch\"></a>configuration epoch</h2><p>哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。</p>\n<p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。</p>\n<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。</p>\n<h2 id=\"configuration-传播\"><a href=\"#configuration-传播\" class=\"headerlink\" title=\"configuration 传播\"></a>configuration 传播</h2><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 <code>pub/sub</code> 消息机制。</p>\n<p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p>\n<h2 id=\"面试题-4\"><a href=\"#面试题-4\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么 Redis 单线程却能支撑高并发？</p>\n<h2 id=\"面试官心理分析-5\"><a href=\"#面试官心理分析-5\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>这个是问 Redis 的时候，最基本的问题吧，Redis 最基本的一个内部原理和特点，就是 Redis 实际上是个<strong>单线程工作模型</strong>，你要是这个都不知道，那后面玩儿 Redis 的时候，出了问题岂不是什么都不知道？</p>\n<p>还有可能面试官会问问你 Redis 和 Memcached 的区别，但是 Memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 Redis，没什么公司用 Memcached 了。</p>\n<h2 id=\"面试题剖析-5\"><a href=\"#面试题剖析-5\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"Redis-和-Memcached-有啥区别？\"><a href=\"#Redis-和-Memcached-有啥区别？\" class=\"headerlink\" title=\"Redis 和 Memcached 有啥区别？\"></a>Redis 和 Memcached 有啥区别？</h3><h4 id=\"Redis-支持复杂的数据结构\"><a href=\"#Redis-支持复杂的数据结构\" class=\"headerlink\" title=\"Redis 支持复杂的数据结构\"></a>Redis 支持复杂的数据结构</h4><p>Redis 相比 Memcached 来说，拥有<a href=\"Redis-%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\">更多的数据结构</a>，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。</p>\n<h4 id=\"Redis-原生支持集群模式\"><a href=\"#Redis-原生支持集群模式\" class=\"headerlink\" title=\"Redis 原生支持集群模式\"></a>Redis 原生支持集群模式</h4><p>在 Redis3.x 版本中，便能支持 cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p>\n<h4 id=\"性能对比\"><a href=\"#性能对比\" class=\"headerlink\" title=\"性能对比\"></a>性能对比</h4><p>由于 Redis 只使用<strong>单核</strong>，而 Memcached 可以使用<strong>多核</strong>，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。</p>\n<h3 id=\"Redis-的线程模型\"><a href=\"#Redis-的线程模型\" class=\"headerlink\" title=\"Redis 的线程模型\"></a>Redis 的线程模型</h3><p>Redis 内部使用文件事件处理器 <code>file event handler</code> ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p>\n<p>文件事件处理器的结构包含 4 个部分：</p>\n<ul>\n<li>多个 socket</li>\n<li>IO 多路复用程序</li>\n<li>文件事件分派器</li>\n<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>\n</ul>\n<p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p>\n<p>来看客户端与 Redis 的一次通信过程：</p>\n<p><img src=\"redis-single-thread-model.png\" alt=\"redis知识点整理\"></p>\n<p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p>\n<p>首先，Redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p>\n<p>客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p>\n<p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 Redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p>\n<p>如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code> ，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p>\n<p>这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《<a href=\"https://github.com/doocs/technical-books#database\">Redis 设计与实现——黄健宏</a>》进行系统学习。</p>\n<h3 id=\"为啥-Redis-单线程模型也能效率这么高？\"><a href=\"#为啥-Redis-单线程模型也能效率这么高？\" class=\"headerlink\" title=\"为啥 Redis 单线程模型也能效率这么高？\"></a>为啥 Redis 单线程模型也能效率这么高？</h3><ul>\n<li>纯内存操作。</li>\n<li>核心是基于非阻塞的 IO 多路复用机制。</li>\n<li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li>\n<li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li>\n</ul>\n<h3 id=\"Redis-6-0-开始引入多线程\"><a href=\"#Redis-6-0-开始引入多线程\" class=\"headerlink\" title=\"Redis 6.0 开始引入多线程\"></a>Redis 6.0 开始引入多线程</h3><p><strong>注意！</strong> Redis 6.0 之后的版本抛弃了单线程模型这一设计，<strong>原本使用单线程运行的 Redis 也开始选择性地使用多线程模型</strong>。</p>\n<p>前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。</p>\n<p><strong>Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。</strong> 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间(释放操作不会阻塞网络 IO 读写,因为网络 IO 读写与释放的命令执行不是同一个线程)也能减少对 Redis 主线程阻塞的时间，提高执行的效率。</p>\n","site":{"data":{}},"excerpt":"<p>redis知识点整理</p>","more":"<h2 id=\"面试题\"><a href=\"#面试题\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？</p>\n<h2 id=\"面试官心理分析\"><a href=\"#面试官心理分析\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。</p>\n<h2 id=\"面试题剖析\"><a href=\"#面试题剖析\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"缓存雪崩-Cache-Avalanche\"><a href=\"#缓存雪崩-Cache-Avalanche\" class=\"headerlink\" title=\"缓存雪崩(Cache Avalanche)\"></a>缓存雪崩(Cache Avalanche)</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p>\n<p>这就是缓存雪崩。</p>\n<p><img src=\"redis-caching-avalanche.png\" alt=\"redis知识点整理\"></p>\n<p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p>\n<p>缓存雪崩的事前事中事后的解决方案如下：</p>\n<ul>\n<li>事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。</li>\n<li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li>\n<li>事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li>\n</ul>\n<p><img src=\"redis-caching-avalanche-solution.png\" alt=\"redis知识点整理\"></p>\n<p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。</p>\n<p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p>\n<p>好处：</p>\n<ul>\n<li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li>\n<li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li>\n<li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li>\n</ul>\n<h3 id=\"缓存穿透-Cache-Penetration\"><a href=\"#缓存穿透-Cache-Penetration\" class=\"headerlink\" title=\"缓存穿透(Cache Penetration)\"></a>缓存穿透(Cache Penetration)</h3><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p>\n<p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p>\n<p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p>\n<p><img src=\"redis-caching-penetration.png\" alt=\"redis知识点整理\"></p>\n<p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code> 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p>\n<p>当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：</p>\n<ul>\n<li>请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。</li>\n<li>请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。</li>\n</ul>\n<p>使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。</p>\n<p><img src=\"redis-caching-avoid-penetration.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"缓存击穿-Hotspot-Invalid\"><a href=\"#缓存击穿-Hotspot-Invalid\" class=\"headerlink\" title=\"缓存击穿(Hotspot Invalid)\"></a>缓存击穿(Hotspot Invalid)</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p>\n<p>不同场景下的解决方式可如下：</p>\n<ul>\n<li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li>\n<li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li>\n<li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li>\n</ul>\n<h2 id=\"面试题-1\"><a href=\"#面试题-1\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>如何保证缓存与数据库的双写一致性？</p>\n<h2 id=\"面试官心理分析-1\"><a href=\"#面试官心理分析-1\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>\n<h2 id=\"面试题剖析-1\"><a href=\"#面试题剖析-1\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p>\n<p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>\n<h3 id=\"Cache-Aside-Pattern\"><a href=\"#Cache-Aside-Pattern\" class=\"headerlink\" title=\"Cache Aside Pattern\"></a>Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p>\n<ul>\n<li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li>\n<li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li>\n</ul>\n<p><strong>为什么是删除缓存，而不是更新缓存？</strong></p>\n<p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p>\n<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p>\n<p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p>\n<p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p>\n<p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p>\n<h3 id=\"最初级的缓存不一致问题及解决方案\"><a href=\"#最初级的缓存不一致问题及解决方案\" class=\"headerlink\" title=\"最初级的缓存不一致问题及解决方案\"></a>最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p>\n<p><img src=\"redis-junior-inconsistent.png\" alt=\"redis知识点整理\"></p>\n<p>解决思路 1：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p>\n<p>解决思路 2：延时双删。依旧是先更新数据库，再删除缓存，唯一不同的是，我们把这个删除的动作，在不久之后再执行一次，比如 5s 之后。</p>\n<pre><code class=\"java\">public void set(key, value) &#123;\n    putToDb(key, value);\n    deleteFromRedis(key);\n\n    // ... a few seconds later\n    deleteFromRedis(key);\n&#125;\n</code></pre>\n<p>删除的动作，可以有多种选择，比如：1. 使用 <code>DelayQueue</code>，会随着 JVM 进程的死亡，丢失更新的风险；2. 放在 <code>MQ</code>，但编码复杂度为增加。总之，我们需要综合各种因素去做设计，选择一个最合理的解决方案。</p>\n<h3 id=\"比较复杂的数据不一致问题分析\"><a href=\"#比较复杂的数据不一致问题分析\" class=\"headerlink\" title=\"比较复杂的数据不一致问题分析\"></a>比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了…</p>\n<p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p>\n<p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p>\n<p><strong>解决方案如下：</strong></p>\n<p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。</p>\n<p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p>\n<p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p>\n<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p>\n<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p>\n<p>高并发的场景下，该解决方案要注意的问题：</p>\n<ul>\n<li>读请求长时阻塞</li>\n</ul>\n<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p>\n<p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p>\n<p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<strong>读请求的长时阻塞</strong>。</p>\n<p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p>\n<p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p>\n<p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p>\n<p>我们来<strong>实际粗略测算一下</strong>。</p>\n<p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p>\n<p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p>\n<ul>\n<li>读请求并发量过高</li>\n</ul>\n<p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p>\n<p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p>\n<ul>\n<li>多服务实例部署的请求路由</li>\n</ul>\n<p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p>\n<p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p>\n<ul>\n<li>热点商品的路由问题，导致请求的倾斜</li>\n</ul>\n<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p>\n<h2 id=\"面试题-2\"><a href=\"#面试题-2\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？</p>\n<h2 id=\"面试官心理分析-2\"><a href=\"#面试官心理分析-2\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。</p>\n<p>其实问这个问题，主要有两个原因：</p>\n<ul>\n<li>看看你到底有没有全面的了解 Redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；</li>\n<li>看看你在实际项目里都怎么玩儿过 Redis。</li>\n</ul>\n<p>要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。</p>\n<h2 id=\"面试题剖析-2\"><a href=\"#面试题剖析-2\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>Redis 主要有以下几种数据类型：</p>\n<ul>\n<li>Strings</li>\n<li>Hashes</li>\n<li>Lists</li>\n<li>Sets</li>\n<li>Sorted Sets</li>\n</ul>\n<blockquote>\n<p>Redis 除了这 5 种数据类型之外，还有 Bitmaps、HyperLogLogs、Streams 等。</p>\n</blockquote>\n<h3 id=\"Strings\"><a href=\"#Strings\" class=\"headerlink\" title=\"Strings\"></a>Strings</h3><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p>\n<pre><code class=\"bash\">set college szu\n</code></pre>\n<h3 id=\"Hashes\"><a href=\"#Hashes\" class=\"headerlink\" title=\"Hashes\"></a>Hashes</h3><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p>\n<pre><code class=\"bash\">hset person name bingo\nhset person age 20\nhset person id 1\nhget person name\n</code></pre>\n<pre><code class=\"json\">(person = &#123;\n  &quot;name&quot;: &quot;bingo&quot;,\n  &quot;age&quot;: 20,\n  &quot;id&quot;: 1\n&#125;)\n</code></pre>\n<h3 id=\"Lists\"><a href=\"#Lists\" class=\"headerlink\" title=\"Lists\"></a>Lists</h3><p>Lists 是有序列表，这个可以玩儿出很多花样。</p>\n<p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p>\n<p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p>\n<pre><code class=\"bash\"># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。\nlrange mylist 0 -1\n</code></pre>\n<p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。</p>\n<pre><code class=\"bash\">lpush mylist 1\nlpush mylist 2\nlpush mylist 3 4 5\n\n# 1\nrpop mylist\n</code></pre>\n<h3 id=\"Sets\"><a href=\"#Sets\" class=\"headerlink\" title=\"Sets\"></a>Sets</h3><p>Sets 是无序集合，自动去重。</p>\n<p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。</p>\n<p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p>\n<p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。</p>\n<pre><code class=\"bash\">#-------操作一个set-------\n# 添加元素\nsadd mySet 1\n\n# 查看全部元素\nsmembers mySet\n\n# 判断是否包含某个值\nsismember mySet 3\n\n# 删除某个/些元素\nsrem mySet 1\nsrem mySet 2 4\n\n# 查看元素个数\nscard mySet\n\n# 随机删除一个元素\nspop mySet\n\n#-------操作多个set-------\n# 将一个set的元素移动到另外一个set\nsmove yourSet mySet 2\n\n# 求两set的交集\nsinter yourSet mySet\n\n# 求两set的并集\nsunion yourSet mySet\n\n# 求在yourSet中而不在mySet中的元素\nsdiff yourSet mySet\n</code></pre>\n<h3 id=\"Sorted-Sets\"><a href=\"#Sorted-Sets\" class=\"headerlink\" title=\"Sorted Sets\"></a>Sorted Sets</h3><p>Sorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p>\n<pre><code class=\"bash\">zadd board 85 zhangsan\nzadd board 72 lisi\nzadd board 96 wangwu\nzadd board 63 zhaoliu\n\n# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）\nzrevrange board 0 3\n\n# 获取某用户的排名\nzrank board zhaoliu\n</code></pre>\n<h2 id=\"面试题-3\"><a href=\"#面试题-3\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？</p>\n<h2 id=\"面试官心理分析-3\"><a href=\"#面试官心理分析-3\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 Redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？</p>\n<p>常见的有两个问题：</p>\n<ul>\n<li>往 Redis 写入的数据怎么没了？</li>\n</ul>\n<p>可能有同学会遇到，在生产环境的 Redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 Redis 你就没用对啊。Redis 是缓存，你给当存储了是吧？</p>\n<p>啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。Redis 主要是基于内存来进行高性能、高并发的读写操作的。</p>\n<p>那既然内存是有限的，比如 Redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。</p>\n<ul>\n<li>数据明明过期了，怎么还占用着内存？</li>\n</ul>\n<p>这是由 Redis 的过期策略来决定。</p>\n<h2 id=\"面试题剖析-3\"><a href=\"#面试题剖析-3\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"Redis-过期策略\"><a href=\"#Redis-过期策略\" class=\"headerlink\" title=\"Redis 过期策略\"></a>Redis 过期策略</h3><p>Redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p>\n<p>所谓<strong>定期删除</strong>，指的是 Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。</p>\n<p>假设 Redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 Redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的<strong>灾难</strong>。实际上 Redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p>\n<p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，Redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p>\n<blockquote>\n<p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p>\n</blockquote>\n<p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 Redis 内存块耗尽了，咋整？</p>\n<p>答案是：<strong>走内存淘汰机制</strong>。</p>\n<h3 id=\"内存淘汰机制\"><a href=\"#内存淘汰机制\" class=\"headerlink\" title=\"内存淘汰机制\"></a>内存淘汰机制</h3><p>Redis 内存淘汰机制有以下几个：</p>\n<ul>\n<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li>\n<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li>\n<li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li>\n<li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li>\n<li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li>\n<li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li>\n</ul>\n<h3 id=\"手写一个-LRU-算法\"><a href=\"#手写一个-LRU-算法\" class=\"headerlink\" title=\"手写一个 LRU 算法\"></a>手写一个 LRU 算法</h3><p>LRU 就是 Least Recently Used 的缩写，翻译过来就是“最近最少使用”。也就是说 LRU 算法会将最近最少用的缓存移除，让给最新使用的缓存。而往往最常读取的，也就是读取次数最多的，所以利用好 LRU 算法，我们能够提供对热点数据的缓存效率，能够提高缓存服务的内存使用率。</p>\n<p>那么如何实现呢？</p>\n<p>其实，实现的思路非常简单，就像下面这张图种描述的一样。</p>\n<p><img src=\"lru.png\" alt=\"redis知识点整理\"></p>\n<p>你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。</p>\n<p>不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。</p>\n<p><img src=\"lru-cache.png\" alt=\"redis知识点整理\"></p>\n<pre><code class=\"java\">public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;\n    private int capacity;\n\n    /**\n     * 传递进来最多能缓存多少数据\n     *\n     * @param capacity 缓存大小\n     */\n    public LRUCache(int capacity) &#123;\n        super(capacity, 0.75f, true);\n        this.capacity = capacity;\n    &#125;\n\n    /**\n     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据\n     *\n     * @param eldest 最老的数据项\n     * @return true则移除最老的数据\n     */\n    @Override\n    protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;\n        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据\n        return size() &gt; capacity;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"Redis-主从架构\"><a href=\"#Redis-主从架构\" class=\"headerlink\" title=\"Redis 主从架构\"></a>Redis 主从架构</h2><p>单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现水平扩容，<strong>支撑读高并发</strong>。</p>\n<p><img src=\"redis-master-slave.png\" alt=\"redis知识点整理\"></p>\n<p>Redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>\n<h2 id=\"Redis-replication-的核心机制\"><a href=\"#Redis-replication-的核心机制\" class=\"headerlink\" title=\"Redis replication 的核心机制\"></a>Redis replication 的核心机制</h2><ul>\n<li>Redis 采用<strong>异步方式</strong>复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；</li>\n<li>一个 master node 是可以配置多个 slave node 的；</li>\n<li>slave node 也可以连接其他的 slave node；</li>\n<li>slave node 做复制的时候，不会 block master node 的正常工作；</li>\n<li>slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</li>\n<li>slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</li>\n</ul>\n<p>注意，如果采用了主从架构，那么建议必须<strong>开启</strong> master node 的 <a href=\"#Redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F\">持久化</a>，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。</p>\n<p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能<strong>确保启动的时候，是有数据的</strong>，即使采用了后续讲解的<a href=\"#Redis-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8\">高可用机制</a>，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p>\n<h2 id=\"Redis-主从复制的核心原理\"><a href=\"#Redis-主从复制的核心原理\" class=\"headerlink\" title=\"Redis 主从复制的核心原理\"></a>Redis 主从复制的核心原理</h2><p>当启动一个 slave node 的时候，它会发送一个 <code>PSYNC</code> 命令给 master node。</p>\n<p>如果这是 slave node 初次连接到 master node，那么会触发一次 <code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 <code>RDB</code> 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 <code>RDB</code> 文件生成完毕后， master 会将这个 <code>RDB</code> 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存</strong>中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p>\n<p><img src=\"redis-master-slave-replication.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"主从复制的断点续传\"><a href=\"#主从复制的断点续传\" class=\"headerlink\" title=\"主从复制的断点续传\"></a>主从复制的断点续传</h3><p>从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p>\n<p>master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 <code>resynchronization</code> 。</p>\n<blockquote>\n<p>如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。</p>\n</blockquote>\n<h3 id=\"无磁盘化复制\"><a href=\"#无磁盘化复制\" class=\"headerlink\" title=\"无磁盘化复制\"></a>无磁盘化复制</h3><p>master 在内存中直接创建 <code>RDB</code> ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 <code>repl-diskless-sync yes</code> 即可。</p>\n<pre><code class=\"bash\">repl-diskless-sync yes\n\n# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来\nrepl-diskless-sync-delay 5\n</code></pre>\n<h3 id=\"过期-key-处理\"><a href=\"#过期-key-处理\" class=\"headerlink\" title=\"过期 key 处理\"></a>过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p>\n<h2 id=\"复制的完整流程\"><a href=\"#复制的完整流程\" class=\"headerlink\" title=\"复制的完整流程\"></a>复制的完整流程</h2><p>slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 <code>host</code> 和 <code>ip</code> ，但是复制流程没开始。</p>\n<p>slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 <code>ping</code> 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node <strong>第一次执行全量复制</strong>，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。</p>\n<p><img src=\"redis-master-slave-replication-detail.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"全量复制\"><a href=\"#全量复制\" class=\"headerlink\" title=\"全量复制\"></a>全量复制</h3><ul>\n<li>master 执行 bgsave ，在本地生成一份 rdb 快照文件。</li>\n<li>master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)</li>\n<li>master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。</li>\n<li>如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。</li>\n</ul>\n<pre><code class=\"bash\">client-output-buffer-limit slave 256MB 64MB 60\n</code></pre>\n<ul>\n<li>slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中。注意，在清空旧数据之前，slave node 依然会<strong>基于旧的数据版本</strong>对外提供服务。</li>\n<li>如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。</li>\n</ul>\n<h3 id=\"增量复制\"><a href=\"#增量复制\" class=\"headerlink\" title=\"增量复制\"></a>增量复制</h3><ul>\n<li>如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。</li>\n<li>master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。</li>\n<li>master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。</li>\n</ul>\n<h3 id=\"heartbeat\"><a href=\"#heartbeat\" class=\"headerlink\" title=\"heartbeat\"></a>heartbeat</h3><p>主从节点互相都会发送 heartbeat 信息。</p>\n<p>master 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。</p>\n<h3 id=\"异步复制\"><a href=\"#异步复制\" class=\"headerlink\" title=\"异步复制\"></a>异步复制</h3><p>master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。</p>\n<h2 id=\"Redis-如何才能做到高可用\"><a href=\"#Redis-如何才能做到高可用\" class=\"headerlink\" title=\"Redis 如何才能做到高可用\"></a>Redis 如何才能做到高可用</h2><p>如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。</p>\n<p>一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。</p>\n<p>但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。</p>\n<p>Redis 的高可用架构，叫做 <code>failover</code> <strong>故障转移</strong>，也可以叫做主备切换。</p>\n<p>master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用。</p>\n<h2 id=\"Redis的持久化有哪几种方式\"><a href=\"#Redis的持久化有哪几种方式\" class=\"headerlink\" title=\"Redis的持久化有哪几种方式\"></a>Redis的持久化有哪几种方式</h2><p>Redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？</p>\n<h2 id=\"面试官心理分析-4\"><a href=\"#面试官心理分析-4\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>Redis 如果仅仅只是将数据缓存在内存里面，如果 Redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 Redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。</p>\n<p>如果 Redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。</p>\n<p>这个其实一样，针对的都是 Redis 的生产环境可能遇到的一些问题，就是 Redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？</p>\n<h2 id=\"面试题剖析-4\"><a href=\"#面试题剖析-4\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><p>持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 Redis 整个挂了，然后 Redis 就不可用了，你要做的事情就是让 Redis 变得可用，尽快变得可用。</p>\n<p>重启 Redis，尽快让它对外提供服务，如果没做数据备份，这时候 Redis 启动了，也不可用啊，数据都没了。</p>\n<p>很可能说，大量的请求过来，缓存全部无法命中，在 Redis 里根本找不到数据，这个时候就死定了，出现<strong>缓存雪崩</strong>问题。所有请求没有在 Redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了…</p>\n<p>如果你把 Redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 Redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。</p>\n<h3 id=\"Redis-持久化的两种方式\"><a href=\"#Redis-持久化的两种方式\" class=\"headerlink\" title=\"Redis 持久化的两种方式\"></a>Redis 持久化的两种方式</h3><ul>\n<li>RDB：RDB 持久化机制，是对 Redis 中的数据执行<strong>周期性</strong>的持久化。</li>\n<li>AOF：AOF 机制对每条写入命令作为日志，以 <code>append-only</code> 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过<strong>回放</strong> AOF 日志中的写入指令来重新构建整个数据集。</li>\n</ul>\n<p>通过 RDB 或 AOF，都可以将 Redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。</p>\n<p>如果 Redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 Redis，Redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。</p>\n<p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 <strong>AOF</strong> 来重新构建数据，因为 AOF 中的<strong>数据更加完整</strong>。</p>\n<h4 id=\"RDB-优缺点\"><a href=\"#RDB-优缺点\" class=\"headerlink\" title=\"RDB 优缺点\"></a>RDB 优缺点</h4><ul>\n<li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，<strong>非常适合做冷备</strong>，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 Redis 中的数据。</li>\n<li>RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis <strong>保持高性能</strong>，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li>\n<li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。</li>\n<li>如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟（甚至更长时间）的数据。</li>\n<li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li>\n</ul>\n<h4 id=\"AOF-优缺点\"><a href=\"#AOF-优缺点\" class=\"headerlink\" title=\"AOF 优缺点\"></a>AOF 优缺点</h4><ul>\n<li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 <code>fsync</code> 操作，最多丢失 1 秒钟的数据。</li>\n<li>AOF 日志文件以 <code>append-only</code> 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li>\n<li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 <code>rewrite</code> log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li>\n<li>AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常<strong>适合做灾难性的误删除的紧急恢复</strong>。比如某人不小心用 <code>flushall</code> 命令清空了所有数据，只要这个时候后台 <code>rewrite</code> 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 <code>flushall</code> 命令给删了，然后再将该 <code>AOF</code> 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li>\n<li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li>\n<li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 <code>fsync</code> 一次日志文件，当然，每秒一次 <code>fsync</code> ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）</li>\n<li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 <code>merge</code> 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是<strong>基于当时内存中的数据进行指令的重新构建</strong>，这样健壮性会好很多。</li>\n</ul>\n<h3 id=\"RDB-和-AOF-到底该如何选择\"><a href=\"#RDB-和-AOF-到底该如何选择\" class=\"headerlink\" title=\"RDB 和 AOF 到底该如何选择\"></a>RDB 和 AOF 到底该如何选择</h3><ul>\n<li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li>\n<li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li>\n<li>Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li>\n</ul>\n<h2 id=\"Redis-哨兵集群实现高可用\"><a href=\"#Redis-哨兵集群实现高可用\" class=\"headerlink\" title=\"Redis 哨兵集群实现高可用\"></a>Redis 哨兵集群实现高可用</h2><h2 id=\"哨兵的介绍\"><a href=\"#哨兵的介绍\" class=\"headerlink\" title=\"哨兵的介绍\"></a>哨兵的介绍</h2><p>sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能：</p>\n<ul>\n<li>集群监控：负责监控 Redis master 和 slave 进程是否正常工作。</li>\n<li>消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>\n<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>\n<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>\n</ul>\n<p>哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>\n<ul>\n<li>故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</li>\n<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</li>\n</ul>\n<h2 id=\"哨兵的核心知识\"><a href=\"#哨兵的核心知识\" class=\"headerlink\" title=\"哨兵的核心知识\"></a>哨兵的核心知识</h2><ul>\n<li>哨兵至少需要 3 个实例，来保证自己的健壮性。</li>\n<li>哨兵 + Redis 主从的部署架构，是<strong>不保证数据零丢失</strong>的，只能保证 Redis 集群的高可用性。</li>\n<li>对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。</li>\n</ul>\n<p>哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。</p>\n<pre><code>+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n</code></pre>\n<p>配置 <code>quorum=1</code> ，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。</p>\n<pre><code>2 个哨兵，majority=2\n3 个哨兵，majority=2\n4 个哨兵，majority=2\n5 个哨兵，majority=3\n...\n</code></pre>\n<p>如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。</p>\n<p>经典的 3 节点哨兵集群是这样的：</p>\n<pre><code>       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n</code></pre>\n<p>配置 <code>quorum=2</code> ，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。</p>\n<h2 id=\"Redis-哨兵主备切换的数据丢失问题\"><a href=\"#Redis-哨兵主备切换的数据丢失问题\" class=\"headerlink\" title=\"Redis 哨兵主备切换的数据丢失问题\"></a>Redis 哨兵主备切换的数据丢失问题</h2><h3 id=\"导致数据丢失的两种情况\"><a href=\"#导致数据丢失的两种情况\" class=\"headerlink\" title=\"导致数据丢失的两种情况\"></a>导致数据丢失的两种情况</h3><p>主备切换的过程，可能会导致数据丢失：</p>\n<ul>\n<li>异步复制导致的数据丢失</li>\n</ul>\n<p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。</p>\n<p><img src=\"async-replication-data-lose-case.png\" alt=\"redis知识点整理\"></p>\n<ul>\n<li>脑裂导致的数据丢失</li>\n</ul>\n<p>脑裂，也就是说，某个 master 所在机器突然<strong>脱离了正常的网络</strong>，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会<strong>认为</strong> master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p>\n<p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p>\n<p><img src=\"redis-cluster-split-brain.png\" alt=\"redis知识点整理\"></p>\n<h3 id=\"数据丢失问题的解决方案\"><a href=\"#数据丢失问题的解决方案\" class=\"headerlink\" title=\"数据丢失问题的解决方案\"></a>数据丢失问题的解决方案</h3><p>进行如下配置：</p>\n<pre><code class=\"bash\">min-slaves-to-write 1\nmin-slaves-max-lag 10\n</code></pre>\n<p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p>\n<p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p>\n<ul>\n<li>减少异步复制数据的丢失</li>\n</ul>\n<p>有了 <code>min-slaves-max-lag</code> 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p>\n<ul>\n<li>减少脑裂的数据丢失</li>\n</ul>\n<p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。</p>\n<h2 id=\"sdown-和-odown-转换机制\"><a href=\"#sdown-和-odown-转换机制\" class=\"headerlink\" title=\"sdown 和 odown 转换机制\"></a>sdown 和 odown 转换机制</h2><ul>\n<li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li>\n<li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li>\n</ul>\n<p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 <code>is-master-down-after-milliseconds</code> 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p>\n<h2 id=\"哨兵集群的自动发现机制\"><a href=\"#哨兵集群的自动发现机制\" class=\"headerlink\" title=\"哨兵集群的自动发现机制\"></a>哨兵集群的自动发现机制</h2><p>哨兵互相之间的发现，是通过 Redis 的 <code>pub/sub</code> 系统实现的，每个哨兵都会往 <code>__sentinel__:hello</code> 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p>\n<p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <code>__sentinel__:hello</code> channel 里<strong>发送一个消息</strong>，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p>\n<p>每个哨兵也会去<strong>监听</strong>自己监控的每个 master+slaves 对应的 <code>__sentinel__:hello</code> channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p>\n<p>每个哨兵还会跟其他哨兵交换对 <code>master</code> 的监控配置，互相进行监控配置的同步。</p>\n<h2 id=\"slave-配置的自动纠正\"><a href=\"#slave-配置的自动纠正\" class=\"headerlink\" title=\"slave 配置的自动纠正\"></a>slave 配置的自动纠正</h2><p>哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。</p>\n<h2 id=\"slave-gt-master-选举算法\"><a href=\"#slave-gt-master-选举算法\" class=\"headerlink\" title=\"slave-&gt;master 选举算法\"></a>slave-&gt;master 选举算法</h2><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p>\n<ul>\n<li>跟 master 断开连接的时长</li>\n<li>slave 优先级</li>\n<li>复制 offset</li>\n<li>run id</li>\n</ul>\n<p>如果一个 slave 跟 master 断开连接的时间已经超过了 <code>down-after-milliseconds</code> 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p>\n<pre><code>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n</code></pre>\n<p>接下来会对 slave 进行排序：</p>\n<ul>\n<li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li>\n<li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li>\n<li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li>\n</ul>\n<h2 id=\"quorum-和-majority\"><a href=\"#quorum-和-majority\" class=\"headerlink\" title=\"quorum 和 majority\"></a>quorum 和 majority</h2><p>每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。</p>\n<p>如果 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。</p>\n<p>但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。</p>\n<h2 id=\"configuration-epoch\"><a href=\"#configuration-epoch\" class=\"headerlink\" title=\"configuration epoch\"></a>configuration epoch</h2><p>哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。</p>\n<p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。</p>\n<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。</p>\n<h2 id=\"configuration-传播\"><a href=\"#configuration-传播\" class=\"headerlink\" title=\"configuration 传播\"></a>configuration 传播</h2><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 <code>pub/sub</code> 消息机制。</p>\n<p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p>\n<h2 id=\"面试题-4\"><a href=\"#面试题-4\" class=\"headerlink\" title=\"面试题\"></a>面试题</h2><p>Redis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么 Redis 单线程却能支撑高并发？</p>\n<h2 id=\"面试官心理分析-5\"><a href=\"#面试官心理分析-5\" class=\"headerlink\" title=\"面试官心理分析\"></a>面试官心理分析</h2><p>这个是问 Redis 的时候，最基本的问题吧，Redis 最基本的一个内部原理和特点，就是 Redis 实际上是个<strong>单线程工作模型</strong>，你要是这个都不知道，那后面玩儿 Redis 的时候，出了问题岂不是什么都不知道？</p>\n<p>还有可能面试官会问问你 Redis 和 Memcached 的区别，但是 Memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 Redis，没什么公司用 Memcached 了。</p>\n<h2 id=\"面试题剖析-5\"><a href=\"#面试题剖析-5\" class=\"headerlink\" title=\"面试题剖析\"></a>面试题剖析</h2><h3 id=\"Redis-和-Memcached-有啥区别？\"><a href=\"#Redis-和-Memcached-有啥区别？\" class=\"headerlink\" title=\"Redis 和 Memcached 有啥区别？\"></a>Redis 和 Memcached 有啥区别？</h3><h4 id=\"Redis-支持复杂的数据结构\"><a href=\"#Redis-支持复杂的数据结构\" class=\"headerlink\" title=\"Redis 支持复杂的数据结构\"></a>Redis 支持复杂的数据结构</h4><p>Redis 相比 Memcached 来说，拥有<a href=\"Redis-%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\">更多的数据结构</a>，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。</p>\n<h4 id=\"Redis-原生支持集群模式\"><a href=\"#Redis-原生支持集群模式\" class=\"headerlink\" title=\"Redis 原生支持集群模式\"></a>Redis 原生支持集群模式</h4><p>在 Redis3.x 版本中，便能支持 cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p>\n<h4 id=\"性能对比\"><a href=\"#性能对比\" class=\"headerlink\" title=\"性能对比\"></a>性能对比</h4><p>由于 Redis 只使用<strong>单核</strong>，而 Memcached 可以使用<strong>多核</strong>，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。</p>\n<h3 id=\"Redis-的线程模型\"><a href=\"#Redis-的线程模型\" class=\"headerlink\" title=\"Redis 的线程模型\"></a>Redis 的线程模型</h3><p>Redis 内部使用文件事件处理器 <code>file event handler</code> ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p>\n<p>文件事件处理器的结构包含 4 个部分：</p>\n<ul>\n<li>多个 socket</li>\n<li>IO 多路复用程序</li>\n<li>文件事件分派器</li>\n<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>\n</ul>\n<p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p>\n<p>来看客户端与 Redis 的一次通信过程：</p>\n<p><img src=\"redis-single-thread-model.png\" alt=\"redis知识点整理\"></p>\n<p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p>\n<p>首先，Redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p>\n<p>客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p>\n<p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 Redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p>\n<p>如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code> ，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p>\n<p>这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《<a href=\"https://github.com/doocs/technical-books#database\">Redis 设计与实现——黄健宏</a>》进行系统学习。</p>\n<h3 id=\"为啥-Redis-单线程模型也能效率这么高？\"><a href=\"#为啥-Redis-单线程模型也能效率这么高？\" class=\"headerlink\" title=\"为啥 Redis 单线程模型也能效率这么高？\"></a>为啥 Redis 单线程模型也能效率这么高？</h3><ul>\n<li>纯内存操作。</li>\n<li>核心是基于非阻塞的 IO 多路复用机制。</li>\n<li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li>\n<li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li>\n</ul>\n<h3 id=\"Redis-6-0-开始引入多线程\"><a href=\"#Redis-6-0-开始引入多线程\" class=\"headerlink\" title=\"Redis 6.0 开始引入多线程\"></a>Redis 6.0 开始引入多线程</h3><p><strong>注意！</strong> Redis 6.0 之后的版本抛弃了单线程模型这一设计，<strong>原本使用单线程运行的 Redis 也开始选择性地使用多线程模型</strong>。</p>\n<p>前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。</p>\n<p><strong>Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。</strong> 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间(释放操作不会阻塞网络 IO 读写,因为网络 IO 读写与释放的命令执行不是同一个线程)也能减少对 Redis 主线程阻塞的时间，提高执行的效率。</p>"},{"title":"分库分表之后的id主键如何处理","date":"2022-09-28T06:50:17.000Z","_content":"分库分表之后，id 主键如何处理？\n<!--more-->\n## 分析\n\n其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个**全局唯一**的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。\n\n## 剖析\n\n### 基于数据库的实现方案\n\n#### 数据库自增 id\n\n这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。\n\n这个方案的好处就是方便简单，谁都会用；**缺点就是单库生成**自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是**无论如何都是基于单个数据库**。\n\n**适合的场景**：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你**并发不高，但是数据量太大**导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。\n\n#### 设置数据库 sequence 或者表自增字段步长\n\n可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。\n\n比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。\n\n![分库分表之后的id主键如何处理](database-id-sequence-step.png)\n\n**适合的场景**：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。\n\n### UUID\n\n好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，**作为主键性能太差**了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。\n\n适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。\n\n```java\nUUID.randomUUID().toString().replace(\"-\", \"\") -> sfsdf23423rr234sfdaf\n```\n\n### 获取系统当前时间\n\n这个就是获取当前时间即可，但是问题是，**并发很高的时候**，比如一秒并发几千，**会有重复的情况**，这个是肯定不合适的。基本就不用考虑了。\n\n适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。\n\n### snowflake 算法\n\nsnowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。\n\n- 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。\n- 41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 `2^41 - 1` ，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示 69 年的时间。\n- 10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 `2^5` 个机房（32 个机房），每个机房里可以代表 `2^5` 个机器（32 台机器）。\n- 12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 `2^12 - 1 = 4096` ，也就是说可以用这个 12 bits 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。\n\n```sh\n0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000\n```\n\n```java\npublic class IdWorker {\n\n    private long workerId;\n    private long datacenterId;\n    private long sequence;\n\n    public IdWorker(long workerId, long datacenterId, long sequence) {\n        // sanity check for workerId\n        // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(\n                    String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(\n                    String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        System.out.printf(\n                \"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d\",\n                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);\n\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n        this.sequence = sequence;\n    }\n\n    private long twepoch = 1288834974657L;\n\n    private long workerIdBits = 5L;\n    private long datacenterIdBits = 5L;\n\n    // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内\n    private long maxWorkerId = -1L ^ (-1L << workerIdBits);\n\n    // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内\n    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n    private long sequenceBits = 12L;\n\n    private long workerIdShift = sequenceBits;\n    private long datacenterIdShift = sequenceBits + workerIdBits;\n    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n    private long sequenceMask = -1L ^ (-1L << sequenceBits);\n\n    private long lastTimestamp = -1L;\n\n    public long getWorkerId() {\n        return workerId;\n    }\n\n    public long getDatacenterId() {\n        return datacenterId;\n    }\n\n    public long getTimestamp() {\n        return System.currentTimeMillis();\n    }\n\n    public synchronized long nextId() {\n        // 这儿就是获取当前时间戳，单位是毫秒\n        long timestamp = timeGen();\n\n        if (timestamp < lastTimestamp) {\n            System.err.printf(\"clock is moving backwards.  Rejecting requests until %d.\", lastTimestamp);\n            throw new RuntimeException(String.format(\n                    \"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        if (lastTimestamp == timestamp) {\n            // 这个意思是说一个毫秒内最多只能有4096个数字\n            // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            sequence = (sequence + 1) & sequenceMask;\n            if (sequence == 0) {\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        } else {\n            sequence = 0;\n        }\n\n        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒\n        lastTimestamp = timestamp;\n\n        // 这儿就是将时间戳左移，放到 41 bit那儿；\n        // 将机房 id左移放到 5 bit那儿；\n        // 将机器id左移放到5 bit那儿；将序号放最后12 bit；\n        // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型\n        return ((timestamp - twepoch) << timestampLeftShift) | (datacenterId << datacenterIdShift)\n                | (workerId << workerIdShift) | sequence;\n    }\n\n    private long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n\n    private long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    // ---------------测试---------------\n    public static void main(String[] args) {\n        IdWorker worker = new IdWorker(1, 1, 1);\n        for (int i = 0; i < 30; i++) {\n            System.out.println(worker.nextId());\n        }\n    }\n\n}\n\n```\n\n怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个**机房** id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的**机器** id（但是最大只能是 32 以内），剩下的那个 12 bit 序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。\n\n所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。\n\n利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。\n\n这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。\n","source":"_posts/分库分表之后的id主键如何处理.md","raw":"---\ntitle: 分库分表之后的id主键如何处理\ndate: 2022-09-28 14:50:17\ntags: \n- 数据库\n- 分库分表\n---\n分库分表之后，id 主键如何处理？\n<!--more-->\n## 分析\n\n其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个**全局唯一**的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。\n\n## 剖析\n\n### 基于数据库的实现方案\n\n#### 数据库自增 id\n\n这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。\n\n这个方案的好处就是方便简单，谁都会用；**缺点就是单库生成**自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是**无论如何都是基于单个数据库**。\n\n**适合的场景**：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你**并发不高，但是数据量太大**导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。\n\n#### 设置数据库 sequence 或者表自增字段步长\n\n可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。\n\n比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。\n\n![分库分表之后的id主键如何处理](database-id-sequence-step.png)\n\n**适合的场景**：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。\n\n### UUID\n\n好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，**作为主键性能太差**了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。\n\n适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。\n\n```java\nUUID.randomUUID().toString().replace(\"-\", \"\") -> sfsdf23423rr234sfdaf\n```\n\n### 获取系统当前时间\n\n这个就是获取当前时间即可，但是问题是，**并发很高的时候**，比如一秒并发几千，**会有重复的情况**，这个是肯定不合适的。基本就不用考虑了。\n\n适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。\n\n### snowflake 算法\n\nsnowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。\n\n- 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。\n- 41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 `2^41 - 1` ，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示 69 年的时间。\n- 10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 `2^5` 个机房（32 个机房），每个机房里可以代表 `2^5` 个机器（32 台机器）。\n- 12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 `2^12 - 1 = 4096` ，也就是说可以用这个 12 bits 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。\n\n```sh\n0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000\n```\n\n```java\npublic class IdWorker {\n\n    private long workerId;\n    private long datacenterId;\n    private long sequence;\n\n    public IdWorker(long workerId, long datacenterId, long sequence) {\n        // sanity check for workerId\n        // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(\n                    String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(\n                    String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        System.out.printf(\n                \"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d\",\n                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);\n\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n        this.sequence = sequence;\n    }\n\n    private long twepoch = 1288834974657L;\n\n    private long workerIdBits = 5L;\n    private long datacenterIdBits = 5L;\n\n    // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内\n    private long maxWorkerId = -1L ^ (-1L << workerIdBits);\n\n    // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内\n    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n    private long sequenceBits = 12L;\n\n    private long workerIdShift = sequenceBits;\n    private long datacenterIdShift = sequenceBits + workerIdBits;\n    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n    private long sequenceMask = -1L ^ (-1L << sequenceBits);\n\n    private long lastTimestamp = -1L;\n\n    public long getWorkerId() {\n        return workerId;\n    }\n\n    public long getDatacenterId() {\n        return datacenterId;\n    }\n\n    public long getTimestamp() {\n        return System.currentTimeMillis();\n    }\n\n    public synchronized long nextId() {\n        // 这儿就是获取当前时间戳，单位是毫秒\n        long timestamp = timeGen();\n\n        if (timestamp < lastTimestamp) {\n            System.err.printf(\"clock is moving backwards.  Rejecting requests until %d.\", lastTimestamp);\n            throw new RuntimeException(String.format(\n                    \"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        if (lastTimestamp == timestamp) {\n            // 这个意思是说一个毫秒内最多只能有4096个数字\n            // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            sequence = (sequence + 1) & sequenceMask;\n            if (sequence == 0) {\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        } else {\n            sequence = 0;\n        }\n\n        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒\n        lastTimestamp = timestamp;\n\n        // 这儿就是将时间戳左移，放到 41 bit那儿；\n        // 将机房 id左移放到 5 bit那儿；\n        // 将机器id左移放到5 bit那儿；将序号放最后12 bit；\n        // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型\n        return ((timestamp - twepoch) << timestampLeftShift) | (datacenterId << datacenterIdShift)\n                | (workerId << workerIdShift) | sequence;\n    }\n\n    private long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n\n    private long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    // ---------------测试---------------\n    public static void main(String[] args) {\n        IdWorker worker = new IdWorker(1, 1, 1);\n        for (int i = 0; i < 30; i++) {\n            System.out.println(worker.nextId());\n        }\n    }\n\n}\n\n```\n\n怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个**机房** id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的**机器** id（但是最大只能是 32 以内），剩下的那个 12 bit 序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。\n\n所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。\n\n利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。\n\n这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。\n","slug":"分库分表之后的id主键如何处理","published":1,"updated":"2022-09-28T06:52:26.300Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0kz000qekwe3a425ww3","content":"<p>分库分表之后，id 主键如何处理？</p>\n<span id=\"more\"></span>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个<strong>全局唯一</strong>的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><h3 id=\"基于数据库的实现方案\"><a href=\"#基于数据库的实现方案\" class=\"headerlink\" title=\"基于数据库的实现方案\"></a>基于数据库的实现方案</h3><h4 id=\"数据库自增-id\"><a href=\"#数据库自增-id\" class=\"headerlink\" title=\"数据库自增 id\"></a>数据库自增 id</h4><p>这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。</p>\n<p>这个方案的好处就是方便简单，谁都会用；<strong>缺点就是单库生成</strong>自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是<strong>无论如何都是基于单个数据库</strong>。</p>\n<p><strong>适合的场景</strong>：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你<strong>并发不高，但是数据量太大</strong>导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。</p>\n<h4 id=\"设置数据库-sequence-或者表自增字段步长\"><a href=\"#设置数据库-sequence-或者表自增字段步长\" class=\"headerlink\" title=\"设置数据库 sequence 或者表自增字段步长\"></a>设置数据库 sequence 或者表自增字段步长</h4><p>可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。</p>\n<p>比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。</p>\n<p><img src=\"database-id-sequence-step.png\" alt=\"分库分表之后的id主键如何处理\"></p>\n<p><strong>适合的场景</strong>：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。</p>\n<h3 id=\"UUID\"><a href=\"#UUID\" class=\"headerlink\" title=\"UUID\"></a>UUID</h3><p>好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，<strong>作为主键性能太差</strong>了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。</p>\n<p>适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。</p>\n<pre><code class=\"java\">UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;) -&gt; sfsdf23423rr234sfdaf\n</code></pre>\n<h3 id=\"获取系统当前时间\"><a href=\"#获取系统当前时间\" class=\"headerlink\" title=\"获取系统当前时间\"></a>获取系统当前时间</h3><p>这个就是获取当前时间即可，但是问题是，<strong>并发很高的时候</strong>，比如一秒并发几千，<strong>会有重复的情况</strong>，这个是肯定不合适的。基本就不用考虑了。</p>\n<p>适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。</p>\n<h3 id=\"snowflake-算法\"><a href=\"#snowflake-算法\" class=\"headerlink\" title=\"snowflake 算法\"></a>snowflake 算法</h3><p>snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。</p>\n<ul>\n<li>1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。</li>\n<li>41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 <code>2^41 - 1</code> ，也就是可以标识 <code>2^41 - 1</code> 个毫秒值，换算成年就是表示 69 年的时间。</li>\n<li>10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 <code>2^5</code> 个机房（32 个机房），每个机房里可以代表 <code>2^5</code> 个机器（32 台机器）。</li>\n<li>12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 <code>2^12 - 1 = 4096</code> ，也就是说可以用这个 12 bits 代表的数字来区分<strong>同一个毫秒内</strong>的 4096 个不同的 id。</li>\n</ul>\n<pre><code class=\"sh\">0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000\n</code></pre>\n<pre><code class=\"java\">public class IdWorker &#123;\n\n    private long workerId;\n    private long datacenterId;\n    private long sequence;\n\n    public IdWorker(long workerId, long datacenterId, long sequence) &#123;\n        // sanity check for workerId\n        // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0\n        if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123;\n            throw new IllegalArgumentException(\n                    String.format(&quot;worker Id can&#39;t be greater than %d or less than 0&quot;, maxWorkerId));\n        &#125;\n        if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123;\n            throw new IllegalArgumentException(\n                    String.format(&quot;datacenter Id can&#39;t be greater than %d or less than 0&quot;, maxDatacenterId));\n        &#125;\n        System.out.printf(\n                &quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;,\n                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);\n\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n        this.sequence = sequence;\n    &#125;\n\n    private long twepoch = 1288834974657L;\n\n    private long workerIdBits = 5L;\n    private long datacenterIdBits = 5L;\n\n    // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内\n    private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits);\n\n    // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内\n    private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits);\n    private long sequenceBits = 12L;\n\n    private long workerIdShift = sequenceBits;\n    private long datacenterIdShift = sequenceBits + workerIdBits;\n    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n    private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits);\n\n    private long lastTimestamp = -1L;\n\n    public long getWorkerId() &#123;\n        return workerId;\n    &#125;\n\n    public long getDatacenterId() &#123;\n        return datacenterId;\n    &#125;\n\n    public long getTimestamp() &#123;\n        return System.currentTimeMillis();\n    &#125;\n\n    public synchronized long nextId() &#123;\n        // 这儿就是获取当前时间戳，单位是毫秒\n        long timestamp = timeGen();\n\n        if (timestamp &lt; lastTimestamp) &#123;\n            System.err.printf(&quot;clock is moving backwards.  Rejecting requests until %d.&quot;, lastTimestamp);\n            throw new RuntimeException(String.format(\n                    &quot;Clock moved backwards.  Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp));\n        &#125;\n\n        if (lastTimestamp == timestamp) &#123;\n            // 这个意思是说一个毫秒内最多只能有4096个数字\n            // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            sequence = (sequence + 1) &amp; sequenceMask;\n            if (sequence == 0) &#123;\n                timestamp = tilNextMillis(lastTimestamp);\n            &#125;\n        &#125; else &#123;\n            sequence = 0;\n        &#125;\n\n        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒\n        lastTimestamp = timestamp;\n\n        // 这儿就是将时间戳左移，放到 41 bit那儿；\n        // 将机房 id左移放到 5 bit那儿；\n        // 将机器id左移放到5 bit那儿；将序号放最后12 bit；\n        // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型\n        return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift)\n                | (workerId &lt;&lt; workerIdShift) | sequence;\n    &#125;\n\n    private long tilNextMillis(long lastTimestamp) &#123;\n        long timestamp = timeGen();\n        while (timestamp &lt;= lastTimestamp) &#123;\n            timestamp = timeGen();\n        &#125;\n        return timestamp;\n    &#125;\n\n    private long timeGen() &#123;\n        return System.currentTimeMillis();\n    &#125;\n\n    // ---------------测试---------------\n    public static void main(String[] args) &#123;\n        IdWorker worker = new IdWorker(1, 1, 1);\n        for (int i = 0; i &lt; 30; i++) &#123;\n            System.out.println(worker.nextId());\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<p>怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个<strong>机房</strong> id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的<strong>机器</strong> id（但是最大只能是 32 以内），剩下的那个 12 bit 序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。</p>\n<p>所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。</p>\n<p>利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。</p>\n<p>这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。</p>\n","site":{"data":{}},"excerpt":"<p>分库分表之后，id 主键如何处理？</p>","more":"<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个<strong>全局唯一</strong>的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><h3 id=\"基于数据库的实现方案\"><a href=\"#基于数据库的实现方案\" class=\"headerlink\" title=\"基于数据库的实现方案\"></a>基于数据库的实现方案</h3><h4 id=\"数据库自增-id\"><a href=\"#数据库自增-id\" class=\"headerlink\" title=\"数据库自增 id\"></a>数据库自增 id</h4><p>这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。</p>\n<p>这个方案的好处就是方便简单，谁都会用；<strong>缺点就是单库生成</strong>自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是<strong>无论如何都是基于单个数据库</strong>。</p>\n<p><strong>适合的场景</strong>：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你<strong>并发不高，但是数据量太大</strong>导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。</p>\n<h4 id=\"设置数据库-sequence-或者表自增字段步长\"><a href=\"#设置数据库-sequence-或者表自增字段步长\" class=\"headerlink\" title=\"设置数据库 sequence 或者表自增字段步长\"></a>设置数据库 sequence 或者表自增字段步长</h4><p>可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。</p>\n<p>比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。</p>\n<p><img src=\"database-id-sequence-step.png\" alt=\"分库分表之后的id主键如何处理\"></p>\n<p><strong>适合的场景</strong>：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。</p>\n<h3 id=\"UUID\"><a href=\"#UUID\" class=\"headerlink\" title=\"UUID\"></a>UUID</h3><p>好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，<strong>作为主键性能太差</strong>了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。</p>\n<p>适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。</p>\n<pre><code class=\"java\">UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;) -&gt; sfsdf23423rr234sfdaf\n</code></pre>\n<h3 id=\"获取系统当前时间\"><a href=\"#获取系统当前时间\" class=\"headerlink\" title=\"获取系统当前时间\"></a>获取系统当前时间</h3><p>这个就是获取当前时间即可，但是问题是，<strong>并发很高的时候</strong>，比如一秒并发几千，<strong>会有重复的情况</strong>，这个是肯定不合适的。基本就不用考虑了。</p>\n<p>适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。</p>\n<h3 id=\"snowflake-算法\"><a href=\"#snowflake-算法\" class=\"headerlink\" title=\"snowflake 算法\"></a>snowflake 算法</h3><p>snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。</p>\n<ul>\n<li>1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。</li>\n<li>41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 <code>2^41 - 1</code> ，也就是可以标识 <code>2^41 - 1</code> 个毫秒值，换算成年就是表示 69 年的时间。</li>\n<li>10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 <code>2^5</code> 个机房（32 个机房），每个机房里可以代表 <code>2^5</code> 个机器（32 台机器）。</li>\n<li>12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 <code>2^12 - 1 = 4096</code> ，也就是说可以用这个 12 bits 代表的数字来区分<strong>同一个毫秒内</strong>的 4096 个不同的 id。</li>\n</ul>\n<pre><code class=\"sh\">0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000\n</code></pre>\n<pre><code class=\"java\">public class IdWorker &#123;\n\n    private long workerId;\n    private long datacenterId;\n    private long sequence;\n\n    public IdWorker(long workerId, long datacenterId, long sequence) &#123;\n        // sanity check for workerId\n        // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0\n        if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123;\n            throw new IllegalArgumentException(\n                    String.format(&quot;worker Id can&#39;t be greater than %d or less than 0&quot;, maxWorkerId));\n        &#125;\n        if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123;\n            throw new IllegalArgumentException(\n                    String.format(&quot;datacenter Id can&#39;t be greater than %d or less than 0&quot;, maxDatacenterId));\n        &#125;\n        System.out.printf(\n                &quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;,\n                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);\n\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n        this.sequence = sequence;\n    &#125;\n\n    private long twepoch = 1288834974657L;\n\n    private long workerIdBits = 5L;\n    private long datacenterIdBits = 5L;\n\n    // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内\n    private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits);\n\n    // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内\n    private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits);\n    private long sequenceBits = 12L;\n\n    private long workerIdShift = sequenceBits;\n    private long datacenterIdShift = sequenceBits + workerIdBits;\n    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n    private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits);\n\n    private long lastTimestamp = -1L;\n\n    public long getWorkerId() &#123;\n        return workerId;\n    &#125;\n\n    public long getDatacenterId() &#123;\n        return datacenterId;\n    &#125;\n\n    public long getTimestamp() &#123;\n        return System.currentTimeMillis();\n    &#125;\n\n    public synchronized long nextId() &#123;\n        // 这儿就是获取当前时间戳，单位是毫秒\n        long timestamp = timeGen();\n\n        if (timestamp &lt; lastTimestamp) &#123;\n            System.err.printf(&quot;clock is moving backwards.  Rejecting requests until %d.&quot;, lastTimestamp);\n            throw new RuntimeException(String.format(\n                    &quot;Clock moved backwards.  Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp));\n        &#125;\n\n        if (lastTimestamp == timestamp) &#123;\n            // 这个意思是说一个毫秒内最多只能有4096个数字\n            // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            sequence = (sequence + 1) &amp; sequenceMask;\n            if (sequence == 0) &#123;\n                timestamp = tilNextMillis(lastTimestamp);\n            &#125;\n        &#125; else &#123;\n            sequence = 0;\n        &#125;\n\n        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒\n        lastTimestamp = timestamp;\n\n        // 这儿就是将时间戳左移，放到 41 bit那儿；\n        // 将机房 id左移放到 5 bit那儿；\n        // 将机器id左移放到5 bit那儿；将序号放最后12 bit；\n        // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型\n        return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift)\n                | (workerId &lt;&lt; workerIdShift) | sequence;\n    &#125;\n\n    private long tilNextMillis(long lastTimestamp) &#123;\n        long timestamp = timeGen();\n        while (timestamp &lt;= lastTimestamp) &#123;\n            timestamp = timeGen();\n        &#125;\n        return timestamp;\n    &#125;\n\n    private long timeGen() &#123;\n        return System.currentTimeMillis();\n    &#125;\n\n    // ---------------测试---------------\n    public static void main(String[] args) &#123;\n        IdWorker worker = new IdWorker(1, 1, 1);\n        for (int i = 0; i &lt; 30; i++) &#123;\n            System.out.println(worker.nextId());\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<p>怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个<strong>机房</strong> id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的<strong>机器</strong> id（但是最大只能是 32 以内），剩下的那个 12 bit 序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。</p>\n<p>所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。</p>\n<p>利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。</p>\n<p>这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。</p>"},{"title":"可以动态扩容缩容的分库分表方案","date":"2022-09-28T06:42:26.000Z","_content":"如何设计可以动态扩容缩容的分库分表方案？\n<!--more-->\n## 分析\n\n对于分库分表来说，主要是面对以下问题：\n\n- 选择一个数据库中间件，调研、学习、测试；\n- 设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；\n- 基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；\n- 完成单库单表到分库分表的**迁移**，双写方案；\n- 线上系统开始基于分库分表对外提供服务；\n- 扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？\n\n这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。\n\n那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。\n\n这都是玩儿分库分表线上必须经历的事儿。\n\n## 剖析\n\n### 停机扩容（不推荐）\n\n这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然**分库分表**就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。\n\n从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1 小时数据就导完了。这没有问题。\n\n如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。\n\n### 优化后的方案\n\n一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。\n\n我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。\n\n每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 _ 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 _ 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个 MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。\n\n有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。\n\n1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。\n\n每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。\n\n谈分库分表的扩容，**第一次分库分表，就一次性给他分个够**，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。\n\n一个实践是利用 `32 * 32` 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。\n\n| orderId | id % 32 (库) | id / 32 % 32 (表) |\n| ------- | ------------ | ----------------- |\n| 259     | 3            | 8                 |\n| 1189    | 5            | 5                 |\n| 352     | 0            | 11                |\n| 4593    | 17           | 15                |\n\n刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。\n\n比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。\n\n这么搞，是不用自己写代码做数据迁移的，都交给 DBA 来搞好了，但是 DBA 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。\n\n哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。\n\n这里对步骤做一个总结：\n\n1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 \\* 32 表，对于大部分公司来说，可能几年都够了。\n2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表\n3. 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。\n4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。\n5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。\n6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。\n","source":"_posts/可以动态扩容缩容的分库分表方案.md","raw":"---\ntitle: 可以动态扩容缩容的分库分表方案\ndate: 2022-09-28 14:42:26\ntags: \n- 数据库\n- 分库分表\n---\n如何设计可以动态扩容缩容的分库分表方案？\n<!--more-->\n## 分析\n\n对于分库分表来说，主要是面对以下问题：\n\n- 选择一个数据库中间件，调研、学习、测试；\n- 设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；\n- 基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；\n- 完成单库单表到分库分表的**迁移**，双写方案；\n- 线上系统开始基于分库分表对外提供服务；\n- 扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？\n\n这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。\n\n那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。\n\n这都是玩儿分库分表线上必须经历的事儿。\n\n## 剖析\n\n### 停机扩容（不推荐）\n\n这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然**分库分表**就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。\n\n从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1 小时数据就导完了。这没有问题。\n\n如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。\n\n### 优化后的方案\n\n一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。\n\n我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。\n\n每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 _ 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 _ 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个 MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。\n\n有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。\n\n1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。\n\n每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。\n\n谈分库分表的扩容，**第一次分库分表，就一次性给他分个够**，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。\n\n一个实践是利用 `32 * 32` 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。\n\n| orderId | id % 32 (库) | id / 32 % 32 (表) |\n| ------- | ------------ | ----------------- |\n| 259     | 3            | 8                 |\n| 1189    | 5            | 5                 |\n| 352     | 0            | 11                |\n| 4593    | 17           | 15                |\n\n刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。\n\n比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。\n\n这么搞，是不用自己写代码做数据迁移的，都交给 DBA 来搞好了，但是 DBA 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。\n\n哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。\n\n这里对步骤做一个总结：\n\n1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 \\* 32 表，对于大部分公司来说，可能几年都够了。\n2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表\n3. 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。\n4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。\n5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。\n6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。\n","slug":"可以动态扩容缩容的分库分表方案","published":1,"updated":"2022-09-28T06:45:33.421Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0l1000rekweg53i5j2q","content":"<p>如何设计可以动态扩容缩容的分库分表方案？</p>\n<span id=\"more\"></span>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>对于分库分表来说，主要是面对以下问题：</p>\n<ul>\n<li>选择一个数据库中间件，调研、学习、测试；</li>\n<li>设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；</li>\n<li>基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；</li>\n<li>完成单库单表到分库分表的<strong>迁移</strong>，双写方案；</li>\n<li>线上系统开始基于分库分表对外提供服务；</li>\n<li>扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？</li>\n</ul>\n<p>这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。</p>\n<p>那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。</p>\n<p>这都是玩儿分库分表线上必须经历的事儿。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><h3 id=\"停机扩容（不推荐）\"><a href=\"#停机扩容（不推荐）\" class=\"headerlink\" title=\"停机扩容（不推荐）\"></a>停机扩容（不推荐）</h3><p>这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然<strong>分库分表</strong>就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。</p>\n<p>从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1 小时数据就导完了。这没有问题。</p>\n<p>如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。</p>\n<h3 id=\"优化后的方案\"><a href=\"#优化后的方案\" class=\"headerlink\" title=\"优化后的方案\"></a>优化后的方案</h3><p>一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。</p>\n<p>我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。</p>\n<p>每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 _ 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 _ 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个 MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。</p>\n<p>有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。</p>\n<p>1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。</p>\n<p>每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。</p>\n<p>谈分库分表的扩容，<strong>第一次分库分表，就一次性给他分个够</strong>，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。</p>\n<p>一个实践是利用 <code>32 * 32</code> 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。</p>\n<table>\n<thead>\n<tr>\n<th>orderId</th>\n<th>id % 32 (库)</th>\n<th>id / 32 % 32 (表)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>259</td>\n<td>3</td>\n<td>8</td>\n</tr>\n<tr>\n<td>1189</td>\n<td>5</td>\n<td>5</td>\n</tr>\n<tr>\n<td>352</td>\n<td>0</td>\n<td>11</td>\n</tr>\n<tr>\n<td>4593</td>\n<td>17</td>\n<td>15</td>\n</tr>\n</tbody></table>\n<p>刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。</p>\n<p>比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。</p>\n<p>这么搞，是不用自己写代码做数据迁移的，都交给 DBA 来搞好了，但是 DBA 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。</p>\n<p>哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。</p>\n<p>这里对步骤做一个总结：</p>\n<ol>\n<li>设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。</li>\n<li>路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表</li>\n<li>扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。</li>\n<li>由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。</li>\n<li>我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。</li>\n<li>重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>如何设计可以动态扩容缩容的分库分表方案？</p>","more":"<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>对于分库分表来说，主要是面对以下问题：</p>\n<ul>\n<li>选择一个数据库中间件，调研、学习、测试；</li>\n<li>设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；</li>\n<li>基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；</li>\n<li>完成单库单表到分库分表的<strong>迁移</strong>，双写方案；</li>\n<li>线上系统开始基于分库分表对外提供服务；</li>\n<li>扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？</li>\n</ul>\n<p>这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。</p>\n<p>那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。</p>\n<p>这都是玩儿分库分表线上必须经历的事儿。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><h3 id=\"停机扩容（不推荐）\"><a href=\"#停机扩容（不推荐）\" class=\"headerlink\" title=\"停机扩容（不推荐）\"></a>停机扩容（不推荐）</h3><p>这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然<strong>分库分表</strong>就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。</p>\n<p>从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1 小时数据就导完了。这没有问题。</p>\n<p>如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。</p>\n<h3 id=\"优化后的方案\"><a href=\"#优化后的方案\" class=\"headerlink\" title=\"优化后的方案\"></a>优化后的方案</h3><p>一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。</p>\n<p>我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。</p>\n<p>每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 _ 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 _ 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个 MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。</p>\n<p>有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。</p>\n<p>1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。</p>\n<p>每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。</p>\n<p>谈分库分表的扩容，<strong>第一次分库分表，就一次性给他分个够</strong>，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。</p>\n<p>一个实践是利用 <code>32 * 32</code> 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。</p>\n<table>\n<thead>\n<tr>\n<th>orderId</th>\n<th>id % 32 (库)</th>\n<th>id / 32 % 32 (表)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>259</td>\n<td>3</td>\n<td>8</td>\n</tr>\n<tr>\n<td>1189</td>\n<td>5</td>\n<td>5</td>\n</tr>\n<tr>\n<td>352</td>\n<td>0</td>\n<td>11</td>\n</tr>\n<tr>\n<td>4593</td>\n<td>17</td>\n<td>15</td>\n</tr>\n</tbody></table>\n<p>刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。</p>\n<p>比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。</p>\n<p>这么搞，是不用自己写代码做数据迁移的，都交给 DBA 来搞好了，但是 DBA 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。</p>\n<p>哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。</p>\n<p>这里对步骤做一个总结：</p>\n<ol>\n<li>设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。</li>\n<li>路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表</li>\n<li>扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。</li>\n<li>由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。</li>\n<li>我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。</li>\n<li>重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li>\n</ol>"},{"title":"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？","date":"2022-09-28T06:59:57.000Z","_content":"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表**动态切换**到分库分表上？\n<!--more-->\n## 分析\n\n你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？\n\n所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。\n\n## 剖析\n\n这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。\n\n### 停机迁移方案\n\n我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。\n\n接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个**导数的一次性工具**，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。\n\n导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。\n\n验证一下，ok 了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。\n\n但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。\n\n![现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？](database-shard-method-1.png)\n\n### 双写迁移方案\n\n这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。\n\n简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**，这就是所谓的**双写**，同时写俩库，老库和新库。\n\n然后**系统部署**之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。\n\n导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。\n\n接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。\n\n![现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？](database-shard-method-2.png)\n","source":"_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？.md","raw":"---\ntitle: 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？\ndate: 2022-09-28 14:59:57\ntags:\n- 数据库\n- 分库分表\n---\n现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表**动态切换**到分库分表上？\n<!--more-->\n## 分析\n\n你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？\n\n所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。\n\n## 剖析\n\n这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。\n\n### 停机迁移方案\n\n我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。\n\n接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个**导数的一次性工具**，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。\n\n导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。\n\n验证一下，ok 了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。\n\n但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。\n\n![现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？](database-shard-method-1.png)\n\n### 双写迁移方案\n\n这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。\n\n简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**，这就是所谓的**双写**，同时写俩库，老库和新库。\n\n然后**系统部署**之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。\n\n导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。\n\n接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。\n\n![现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？](database-shard-method-2.png)\n","slug":"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？","published":1,"updated":"2022-09-28T07:01:45.165Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0l1000tekwed662bzd6","content":"<p>现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表<strong>动态切换</strong>到分库分表上？</p>\n<span id=\"more\"></span>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？</p>\n<p>所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><p>这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。</p>\n<h3 id=\"停机迁移方案\"><a href=\"#停机迁移方案\" class=\"headerlink\" title=\"停机迁移方案\"></a>停机迁移方案</h3><p>我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。</p>\n<p>接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个<strong>导数的一次性工具</strong>，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。</p>\n<p>导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。</p>\n<p>验证一下，ok 了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。</p>\n<p>但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。</p>\n<p><img src=\"database-shard-method-1.png\" alt=\"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？\"></p>\n<h3 id=\"双写迁移方案\"><a href=\"#双写迁移方案\" class=\"headerlink\" title=\"双写迁移方案\"></a>双写迁移方案</h3><p>这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。</p>\n<p>简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong>，这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p>\n<p>然后<strong>系统部署</strong>之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。</p>\n<p>导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。</p>\n<p>接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。</p>\n<p><img src=\"database-shard-method-2.png\" alt=\"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？\"></p>\n","site":{"data":{}},"excerpt":"<p>现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表<strong>动态切换</strong>到分库分表上？</p>","more":"<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><p>你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？</p>\n<p>所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。</p>\n<h2 id=\"剖析\"><a href=\"#剖析\" class=\"headerlink\" title=\"剖析\"></a>剖析</h2><p>这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。</p>\n<h3 id=\"停机迁移方案\"><a href=\"#停机迁移方案\" class=\"headerlink\" title=\"停机迁移方案\"></a>停机迁移方案</h3><p>我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。</p>\n<p>接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个<strong>导数的一次性工具</strong>，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。</p>\n<p>导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。</p>\n<p>验证一下，ok 了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。</p>\n<p>但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。</p>\n<p><img src=\"database-shard-method-1.png\" alt=\"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？\"></p>\n<h3 id=\"双写迁移方案\"><a href=\"#双写迁移方案\" class=\"headerlink\" title=\"双写迁移方案\"></a>双写迁移方案</h3><p>这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。</p>\n<p>简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong>，这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p>\n<p>然后<strong>系统部署</strong>之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。</p>\n<p>导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。</p>\n<p>接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。</p>\n<p><img src=\"database-shard-method-2.png\" alt=\"现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？\"></p>"},{"title":"如何限流？在工作中是怎么做的？说一下具体的实现？","date":"2022-09-26T16:00:00.000Z","coverWidth":1200,"coverHeight":320,"author":"王恺","from":"笔记","_content":"如何限流？在工作中是怎么做的？说一下具体的实现？\n<!--more-->\n## 什么是限流\n\n\n\n> 限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。\n\n## 限流方法\n\n### 计数器\n\n#### 实现方式\n\n控制单位时间内的请求数量。\n\n```java\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Counter {\n    /**\n     * 最大访问数量\n     */\n    private final int limit = 10;\n    /**\n     * 访问时间差\n     */\n    private final long timeout = 1000;\n    /**\n     * 请求时间\n     */\n    private long time;\n    /**\n     * 当前计数器\n     */\n    private AtomicInteger reqCount = new AtomicInteger(0);\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        if (now < time + timeout) {\n            // 单位时间内\n            reqCount.addAndGet(1);\n            return reqCount.get() <= limit;\n        } else {\n            // 超出单位时间\n            time = now;\n            reqCount = new AtomicInteger(0);\n            return true;\n        }\n    }\n}\n\n```\n\n劣势：\n\n假设在 00:01 时发生一个请求，在 00:01-00:58 之间不在发送请求，在 00:59 时发送剩下的所有请求 `n-1` (n 为限流请求数量)，在下一分钟的 00:01 发送 n 个请求，这样在 2 秒钟内请求到达了 `2n - 1` 个。\n\n设每分钟请求数量为 60 个，每秒可以处理 1 个请求，用户在 00:59 发送 60 个请求，在 01:00 发送 60 个请求 此时 2 秒钟有 120 个请求(每秒 60 个请求)，远远大于了每秒钟处理数量的阈值。\n\n### 滑动窗口\n\n#### 实现方式\n\n滑动窗口是对计数器方式的改进，增加一个时间粒度的度量单位，把一分钟分成若干等分(6 份，每份 10 秒)，在每一份上设置独立计数器，在 00:00-00:09 之间发生请求计数器累加 1。当等分数量越大限流统计就越详细。\n\n```java\npackage com.example.demo1.service;\n\nimport java.util.Iterator;\nimport java.util.Random;\nimport java.util.concurrent.ConcurrentLinkedQueue;\nimport java.util.stream.IntStream;\n\npublic class TimeWindow {\n    private ConcurrentLinkedQueue<Long> queue = new ConcurrentLinkedQueue<Long>();\n\n    /**\n     * 间隔秒数\n     */\n    private int seconds;\n\n    /**\n     * 最大限流\n     */\n    private int max;\n\n    public TimeWindow(int max， int seconds) {\n        this.seconds = seconds;\n        this.max = max;\n\n        /**\n         * 永续线程执行清理queue 任务\n         */\n        new Thread(() -> {\n            while (true) {\n                try {\n                    // 等待 间隔秒数-1 执行清理操作\n                    Thread.sleep((seconds - 1) * 1000L);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                clean();\n            }\n        }).start();\n\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        final TimeWindow timeWindow = new TimeWindow(10， 1);\n\n        // 测试3个线程\n        IntStream.range(0， 3).forEach((i) -> {\n            new Thread(() -> {\n\n                while (true) {\n\n                    try {\n                        Thread.sleep(new Random().nextInt(20) * 100);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    timeWindow.take();\n                }\n\n            }).start();\n\n        });\n\n    }\n\n    /**\n     * 获取令牌，并且添加时间\n     */\n    public void take() {\n\n        long start = System.currentTimeMillis();\n        try {\n\n            int size = sizeOfValid();\n            if (size > max) {\n                System.err.println(\"超限\");\n\n            }\n            synchronized (queue) {\n                if (sizeOfValid() > max) {\n                    System.err.println(\"超限\");\n                    System.err.println(\"queue中有 \" + queue.size() + \" 最大数量 \" + max);\n                }\n                this.queue.offer(System.currentTimeMillis());\n            }\n            System.out.println(\"queue中有 \" + queue.size() + \" 最大数量 \" + max);\n\n        }\n\n    }\n\n    public int sizeOfValid() {\n        Iterator<Long> it = queue.iterator();\n        Long ms = System.currentTimeMillis() - seconds * 1000;\n        int count = 0;\n        while (it.hasNext()) {\n            long t = it.next();\n            if (t > ms) {\n                // 在当前的统计时间范围内\n                count++;\n            }\n        }\n\n        return count;\n    }\n\n    /**\n     * 清理过期的时间\n     */\n    public void clean() {\n        Long c = System.currentTimeMillis() - seconds * 1000;\n\n        Long tl = null;\n        while ((tl = queue.peek()) != null && tl < c) {\n            System.out.println(\"清理数据\");\n            queue.poll();\n        }\n    }\n\n}\n\n```\n\n### Leaky Bucket 漏桶\n\n#### 实现方式\n\n规定固定容量的桶，有水进入，有水流出。对于流进的水我们无法估计进来的数量、速度，对于流出的水我们可以控制速度。\n\n```java\npublic class LeakBucket {\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * 水流出去的速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        nowSize = Math.max(0， (nowSize - (now - time) * rate));\n        time = now;\n        if ((nowSize + 1) < total) {\n            nowSize++;\n            return true;\n        } else {\n            return false;\n        }\n\n    }\n}\n```\n\n### Token Bucket 令牌桶\n\n#### 实现方式\n\n规定固定容量的桶， token 以固定速度往桶内填充， 当桶满时 token 不会被继续放入， 每过来一个请求把 token 从桶中移除， 如果桶中没有 token 不能请求。\n\n```java\npublic class TokenBucket {\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * token 放入速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        nowSize = Math.min(total， nowSize + (now - time) * rate);\n        time = now;\n        if (nowSize < 1) {\n            // 桶里没有token\n            return false;\n        } else {\n            // 存在token\n            nowSize -= 1;\n            return true;\n        }\n    }\n\n}\n```\n\n## 工作中的使用\n\n### spring cloud gateway\n\n- spring cloud gateway 默认使用 redis 进行限流，笔者一般只是修改修改参数属于拿来即用，并没有去从头实现上述那些算法。\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n        - id: requestratelimiter_route\n\n          uri: lb://pigx-upms\n          order: 10000\n          predicates:\n            - Path=/admin/**\n\n          filters:\n            - name: RequestRateLimiter\n\n              args:\n                redis-rate-limiter.replenishRate: 1 # 令牌桶的容积\n                redis-rate-limiter.burstCapacity: 3 # 流速 每秒\n                key-resolver: \"#{@remoteAddrKeyResolver}\" #SPEL表达式去的对应的bean\n\n            - StripPrefix=1\n```\n\n```java\n@Bean\nKeyResolver remoteAddrKeyResolver() {\n    return exchange -> Mono.just(exchange.getRequest().getRemoteAddress().getHostName());\n}\n```\n\n### sentinel\n\n- 通过配置来控制每个 url 的流量\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n        port: 8720\n      datasource:\n        ds:\n          nacos:\n            server-addr: localhost:8848\n            dataId: spring-cloud-sentinel-nacos\n            groupId: DEFAULT_GROUP\n            rule-type: flow\n            namespace: xxxxxxxx\n```\n\n- 配置内容在 nacos 上进行编辑\n\n```json\n[\n  {\n    \"resource\": \"/hello\"，\n    \"limitApp\": \"default\"，\n    \"grade\": 1，\n    \"count\": 1，\n    \"strategy\": 0，\n    \"controlBehavior\": 0，\n    \"clusterMode\": false\n  }\n]\n```\n\n- resource：资源名，即限流规则的作用对象。\n- limitApp：流控针对的调用来源，若为 default 则不区分调用来源。\n- grade：限流阈值类型，QPS 或线程数模式，0 代表根据并发数量来限流，1 代表根据 QPS 来进行流量控制。\n- count：限流阈值\n- strategy：判断的根据是资源自身，还是根据其它关联资源 (refResource)，还是根据链路入口\n- controlBehavior：流控效果（直接拒绝 / 排队等待 / 慢启动模式）\n- clusterMode：是否为集群模式\n\n### 总结\n\n> sentinel 和 spring cloud gateway 两个框架都是很好的限流框架， 但是在我使用中还没有将[spring-cloud-alibaba](https://github.com/alibaba/spring-cloud-alibaba)接入到项目中进行使用， 所以我会选择**spring cloud gateway**， 当接入完整的或者接入 Nacos 项目使用 setinel 会有更加好的体验.\n","source":"_posts/限流.md","raw":"---\ntitle: 如何限流？在工作中是怎么做的？说一下具体的实现？\ndate: 2022-09-27\ntags:\n- 限流\ncategories:\n- 笔记\ncoverWidth: 1200\ncoverHeight: 320\nauthor: 王恺\nfrom: 笔记\n---\n如何限流？在工作中是怎么做的？说一下具体的实现？\n<!--more-->\n## 什么是限流\n\n\n\n> 限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。\n\n## 限流方法\n\n### 计数器\n\n#### 实现方式\n\n控制单位时间内的请求数量。\n\n```java\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Counter {\n    /**\n     * 最大访问数量\n     */\n    private final int limit = 10;\n    /**\n     * 访问时间差\n     */\n    private final long timeout = 1000;\n    /**\n     * 请求时间\n     */\n    private long time;\n    /**\n     * 当前计数器\n     */\n    private AtomicInteger reqCount = new AtomicInteger(0);\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        if (now < time + timeout) {\n            // 单位时间内\n            reqCount.addAndGet(1);\n            return reqCount.get() <= limit;\n        } else {\n            // 超出单位时间\n            time = now;\n            reqCount = new AtomicInteger(0);\n            return true;\n        }\n    }\n}\n\n```\n\n劣势：\n\n假设在 00:01 时发生一个请求，在 00:01-00:58 之间不在发送请求，在 00:59 时发送剩下的所有请求 `n-1` (n 为限流请求数量)，在下一分钟的 00:01 发送 n 个请求，这样在 2 秒钟内请求到达了 `2n - 1` 个。\n\n设每分钟请求数量为 60 个，每秒可以处理 1 个请求，用户在 00:59 发送 60 个请求，在 01:00 发送 60 个请求 此时 2 秒钟有 120 个请求(每秒 60 个请求)，远远大于了每秒钟处理数量的阈值。\n\n### 滑动窗口\n\n#### 实现方式\n\n滑动窗口是对计数器方式的改进，增加一个时间粒度的度量单位，把一分钟分成若干等分(6 份，每份 10 秒)，在每一份上设置独立计数器，在 00:00-00:09 之间发生请求计数器累加 1。当等分数量越大限流统计就越详细。\n\n```java\npackage com.example.demo1.service;\n\nimport java.util.Iterator;\nimport java.util.Random;\nimport java.util.concurrent.ConcurrentLinkedQueue;\nimport java.util.stream.IntStream;\n\npublic class TimeWindow {\n    private ConcurrentLinkedQueue<Long> queue = new ConcurrentLinkedQueue<Long>();\n\n    /**\n     * 间隔秒数\n     */\n    private int seconds;\n\n    /**\n     * 最大限流\n     */\n    private int max;\n\n    public TimeWindow(int max， int seconds) {\n        this.seconds = seconds;\n        this.max = max;\n\n        /**\n         * 永续线程执行清理queue 任务\n         */\n        new Thread(() -> {\n            while (true) {\n                try {\n                    // 等待 间隔秒数-1 执行清理操作\n                    Thread.sleep((seconds - 1) * 1000L);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                clean();\n            }\n        }).start();\n\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        final TimeWindow timeWindow = new TimeWindow(10， 1);\n\n        // 测试3个线程\n        IntStream.range(0， 3).forEach((i) -> {\n            new Thread(() -> {\n\n                while (true) {\n\n                    try {\n                        Thread.sleep(new Random().nextInt(20) * 100);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    timeWindow.take();\n                }\n\n            }).start();\n\n        });\n\n    }\n\n    /**\n     * 获取令牌，并且添加时间\n     */\n    public void take() {\n\n        long start = System.currentTimeMillis();\n        try {\n\n            int size = sizeOfValid();\n            if (size > max) {\n                System.err.println(\"超限\");\n\n            }\n            synchronized (queue) {\n                if (sizeOfValid() > max) {\n                    System.err.println(\"超限\");\n                    System.err.println(\"queue中有 \" + queue.size() + \" 最大数量 \" + max);\n                }\n                this.queue.offer(System.currentTimeMillis());\n            }\n            System.out.println(\"queue中有 \" + queue.size() + \" 最大数量 \" + max);\n\n        }\n\n    }\n\n    public int sizeOfValid() {\n        Iterator<Long> it = queue.iterator();\n        Long ms = System.currentTimeMillis() - seconds * 1000;\n        int count = 0;\n        while (it.hasNext()) {\n            long t = it.next();\n            if (t > ms) {\n                // 在当前的统计时间范围内\n                count++;\n            }\n        }\n\n        return count;\n    }\n\n    /**\n     * 清理过期的时间\n     */\n    public void clean() {\n        Long c = System.currentTimeMillis() - seconds * 1000;\n\n        Long tl = null;\n        while ((tl = queue.peek()) != null && tl < c) {\n            System.out.println(\"清理数据\");\n            queue.poll();\n        }\n    }\n\n}\n\n```\n\n### Leaky Bucket 漏桶\n\n#### 实现方式\n\n规定固定容量的桶，有水进入，有水流出。对于流进的水我们无法估计进来的数量、速度，对于流出的水我们可以控制速度。\n\n```java\npublic class LeakBucket {\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * 水流出去的速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        nowSize = Math.max(0， (nowSize - (now - time) * rate));\n        time = now;\n        if ((nowSize + 1) < total) {\n            nowSize++;\n            return true;\n        } else {\n            return false;\n        }\n\n    }\n}\n```\n\n### Token Bucket 令牌桶\n\n#### 实现方式\n\n规定固定容量的桶， token 以固定速度往桶内填充， 当桶满时 token 不会被继续放入， 每过来一个请求把 token 从桶中移除， 如果桶中没有 token 不能请求。\n\n```java\npublic class TokenBucket {\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * token 放入速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() {\n        long now = System.currentTimeMillis();\n        nowSize = Math.min(total， nowSize + (now - time) * rate);\n        time = now;\n        if (nowSize < 1) {\n            // 桶里没有token\n            return false;\n        } else {\n            // 存在token\n            nowSize -= 1;\n            return true;\n        }\n    }\n\n}\n```\n\n## 工作中的使用\n\n### spring cloud gateway\n\n- spring cloud gateway 默认使用 redis 进行限流，笔者一般只是修改修改参数属于拿来即用，并没有去从头实现上述那些算法。\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n        - id: requestratelimiter_route\n\n          uri: lb://pigx-upms\n          order: 10000\n          predicates:\n            - Path=/admin/**\n\n          filters:\n            - name: RequestRateLimiter\n\n              args:\n                redis-rate-limiter.replenishRate: 1 # 令牌桶的容积\n                redis-rate-limiter.burstCapacity: 3 # 流速 每秒\n                key-resolver: \"#{@remoteAddrKeyResolver}\" #SPEL表达式去的对应的bean\n\n            - StripPrefix=1\n```\n\n```java\n@Bean\nKeyResolver remoteAddrKeyResolver() {\n    return exchange -> Mono.just(exchange.getRequest().getRemoteAddress().getHostName());\n}\n```\n\n### sentinel\n\n- 通过配置来控制每个 url 的流量\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n        port: 8720\n      datasource:\n        ds:\n          nacos:\n            server-addr: localhost:8848\n            dataId: spring-cloud-sentinel-nacos\n            groupId: DEFAULT_GROUP\n            rule-type: flow\n            namespace: xxxxxxxx\n```\n\n- 配置内容在 nacos 上进行编辑\n\n```json\n[\n  {\n    \"resource\": \"/hello\"，\n    \"limitApp\": \"default\"，\n    \"grade\": 1，\n    \"count\": 1，\n    \"strategy\": 0，\n    \"controlBehavior\": 0，\n    \"clusterMode\": false\n  }\n]\n```\n\n- resource：资源名，即限流规则的作用对象。\n- limitApp：流控针对的调用来源，若为 default 则不区分调用来源。\n- grade：限流阈值类型，QPS 或线程数模式，0 代表根据并发数量来限流，1 代表根据 QPS 来进行流量控制。\n- count：限流阈值\n- strategy：判断的根据是资源自身，还是根据其它关联资源 (refResource)，还是根据链路入口\n- controlBehavior：流控效果（直接拒绝 / 排队等待 / 慢启动模式）\n- clusterMode：是否为集群模式\n\n### 总结\n\n> sentinel 和 spring cloud gateway 两个框架都是很好的限流框架， 但是在我使用中还没有将[spring-cloud-alibaba](https://github.com/alibaba/spring-cloud-alibaba)接入到项目中进行使用， 所以我会选择**spring cloud gateway**， 当接入完整的或者接入 Nacos 项目使用 setinel 会有更加好的体验.\n","slug":"限流","published":1,"updated":"2022-09-27T09:13:51.578Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0l3000vekwe35xsan66","content":"<p>如何限流？在工作中是怎么做的？说一下具体的实现？</p>\n<span id=\"more\"></span>\n<h2 id=\"什么是限流\"><a href=\"#什么是限流\" class=\"headerlink\" title=\"什么是限流\"></a>什么是限流</h2><blockquote>\n<p>限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。</p>\n</blockquote>\n<h2 id=\"限流方法\"><a href=\"#限流方法\" class=\"headerlink\" title=\"限流方法\"></a>限流方法</h2><h3 id=\"计数器\"><a href=\"#计数器\" class=\"headerlink\" title=\"计数器\"></a>计数器</h3><h4 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>控制单位时间内的请求数量。</p>\n<pre><code class=\"java\">\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Counter &#123;\n    /**\n     * 最大访问数量\n     */\n    private final int limit = 10;\n    /**\n     * 访问时间差\n     */\n    private final long timeout = 1000;\n    /**\n     * 请求时间\n     */\n    private long time;\n    /**\n     * 当前计数器\n     */\n    private AtomicInteger reqCount = new AtomicInteger(0);\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        if (now &lt; time + timeout) &#123;\n            // 单位时间内\n            reqCount.addAndGet(1);\n            return reqCount.get() &lt;= limit;\n        &#125; else &#123;\n            // 超出单位时间\n            time = now;\n            reqCount = new AtomicInteger(0);\n            return true;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<p>劣势：</p>\n<p>假设在 00:01 时发生一个请求，在 00:01-00:58 之间不在发送请求，在 00:59 时发送剩下的所有请求 <code>n-1</code> (n 为限流请求数量)，在下一分钟的 00:01 发送 n 个请求，这样在 2 秒钟内请求到达了 <code>2n - 1</code> 个。</p>\n<p>设每分钟请求数量为 60 个，每秒可以处理 1 个请求，用户在 00:59 发送 60 个请求，在 01:00 发送 60 个请求 此时 2 秒钟有 120 个请求(每秒 60 个请求)，远远大于了每秒钟处理数量的阈值。</p>\n<h3 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h3><h4 id=\"实现方式-1\"><a href=\"#实现方式-1\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>滑动窗口是对计数器方式的改进，增加一个时间粒度的度量单位，把一分钟分成若干等分(6 份，每份 10 秒)，在每一份上设置独立计数器，在 00:00-00:09 之间发生请求计数器累加 1。当等分数量越大限流统计就越详细。</p>\n<pre><code class=\"java\">package com.example.demo1.service;\n\nimport java.util.Iterator;\nimport java.util.Random;\nimport java.util.concurrent.ConcurrentLinkedQueue;\nimport java.util.stream.IntStream;\n\npublic class TimeWindow &#123;\n    private ConcurrentLinkedQueue&lt;Long&gt; queue = new ConcurrentLinkedQueue&lt;Long&gt;();\n\n    /**\n     * 间隔秒数\n     */\n    private int seconds;\n\n    /**\n     * 最大限流\n     */\n    private int max;\n\n    public TimeWindow(int max， int seconds) &#123;\n        this.seconds = seconds;\n        this.max = max;\n\n        /**\n         * 永续线程执行清理queue 任务\n         */\n        new Thread(() -&gt; &#123;\n            while (true) &#123;\n                try &#123;\n                    // 等待 间隔秒数-1 执行清理操作\n                    Thread.sleep((seconds - 1) * 1000L);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n                clean();\n            &#125;\n        &#125;).start();\n\n    &#125;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        final TimeWindow timeWindow = new TimeWindow(10， 1);\n\n        // 测试3个线程\n        IntStream.range(0， 3).forEach((i) -&gt; &#123;\n            new Thread(() -&gt; &#123;\n\n                while (true) &#123;\n\n                    try &#123;\n                        Thread.sleep(new Random().nextInt(20) * 100);\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                    timeWindow.take();\n                &#125;\n\n            &#125;).start();\n\n        &#125;);\n\n    &#125;\n\n    /**\n     * 获取令牌，并且添加时间\n     */\n    public void take() &#123;\n\n        long start = System.currentTimeMillis();\n        try &#123;\n\n            int size = sizeOfValid();\n            if (size &gt; max) &#123;\n                System.err.println(&quot;超限&quot;);\n\n            &#125;\n            synchronized (queue) &#123;\n                if (sizeOfValid() &gt; max) &#123;\n                    System.err.println(&quot;超限&quot;);\n                    System.err.println(&quot;queue中有 &quot; + queue.size() + &quot; 最大数量 &quot; + max);\n                &#125;\n                this.queue.offer(System.currentTimeMillis());\n            &#125;\n            System.out.println(&quot;queue中有 &quot; + queue.size() + &quot; 最大数量 &quot; + max);\n\n        &#125;\n\n    &#125;\n\n    public int sizeOfValid() &#123;\n        Iterator&lt;Long&gt; it = queue.iterator();\n        Long ms = System.currentTimeMillis() - seconds * 1000;\n        int count = 0;\n        while (it.hasNext()) &#123;\n            long t = it.next();\n            if (t &gt; ms) &#123;\n                // 在当前的统计时间范围内\n                count++;\n            &#125;\n        &#125;\n\n        return count;\n    &#125;\n\n    /**\n     * 清理过期的时间\n     */\n    public void clean() &#123;\n        Long c = System.currentTimeMillis() - seconds * 1000;\n\n        Long tl = null;\n        while ((tl = queue.peek()) != null &amp;&amp; tl &lt; c) &#123;\n            System.out.println(&quot;清理数据&quot;);\n            queue.poll();\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<h3 id=\"Leaky-Bucket-漏桶\"><a href=\"#Leaky-Bucket-漏桶\" class=\"headerlink\" title=\"Leaky Bucket 漏桶\"></a>Leaky Bucket 漏桶</h3><h4 id=\"实现方式-2\"><a href=\"#实现方式-2\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>规定固定容量的桶，有水进入，有水流出。对于流进的水我们无法估计进来的数量、速度，对于流出的水我们可以控制速度。</p>\n<pre><code class=\"java\">public class LeakBucket &#123;\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * 水流出去的速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        nowSize = Math.max(0， (nowSize - (now - time) * rate));\n        time = now;\n        if ((nowSize + 1) &lt; total) &#123;\n            nowSize++;\n            return true;\n        &#125; else &#123;\n            return false;\n        &#125;\n\n    &#125;\n&#125;\n</code></pre>\n<h3 id=\"Token-Bucket-令牌桶\"><a href=\"#Token-Bucket-令牌桶\" class=\"headerlink\" title=\"Token Bucket 令牌桶\"></a>Token Bucket 令牌桶</h3><h4 id=\"实现方式-3\"><a href=\"#实现方式-3\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>规定固定容量的桶， token 以固定速度往桶内填充， 当桶满时 token 不会被继续放入， 每过来一个请求把 token 从桶中移除， 如果桶中没有 token 不能请求。</p>\n<pre><code class=\"java\">public class TokenBucket &#123;\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * token 放入速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        nowSize = Math.min(total， nowSize + (now - time) * rate);\n        time = now;\n        if (nowSize &lt; 1) &#123;\n            // 桶里没有token\n            return false;\n        &#125; else &#123;\n            // 存在token\n            nowSize -= 1;\n            return true;\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<h2 id=\"工作中的使用\"><a href=\"#工作中的使用\" class=\"headerlink\" title=\"工作中的使用\"></a>工作中的使用</h2><h3 id=\"spring-cloud-gateway\"><a href=\"#spring-cloud-gateway\" class=\"headerlink\" title=\"spring cloud gateway\"></a>spring cloud gateway</h3><ul>\n<li>spring cloud gateway 默认使用 redis 进行限流，笔者一般只是修改修改参数属于拿来即用，并没有去从头实现上述那些算法。</li>\n</ul>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"yaml\">spring:\n  cloud:\n    gateway:\n      routes:\n        - id: requestratelimiter_route\n\n          uri: lb://pigx-upms\n          order: 10000\n          predicates:\n            - Path=/admin/**\n\n          filters:\n            - name: RequestRateLimiter\n\n              args:\n                redis-rate-limiter.replenishRate: 1 # 令牌桶的容积\n                redis-rate-limiter.burstCapacity: 3 # 流速 每秒\n                key-resolver: &quot;#&#123;@remoteAddrKeyResolver&#125;&quot; #SPEL表达式去的对应的bean\n\n            - StripPrefix=1\n</code></pre>\n<pre><code class=\"java\">@Bean\nKeyResolver remoteAddrKeyResolver() &#123;\n    return exchange -&gt; Mono.just(exchange.getRequest().getRemoteAddress().getHostName());\n&#125;\n</code></pre>\n<h3 id=\"sentinel\"><a href=\"#sentinel\" class=\"headerlink\" title=\"sentinel\"></a>sentinel</h3><ul>\n<li>通过配置来控制每个 url 的流量</li>\n</ul>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"yaml\">spring:\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n        port: 8720\n      datasource:\n        ds:\n          nacos:\n            server-addr: localhost:8848\n            dataId: spring-cloud-sentinel-nacos\n            groupId: DEFAULT_GROUP\n            rule-type: flow\n            namespace: xxxxxxxx\n</code></pre>\n<ul>\n<li>配置内容在 nacos 上进行编辑</li>\n</ul>\n<pre><code class=\"json\">[\n  &#123;\n    &quot;resource&quot;: &quot;/hello&quot;，\n    &quot;limitApp&quot;: &quot;default&quot;，\n    &quot;grade&quot;: 1，\n    &quot;count&quot;: 1，\n    &quot;strategy&quot;: 0，\n    &quot;controlBehavior&quot;: 0，\n    &quot;clusterMode&quot;: false\n  &#125;\n]\n</code></pre>\n<ul>\n<li>resource：资源名，即限流规则的作用对象。</li>\n<li>limitApp：流控针对的调用来源，若为 default 则不区分调用来源。</li>\n<li>grade：限流阈值类型，QPS 或线程数模式，0 代表根据并发数量来限流，1 代表根据 QPS 来进行流量控制。</li>\n<li>count：限流阈值</li>\n<li>strategy：判断的根据是资源自身，还是根据其它关联资源 (refResource)，还是根据链路入口</li>\n<li>controlBehavior：流控效果（直接拒绝 / 排队等待 / 慢启动模式）</li>\n<li>clusterMode：是否为集群模式</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><blockquote>\n<p>sentinel 和 spring cloud gateway 两个框架都是很好的限流框架， 但是在我使用中还没有将<a href=\"https://github.com/alibaba/spring-cloud-alibaba\">spring-cloud-alibaba</a>接入到项目中进行使用， 所以我会选择<strong>spring cloud gateway</strong>， 当接入完整的或者接入 Nacos 项目使用 setinel 会有更加好的体验.</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>如何限流？在工作中是怎么做的？说一下具体的实现？</p>","more":"<h2 id=\"什么是限流\"><a href=\"#什么是限流\" class=\"headerlink\" title=\"什么是限流\"></a>什么是限流</h2><blockquote>\n<p>限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。</p>\n</blockquote>\n<h2 id=\"限流方法\"><a href=\"#限流方法\" class=\"headerlink\" title=\"限流方法\"></a>限流方法</h2><h3 id=\"计数器\"><a href=\"#计数器\" class=\"headerlink\" title=\"计数器\"></a>计数器</h3><h4 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>控制单位时间内的请求数量。</p>\n<pre><code class=\"java\">\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Counter &#123;\n    /**\n     * 最大访问数量\n     */\n    private final int limit = 10;\n    /**\n     * 访问时间差\n     */\n    private final long timeout = 1000;\n    /**\n     * 请求时间\n     */\n    private long time;\n    /**\n     * 当前计数器\n     */\n    private AtomicInteger reqCount = new AtomicInteger(0);\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        if (now &lt; time + timeout) &#123;\n            // 单位时间内\n            reqCount.addAndGet(1);\n            return reqCount.get() &lt;= limit;\n        &#125; else &#123;\n            // 超出单位时间\n            time = now;\n            reqCount = new AtomicInteger(0);\n            return true;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<p>劣势：</p>\n<p>假设在 00:01 时发生一个请求，在 00:01-00:58 之间不在发送请求，在 00:59 时发送剩下的所有请求 <code>n-1</code> (n 为限流请求数量)，在下一分钟的 00:01 发送 n 个请求，这样在 2 秒钟内请求到达了 <code>2n - 1</code> 个。</p>\n<p>设每分钟请求数量为 60 个，每秒可以处理 1 个请求，用户在 00:59 发送 60 个请求，在 01:00 发送 60 个请求 此时 2 秒钟有 120 个请求(每秒 60 个请求)，远远大于了每秒钟处理数量的阈值。</p>\n<h3 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h3><h4 id=\"实现方式-1\"><a href=\"#实现方式-1\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>滑动窗口是对计数器方式的改进，增加一个时间粒度的度量单位，把一分钟分成若干等分(6 份，每份 10 秒)，在每一份上设置独立计数器，在 00:00-00:09 之间发生请求计数器累加 1。当等分数量越大限流统计就越详细。</p>\n<pre><code class=\"java\">package com.example.demo1.service;\n\nimport java.util.Iterator;\nimport java.util.Random;\nimport java.util.concurrent.ConcurrentLinkedQueue;\nimport java.util.stream.IntStream;\n\npublic class TimeWindow &#123;\n    private ConcurrentLinkedQueue&lt;Long&gt; queue = new ConcurrentLinkedQueue&lt;Long&gt;();\n\n    /**\n     * 间隔秒数\n     */\n    private int seconds;\n\n    /**\n     * 最大限流\n     */\n    private int max;\n\n    public TimeWindow(int max， int seconds) &#123;\n        this.seconds = seconds;\n        this.max = max;\n\n        /**\n         * 永续线程执行清理queue 任务\n         */\n        new Thread(() -&gt; &#123;\n            while (true) &#123;\n                try &#123;\n                    // 等待 间隔秒数-1 执行清理操作\n                    Thread.sleep((seconds - 1) * 1000L);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n                clean();\n            &#125;\n        &#125;).start();\n\n    &#125;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        final TimeWindow timeWindow = new TimeWindow(10， 1);\n\n        // 测试3个线程\n        IntStream.range(0， 3).forEach((i) -&gt; &#123;\n            new Thread(() -&gt; &#123;\n\n                while (true) &#123;\n\n                    try &#123;\n                        Thread.sleep(new Random().nextInt(20) * 100);\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                    timeWindow.take();\n                &#125;\n\n            &#125;).start();\n\n        &#125;);\n\n    &#125;\n\n    /**\n     * 获取令牌，并且添加时间\n     */\n    public void take() &#123;\n\n        long start = System.currentTimeMillis();\n        try &#123;\n\n            int size = sizeOfValid();\n            if (size &gt; max) &#123;\n                System.err.println(&quot;超限&quot;);\n\n            &#125;\n            synchronized (queue) &#123;\n                if (sizeOfValid() &gt; max) &#123;\n                    System.err.println(&quot;超限&quot;);\n                    System.err.println(&quot;queue中有 &quot; + queue.size() + &quot; 最大数量 &quot; + max);\n                &#125;\n                this.queue.offer(System.currentTimeMillis());\n            &#125;\n            System.out.println(&quot;queue中有 &quot; + queue.size() + &quot; 最大数量 &quot; + max);\n\n        &#125;\n\n    &#125;\n\n    public int sizeOfValid() &#123;\n        Iterator&lt;Long&gt; it = queue.iterator();\n        Long ms = System.currentTimeMillis() - seconds * 1000;\n        int count = 0;\n        while (it.hasNext()) &#123;\n            long t = it.next();\n            if (t &gt; ms) &#123;\n                // 在当前的统计时间范围内\n                count++;\n            &#125;\n        &#125;\n\n        return count;\n    &#125;\n\n    /**\n     * 清理过期的时间\n     */\n    public void clean() &#123;\n        Long c = System.currentTimeMillis() - seconds * 1000;\n\n        Long tl = null;\n        while ((tl = queue.peek()) != null &amp;&amp; tl &lt; c) &#123;\n            System.out.println(&quot;清理数据&quot;);\n            queue.poll();\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<h3 id=\"Leaky-Bucket-漏桶\"><a href=\"#Leaky-Bucket-漏桶\" class=\"headerlink\" title=\"Leaky Bucket 漏桶\"></a>Leaky Bucket 漏桶</h3><h4 id=\"实现方式-2\"><a href=\"#实现方式-2\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>规定固定容量的桶，有水进入，有水流出。对于流进的水我们无法估计进来的数量、速度，对于流出的水我们可以控制速度。</p>\n<pre><code class=\"java\">public class LeakBucket &#123;\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * 水流出去的速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        nowSize = Math.max(0， (nowSize - (now - time) * rate));\n        time = now;\n        if ((nowSize + 1) &lt; total) &#123;\n            nowSize++;\n            return true;\n        &#125; else &#123;\n            return false;\n        &#125;\n\n    &#125;\n&#125;\n</code></pre>\n<h3 id=\"Token-Bucket-令牌桶\"><a href=\"#Token-Bucket-令牌桶\" class=\"headerlink\" title=\"Token Bucket 令牌桶\"></a>Token Bucket 令牌桶</h3><h4 id=\"实现方式-3\"><a href=\"#实现方式-3\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h4><p>规定固定容量的桶， token 以固定速度往桶内填充， 当桶满时 token 不会被继续放入， 每过来一个请求把 token 从桶中移除， 如果桶中没有 token 不能请求。</p>\n<pre><code class=\"java\">public class TokenBucket &#123;\n    /**\n     * 时间\n     */\n    private long time;\n    /**\n     * 总量\n     */\n    private Double total;\n    /**\n     * token 放入速度\n     */\n    private Double rate;\n    /**\n     * 当前总量\n     */\n    private Double nowSize;\n\n    public boolean limit() &#123;\n        long now = System.currentTimeMillis();\n        nowSize = Math.min(total， nowSize + (now - time) * rate);\n        time = now;\n        if (nowSize &lt; 1) &#123;\n            // 桶里没有token\n            return false;\n        &#125; else &#123;\n            // 存在token\n            nowSize -= 1;\n            return true;\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<h2 id=\"工作中的使用\"><a href=\"#工作中的使用\" class=\"headerlink\" title=\"工作中的使用\"></a>工作中的使用</h2><h3 id=\"spring-cloud-gateway\"><a href=\"#spring-cloud-gateway\" class=\"headerlink\" title=\"spring cloud gateway\"></a>spring cloud gateway</h3><ul>\n<li>spring cloud gateway 默认使用 redis 进行限流，笔者一般只是修改修改参数属于拿来即用，并没有去从头实现上述那些算法。</li>\n</ul>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"yaml\">spring:\n  cloud:\n    gateway:\n      routes:\n        - id: requestratelimiter_route\n\n          uri: lb://pigx-upms\n          order: 10000\n          predicates:\n            - Path=/admin/**\n\n          filters:\n            - name: RequestRateLimiter\n\n              args:\n                redis-rate-limiter.replenishRate: 1 # 令牌桶的容积\n                redis-rate-limiter.burstCapacity: 3 # 流速 每秒\n                key-resolver: &quot;#&#123;@remoteAddrKeyResolver&#125;&quot; #SPEL表达式去的对应的bean\n\n            - StripPrefix=1\n</code></pre>\n<pre><code class=\"java\">@Bean\nKeyResolver remoteAddrKeyResolver() &#123;\n    return exchange -&gt; Mono.just(exchange.getRequest().getRemoteAddress().getHostName());\n&#125;\n</code></pre>\n<h3 id=\"sentinel\"><a href=\"#sentinel\" class=\"headerlink\" title=\"sentinel\"></a>sentinel</h3><ul>\n<li>通过配置来控制每个 url 的流量</li>\n</ul>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"yaml\">spring:\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n        port: 8720\n      datasource:\n        ds:\n          nacos:\n            server-addr: localhost:8848\n            dataId: spring-cloud-sentinel-nacos\n            groupId: DEFAULT_GROUP\n            rule-type: flow\n            namespace: xxxxxxxx\n</code></pre>\n<ul>\n<li>配置内容在 nacos 上进行编辑</li>\n</ul>\n<pre><code class=\"json\">[\n  &#123;\n    &quot;resource&quot;: &quot;/hello&quot;，\n    &quot;limitApp&quot;: &quot;default&quot;，\n    &quot;grade&quot;: 1，\n    &quot;count&quot;: 1，\n    &quot;strategy&quot;: 0，\n    &quot;controlBehavior&quot;: 0，\n    &quot;clusterMode&quot;: false\n  &#125;\n]\n</code></pre>\n<ul>\n<li>resource：资源名，即限流规则的作用对象。</li>\n<li>limitApp：流控针对的调用来源，若为 default 则不区分调用来源。</li>\n<li>grade：限流阈值类型，QPS 或线程数模式，0 代表根据并发数量来限流，1 代表根据 QPS 来进行流量控制。</li>\n<li>count：限流阈值</li>\n<li>strategy：判断的根据是资源自身，还是根据其它关联资源 (refResource)，还是根据链路入口</li>\n<li>controlBehavior：流控效果（直接拒绝 / 排队等待 / 慢启动模式）</li>\n<li>clusterMode：是否为集群模式</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><blockquote>\n<p>sentinel 和 spring cloud gateway 两个框架都是很好的限流框架， 但是在我使用中还没有将<a href=\"https://github.com/alibaba/spring-cloud-alibaba\">spring-cloud-alibaba</a>接入到项目中进行使用， 所以我会选择<strong>spring cloud gateway</strong>， 当接入完整的或者接入 Nacos 项目使用 setinel 会有更加好的体验.</p>\n</blockquote>"},{"title":"阿里巴巴java开发手册","date":"2022-09-27T16:00:00.000Z","coverWidth":1200,"coverHeight":320,"author":"王恺","from":"笔记","_content":"阿里巴巴java开发手册-嵩山版<!--more-->\n# 前言\n\n《Java开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一\n\n线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理\n\n成册，当前的版本是 **嵩山版** 。现代软件行业的高速发展对开发者的综合素质要求越来越高，因为不仅\n\n是编程知识点，其它维度的知识点也会影响到软件的最终交付质量。比如：五花八门的错误码人为地\n\n增加排查问题的难度；数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险；工程结构混\n\n乱导致后续项目维护艰难；没有鉴权的漏洞代码易被黑客攻击等等。所以本手册以Java开发者为中\n\n心视角，划分为编程规约、异常日志、单元测试、安全规约、MySQL数据库、工程结构、设计规约\n\n七个维度，再根据内容特征，细分成若干二级子目录。另外，依据约束力强弱及故障敏感性，规约依\n\n次分为【强制】、【推荐】、【参考】三大类。在延伸信息中，“说明”对规约做了适当扩展和解释；\n\n“正例”提倡什么样的编码和实现方式；“反例”说明需要提防的雷区，以及真实的错误案例。\n\n手册的愿景是 **码出高效，码出质量** 。现代软件架构的复杂性需要协同开发完成，如何高效地协\n\n同呢？无规矩不成方圆，无规范难以协同，比如，制订交通法规表面上是要限制行车权，实际上是保\n\n障公众的人身安全，试想如果没有限速，没有红绿灯，谁还敢上路行驶？对软件来说，适当的规范和\n\n标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的统一方式一起\n\n做事，提升协作效率，降低沟通成本。代码的字里行间流淌的是软件系统的血液，质量的提升是尽可\n\n能少踩坑，杜绝踩重复的坑，切实提升系统稳定性，码出质量。\n\n我们已经在 2017 杭州云栖大会上发布了配套的Java开发规约IDE插件，下载量达到 162 万人\n\n次，阿里云效也集成了代码规约扫描引擎。次年，发布 36 万字的配套详解图书《码出高效》，本书\n\n秉持“图胜于表，表胜于言”的理念，深入浅出地将计算机基础、面向对象思想、JVM探源、数据\n\n结构与集合、并发与多线程、单元测试等知识客观、立体地呈现出来。紧扣学以致用、学以精进的目\n\n标，结合阿里巴巴实践经验和故障案例，与底层源码解析融会贯通，娓娓道来。《码出高效》和《Java\n\n开发手册》稿费所得收入均捐赠公益事情，希望用技术情怀帮助更多的人。\n\n\n## 目录\n\n- 一、编程规约\n   - (一) 命名风格\n   - (二) 常量定义\n   - (三) 代码格式\n   - (四) OOP规约\n   - (五) 日期时间\n   - (六) 集合处理\n   - (七) 并发处理\n   - (八) 控制语句\n   - (九) 注释规约\n   - (十) 前后端规约\n   - (十一) 其他\n- 二、异常日志\n   - (一) 错误码\n   - (二) 异常处理\n   - (三) 日志规约\n- 三、单元测试\n- 四、安全规约\n- 五、MySQL数据库\n   - (一) 建表规约\n   - (二) 索引规约\n   - (三) SQL语句\n   - (四) ORM映射\n- 六、工程结构\n   - (一) 应用分层\n   - (二) 二方库依赖\n   - (三) 服务器\n- 七、设计规约\n- 附 1 ：版本历史\n- 附 2 ：专有名词解释\n- 附 3 ：错误码列表\n\n\n## 一、编程规约\n\n### (一) 命名风格\n\n1. 【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。\n    反例：_name / __name / $name / name_ / name$ / name__\n2. 【强制】所有编程相关的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。\n说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，纯拼音命名方式更要避免采用。\n正例：ali / alibaba / taobao / cainiao/ aliyun/ youku / hangzhou 等国际通用的名称，可视同英文。\n反例：DaZhePromotion [打折] / getPingfenByName() [评分] / String fw[福娃] / int 某变量 = 3\n3. 【强制】代码和注释中都要避免使用任何语言的种族歧视性词语。\n    正例：日本人 / 印度人 / blockList / allowList / secondary\n    反例：RIBENGUIZI / Asan / blackList / whiteList / slave\n4. 【强制】类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO /\n    PO / UID等。\n    正例：ForceCode / UserDO / HtmlDTO / XmlService / TcpUdpDeal / TaPromotion\n    反例：forcecode / UserDo / HTMLDto / XMLService / TCPUDPDeal / TAPromotion\n5. 【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格。\n    正例： localValue / getHttpMessage() / inputUserId\n6. 【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。\n    正例：MAX_STOCK_COUNT / CACHE_EXPIRED_TIME\n    反例：MAX_COUNT / EXPIRED_TIME\n7. 【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类\n    命名以它要测试的类的名称开始，以Test结尾。\n8. 【强制】类型与中括号紧挨相连来表示数组。\n    正例：定义整形数组int[] arrayDemo。\n    反例：在main参数中，使用String args[]来定义。\n9. 【强制】POJO类中的任何布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列\n    化错误。\n\n#### 版本号 制定团队 更新日期 备注\n\n```\n1. 7. 0 阿里巴巴与全球Java社区开发者 2020. 08. 03 嵩山版，首次发布前后端规约\n```\n\n```\n说明：在本文MySQL规约中的建表约定第一条，表达是与否的变量采用is_xxx的命名方式，所以，需要\n在<resultMap>设置从is_xxx到xxx的映射关系。\n反例：定义为基本数据类型Boolean isDeleted的属性，它的方法也是isDeleted()，框架在反向解析的时\n候，“误以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。\n```\n10. 【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用\n    单数形式，但是类名如果有复数含义，类名可以使用复数形式。\n    正例：应用工具类包名为com.alibaba.ei.kunlun.aap.util、类名为MessageUtils（此规则参考spring的\n    框架结构）\n11. 【强制】避免在子父类的成员变量之间、或者不同代码块的局部变量之间采用完全相同的命名，\n使可理解性降低。\n说明：子类、父类成员变量名相同，即使是public类型的变量也能够通过编译，另外，局部变量在同一方\n法内的不同代码块中同名也是合法的，这些情况都要避免。对于非setter/getter的参数名称也要避免与成\n员变量名称相同。\n反例：\npublic class ConfusingName {\npublic int stock;\n// 非setter/getter的参数名称，不允许与本类成员变量同名\npublic void get(String alibaba) {\nif (condition) {\nfinal int money = 666 ;\n// ...\n}\nfor (int i = 0 ; i < 10 ; i++) {\n// 在同一方法体中，不允许与其它代码块中的money命名相同\nfinal int money = 15978 ;\n// ...\n}\n}\n}\nclass Son extends ConfusingName {\n// 不允许与父类的成员变量名称相同\npublic int stock;\n}\n12. 【强制】杜绝完全不规范的缩写，避免望文不知义。\n    反例：AbstractClass“缩写”成AbsClass；condition“缩写”成 condi；Function缩写”成Fu，此类\n    随意缩写严重降低了代码的可阅读性。\n13. 【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组\n    合来表达。\n\n\n```\n正例：对某个对象引用的volatile字段进行原子更新的类名为AtomicReferenceFieldUpdater。\n反例：常见的方法内变量为int a;的定义方式。\n```\n14. 【推荐】在常量与变量的命名时，表示类型的名词放在词尾，以提升辨识度。\n    正例：startTime / workQueue / nameList / TERMINATED_THREAD_COUNT\n    反例：startedAt / QueueOfWork / listName / COUNT_TERMINATED_THREAD\n15. 【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。\n    说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。\n    正例： public class OrderFactory;\n    public class LoginProxy;\n    public class ResourceObserver;\n16. 【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁\n    性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，确定\n    与接口方法相关，并且是整个应用的基础常量。\n    正例：接口方法签名 void commit();\n    接口基础常量 String COMPANY = \"alibaba\";\n    反例：接口方法定义 public abstract void f();\n    说明：JDK8中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。\n17. 接口和实现类的命名有两套规则：\n    1 ）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用\n    Impl的后缀与接口区别。\n    正例：CacheServiceImpl实现CacheService接口。\n    2 ）【推荐】如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able的形容词）。\n    正例：AbstractTranslator实现 Translatable接口。\n18. 【参考】枚举类名带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。\n    说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。\n    正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS / UNKNOWN_REASON。\n19. 【参考】各层命名规约：\n    A) Service/DAO层方法命名规约\n    1 ） 获取单个对象的方法用get做前缀。\n    2 ） 获取多个对象的方法用list做前缀，复数结尾，如：listObjects。\n    3 ） 获取统计值的方法用count做前缀。\n    4 ） 插入的方法用save/insert做前缀。\n    5 ） 删除的方法用remove/delete做前缀。\n    6 ） 修改的方法用update做前缀。\n    B) 领域模型命名规约\n\n\n```\n1 ） 数据对象：xxxDO，xxx即为数据表名。\n2 ） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。\n3 ） 展示对象：xxxVO，xxx一般为网页名称。\n4 ） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。\n```\n### (二) 常量定义\n\n1. 【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。\n    反例：\n       // 本例中，开发者A定义了缓存的key，然后开发者B使用缓存时少了下划线，即key是\"Id#taobao\"+tradeId，导致\n       出现故障\n       String key = \"Id#taobao_\" + tradeId;\n       cache.put(key, value);\n2. 【强制】在long或者Long赋值时，数值后使用大写字母L，不能是小写字母l，小写容易跟\n数字混淆，造成误解。\n说明：Long a = 2l; 写的是数字的 21 ，还是Long型的 2 ？\n3. 【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。\n    说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解，也不利于维护。\n       正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类SystemConfigConsts下。\n4. 【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包\n    内共享常量、类内共享常量。\n    1 ） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。\n    2 ） 应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。\n    反例：易懂变量也要统一定义成应用内共享常量，两位工程师在两个类中分别定义了“YES”的变量：\n    类A中：public static final String YES = \"yes\";\n    类B中：public static final String YES = \"y\";\n    A.YES.equals(B.YES)，预期是true，但实际返回为false，导致线上问题。\n       3 ） 子工程内部共享常量：即在当前子工程的constant目录下。\n       4 ） 包内共享常量：即在当前包下单独的constant目录下。\n       5 ） 类内共享常量：直接在类内部private static final定义。\n5. 【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。\n    说明：如果存在名称之外的延伸属性应使用enum类型，下面正例中的数字就是延伸信息，表示一年中的\n    第几个季节。\n    正例：\n       public enum SeasonEnum {\n       SPRING( 1 ), SUMMER( 2 ), AUTUMN( 3 ), WINTER( 4 );\n       private int seq;\n       SeasonEnum(int seq) {\n\n\n```\nthis.seq = seq;\n}\npublic int getSeq() {\nreturn seq;\n}\n}\n```\n### (三) 代码格式\n\n1. 【强制】如果是大括号内为空，则简洁地写成{}即可，大括号中间无需换行和空格；如果是非\n    空代码块则：\n    1 ） 左大括号前不换行。\n    2 ） 左大括号后换行。\n    3 ） 右大括号前换行。\n    4 ） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。\n2. 【强制】左小括号和右边相邻字符之间不出现空格；右小括号和左边相邻字符之间也不出现空\n格；而左大括号前需要加空格。详见第 5 条下方正例提示。\n反例：if (空格a == b空格)\n3. 【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。\n4. 【强制】任何二目、三目运算符的左右两边都需要加一个空格。\n    说明：包括赋值运算符=、逻辑运算符&&、加减乘除符号等。\n5. 【强制】采用 4 个空格缩进，禁止使用Tab字符。\n说明：如果使用Tab缩进，必须设置 1 个Tab为 4 个空格。IDEA设置Tab为 4 个空格时，请勿勾选Use\ntab character；而在Eclipse中，必须勾选insert spaces for tabs。\n正例： （涉及 1 - 5 点）\npublic static void main(String[] args) {\n// 缩进 4 个空格\nString say = \"hello\";\n// 运算符的左右必须有一个空格\nint flag = 0 ;\n// 关键词if与括号之间必须有一个空格，括号内的f与左括号， 0 与右括号不需要空格\nif (flag == 0 ) {\nSystem.out.println(say);\n}\n// 左大括号前加空格且不换行；左大括号后换行\nif (flag == 1 ) {\nSystem.out.println(\"world\");\n// 右大括号前换行，右大括号后有else，不用换行\n} else {\nSystem.out.println(\"ok\");\n// 在右大括号后直接结束，则必须换行\n}\n}\n\n\n6. 【强制】注释的双斜线与注释内容之间有且仅有一个空格。\n    正例：\n       // 这是示例注释，请注意在双斜线之后有一个空格\n       String commentString = new String();\n7. 【强制】在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。\n    正例：\n       double first = 3.2d;\n       int second = (int)first + 2 ;\n8. 【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：\n    1 ）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。\n    2 ）运算符与下文一起换行。\n    3 ）方法调用的点符号与下文一起换行。\n    4 ）方法调用中的多个参数需要换行时，在逗号后进行。\n    5 ）在括号前不要换行，见反例。\n    正例：\n       StringBuilder sb = new StringBuilder();\n       // 超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点号一起换行\n       sb.append(\"yang\").append(\"hao\")...\n       .append(\"chen\")...\n       .append(\"chen\")...\n       .append(\"chen\");\n    反例：\n       StringBuilder sb = new StringBuilder();\n       // 超过 120 个字符的情况下，不要在括号前换行\n       sb.append(\"you\").append(\"are\")...append\n       (\"lucky\");\n       // 参数很多的方法调用可能超过 120 个字符，逗号后才是换行处\n       method(args1, args2, args3, ...\n       , argsX);\n9. 【强制】方法参数在定义和传入时，多个参数逗号后面必须加空格。\n    正例：下例中实参的args1，后边必须要有一个空格。\n       method(args1, args2, args3);\n10. 【强制】IDE的text file encoding设置为UTF-8; IDE中文件的换行符使用Unix格式，不要\n    使用Windows格式。\n11. 【推荐】单个方法的总行数不超过 80 行。\n    说明：除注释之外的方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过\n    80 行。\n    正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共\n    性逻辑抽取成为共性方法，便于复用和维护。\n\n\n12. 【推荐】没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐。\n    正例：\n       int one = 1 ;\n       long two = 2 L;\n       float three = 3F;\n       StringBuilder sb = new StringBuilder();\n说明：增加sb这个变量，如果需要对齐，则给one、two、three都要增加几个空格，在变量比较多的情\n况下，是非常累赘的事情。\n13. 【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。\n    说明：任何情形，没有必要插入多个空行进行隔开。\n\n### (四) OOP规约\n\n1. 【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成\n    本，直接用类名来访问即可。\n2. 【强制】所有的覆写方法，必须加@Override注解。\n    说明：getObject()与get0bject()的问题。一个是字母的O，一个是数字的 0 ，加@Override可以准确判\n    断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。\n3. 【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。\n说明：可变参数必须放置在参数列表的最后。（建议开发者尽量不用可变参数编程）\n正例：public List<User> listUsers(String type, Long... ids) {...}\n4. 【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生\n    影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。\n5. 【强制】不能使用过时的类或方法。\n    说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数\n    decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；\n    作为调用方来说，有义务去考证过时方法的新实现是什么。\n6. 【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。\n    正例：\"test\".equals(object);\n    反例：object.equals(\"test\");\n    说明：推荐使用JDK7引入的工具类java.util.Objects#equals(Object a, Object b)\n7. 【强制】所有整型包装类对象之间值的比较，全部使用equals方法比较。\n    说明：对于Integer var =? 在- 128 至 127 之间的赋值，Integer对象是在 IntegerCache.cache产生，\n    会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都\n    会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。\n\n\n8. 【强制】任何货币金额，均以最小货币单位且整型类型来进行存储。\n9. 【强制】浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用equals\n来判断。\n说明：浮点数采用“尾数+阶码”的编码方式，类似于科学计数法的“有效数字+指数”的表示方式。二进\n制无法精确表示大部分的十进制小数，具体原理参考《码出高效》。\n反例：\nfloat a = 1.0F - 0.9F;\nfloat b = 0.9F - 0.8F;\nif (a == b) {\n// 预期进入此代码块，执行其它业务逻辑\n// 但事实上a==b的结果为false\n}\nFloat x = Float.valueOf(a);\nFloat y = Float.valueOf(b);\nif (x.equals(y)) {\n// 预期进入此代码块，执行其它业务逻辑\n// 但事实上equals的结果为false\n}\n正例：\n(1) 指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。\nfloat a = 1.0F - 0.9F;\nfloat b = 0.9F - 0.8F;\nfloat diff = 1e- 6 F;\nif (Math.abs(a - b) < diff) {\nSystem.out.println(\"true\");\n}\n(2) 使用BigDecimal来定义值，再进行浮点数的运算操作。\nBigDecimal a = new BigDecimal(\"1.0\");\nBigDecimal b = new BigDecimal(\"0.9\");\nBigDecimal c = new BigDecimal(\"0.8\");\nBigDecimal x = a.subtract(b);\nBigDecimal y = b.subtract(c);\nif (x.compareTo(y) == 0 ) {\nSystem.out.println(\"true\");\n}\n10. 【强制】如上所示BigDecimal的等值比较应使用compareTo()方法，而不是equals()方法。\n    说明：equals()方法会比较值和精度（ 1 .0与 1 .00返回结果为false），而compareTo()则会忽略精度。\n11. 【强制】定义数据对象DO类时，属性类型要与数据库字段类型相匹配。\n    正例：数据库字段的bigint必须与类属性的Long类型相对应。\n    反例：某个案例的数据库表id字段定义类型bigint unsigned，实际类对象属性为Integer，随着id越来\n    越大，超过Integer的表示范围而溢出成为负数。\n\n\n12. 【强制】禁止使用构造方法BigDecimal(double)的方式把double值转化为BigDecimal对象。\n    说明：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。\n    如：BigDecimal g = new BigDecimal(0.1F); 实际的存储值为：0.\n    正例：优先推荐入参为String的构造方法，或使用BigDecimal的valueOf方法，此方法内部其实执行了\n    Double的toString，而Double的toString按double的实际能表达的精度对尾数进行了截断。\nBigDecimal recommend1 = new BigDecimal(\"0.1\");\nBigDecimal recommend2 = BigDecimal.valueOf(0.1);\n13. 关于基本数据类型与包装数据类型的使用标准如下：\n1 ） 【强制】所有的POJO类属性必须使用包装数据类型。\n2 ） 【强制】RPC方法的返回值和参数必须使用包装数据类型。\n3 ） 【推荐】所有的局部变量使用基本数据类型。\n说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或\n者入库检查，都由使用者来保证。\n正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。\n反例：某业务的交易报表上显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调\n用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线-。所以包装数据类型\n的null值，能够表示额外的信息，如：远程调用失败，异常退出。\n14. 【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。\n反例：POJO类的createTime默认值为new Date()，但是这个属性在数据提取时并没有置入具体值，在\n更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。\n15. 【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果\n完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。\n说明：注意serialVersionUID不一致会抛出序列化运行时异常。\n16. 【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。\n17. 【强制】POJO类必须写toString方法。使用IDE中的工具：source> generate toString\n时，如果继承了另一个POJO类，注意在前面加一下super.toString。\n说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。\n18. 【强制】禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法。\n说明：框架在调用属性xxx的提取方法时，并不能确定哪个方法一定是被优先调用到的。\n19. 【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容\n的检查，否则会有抛IndexOutOfBoundsException的风险。\n    说明：\n       String str = \"a,b,c,,\";\n       String[] ary = str.split(\",\");\n       // 预期大于 3 ，结果是 3\n       System.out.println(ary.length);\n\n\n20. 【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便\n    于阅读，此条规则优先于下一条。\n21. 【推荐】 类内方法定义的顺序依次是：公有方法或保护方法 > 私有方法 > getter / setter\n    方法。\n    说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可\n    能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载\n    的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。\n22. 【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在\ngetter/setter方法中，不要增加业务逻辑，增加排查问题的难度。\n反例：\npublic Integer getData () {\nif (condition) {\nreturn this.data + 100 ;\n} else {\nreturn this.data - 100 ;\n}\n}\n23. 【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。\n说明：下例中，反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append\n操作，最后通过toString方法返回String对象，造成内存资源浪费。\n反例：\nString str = \"start\";\nfor (int i = 0 ; i < 100 ; i++) {\nstr = str + \"hello\";\n}\n24. 【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字：\n1 ） 不允许被继承的类，如：String类。\n2 ） 不允许修改引用的域对象，如：POJO类的域变量。\n3 ） 不允许被覆写的方法，如：POJO类的setter方法。\n4 ） 不允许运行过程中重新赋值的局部变量。\n5 ） 避免上下文重复使用一个变量，使用final关键字可以强制重新定义一个变量，方便更好地进行重构。\n25. 【推荐】慎用Object的clone方法来拷贝对象。\n    说明：对象clone方法默认是浅拷贝，若想实现深拷贝，需覆写clone方法实现域对象的深度遍历式拷贝。\n26. 【推荐】类成员与方法访问控制从严：\n    1 ） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。\n    2 ） 工具类不允许有public或default构造方法。\n    3 ） 类非static成员变量并且与子类共享，必须是protected。\n    4 ） 类非static成员变量并且仅在本类使用，必须是private。\n\n\n```\n5 ） 类static成员变量如果仅在本类使用，必须是private。\n6 ） 若是static成员变量，考虑是否为final。\n7 ） 类成员方法只供类内部调用，必须是private。\n8 ） 类成员方法只对继承类公开，那么限制为protected。\n说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果\n是一个private的方法，想删除就删除，可是一个public的service成员方法或成员变量，删除一下，不\n得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你\n会担心的。\n```\n### (五) 日期时间\n\n1. 【强制】日期格式化时，传入pattern中表示年份统一使用小写的y。\n    说明：日期格式化时，yyyy表示当天所在的年，而大写的YYYY代表是week in which year（JDK7之后\n    引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY\n    就是下一年。\n    正例：表示日期和时间的格式如下所示：\n    new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n2. 【强制】在日期格式中分清楚大写的M和小写的m，大写的H和小写的h分别指代的意义。\n说明：日期格式中的这两对字母表意如下：\n1 ） 表示月份是大写的M；\n2 ） 表示分钟则是小写的m；\n3 ） 24 小时制的是大写的H；\n4 ） 12 小时制的则是小写的h。\n3. 【强制】获取当前毫秒数：System.currentTimeMillis(); 而不是new Date().getTime()。\n    说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间\n    等场景，推荐使用Instant类。\n4. 【强制】不允许在程序任何地方中使用： 1 ）java.sql.Date。 2 ）java.sql.Time。\n3 ）java.sql.Timestamp。\n说明：第 1 个不记录时间，getHours()抛出异常；第 2 个不记录日期，getYear()抛出异常；第 3 个在构造\n方法super((time/1000)*1000)，在Timestamp 属性fastTime和nanos分别存储秒和纳秒信息。\n反例： java.util.Date.after(Date)进行时间比较时，当入参是java.sql.Timestamp时，会触发JDK\nBUG(JDK9已修复)，可能导致比较时的意外结果。\n5. 【强制】不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑\n错误。\n\n\n```\n正例：\n// 获取今年的天数\nint daysOfThisYear = LocalDate.now().lengthOfYear();\n// 获取指定某年的天数\nLocalDate.of( 2011 , 1 , 1 ).lengthOfYear();\n反例：\n// 第一种情况：在闰年 366 天时，出现数组越界异常\nint[] dayArray = new int[ 365 ];\n// 第二种情况：一年有效期的会员制，今年 1 月 26 日注册，硬编码 365 返回的却是 1 月 25 日\nCalendar calendar = Calendar.getInstance();\ncalendar.set( 2020 , 1 , 26 );\ncalendar.add(Calendar.DATE, 365 );\n```\n6. 【推荐】避免公历闰年 2 月问题。闰年的 2 月份有 29 天，一年后的那一天不可能是 2 月 29\n    日。\n7. 【推荐】使用枚举值来指代月份。如果使用数字，注意Date，Calendar等日期相关类的月份\n    month取值在 0 - 11 之间。\n    说明：参考JDK原生注释，Month value is 0-based. e.g., 0 for January.\n    正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或\n    比较。\n\n### (六) 集合处理\n\n1. 【强制】关于hashCode和equals的处理，遵循如下规则：\n    1 ） 只要覆写equals，就必须覆写hashCode。\n    2 ） 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须覆写\n    这两种方法。\n    3 ） 如果自定义对象作为Map的键，那么必须覆写hashCode和equals。\n    说明：String因为覆写了hashCode和equals方法，所以可以愉快地将String对象作为key来使用。\n2. 【强制】判断所有集合内部的元素是否为空，使用isEmpty()方法，而不是size()==0的方式。\n    说明：在某些集合中，前者的时间复杂度为O(1)，而且可读性更好。\n    正例：\n       Map<String, Object> map = new HashMap<>( 16 );\n       if(map.isEmpty()) {\n       System.out.println(\"no element in this map.\");\n       }\n\n\n3. 【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要使\n    用含有参数类型为BinaryOperator，参数名为mergeFunction的方法，否则当出现相同key\n    值时会抛出IllegalStateException异常。\n    说明：参数mergeFunction的作用是当出现key重复时，自定义对value的处理策略。\n    正例：\n       List<Pair<String, Double>> pairArrayList = new ArrayList<>( 3 );\n       pairArrayList.add(new Pair<>(\"version\", 12.10));\n       pairArrayList.add(new Pair<>(\"version\", 12.19));\n       pairArrayList.add(new Pair<>(\"version\", 6.28));\n       Map<String, Double> map = pairArrayList.stream().collect(\n       // 生成的map集合中只有一个键值对：{version=6.2 8 }\n       Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - > v2));\n    反例：\n       String[] departments = new String[] {\"iERP\", \"iERP\", \"EIBU\"};\n       // 抛出IllegalStateException异常\n       Map<Integer, String> map = Arrays.stream(departments)\n       .collect(Collectors.toMap(String::hashCode, str -> str));\n4. 【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要注\n    意当value为null时会抛NPE异常。\n    说明：在java.util.HashMap的merge方法里会进行如下的判断：\n       if (value == null || remappingFunction == null)\n          throw new NullPointerException();\n    反例：\n       List<Pair<String, Double>> pairArrayList = new ArrayList<>( 2 );\n       pairArrayList.add(new Pair<>(\"version1\", 8. 3 ));\n       pairArrayList.add(new Pair<>(\"version2\", null));\n       Map<String, Double> map = pairArrayList.stream().collect(\n       // 抛出NullPointerException异常\n       Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - > v2));\n5. 【强制】ArrayList的subList结果不可强转成ArrayList，否则会抛出 ClassCastException异\n    常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。\n    说明：subList()返回的是ArrayList的内部类SubList，并不是 ArrayList本身，而是ArrayList 的一个视\n    图，对于SubList的所有操作最终会反映到原列表上。\n6. 【强制】使用Map的方法keySet()/values()/entrySet()返回集合对象时，不可以对其进行添\n    加元素操作，否则会抛出UnsupportedOperationException异常。\n7. 【强制】Collections类返回的对象，如：emptyList()/singletonList()等都是immutable list，\n不可对其进行添加或者删除元素的操作。\n反例：如果查询无结果，返回Collections.emptyList()空集合对象，调用方一旦进行了添加元素的操作，就\n会触发UnsupportedOperationException异常。\n\n\n8. 【强制】在subList场景中，高度注意对父集合元素的增加或删除，均会导致子列表的遍历、\n    增加、删除产生ConcurrentModificationException 异常。\n9. 【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一\n致、长度为 0 的空数组。\n反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现\nClassCastException错误。\n正例：\nList<String> list = new ArrayList<>( 2 );\nlist.add(\"guan\");\nlist.add(\"bao\");\nString[] array = list.toArray(new String[ 0 ]);\n说明：使用toArray带参方法，数组空间大小的length：\n1 ） 等于 0 ，动态创建与size相同的数组，性能最好。\n2 ） 大于 0 但小于size，重新创建大小等于size的数组，增加GC负担。\n3 ） 等于size，在高并发情况下，数组创建完成之后，size正在变大的情况下，负面影响与 2 相同。\n4 ） 大于size，空间浪费，且在size处插入null值，存在NPE隐患。\n10. 【强制】在使用Collection接口任何实现类的addAll()方法时，都要对输入的集合参数进行\nNPE判断。\n说明：在ArrayList#addAll方法的第一行代码即Object[] a = c.toArray(); 其中c为输入集合参数，如果\n为null，则直接抛出异常。\n11. 【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，\n它的add/remove/clear方法会抛出UnsupportedOperationException异常。\n说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配\n器模式，只是转换接口，后台的数据仍是数组。\nString[] str = new String[] { \"chen\", \"yang\", \"hao\" };\nList list = Arrays.asList(str);\n第一种情况：list.add(\"yangguanbao\"); 运行时异常。\n第二种情况：str[0] = \"change\"; 也会随之修改，反之亦然。\n12. 【强制】泛型通配符<? extends T>来接收返回的数据，此写法的泛型集合不能使用add方法，\n而<? super T>不能使用get方法，两者在接口调用赋值的场景中容易出错。\n说明：扩展说一下PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用\n<? extends T>。第二、经常往里插入的，适合用<? super T>\n13. 【强制】在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行\ninstanceof判断，避免抛出ClassCastException异常。\n说明：毕竟泛型是在JDK5后才出现，考虑到向前兼容，编译器是允许非泛型集合与泛型集合互相赋值。\n\n\n```\n反例：\nList<String> generics = null;\nList notGenerics = new ArrayList( 10 );\nnotGenerics.add(new Object());\nnotGenerics.add(new Integer( 1 ));\ngenerics = notGenerics;\n// 此处抛出ClassCastException异常\nString string = generics.get( 0 );\n```\n14. 【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator\n    方式，如果并发操作，需要对Iterator对象加锁。\n       正例：\n          List<String> list = new ArrayList<>();\n          list.add(\"1\");\n          list.add(\"2\");\n          Iterator<String> iterator = list.iterator();\n          while (iterator.hasNext()) {\n          String item = iterator.next();\n          if (删除元素的条件) {\n          iterator.remove();\n          }\n          }\n       反例：\n          for (String item : list) {\n          if (\"1\".equals(item)) {\n          list.remove(item);\n          }\n          }\n       说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？\n15. 【强制】在JDK 7 版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，\n    Collections.sort会抛IllegalArgumentException异常。\n    说明：三个条件如下\n    1 ） x，y的比较结果和y，x的比较结果相反。\n    2 ） x>y，y>z，则x>z。\n    3 ） x=y，则x，z比较结果和y，z比较结果相同。\n    反例：下例中没有处理相等的情况，交换两个对象判断结果并不互反，不符合第一个条件，在实际使用中\n    可能会出现异常。\n       new Comparator<Student>() {\n       @Override\n       public int compare(Student o1, Student o2) {\n       return o1.getId() > o2.getId()? 1 : - 1 ;\n       }\n       };\n16. 【推荐】集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。\n    说明：菱形泛型，即diamond，直接使用<>来指代前边已经指定的类型。\n\n\n```\n正例：\n// diamond方式，即<>\nHashMap<String, String> userCache = new HashMap<>( 16 );\n// 全省略方式\nArrayList<User> users = new ArrayList( 10 );\n```\n17. 【推荐】集合初始化时，指定集合初始值大小。\n    说明：HashMap使用HashMap(int initialCapacity) 初始化，如果暂时无法确定集合大小，那么指定默\n    认值（ 16 ）即可。\n    正例：initialCapacity = (需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loader factor）默认\n    为0.75，如果暂时无法确定初始值大小，请设置为 16 （即默认值）。\n       反例： HashMap需要放置 1024 个元素，由于没有设置容量初始大小，随着元素增加而被迫不断扩容，\n       resize()方法总共会调用 8 次，反复重建哈希表和数据迁移。当放置的集合元素个数达千万级时会影响程序\n       性能。\n18. 【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。\n说明：keySet其实是遍历了 2 次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的\nvalue。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用\nMap.forEach方法。\n正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对\n象；entrySet()返回的是K-V值组合集合。\n19. 【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格：\n\n```\n集合类 Key Value Super 说明\nHashtable 不允许为null 不允许为null Dictionary 线程安全\nConcurrentHashMap 不允许为null 不允许为null AbstractMap 锁分段技术（JDK8:CAS）\nTreeMap 不允许为null 允许为null AbstractMap 线程不安全\nHashMap 允许为null 允许为null AbstractMap 线程不安全\n反例：由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储\nnull值时会抛出NPE异常。\n```\n20. 【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳\n    定性(unorder)带来的负面影响。\n    说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。\n    如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。\n21. 【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的\n    contains()进行遍历去重或者判断包含操作。\n\n\n### (七) 并发处理\n\n1. 【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。\n    说明：资源驱动类、工具类、单例工厂类都需要注意。\n2. 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。\n正例：自定义线程工厂，并且根据外部特征进行分组，比如，来自同一机房的调用，把机房编号赋值给\nwhatFeatureOfGroup\npublic class UserThreadFactory implements ThreadFactory {\nprivate final String namePrefix;\nprivate final AtomicInteger nextId = new AtomicInteger( 1 );\n// 定义线程组名称，在利用jstack来排查问题时，非常有帮助\nUserThreadFactory(String whatFeatureOfGroup) {\nnamePrefix = \"From UserThreadFactory's \" + whatFeatureOfGroup + \"-Worker-\";\n}\n@Override\npublic Thread newThread(Runnable task) {\nString name = namePrefix + nextId.getAndIncrement();\nThread thread = new Thread(null, task, name, 0 , false);\nSystem.out.println(thread.getName());\nreturn thread;\n}\n}\n3. 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。\n说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。\n如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。\n4. 【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这\n样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。\n说明：Executors返回的线程池对象的弊端如下：\n1 ） FixedThreadPool和SingleThreadPool：\n允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。\n2 ） CachedThreadPool：\n允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。\n5. 【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，\n必须加锁，或者使用DateUtils工具类。\n正例：注意线程安全，使用DateUtils。亦推荐如下处理：\nprivate static final ThreadLocal<DateFormat> df = new ThreadLocal<DateFormat>() {\n@Override\nprotected DateFormat initialValue() {\nreturn new SimpleDateFormat(\"yyyy-MM-dd\");\n}\n};\n\n\n```\n说明：如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，\nDateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful strong immutable\nthread-safe。\n```\n6. 【强制】必须回收自定义的ThreadLocal变量，尤其在线程池场景下，线程经常会被复用，\n    如果不清理自定义的 ThreadLocal变量，可能会影响后续业务逻辑和造成内存泄露等问题。\n    尽量在代理中使用try-finally块进行回收。\n    正例：\n       objectThreadLocal.set(userInfo);\n       try {\n       // ...\n       } finally {\n       objectThreadLocal.remove();\n       }\n7. 【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能\n    锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。\n       说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。\n8. 【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造\n成死锁。\n说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、\nB、C，否则可能出现死锁。\n9. 【强制】在使用阻塞等待获取锁的方式中，必须在try代码块之外，并且在加锁方法与try代\n    码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在finally中无法解锁。\n    说明一：如果在lock方法与try代码块之间的方法调用抛出异常，那么无法解锁，造成其它线程无法成功\n    获取锁。\n    说明二：如果lock方法在try代码块之内，可能由于其它方法抛出异常，导致在finally代码块中，unlock\n    对未加锁的对象解锁，它会调用AQS的tryRelease方法（取决于具体实现类），抛出\n    IllegalMonitorStateException异常。\n    说明三：在Lock对象的lock方法实现中可能抛出unchecked异常，产生的后果与说明二相同。\n    正例：\n       Lock lock = new XxxLock();\n       // ...\n       lock.lock();\n       try {\n       doSomething();\n       doOthers();\n       } finally {\n       lock.unlock();\n       }\n反例：\nLock lock = new XxxLock();\n// ...\n\n\n```\ntry {\n// 如果此处抛出异常，则直接执行finally代码块\ndoSomething();\n// 无论加锁是否成功，finally代码块都会执行\nlock.lock();\ndoOthers();\n} finally {\nlock.unlock();\n}\n```\n10. 【强制】在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否\n    持有锁。锁的释放规则与锁的阻塞等待方式相同。\n    说明：Lock对象的unlock方法在执行时，它会调用AQS的tryRelease方法（取决于具体实现类），如果\n    当前线程不持有锁，则抛出IllegalMonitorStateException异常。\n    正例：\n       Lock lock = new XxxLock();\n       // ...\n       boolean isLocked = lock.tryLock();\n       if (isLocked) {\n       try {\n       doSomething();\n       doOthers();\n       } finally {\n       lock.unlock();\n       }\n       }\n11. 【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加\n锁，要么在数据库层使用乐观锁，使用version作为更新依据。\n说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于\n3 次。\n12. 【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛\n出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。\n13. 【推荐】资金相关的金融敏感信息，使用悲观锁策略。\n    说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策\n    略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观\n    锁更新。\n       正例：悲观锁遵循一锁、二判、三更新、四释放的原则。\n14. 【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方\n法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至\nawait方法，直到超时才返回结果。\n说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。\n\n\n15. 【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed\n    导致的性能下降。\n       说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。\n       正例：在JDK7之后，可以直接使用API ThreadLocalRandom，而在 JDK7之前，需要编码保证每个线\n       程持有一个单独的Random实例。\n16. 【推荐】通过双重检查锁（double-checked locking）（在并发场景下）存在延迟初始化的优化\n    问题隐患（可参考 The \"Double-Checked Locking is Broken\" Declaration），推荐解决方案中较\n    为简单一种（适用于JDK 5 及以上版本），将目标属性声明为 volatile型，比如将helper的属\n    性声明修改为`private volatile Helper helper = null;`。\n    正例：\n       public class LazyInitDemo {\n       private volatile Helper helper = null;\n       public Helper getHelper() {\n       if (helper == null) {\n       synchronized (this) {\n       if (helper == null) { helper = new Helper(); }\n       }\n       }\n       return helper;\n       }\n       // other methods and fields...\n       }\n17. 【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但\n    是如果多写，同样无法解决线程安全问题。\n       说明：如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger();\n       count.addAndGet(1); 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观\n       锁的重试次数）。\n18. 【参考】HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在\n开发过程中注意规避此风险。\n19. 【参考】ThreadLocal对象使用static修饰，ThreadLocal无法解决共享对象的更新问题。\n说明：这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量，\n也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可\n以操控这个变量。\n\n### (八) 控制语句\n\n1. 【强制】在一个switch块内，每个case要么通过continue/break/return等来终止，要么\n    注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default\n\n\n```\n语句并且放在最后，即使它什么代码也没有。\n说明：注意break是退出switch语句块，而return是退出方法体。\n```\n2. 【强制】当switch括号内的变量类型为String并且此变量为外部参数时，必须先进行null\n    判断。\n    反例：如下的代码输出是什么？\n       public class SwitchString {\n       public static void main(String[] args) {\n       method(null);\n       }\n       public static void method(String param) {\n       switch (param) {\n       // 肯定不是进入这里\n       case \"sth\":\n       System.out.println(\"it's sth\");\n       break;\n       // 也不是进入这里\n       case \"null\":\n       System.out.println(\"it's null\");\n       break;\n       // 也不是进入这里\n       default:\n       System.out.println(\"default\");\n       }\n       }\n       }\n3. 【强制】在if/else/for/while/do语句中必须使用大括号。\n    说明：即使只有一行代码，也禁止不采用大括号的编码方式：if (condition) statements;\n4. 【强制】三目运算符condition? 表达式1 : 表达式 2 中，高度注意表达式 1 和 2 在类型对齐\n    时，可能抛出因自动拆箱导致的NPE异常。\n    说明：以下两种场景会触发类型对齐的拆箱操作：\n    1 ） 表达式 1 或表达式 2 的值只要有一个是原始类型。\n    2 ） 表达式 1 或表达式 2 的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。\n       反例：\n          Integer a = 1 ;\n          Integer b = 2 ;\n          Integer c = null;\n          Boolean flag = false;\n          // a*b的结果是int类型，那么c会强制拆箱成int类型，抛出NPE异常\n          Integer result=(flag? a*b : c);\n5. 【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。\n说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件\n来代替。\n\n\n```\n反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，\n这样的话，活动无法终止。\n```\n6. 【推荐】当某个方法的代码总行数超过 10 行时，return / throw 等中断逻辑的右大括号后均\n    需要加一个空行。\n    说明：这样做逻辑清晰，有利于代码阅读时重点关注。\n7. 【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成：\nif (condition) {\n...\nreturn obj;\n}\n// 接着写else的业务逻辑代码;\n说明：如果非使用if()...else if()...else...方式表达逻辑，避免后续代码维护困难，请勿超过 3 层。\n正例：超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句\n示例如下：\npublic void findBoyfriend (Man man) {\nif (man.isUgly()) {\nSystem.out.println(\"本姑娘是外貌协会的资深会员\");\nreturn;\n}\nif (man.isPoor()) {\nSystem.out.println(\"贫贱夫妻百事哀\");\nreturn;\n}\nif (man.isBadTemper()) {\nSystem.out.println(\"银河有多远，你就给我滚多远\");\nreturn;\n}\nSystem.out.println(\"可以先交往一段时间看看\");\n}\n8. 【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复\n    杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。\n    说明：很多 if 语句内的逻辑表达式相当复杂，与、或、取反混合运算，甚至各种方法纵深调用，理解成本\n    非常高。如果赋值一个非常好理解的布尔变量名字，则是件令人爽心悦目的事情。\n    正例：\n       // 伪代码如下\n       final boolean existed = (file.open(fileName, \"w\") != null) && (...) || (...);\n       if (existed) {\n       ...\n       }\n反例：\npublic final void acquire ( long arg) {\nif (!tryAcquire(arg) &&\nacquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {\nselfInterrupt();\n}\n\n\n9. 【推荐】不要在其它表达式（尤其是条件表达式）中，插入赋值语句。\n    说明：赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行。\n    反例：\n       public Lock getLock(boolean fair) {\n       // 算术表达式中出现赋值操作，容易忽略count值已经被改变\n       threshold = (count = Integer.MAX_VALUE) - 1 ;\n       // 条件表达式中出现赋值操作，容易误认为是sync==fair\n       return (sync = fair)? new FairSync() : new NonfairSync();\n       }\n10. 【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、\n    获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。\n11. 【推荐】避免采用取反逻辑运算符。\n    说明：取反逻辑不利于快速理解，并且取反逻辑写法一般都存在对应的正向逻辑写法。\n    正例：使用if (x < 628) 来表达 x 小于 628 。\n    反例：使用if (!(x >= 628)) 来表达 x 小于 628 。\n12. 【推荐】公开接口需要进行入参保护，尤其是批量操作的接口。\n    反例：某业务系统，提供一个用户批量查询的接口，API文档上有说最多查多少个，但接口实现上没做任何\n    保护，导致调用方传了一个 1000 的用户id数组过来后，查询信息后，内存爆了。\n13. 【参考】下列情形，需要进行参数校验：\n    1 ） 调用频次低的方法。\n    2 ） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致\n    中间执行回退，或者错误，那得不偿失。\n    3 ） 需要极高稳定性和可用性的方法。\n    4 ） 对外提供的开放接口，不管是RPC/API/HTTP接口。\n       5 ） 敏感权限入口。\n14. 【参考】下列情形，不需要进行参数校验：\n1 ） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查。\n2 ） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露\n问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可\n以省略。\n3 ） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检\n查或者肯定不会有问题，此时可以不校验参数。\n\n\n### (九) 注释规约\n\n1. 【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/**内容*/格式，不得使用\n    // xxx方式。\n    说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE\n    中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。\n2. 【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、\n    异常说明外，还必须指出该方法做什么事情，实现什么功能。\n    说明：对子类的实现要求，或者调用注意事项，请一并说明。\n3. 【强制】所有的类都必须添加创建者和创建日期。\n说明：在设置模板时，注意IDEA的@author为`${USER}`，而eclipse的@author为`${user}`，大小写有\n区别，而日期的设置统一为yyyy/MM/dd的格式。\n正例：\n/**\n\n```\n* @author yangguanbao\n* @date 2016/10/31\n*/\n```\n4. 【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使\n    用/* */注释，注意与代码对齐。\n5. 【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。\n6. 【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持\n    英文原文即可。\n    反例：“TCP连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。\n7. 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑\n    等的修改。\n    说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了\n    导航的意义。\n8. 【推荐】在类中删除未使用的任何字段、方法、内部类；在方法中删除未使用的任何参数声明\n    与内部变量。\n9. 【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。\n    说明：代码被注释掉有两种可能性： 1 ）后续会恢复此段代码逻辑。 2 ）永久不用。前者如果没有备注信息，\n    难以知晓注释动机。后者建议直接删掉即可，假如需要查阅历史代码，登录代码仓库即可。\n\n\n10. 【参考】对于注释的要求：第一、能够准确反映设计思想和代码逻辑；第二、能够描述业务含\n    义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同\n    天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看\n    的，使其能够快速接替自己的工作。\n11. 【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一\n个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释又是相当大的负担。\n反例：\n// put elephant into fridge\nput(elephant, fridge);\n方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不\n需要额外的注释。\n12. 【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，\n经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。\n1 ） 待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）\n表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没\n有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）。\n2 ） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）\n在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。\n\n### (十) 前后端规约\n\n1. 【强制】前后端交互的API，需要明确协议、域名、路径、请求方法、请求内容、状态码、响\n    应体。\n    说明：\n       1 ） 协议：生产环境必须使用HTTPS。\n       2 ） 路径：每一个API需对应一个路径，表示API具体的请求地址：\n       a） 代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。\n       b） URL路径不能使用大写，单词如果需要分隔，统一使用下划线。\n       c） 路径禁止携带表示请求内容类型的后缀，比如\".json\",\".xml\"，通过accept头表达即可。\n       3 ） 请求方法：对具体操作的定义，常见的请求方法如下：\n       a） GET：从服务器取出资源。\n       b） POST：在服务器新建一个资源。\n       c） PUT：在服务器更新资源。\n       d） DELETE：从服务器删除资源。\n       4 ） 请求内容：URL带的参数必须无敏感信息或符合安全要求；body里带参数时必须设置Content-Type。\n       5 ） 响应体：响应体body可放置多种数据类型，由Content-Type头来确定。\n\n\n2. 【强制】前后端数据列表相关的接口返回，如果为空，则返回空数组[]或空集合{}。\n    说明：此条约定有利于数据层面上的协作更加高效，减少前端很多琐碎的null判断。\n3. 【强制】服务端发生错误时，返回给前端的响应信息必须包含HTTP状态码，errorCode、\n    errorMessage、用户提示信息四个部分。\n    说明：四个部分的涉众对象分别是浏览器、前端开发、错误排查人员、用户。其中输出给用户的提示信息\n    要求：简短清晰、提示友好，引导用户进行下一步操作或解释错误原因，提示信息可以包括错误原因、上\n    下文环境、推荐操作等。 errorCode：参考 **附表 3** 。errorMessage：简要描述后端出错原因，便于错误排\n    查人员快速定位问题，注意不要包含敏感数据信息。\n    正例：常见的HTTP状态码如下\n    1 ） 200 OK: 表明该请求被成功地完成，所请求的资源发送到客户端。\n    2 ） 401 Unauthorized: 请求要求身份验证，常见对于需要登录而用户未登录的情况。\n    3 ） 403 Forbidden：服务器拒绝请求，常见于机密信息或复制其它登录用户链接访问服务器的情况。\n    4 ） 404 Not Found: 服务器无法取得所请求的网页，请求资源不存在。\n    5 ） 500 Internal Server Error: 服务器内部错误。\n4. 【强制】在前后端交互的JSON格式数据中，所有的key必须为小写字母开始的\n    lowerCamelCase风格，符合英文表达习惯，且表意完整。\n    正例：errorCode / errorMessage / assetStatus / menuList / orderList / configFlag\n    反例：ERRORCODE / ERROR_CODE / error_message / error-message / errormessage /\n    ErrorMessage / msg\n5. 【强制】errorMessage是前后端错误追踪机制的体现，可以在前端输出到type=\"hidden\"\n文字类控件中，或者用户端的日志中，帮助我们快速地定位出问题。\n6. 【强制】对于需要使用超大整数的场景，服务端一律使用String字符串类型返回，禁止使用\nLong类型。\n说明：Java服务端如果直接返回Long整型数据给前端，JS会自动转换为Number类型（注：此类型为双\n精度浮点数，表示原理与取值范围等同于Java中的Double）。Long类型能表示的最大值是 2 的 63 次方\n- 1 ，在取值范围之内，超过 2 的 53 次方 (9007199254740992)的数值转化为JS的Number时，有些数\n值会有精度损失。扩展说明，在Long取值范围内，任何 2 的指数次整数都是绝对不会存在精度损失的，所\n以说精度损失是一个概率问题。若浮点数尾数位与指数位空间不限，则可以精确表示任何整数，但很不幸，\n双精度浮点数的尾数位只有 52 位。\n反例：通常在订单号或交易号大于等于 16 位，大概率会出现前后端单据不一致的情况，比如，\"orderId\":\n362909601374617692 ，前端拿到的值却是: 36290960137461766 0 。\n7. 【强制】HTTP请求通过URL传递参数时，不能超过 2048 字节。\n    说明：不同浏览器对于URL的最大长度限制略有不同，并且对超出最大长度的处理逻辑也有差异， 2048\n    字节是取所有浏览器的最小值。\n\n\n```\n反例：某业务将退货的商品id列表放在URL中作为参数传递，当一次退货商品数量过多时，URL参数超长，\n传递到后端的参数被截断，导致部分商品未能正确退货。\n```\n8. 【强制】HTTP请求通过body传递内容时，必须控制长度，超出最大长度后，后端解析会出\n    错。\n    说明：nginx默认限制是1MB，tomcat默认限制为2MB，当确实有业务需要传较大内容时，可以通过调\n    大服务器端的限制。\n9. 【强制】在翻页场景中，用户输入参数的小于 1 ，则前端返回第一页参数给后端；后端发现用\n户输入的参数大于总页数，直接返回最后一页。\n10. 【强制】服务器内部重定向必须使用forward；外部重定向地址必须使用URL统一代理模块\n生成，否则会因线上采用HTTPS协议而导致浏览器提示“不安全”，并且还会带来URL维护\n不一致的问题。\n11. 【推荐】服务器返回信息必须被标记是否可以缓存，如果缓存，客户端可能会重用之前的请求\n    结果。\n    说明：缓存有利于减少交互次数，减少交互的平均延迟。\n    正例：http 1.1中，s-maxage告诉服务器进行缓存，时间单位为秒，用法如下，\n    response.setHeader(\"Cache-Control\", \"s-maxage=\" + cacheSeconds);\n12. 【推荐】服务端返回的数据，使用JSON格式而非XML。\n    说明：尽管HTTP支持使用不同的输出格式，例如纯文本，JSON，CSV，XML，RSS甚至HTML。如果我\n    们使用的面向用户的服务，应该选择JSON作为通信中使用的标准数据交换格式，包括请求和响应。此外，\n    application/JSON是一种通用的MIME类型，具有实用、精简、易读的特点。\n13. 【推荐】前后端的时间格式统一为\"yyyy-MM-dd HH:mm:ss\"，统一为GMT。\n14. 【参考】在接口路径中不要加入版本号，版本控制在HTTP头信息中体现，有利于向前兼容。\n说明：当用户在低版本与高版本之间反复切换工作时，会导致迁移复杂度升高，存在数据错乱风险。\n\n### (十一) 其他\n\n1. 【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。\n    说明：不要在方法体内定义：Pattern pattern = Pattern.compile(“规则”);\n2. 【强制】避免用Apache Beanutils进行属性的copy。\n    说明：Apache BeanUtils性能较差，可以使用其他方案比如Spring BeanUtils, Cglib BeanCopier，注意\n    均是浅拷贝。\n\n\n3. 【强制】velocity调用POJO类的属性时，直接使用属性名取值即可，模板引擎会自动按规范\n    调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），\n    会自动调用isXxx()方法。\n    说明：注意如果是Boolean包装类对象，优先调用getXxx()的方法。\n4. 【强制】后台输送给页面的变量必须加$!{var}——中间的感叹号。\n    说明：如果var等于null或者不存在，那么${var}会直接显示在页面上。\n5. 【强制】注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x<1（能够\n    取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大 10 的若干倍然后\n    取整，直接使用Random对象的nextInt或者nextLong方法。\n6. 【推荐】不要在视图模板中加入任何复杂的逻辑。\n说明：根据MVC理论，视图的职责是展示，不要抢模型和控制器的活。\n7. 【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。\n8. 【推荐】及时清理不再使用的代码段或配置信息。\n说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。\n正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)\n来说明注释掉代码的理由。如：\npublic static void hello() {\n/// 业务方通知活动暂停\n// Business business = new Business();\n// business.active();\nSystem.out.println(\"it's finished\");\n}\n\n\n## 二、异常日志\n\n### (一) 错误码\n\n1. 【强制】错误码的制定原则：快速溯源、沟通标准化。\n    说明： 错误码想得过于完美和复杂，就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身\n    携带并且简单易懂。\n    正例：错误码回答的问题是谁的错？错在哪？ 1 ）错误码必须能够快速知晓错误来源，可快速判断是谁的问\n    题。 2 ）错误码必须能够进行清晰地比对（代码中容易equals）。 3 ）错误码有利于团队快速对错误原因达\n    到一致认知。\n2. 【强制】错误码不体现版本号和错误等级信息。\n    说明：错误码以不断追加的方式进行兼容。错误等级由日志和错误码本身的释义来决定。\n3. 【强制】全部正常，但不得不填充错误码时返回五个零： 00000 。\n4. 【强制】错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。\n    说明：错误产生来源分为A/B/C，A表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付\n    超时等问题；B表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；C表示错误来源\n    于第三方服务，比如CDN服务出错，消息投递超时等问题；四位数字编号从 0001 到 9999 ，大类之间的\n    步长间距预留 100 ，参考文末 **附表 3** 。\n5. 【强制】编号不与公司业务架构，更不与组织架构挂钩，以先到先得的原则在统一平台上进行，\n    审批生效，编号即被永久固定。\n6. 【强制】错误码使用者避免随意定义新的错误码。\n    说明：尽可能在原有错误码附表中找到语义相同或者相近的错误码在代码中使用即可。\n7. 【强制】错误码不能直接输出给用户作为提示信息使用。\n    说明：堆栈（stack_trace）、错误信息(error_message)、错误码（error_code）、提示信息（user_tip）\n    是一个有效关联并互相转义的和谐整体，但是请勿互相越俎代庖。\n8. 【推荐】错误码之外的业务独特信息由error_message来承载，而不是让错误码本身涵盖过\n    多具体业务属性。\n9. 【推荐】在获取第三方服务错误码时，向上抛出允许本系统转义，由C转为B，并且在错误信\n    息上带上原有的第三方错误码。\n10. 【参考】错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。\n    说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、\n\n\n```\nB0001（系统执行出错）、C0001（调用第三方服务出错）。\n正例：调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。\n```\n11. 【参考】错误码的后三位编号与HTTP状态码没有任何关系。\n12. 【参考】错误码有利于不同文化背景的开发者进行交流与代码协作。\n    说明：英文单词形式的错误码不利于非英语母语国家（如阿拉伯语、希伯来语、俄罗斯语等）之间的开发\n    者互相协作。\n13. 【参考】错误码即人性，感性认知+口口相传，使用纯数字来进行错误码编排不利于感性记忆\n    和分类。\n    说明：数字是一个整体，每位数字的地位和含义是相同的。\n    反例：一个五位数字 12345 ，第 1 位是错误等级，第 2 位是错误来源， 345 是编号，人的大脑不会主动地\n    拆开并分辨每位数字的不同含义。\n\n### (二) 异常处理\n\n1. 【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过\n    catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。\n    说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不\n    通过catch NumberFormatException来实现。\n    正例：if (obj != null) {...}\n    反例：try { obj.method(); } catch (NullPointerException e) {...}\n2. 【强制】异常捕获后不要用来做流程控制，条件控制。\n    说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。\n3. 【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。\n    对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。\n    说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，\n    这是一种不负责任的表现。\n    正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程\n    序上作出分门别类的判断，并提示给用户。\n4. 【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请\n    将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的\n    内容。\n5. 【强制】事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。\n\n\n6. 【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。\n    说明：如果JDK7及以上，可以使用try-with-resources方式。\n7. 【强制】不要在finally块中使用return。\n说明：try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存\n在return语句，则在此直接返回，无情丢弃掉try块中的返回点。\n反例：\nprivate int x = 0 ;\npublic int checkReturn() {\ntry {\n// x等于 1 ，此处不返回\nreturn ++x;\n} finally {\n// 返回的结果是 2\nreturn ++x;\n}\n}\n8. 【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。\n    说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。\n9. 【强制】在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable\n    类来进行拦截。\n    说明：通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出\n    NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，\n    或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代\n    码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。\n10. 【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说\n    明什么情况下会返回null值。\n    说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也\n    并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。\n11. 【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景：\n1 ） 返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。\n反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。\n2 ） 数据库的查询结果可能为null。\n3 ） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。\n4 ） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。\n5 ） 对于Session中获取的数据，建议进行NPE检查，避免空指针。\n6 ） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。\n正例：使用JDK8的Optional类来防止NPE问题。\n\n\n12. 【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，\n    更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定\n    义过的自定义异常，如：DAOException / ServiceException等。\n13. 【参考】对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；\n    跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、\n    errorMessage；而应用内部直接抛出异常即可。\n    说明：关于RPC方法返回方式使用Result方式的理由：\n    1 ）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。\n    2 ）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题\n    的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。\n\n### (三) 日志规约\n\n1. 【强制】应用中不可直接使用日志系统（Log 4 j、Logback）中的API，而应依赖使用日志框架\n    （SLF4J、JCL--Jakarta Commons Logging）中的API，使用门面模式的日志框架，有利于维护和\n    各个类的日志处理方式统一。\n    说明：日志框架（SLF4J、JCL--Jakarta Commons Logging）的使用方式（推荐使用SLF4J）\n使用SLF4J：\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nprivate static final Logger logger = LoggerFactory.getLogger(Test.class);\n使用JCL：\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nprivate static final Log log = LogFactory.getLog(Test.class);\n2. 【强制】所有日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。对于\n当天日志，以“应用名.log”来保存，保存在/home/admin/应用名/logs/目录下，过往日志\n格式为: {logname}.log.{保存日期}，日期格式：yyyy-MM-dd\n正例：以aap应用为例，日志保存在/home/admin/aapserver/logs/aap.log，历史日志名称为\naap.log.2016- 08 - 01\n3. 【强制】根据国家法律，网络运行状态、网络安全事件、个人敏感信息操作等相关记录，留存\n    的日志不少于六个月，并且进行网络多机备份。\n4. 【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：\n    appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描\n    述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查\n    找。\n\n\n```\n说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系\n统进行及时监控。\n正例：mppserver应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log\n```\n5. 【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式。\n    说明：因为String字符串的拼接会使用StringBuilder的append()方式，有一定的性能损耗。使用占位符仅\n    是替换动作，可以有效提升性能。\n    正例：logger.debug(\"Processing trade with id: {} and symbol: {}\", id, symbol);\n6. 【强制】对于trace/debug/info级别的日志输出，必须进行日志级别的开关判断。\n    说明：虽然在debug(参数)的方法体内第一行代码isDisabled(Level.DEBUG_INT)为真时（Slf4j的常见实现\n    Log4j和Logback），就直接return，但是参数可能会进行字符串拼接运算。此外，如果debug(getName())\n    这种参数内有getName()方法调用，无谓浪费方法调用的开销。\n    正例：\n       // 如果判断为真，那么可以输出trace和debug级别的日志\n       if (logger.isDebugEnabled()) {\n       logger.debug(\"Current ID is: {} and name is: {}\", id, getName());\n       }\n7. 【强制】避免重复打印日志，浪费磁盘空间，务必在日志配置文件中设置additivity=false。\n    正例：<logger name=\"com.taobao.dubbo.config\" additivity=\"false\">\n8. 【强制】生产环境禁止直接使用System.out 或System.err 输出日志或使用\n    e.printStackTrace()打印异常堆栈。\n    说明：标准日志输出与标准错误输出文件每次Jboss重启时才滚动，如果大量输出送往这两个文件，容易\n    造成文件大小超过操作系统大小限制。\n9. 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过\n关键字throws往上抛出。\n正例：logger.error(\"inputParams:{} and errorMessage:{}\", 各类参数或者对象toString(), e.getMessage(), e);\n10. 【强制】日志打印时禁止直接用JSON工具将对象转换成String。\n说明：如果对象里某些get方法被覆写，存在抛出异常的情况，则可能会因为打印日志而影响正常业务流\n程的执行。\n正例：打印日志时仅打印出业务相关属性值或者调用其对象的toString()方法。\n11. 【推荐】谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用\nwarn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑\n爆，并记得及时删除这些观察日志。\n说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些\n日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？\n\n\n12. 【推荐】可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适\n    从。如非必要，请不要在此场景打出error级别，避免频繁报警。\n    说明：注意日志输出的级别，error级别只记录系统逻辑出错、异常或者重要的错误信息。\n13. 【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用\n    中文描述即可，否则容易产生歧义。\n    说明：国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息。\n\n\n## 三、单元测试\n\n1. 【强制】好的单元测试必须遵守AIR原则。\n    说明：单元测试在线上运行时，感觉像空气（AIR）一样感觉不到，但在测试质量的保障上，却是非常关键\n    的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。\n       ⚫ A：Automatic（自动化）\n       ⚫ I：Independent（独立性）\n⚫ R：Repeatable（可重复）\n2. 【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执\n    行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元\n    测试中不准使用System.out来进行人肉验证，必须使用assert来验证。\n3. 【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间\n    决不能互相调用，也不能依赖执行的先后次序。\n    反例：method2需要依赖method1的执行，将执行结果作为method2的输入。\n4. 【强制】单元测试是可以重复执行的，不能受到外界环境的影响。\n    说明：单元测试通常会被放到持续集成中，每次有代码check in时单元测试都会被执行。如果单测对外部\n    环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。\n    正例：为了不受外界环境影响，要求设计代码时就把SUT的依赖改成注入，在测试时用spring 这样的DI\n    框架注入一个本地（内存）实现或者Mock实现。\n5. 【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级\n    别，一般是方法级别。\n    说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑，\n    那是集成测试的领域。\n6. 【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。\n    说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。\n7. 【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。\n说明：源码编译时会跳过此目录，而单元测试框架默认是扫描此目录。\n8. 【推荐】单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都\n    要达到100%\n    说明：在工程规约的应用分层中提到的DAO层，Manager层，可重用度高的Service，都应该进行单元测\n    试。\n\n\n9. 【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量。\n    ⚫ B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。\n    ⚫ C：Correct，正确的输入，并得到预期的结果。\n    ⚫ D：Design，与设计文档相结合，来编写单元测试。\n    ⚫ E：Error，强制错误信息输入（如：非法数据、异常流程、业务允许外等），并得到预期的结果。\n10. 【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或\n者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。\n反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数\n据并不符合业务插入规则，导致测试结果异常。\n11. 【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对\n    单元测试产生的数据有明确的前后缀标识。\n    正例：在阿里巴巴企业智能事业部的内部单元测试中，使用ENTERPRISE_INTELLIGENCE _UNIT_TEST_\n    的前缀来标识单元测试相关代码。\n12. 【推荐】对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试\n    要求而书写不规范测试代码。\n13. 【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆\n    盖所有测试用例（UC）。\n14. 【推荐】单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补\n    充单元测试用例。\n15. 【参考】为了更方便地进行单元测试，业务代码应避免以下情况：\n\n```\n⚫ 构造方法中做的事情过多。\n⚫ 存在过多的全局变量和静态方法。\n⚫ 存在过多的外部依赖。\n⚫ 存在过多的条件语句。\n说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。\n```\n16. 【参考】不要对单元测试存在如下误解：\n\n```\n⚫ 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。\n⚫ 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。\n⚫ 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。\n⚫ 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。\n```\n\n## 四、安全规约\n\n1. 【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。\n    说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容。\n2. 【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。\n    说明：中国大陆个人手机号码显示： 139 **** 1219 ，隐藏中间 4 位，防止隐私泄露。\n3. 【强制】用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，\n    禁止字符串拼接SQL访问数据库。\n    反例：某系统签名大量被恶意修改，即是因为对于危险字符 # --没有进行转义，导致数据库更新时，where\n    后边的信息被注释掉，对全库进行更新。\n4. 【强制】用户请求传入的任何参数必须做有效性验证。\n说明：忽略参数校验可能导致：\n⚫ page size过大导致内存溢出\n⚫ 恶意order by导致数据库慢查询\n⚫ 缓存击穿\n⚫ SSRF\n⚫ 任意重定向\n⚫ SQL注入，Shell注入，反序列化注入\n⚫ 正则输入源串拒绝服务ReDoS\n    Java代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用\n    的是特殊构造的字符串来验证，有可能导致死循环的结果。\n5. 【强制】禁止向HTML页面输出未经安全过滤或未正确转义的用户数据。\n6. 【强制】表单、AJAX提交必须执行CSRF安全验证。\n    说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF漏洞的应用/\n    网站，攻击者可以事先构造好URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用\n    户参数进行相应修改。\n7. 【强制】URL外部重定向传入的目标地址必须执行白名单过滤。\n8. 【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机\n    制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。\n    说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并\n    造成短信平台资源浪费。\n9. 【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过\n    滤等风控策略。\n\n\n## 五、MySQL数据库\n\n### (一) 建表规约\n\n1. 【强制】表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint\n    （ 1 表示是， 0 表示否）。\n    说明：任何字段如果为非负数，必须是unsigned。\n    注意：POJO类中的任何布尔类型的变量，都不要加is前缀，所以，需要在<resultMap>设置从is_xxx到\n    Xxx的映射关系。数据库表示是与否的值，使用tinyint类型，坚持is_xxx的命名方式是为了明确其取值含\n    义与取值范围。\n    正例：表达逻辑删除的字段名is_deleted， 1 表示删除， 0 表示未删除。\n2. 【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只\n    出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。\n       说明：MySQL在Windows下不区分大小写，但在Linux下默认是区分大小写。因此，数据库名、表名、\n       字段名，都不允许出现任何大写字母，避免节外生枝。\n       正例：aliyun_admin，rdc_config，level3_name\n       反例：AliyunAdmin，rdcConfig，level_3_name\n3. 【强制】表名不使用复数名词。\n说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于DO类名也是单数形式，符合\n表达习惯。\n4. 【强制】禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字。\n5. 【强制】主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。\n说明：pk_ 即primary key；uk_ 即 unique key；idx_ 即index的简称。\n6. 【强制】小数类型为decimal，禁止使用float和double。\n说明：在存储的时候，float 和 double 都存在精度损失的问题，很可能在比较值的时候，得到不正确的\n结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数并分开存储。\n7. 【强制】如果存储的字符串长度几乎相等，使用char定长字符串类型。\n8. 【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000 ，如果存储长度\n大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效\n率。\n9. 【强制】表必备三字段：id, create_time, update_time。\n说明：其中id必为主键，类型为bigint unsigned、单表时自增、步长为 1 。create_time, update_time\n的类型均为datetime类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。\n\n\n10. 【推荐】表的命名最好是遵循“业务名称_表的作用”。\n    正例：alipay_task / force_project / trade_config\n11. 【推荐】库名与应用名称尽量一致。\n12. 【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。\n13. 【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：\n1 ） 不是频繁修改的字段。\n2 ） 不是唯一索引的字段。\n3 ） 不是varchar超长字段，更不能是text字段。\n正例：各业务线经常冗余存储商品名称，避免查询时需要调用IC服务获取。\n14. 【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。\n    说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。\n15. 【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索\n    速度。\n    正例：无符号值可以避免误存负数，且扩大了表示范围。\n\n```\n对象 年龄区间 类型 字节 表示范围\n人 150 岁之内 tinyint unsigned 1 无符号值： 0 到 255\n龟 数百岁 smallint unsigned 2 无符号值： 0 到 65535\n恐龙化石 数千万年 int unsigned 4 无符号值： 0 到约 43 亿\n太阳 约 50 亿年 bigint unsigned 8 无符号值： 0 到约 10 的 19 次方\n```\n### (二) 索引规约\n\n1. 【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。\n    说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，\n    即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。\n2. 【强制】超过三个表禁止join。需要join的字段，数据类型保持绝对一致；多表关联查询时，\n    保证被关联的字段需要有索引。\n    说明：即使双表join也要注意表索引、SQL性能。\n3. 【强制】在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据\n    实际文本区分度决定索引长度。\n\n\n```\n说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%\n以上，可以使用count(distinct left(列名, 索引长度))/count(*)的区分度来确定。\n```\n4. 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。\n    说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。\n5. 【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索\n    引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。\n    正例：where a=? and b=? order by c; 索引：a_b_c\n    反例：索引如果存在范围查询，那么索引有序性无法利用，如：WHERE a>10 ORDER BY b; 索引a_b无\n    法排序。\n6. 【推荐】利用覆盖索引来进行查询操作，避免回表。\n    说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这\n    个目录就是起到覆盖索引的作用。\n    正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效\n    果，用explain的结果，extra列会出现：using index。\n7. 【推荐】利用延迟关联或者子查询优化超多分页场景。\n    说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当\n    offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL\n    改写。\n    正例：先快速定位需要获取的id段，然后再关联：\n    SELECT t1.* FROM 表 1 as t1, (select id from 表1 where 条件 LIMIT 100000,20 ) as t2 where t1.id=t2.id\n8. 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts\n    最好。\n    说明：\n    1 ） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。\n    2 ） ref 指的是使用普通的索引（normal index）。\n    3 ） range 对索引进行范围检索。\n    反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range\n    还低，与全表扫描是小巫见大巫。\n9. 【推荐】建组合索引的时候，区分度最高的在最左边。\n    正例：如果where a=? and b=?，a列的几乎接近于唯一值，那么只需要单建idx_a索引即可。\n    说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where c>? and d=?\n    那么即使c的区分度更高，也必须把d放在索引的最前列，即建立组合索引idx_d_c。\n10. 【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。\n\n\n11. 【参考】创建索引时避免有如下极端误解：\n    1 ） 索引宁滥勿缺。认为一个查询就需要建一个索引。\n    2 ） 吝啬索引的创建。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。\n    3 ） 抵制惟一索引。认为惟一索引一律需要在应用层通过“先查后插”方式解决。\n\n### (三) SQL语句\n\n1. 【强制】不要使用count(列名)或count(常量)来替代count(*)，count(*)是SQL92定义的标\n    准统计行数的语法，跟数据库无关，跟NULL和非NULL无关。\n    说明：count(*)会统计值为NULL的行，而count(列名)不会统计此列为NULL值的行。\n2. 【强制】count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1,\n    col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为 0 。\n3. 【强制】当某一列的值全是NULL时，count(col)的返回结果为 0 ，但sum(col)的返回结果为\n    NULL，因此使用sum()时需注意NPE问题。\n    正例：可以使用如下方式来避免sum的NPE问题：SELECT IFNULL(SUM(column), 0) FROM table;\n4. 【强制】使用ISNULL()来判断是否为NULL值。\n    说明：NULL与任何值的直接比较都为NULL。\n    1 ） NULL<>NULL的返回结果是NULL，而不是false。\n    2 ） NULL=NULL的返回结果是NULL，而不是true。\n    3 ） NULL<>1的返回结果是NULL，而不是true。\n    反例：在SQL语句中，如果在null前换行，影响可读性。select * from table where column1 is null and\n    column3 is not null; 而`ISNULL(column)`是一个整体，简洁易懂。从性能数据上分析，`ISNULL(column)`\n    执行效率更快一些。\n5. 【强制】代码中写分页查询逻辑时，若count为 0 应直接返回，避免执行后面的分页语句。\n6. 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。\n    说明：（概念解释）学生表中的student_id是主键，那么成绩表中的student_id则为外键。如果更新学\n    生表中的student_id，同时触发成绩表中的student_id更新，即为级联更新。外键与级联更新适用于单机\n    低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库\n    的插入速度。\n7. 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。\n8. 【强制】数据订正（特别是删除或修改记录操作）时，要先select，避免出现误删除，确认无\n    误才能执行更新语句。\n\n\n9. 【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或\n    表名）进行限定。\n    说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且\n    操作列在多个表中存在时，就会抛异常。\n    正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id;\n    反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在\n    某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column\n    'name' in field list is ambiguous。\n10. 【推荐】SQL语句中表的别名前加as，并且以t1、t2、t3、...的顺序依次命名。\n    说明： 1 ）别名可以是表的简称，或者是依照表在SQL语句中出现的顺序，以t1、t2、t3的方式命名。 2 ）\n    别名前加as使别名更容易识别。\n    正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id;\n11. 【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控\n    制在 1000 个之内。\n12. 【参考】因国际化需要，所有的字符存储与表示，均采用utf 8 字符集，那么字符计数方法需\n    要注意。\n    说明：\n    SELECT LENGTH(\"轻松工作\")； 返回为 12\n    SELECT CHARACTER_LENGTH(\"轻松工作\")； 返回为 4\n    如果需要存储表情，那么选择utf 8 mb4来进行存储，注意它与utf 8 编码的区别。\n13. 【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE\n    无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句。\n    说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。\n\n### (四) ORM映射\n\n1. 【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。\n    说明： 1 ）增加查询分析器解析成本。 2 ）增减字段容易与resultMap配置不一致。 3 ）无用字段增加网络\n    消耗，尤其是text类型的字段。\n2. 【强制】POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行\n    字段与属性之间的映射。\n    说明：参见定义POJO类以及数据库字段定义规定，在sql.xml增加映射，是必须的。\n\n\n3. 【强制】不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要\n    定义<resultMap>；反过来，每一个表也必然有一个<resultMap>与之对应。\n    说明：配置映射关系，使字段与DO类解耦，方便维护。\n4. 【强制】sql.xml配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现SQL注入。\n5. 【强制】iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用。\n说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取\nstart,size的子集合。\n正例：\nMap<String, Object> map = new HashMap<>( 16 );\nmap.put(\"start\", start);\nmap.put(\"size\", size);\n6. 【强制】不允许直接拿HashMap与Hashtable作为查询结果集的输出。\n    反例：某同学为避免写一个<resultMap>xxx</resultMap>，直接使用HashTable来接收数据库返回结\n    果，结果出现日常是把bigint转成Long值，而线上由于数据库版本不一样，解析成BigInteger，导致线\n    上问题。\n7. 【强制】更新数据表记录时，必须同时更新记录对应的update_time字段值为当前时间。\n8. 【推荐】不要写一个大而全的数据更新接口。传入为POJO类，不管是不是自己的目标更新字\n    段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，\n    不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储。\n9. 【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需\n    要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。\n10. 【参考】<isEqual>中的compareValue是与属性值对比的常量，一般是数字，表示相等时\n    带上此条件；<isNotEmpty>表示不为空且不为null时执行；<isNotNull>表示不为null值\n    时执行。\n\n\n## 六、工程结构\n\n### (一) 应用分层\n\n1. 【推荐】根据业务架构实践，结合业界分层规范与流行技术框架分析，推荐分层结构如图所示，\n    默认上层依赖于下层，箭头关系表示可直接依赖，如：开放API层可以依赖于Web层\n    （Controller层），也可以直接依赖于Service层，依此类推：\n       - 开放API层：可直接封装Service接口暴露成RPC接口；通过Web封装成http接口；网关控制层等。\n       - 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移\n          动端展示等。\n       - Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。\n       - Service层：相对具体的业务逻辑服务层。\n       - Manager层：通用业务处理层，它有如下特征：\n          1 ） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。\n          2 ） 对Service层通用能力的下沉，如缓存方案、中间件通用处理。\n          3 ） 与DAO层交互，对多个DAO的组合复用。\n       - DAO层：数据访问层，与底层MySQL、Oracle、Hbase、OB等进行数据交互。\n       - 第三方服务：包括其它部门RPC服务接口，基础平台，其它公司的HTTP接口，如淘宝开放平台、支\n          付宝付款服务、高德地图服务等。\n       - 外部数据接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。\n2. 【参考】（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进\n行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因\n为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，\n\n\n```\n浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，\n相当于保护案发现场。Manager层与Service同机部署，日志方式与DAO层处理一致，如果是\n单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处\n于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，\n尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。\n```\n3. 【参考】分层领域模型规约：\n    - DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。\n    - DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。\n    - BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。\n    - Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用Map类\n       来传输。\n    - VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。\n\n### (二) 二方库依赖\n\n1. 【强制】定义GAV遵从以下规则：\n    1 ） GroupID格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。\n    说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。\n    正例：com.taobao.jstorm 或 com.alibaba.dubbo.register\n    2 ） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。\n    正例：dubbo-client / fastjson-api / jstorm-tool\n    3 ） Version：详细规定参考下方。\n2. 【强制】二方库版本号命名方式：主版本号.次版本号.修订号\n1 ）主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。\n2 ） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。\n3 ） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。\n说明：注意起始版本号必须为：1.0.0，而不是0.0.1。\n反例：仓库内某二方库版本号从1.0.0.0开始，一直默默“升级”成1.0.0.64，完全失去版本的语义信息。\n3. 【强制】线上应用不要依赖SNAPSHOT版本（安全包除外）；正式发布的类库必须先去中央仓\n    库进行查证，使RELEASE版本号有延续性，且版本号不允许覆盖升级。\n    说明：不依赖SNAPSHOT版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。\n4. 【强制】二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，\n    必须明确评估和验证。\n\n\n```\n说明：在升级时，进行dependency:resolve前后信息比对，如果仲裁结果完全不一致，那么通过\ndependency:tree命令，找出差异点，进行<exclude>排除jar包。\n```\n5. 【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚\n    举类型或者包含枚举类型的POJO对象。\n6. 【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。\n    说明：依赖springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版\n    本：${spring.version}，定义依赖的时候，引用该版本。\n7. 【强制】禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的\n    Version。\n    说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个war，只能有一个版本号出现在最后的\n    lib目录中。曾经出现过线下调试是正确的，发布到线上却出故障的先例。\n8. 【推荐】底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现。\n9. 【推荐】所有pom文件中的依赖声明放在<dependencies>语句块中，所有版本仲裁放在\n    <dependencyManagement>语句块中。\n    说明：<dependencyManagement>里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，\n    version和scope都读取自父pom。而<dependencies>所有声明在主pom的<dependencies>里的依\n    赖都会自动引入，并默认被所有的子项目继承。\n10. 【推荐】二方库不要有配置项，最低限度不要再增加配置项。\n11. 【推荐】不要使用不稳定的工具包或者Utils类。\n    说明：不稳定指的是提供方无法做到向下兼容，在编译阶段正常，但在运行时产生异常，因此，尽量使用\n    业界稳定的二方工具包。\n12. 【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：\n    1 ） **精简可控原则** 。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、\n    常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log\n    具体实现，只依赖日志框架。\n    2 ） **稳定可追溯原则** 。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除\n    非用户主动升级版本，否则公共二方库的行为不应该发生变化。\n\n### (三) 服务器\n\n1. 【推荐】高并发服务器建议调小TCP协议的time_wait超时时间。\n    说明：操作系统默认 240 秒后，才会关闭处于time_wait状态的连接，在高并发访问下，服务器端会因为\n    处于time_wait的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。\n\n\n```\n正例：在linux服务器上请通过变更/etc/sysctl.conf文件去修改该缺省值（秒）：\nnet.ipv4.tcp_fin_timeout = 30\n```\n2. 【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）。\n    说明：主流操作系统的设计是将TCP/UDP连接采用与文件一样的方式去管理，即一个连接对应于一个fd。\n    主流的linux服务器默认所支持最大fd数量为 1024 ，当并发连接数很大时很容易因为fd不足而出现“open\n    too many files”错误，导致新的连接无法建立。建议将linux服务器所支持的最大句柄数调高数倍（与服\n    务器的内存数量相关）。\n3. 【推荐】给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM\n    场景时输出dump信息。\n    说明：OOM的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。\n4. 【推荐】在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整\n    堆大小带来的压力。\n5. 【参考】服务器内部重定向必须使用forward；外部重定向地址必须使用URL Broker生成，否\n    则因线上采用HTTPS协议而导致浏览器提示“不安全“。此外，还会带来URL维护不一致的\n    问题。\n\n\n## 七、设计规约\n\n1. 【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。\n    说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系\n    统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后，\n    需要进行double check。\n    正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发\n    展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段）\n    也需要进行评审通过后上线。\n2. 【强制】在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过 5 个，\n    使用用例图来表达更加清晰的结构化需求。\n3. 【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发\n    条件。\n    说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换\n    关系，再明确触发状态转换的条件是什么。\n    正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两\n    种状态之间是不可能有直接转换关系的。\n4. 【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确\n    各调用环节的输入与输出。\n    说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。\n5. 【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类\n    之间的关系。\n    说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造蚂蚁Z空间大楼，肯定需要详细\n    的施工图。\n6. 【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活\n    动图来表示。\n    说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。\n7. 【推荐】系统架构设计时明确以下目标：\n⚫ 确定系统边界。确定系统在技术层面上的做与不做。\n⚫ 确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。\n⚫ 确定指导后续设计与演化的原则。使后续的子系统或模块设计在一个既定的框架内和技术方向上继\n续演化。\n\n\n⚫ 确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。\n\n8. 【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。\n    反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演\n    练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。\n9. 【推荐】类在设计与实现时要符合单一原则。\n    说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。\n10. 【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。\n    说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现，\n    比如，“把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。\n11. 【推荐】系统设计阶段，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。\n    说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。\n12. 【推荐】系统设计阶段，注意对扩展开放，对修改闭合。\n    说明：极端情况下，交付的代码是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。\n13. 【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方\n法等，在系统中不出现重复代码的情况，即DRY原则（Don't Repeat Yourself）。\n说明：随着代码的重复次数不断增加，维护成本指数级上升。随意复制和粘贴代码，必然会导致代码的重复，\n在维护代码时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。\n正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取：\nprivate boolean checkParam(DTO dto) {...}\n14. 【推荐】避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布。\n说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上\n的必要设计和文档沉淀是需要的。\n反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样\n的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。\n15. 【参考】设计文档的作用是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。\n    说明：避免为了设计而设计，系统设计文档有助于后期的系统维护和重构，所以设计结果需要进行分类归\n    档保存。\n16. 【参考】可扩展性的本质是找到系统的变化点，并隔离变化点。\n    说明：世间众多设计模式其实就是一种设计模式即隔离变化点的模式。\n    正例：极致扩展性的标志，就是需求的新增，不会在原有代码交付物上进行任何形式的修改。\n\n\n17. 【参考】设计的本质就是识别和表达系统难点。\n    说明：识别和表达完全是两回事，很多人错误地认为识别到系统难点在哪里，表达只是自然而然的事情，\n    但是大家在设计评审中经常出现语焉不详，甚至是词不达意的情况。准确地表达系统难点需要具备如下能\n    力： 表达规则和表达工具的熟练性。抽象思维和总结能力的局限性。基础知识体系的完备性。深入浅出的\n    生动表达力。\n18. 【参考】代码即文档的观点是错误的，清晰的代码只是文档的某个片断，而不是全部。\n    说明：代码的深度调用，模块层面上的依赖关系网，业务场景逻辑，非功能性需求等问题是需要相应的文\n    档来完整地呈现的。\n19. 【参考】在做无障碍产品设计时，需要考虑到：\n\n```\n⚫ 所有可交互的控件元素必须能被tab键聚焦，并且焦点顺序需符合自然操作逻辑。\n⚫ 用于登录校验和请求拦截的验证码均需提供图形验证以外的其它方式。\n⚫ 自定义的控件类型需明确交互方式。\n正例：用户登录场景中，输入框的按钮都需要考虑tab键聚焦，符合自然逻辑的操作顺序如下，“输入用\n户名，输入密码，输入验证码，点击登录”，其中验证码实现语音验证方式。如果有自定义标签实现的控\n件设置控件类型可使用role属性。\n```\n\n## 附 1 ：版本历史\n\n#### 版本号 版本名 发布日期 备注\n\n#### -- - - 2 016.12.07 试读版本首次对外发布\n\n#### 1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布\n\n#### 1.0.1 - - 2017. 0 2. 13\n\n```\n1 ）修正String[]的前后矛盾。\n2 ）vm修正成velocity。\n3 ）修正countdown描述错误。\n```\n#### 1.0.2 - - 2017. 0 2.20\n\n#### 1 ）去除文底水印。\n\n#### 2 ）数据类型中引用太阳系年龄问题。\n\n#### 3 ）修正关于异常和方法签名的部分描述。\n\n```\n4 ）修正final描述。\n5 ）去除Comparator部分描述。\n```\n#### 1 .1.0 - - 2017. 0 2.27\n\n#### 1 ）增加前言。\n\n```\n2 ）增加<? extends T>描述和说明。\n3 ）增加版本历史。\n4 ）增加专有名词解释。\n```\n#### 1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。\n\n#### 1.2.0 完美版 2017. 0 5.20\n\n#### 1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\n\n```\n2 ）增加final的适用场景描述。\n3 ）增加关于锁的粒度的说明。\n4 ）增加“指定集合大小”的详细说明以及正反例。\n5 ）增加卫语句的示例代码。\n6 ）明确数据库表示删除概念的字段名为is_deleted\n```\n#### 1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\n\n```\n1.3.1 纪念版 2017.11.30 修正部分描述；采用和P3C开源IDE检测插件相同的Apache2.0协议。\n1.4.0 详尽版 2018. 0 5.20 增加设计规约大类，共 16 条。\n```\n\n#### 版本号 版本名 发布日期 备注\n\n#### 1 .5.0 华山版 2 019.0 6. 19\n\n```\n1 ）鉴于本手册是社区开发者集体智慧的结晶，本版本移除阿里巴巴Java开发手册的\n限定词“阿里巴巴”。\n2 ）新增 21 条新规约。比如，switch的NPE问题、浮点数的比较、无泛型限制、锁的\n使用方式、判断表达式、日期格式等。\n3 ）修改描述 112 处。比如，IFNULL的判断、集合的toArray、日志处理等。\n4 ）完善若干处示例。比如，命名示例、卫语句示例、enum示例、finally的return\n示例等。\n```\n#### 1.6.0\n\n#### 泰山版\n\n#### 2020.04.22\n\n#### 1 ）发布错误码统一解决方案，详细参考 附表 3 。\n\n#### 2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\n\n```\n查询的表别名限定，Collectors类的toMap()方法使用注意等。\n3 ）修改描述 90 处。比如，阻塞等待锁、建表的小数类型等。\n4 ）完善若干处示例。比如，ISNULL的示例等。\n```\n#### 1. 7. 0 嵩山版 2020.0 8. 03\n\n#### 1 ）新增前后端规约 14 条。\n\n#### 2 ）新增禁止任何歧视性用语的约定。\n\n#### 3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。\n\n```\n4 ）修正BigDecimal类中关于compareTo和equals的等值比较。\n5 ）修正HashMap关于 1024 个元素扩容的次数。\n6 ）修正架构分层规范与相关说明。\n7 ）修正泰山版中部分格式错误和描述错误。\n```\n\n## 附 2 ：专有名词解释\n\n1. POJO（Plain Ordinary Java Object）: 在本规约中，POJO专指只有setter/getter/toString的\n    简单类，包括DO/DTO/BO/VO等。\n2. DO（Data Object）：阿里巴巴专指数据库表一一对应的POJO类。此对象与数据库表结构一\n    一对应，通过DAO层向上传输数据源对象。\n3. DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。\n4. BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。\n5. Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用\n    Map类来传输。\n6. VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。\n7. AO（Application Object）: 阿里巴巴专指Application Object，即在Service层上，极为贴近\n    业务的复用代码。\n8. CAS（Compare And Swap）：解决多线程并行情况下使用锁造成性能损耗的一种机制，这是\n    硬件实现的原子操作。CAS操作包含三个操作数：内存位置、预期原值和新值。如果内存位\n    置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何\n    操作。\n9. GAV（GroupId、ArtifactId、Version）: Maven坐标，是用来唯一标识jar包。\n10. OOP（Object Oriented Programming）: 本文泛指类、对象的编程处理方式。\n11. AQS（AbstractQueuedSynchronizer）: 利用先进先出队列实现的底层同步工具类，它是很多上\n    层同步实现类的基础，比如：ReentrantLock、CountDownLatch、Semaphore等，它们通\n    过继承AQS实现其模版方法，然后将AQS子类作为同步组件的内部类，通常命名为Sync。\n12. ORM（Object Relation Mapping）: 对象关系映射，对象领域模型与底层数据之间的转换，本\n    文泛指iBATIS, mybatis等框架。\n13. NPE（java.lang.NullPointerException）: 空指针异常。\n14. OOM（Out Of Memory）: 源于 java.lang.OutOfMemoryError，当 JVM 没有足够的内存\n    来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。\n15. 一方库: 本工程内部子项目模块依赖的库（jar 包）。\n16. 二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar 包）。\n17. 三方库: 公司之外的开源库（jar 包）。\n\n\n## 附 3 ：错误码列表\n\n#### 错误码 中文描述 说明\n\n```\n00000 一切ok 正确执行后的返回\nA0001 用户端错误 一级宏观错误码\nA0100 用户注册错误 二级宏观错误码\nA0101 用户未同意隐私协议\nA0102 注册国家或地区受限\nA0110 用户名校验失败\nA0111 用户名已存在\nA0112 用户名包含敏感词\nA0113 用户名包含特殊字符\nA0120 密码校验失败\nA0121 密码长度不够\nA0122 密码强度不够\nA0130 校验码输入错误\nA0131 短信校验码输入错误\nA0132 邮件校验码输入错误\nA0133 语音校验码输入错误\nA0140 用户证件异常\nA0141 用户证件类型未选择\nA0142 大陆身份证编号校验非法\nA0143 护照编号校验非法\nA0144 军官证编号校验非法\nA0150 用户基本信息校验失败\nA0151 手机格式校验失败\nA0152 地址格式校验失败\nA0153 邮箱格式校验失败\nA0200 用户登录异常 二级宏观错误码\nA0201 用户账户不存在\n```\n\n#### A0202 用户账户被冻结\n\n#### A0203 用户账户已作废\n\n#### A0210 用户密码错误\n\n#### A0211 用户输入密码错误次数超限\n\n#### A0220 用户身份校验失败\n\n#### A0221 用户指纹识别失败\n\n#### A0222 用户面容识别失败\n\n#### A0223 用户未获得第三方登录授权\n\n#### A0230 用户登录已过期\n\n#### A0240 用户验证码错误\n\n#### A0241 用户验证码尝试次数超限\n\nA0300 访问权限异常 二级宏观错误码\n\nA0301 访问未授权\n\nA0302 正在授权中\n\nA0303 用户授权申请被拒绝\n\nA0310 因访问对象隐私设置被拦截\n\nA0311 授权已过期\n\nA0312 无权限使用API\n\nA0320 用户访问被拦截\n\nA0321 黑名单用户\n\nA0322 账号被冻结\n\nA0323 非法IP地址\n\nA0324 网关访问受限\n\nA0325 地域黑名单\n\nA0330 服务已欠费\n\nA0340 用户签名异常\n\nA0341 RSA签名错误\n\nA0400 用户请求参数错误 二级宏观错误码\n\nA0401 包含非法恶意跳转链接\n\nA0402 无效的用户输入\n\n\n#### A0410 请求必填参数为空\n\n#### A0411 用户订单号为空\n\n#### A0412 订购数量为空\n\n#### A0413 缺少时间戳参数\n\n#### A0414 非法的时间戳参数\n\n#### A0420 请求参数值超出允许的范围\n\n#### A0421 参数格式不匹配\n\n#### A0422 地址不在服务范围\n\n#### A0423 时间不在服务范围\n\n#### A0424 金额超出限制\n\n#### A0425 数量超出限制\n\n#### A0426 请求批量处理总个数超出限制\n\n#### A0427 请求JSON解析失败\n\n#### A0430 用户输入内容非法\n\n#### A0431 包含违禁敏感词\n\n#### A0432 图片包含违禁信息\n\n#### A0433 文件侵犯版权\n\n#### A0440 用户操作异常\n\n#### A0441 用户支付超时\n\n#### A0442 确认订单超时\n\n#### A0443 订单已关闭\n\nA0500 用户请求服务异常 二级宏观错误码\n\nA0501 请求次数超出限制\n\nA0502 请求并发数超出限制\n\nA0503 用户操作请等待\n\nA0504 WebSocket连接异常\n\nA0505 WebSocket连接断开\n\nA0506 用户重复请求\n\nA0600 用户资源异常 二级宏观错误码\n\nA0601 账户余额不足\n\n\n#### A0602 用户磁盘空间不足\n\n#### A0603 用户内存空间不足\n\n#### A0604 用户OSS容量不足\n\n#### A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数\n\n#### A0700 用户上传文件异常 二级宏观错误码\n\n#### A0701 用户上传文件类型不匹配\n\n#### A0702 用户上传文件太大\n\n#### A0703 用户上传图片太大\n\n#### A0704 用户上传视频太大\n\n#### A0705 用户上传压缩文件太大\n\n#### A0800 用户当前版本异常 二级宏观错误码\n\n#### A0801 用户安装版本与系统不匹配\n\n#### A0802 用户安装版本过低\n\n#### A0803 用户安装版本过高\n\n#### A0804 用户安装版本已过期\n\n#### A0805 用户API请求版本不匹配\n\n#### A0806 用户API请求版本过高\n\n#### A0807 用户API请求版本过低\n\n#### A0900 用户隐私未授权 二级宏观错误码\n\n#### A0901 用户隐私未签署\n\n#### A0902 用户摄像头未授权\n\n#### A0903 用户相机未授权\n\n#### A0904 用户图片库未授权\n\n#### A0905 用户文件未授权\n\n#### A0906 用户位置信息未授权\n\n#### A0907 用户通讯录未授权\n\n#### A1000 用户设备异常 二级宏观错误码\n\n#### A1001 用户相机异常\n\n#### A1002 用户麦克风异常\n\n#### A1003 用户听筒异常\n\n\n#### A1004 用户扬声器异常\n\n#### A1005 用户GPS定位异常\n\n#### -\n\n-\n\n#### B0001 系统执行出错 一级宏观错误码\n\n#### B0100 系统执行超时 二级宏观错误码\n\n#### B0101 系统订单处理超时\n\n#### B0200 系统容灾功能被触发 二级宏观错误码\n\n#### B0210 系统限流\n\n#### B0220 系统功能降级\n\n#### B0300 系统资源异常 二级宏观错误码\n\n#### B0310 系统资源耗尽\n\n#### B0311 系统磁盘空间耗尽\n\n#### B0312 系统内存耗尽\n\n#### B0313 文件句柄耗尽\n\n#### B0314 系统连接池耗尽\n\n#### B0315 系统线程池耗尽\n\n#### B0320 系统资源访问异常\n\n#### B0321 系统读取磁盘文件失败\n\n#### -\n\n#### -\n\n#### C0001 调用第三方服务出错 一级宏观错误码\n\n#### C0100 中间件服务出错 二级宏观错误码\n\n#### C0110 RPC服务出错\n\n#### C0111 RPC服务未找到\n\n#### C0112 RPC服务未注册\n\n#### C0113 接口不存在\n\n#### C0120 消息服务出错\n\n#### C0121 消息投递出错\n\n#### C0122 消息消费出错\n\n#### C0123 消息订阅出错\n\n#### C0124 消息分组未查到\n\n\n#### C0130 缓存服务出错\n\nC0131 key长度超过限制\n\nC0132 value长度超过限制\n\nC0133 存储容量已满\n\nC0134 不支持的数据格式\n\nC0140 配置服务出错\n\nC0150 网络资源服务出错\n\nC0151 VPN服务出错\n\nC0152 CDN服务出错\n\nC0153 域名解析服务出错\n\nC0154 网关服务出错\n\nC0200 第三方系统执行超时 二级宏观错误码\n\nC0210 RPC执行超时\n\nC0220 消息投递超时\n\nC0230 缓存服务超时\n\nC0240 配置服务超时\n\nC0250 数据库服务超时\n\nC0300 数据库服务出错 二级宏观错误码\n\nC0311 表不存在\n\nC0312 列不存在\n\nC0321 多表关联中存在多个相同名称的列\n\nC0331 数据库死锁\n\nC0341 主键冲突\n\nC0400 第三方容灾系统被触发 二级宏观错误码\n\nC0401 第三方系统限流\n\nC0402 第三方功能降级\n\nC0500 通知服务出错 二级宏观错误码\n\nC0501 短信提醒服务失败\n\nC0502 语音提醒服务失败\n\nC0503 邮件提醒服务失败\n\n\n\n","source":"_posts/阿里巴巴java开发手册-嵩山版.md","raw":"---\ntitle: 阿里巴巴java开发手册\ndate: 2022-09-28\ntags:\n- java\ncategories:\n- 笔记\n# cover: /images/post/markerdown.jpg\ncoverWidth: 1200\ncoverHeight: 320\nauthor: 王恺\nfrom: 笔记\n---\n阿里巴巴java开发手册-嵩山版<!--more-->\n# 前言\n\n《Java开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一\n\n线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理\n\n成册，当前的版本是 **嵩山版** 。现代软件行业的高速发展对开发者的综合素质要求越来越高，因为不仅\n\n是编程知识点，其它维度的知识点也会影响到软件的最终交付质量。比如：五花八门的错误码人为地\n\n增加排查问题的难度；数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险；工程结构混\n\n乱导致后续项目维护艰难；没有鉴权的漏洞代码易被黑客攻击等等。所以本手册以Java开发者为中\n\n心视角，划分为编程规约、异常日志、单元测试、安全规约、MySQL数据库、工程结构、设计规约\n\n七个维度，再根据内容特征，细分成若干二级子目录。另外，依据约束力强弱及故障敏感性，规约依\n\n次分为【强制】、【推荐】、【参考】三大类。在延伸信息中，“说明”对规约做了适当扩展和解释；\n\n“正例”提倡什么样的编码和实现方式；“反例”说明需要提防的雷区，以及真实的错误案例。\n\n手册的愿景是 **码出高效，码出质量** 。现代软件架构的复杂性需要协同开发完成，如何高效地协\n\n同呢？无规矩不成方圆，无规范难以协同，比如，制订交通法规表面上是要限制行车权，实际上是保\n\n障公众的人身安全，试想如果没有限速，没有红绿灯，谁还敢上路行驶？对软件来说，适当的规范和\n\n标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的统一方式一起\n\n做事，提升协作效率，降低沟通成本。代码的字里行间流淌的是软件系统的血液，质量的提升是尽可\n\n能少踩坑，杜绝踩重复的坑，切实提升系统稳定性，码出质量。\n\n我们已经在 2017 杭州云栖大会上发布了配套的Java开发规约IDE插件，下载量达到 162 万人\n\n次，阿里云效也集成了代码规约扫描引擎。次年，发布 36 万字的配套详解图书《码出高效》，本书\n\n秉持“图胜于表，表胜于言”的理念，深入浅出地将计算机基础、面向对象思想、JVM探源、数据\n\n结构与集合、并发与多线程、单元测试等知识客观、立体地呈现出来。紧扣学以致用、学以精进的目\n\n标，结合阿里巴巴实践经验和故障案例，与底层源码解析融会贯通，娓娓道来。《码出高效》和《Java\n\n开发手册》稿费所得收入均捐赠公益事情，希望用技术情怀帮助更多的人。\n\n\n## 目录\n\n- 一、编程规约\n   - (一) 命名风格\n   - (二) 常量定义\n   - (三) 代码格式\n   - (四) OOP规约\n   - (五) 日期时间\n   - (六) 集合处理\n   - (七) 并发处理\n   - (八) 控制语句\n   - (九) 注释规约\n   - (十) 前后端规约\n   - (十一) 其他\n- 二、异常日志\n   - (一) 错误码\n   - (二) 异常处理\n   - (三) 日志规约\n- 三、单元测试\n- 四、安全规约\n- 五、MySQL数据库\n   - (一) 建表规约\n   - (二) 索引规约\n   - (三) SQL语句\n   - (四) ORM映射\n- 六、工程结构\n   - (一) 应用分层\n   - (二) 二方库依赖\n   - (三) 服务器\n- 七、设计规约\n- 附 1 ：版本历史\n- 附 2 ：专有名词解释\n- 附 3 ：错误码列表\n\n\n## 一、编程规约\n\n### (一) 命名风格\n\n1. 【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。\n    反例：_name / __name / $name / name_ / name$ / name__\n2. 【强制】所有编程相关的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。\n说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，纯拼音命名方式更要避免采用。\n正例：ali / alibaba / taobao / cainiao/ aliyun/ youku / hangzhou 等国际通用的名称，可视同英文。\n反例：DaZhePromotion [打折] / getPingfenByName() [评分] / String fw[福娃] / int 某变量 = 3\n3. 【强制】代码和注释中都要避免使用任何语言的种族歧视性词语。\n    正例：日本人 / 印度人 / blockList / allowList / secondary\n    反例：RIBENGUIZI / Asan / blackList / whiteList / slave\n4. 【强制】类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO /\n    PO / UID等。\n    正例：ForceCode / UserDO / HtmlDTO / XmlService / TcpUdpDeal / TaPromotion\n    反例：forcecode / UserDo / HTMLDto / XMLService / TCPUDPDeal / TAPromotion\n5. 【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格。\n    正例： localValue / getHttpMessage() / inputUserId\n6. 【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。\n    正例：MAX_STOCK_COUNT / CACHE_EXPIRED_TIME\n    反例：MAX_COUNT / EXPIRED_TIME\n7. 【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类\n    命名以它要测试的类的名称开始，以Test结尾。\n8. 【强制】类型与中括号紧挨相连来表示数组。\n    正例：定义整形数组int[] arrayDemo。\n    反例：在main参数中，使用String args[]来定义。\n9. 【强制】POJO类中的任何布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列\n    化错误。\n\n#### 版本号 制定团队 更新日期 备注\n\n```\n1. 7. 0 阿里巴巴与全球Java社区开发者 2020. 08. 03 嵩山版，首次发布前后端规约\n```\n\n```\n说明：在本文MySQL规约中的建表约定第一条，表达是与否的变量采用is_xxx的命名方式，所以，需要\n在<resultMap>设置从is_xxx到xxx的映射关系。\n反例：定义为基本数据类型Boolean isDeleted的属性，它的方法也是isDeleted()，框架在反向解析的时\n候，“误以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。\n```\n10. 【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用\n    单数形式，但是类名如果有复数含义，类名可以使用复数形式。\n    正例：应用工具类包名为com.alibaba.ei.kunlun.aap.util、类名为MessageUtils（此规则参考spring的\n    框架结构）\n11. 【强制】避免在子父类的成员变量之间、或者不同代码块的局部变量之间采用完全相同的命名，\n使可理解性降低。\n说明：子类、父类成员变量名相同，即使是public类型的变量也能够通过编译，另外，局部变量在同一方\n法内的不同代码块中同名也是合法的，这些情况都要避免。对于非setter/getter的参数名称也要避免与成\n员变量名称相同。\n反例：\npublic class ConfusingName {\npublic int stock;\n// 非setter/getter的参数名称，不允许与本类成员变量同名\npublic void get(String alibaba) {\nif (condition) {\nfinal int money = 666 ;\n// ...\n}\nfor (int i = 0 ; i < 10 ; i++) {\n// 在同一方法体中，不允许与其它代码块中的money命名相同\nfinal int money = 15978 ;\n// ...\n}\n}\n}\nclass Son extends ConfusingName {\n// 不允许与父类的成员变量名称相同\npublic int stock;\n}\n12. 【强制】杜绝完全不规范的缩写，避免望文不知义。\n    反例：AbstractClass“缩写”成AbsClass；condition“缩写”成 condi；Function缩写”成Fu，此类\n    随意缩写严重降低了代码的可阅读性。\n13. 【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组\n    合来表达。\n\n\n```\n正例：对某个对象引用的volatile字段进行原子更新的类名为AtomicReferenceFieldUpdater。\n反例：常见的方法内变量为int a;的定义方式。\n```\n14. 【推荐】在常量与变量的命名时，表示类型的名词放在词尾，以提升辨识度。\n    正例：startTime / workQueue / nameList / TERMINATED_THREAD_COUNT\n    反例：startedAt / QueueOfWork / listName / COUNT_TERMINATED_THREAD\n15. 【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。\n    说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。\n    正例： public class OrderFactory;\n    public class LoginProxy;\n    public class ResourceObserver;\n16. 【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁\n    性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，确定\n    与接口方法相关，并且是整个应用的基础常量。\n    正例：接口方法签名 void commit();\n    接口基础常量 String COMPANY = \"alibaba\";\n    反例：接口方法定义 public abstract void f();\n    说明：JDK8中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。\n17. 接口和实现类的命名有两套规则：\n    1 ）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用\n    Impl的后缀与接口区别。\n    正例：CacheServiceImpl实现CacheService接口。\n    2 ）【推荐】如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able的形容词）。\n    正例：AbstractTranslator实现 Translatable接口。\n18. 【参考】枚举类名带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。\n    说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。\n    正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS / UNKNOWN_REASON。\n19. 【参考】各层命名规约：\n    A) Service/DAO层方法命名规约\n    1 ） 获取单个对象的方法用get做前缀。\n    2 ） 获取多个对象的方法用list做前缀，复数结尾，如：listObjects。\n    3 ） 获取统计值的方法用count做前缀。\n    4 ） 插入的方法用save/insert做前缀。\n    5 ） 删除的方法用remove/delete做前缀。\n    6 ） 修改的方法用update做前缀。\n    B) 领域模型命名规约\n\n\n```\n1 ） 数据对象：xxxDO，xxx即为数据表名。\n2 ） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。\n3 ） 展示对象：xxxVO，xxx一般为网页名称。\n4 ） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。\n```\n### (二) 常量定义\n\n1. 【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。\n    反例：\n       // 本例中，开发者A定义了缓存的key，然后开发者B使用缓存时少了下划线，即key是\"Id#taobao\"+tradeId，导致\n       出现故障\n       String key = \"Id#taobao_\" + tradeId;\n       cache.put(key, value);\n2. 【强制】在long或者Long赋值时，数值后使用大写字母L，不能是小写字母l，小写容易跟\n数字混淆，造成误解。\n说明：Long a = 2l; 写的是数字的 21 ，还是Long型的 2 ？\n3. 【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。\n    说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解，也不利于维护。\n       正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类SystemConfigConsts下。\n4. 【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包\n    内共享常量、类内共享常量。\n    1 ） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。\n    2 ） 应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。\n    反例：易懂变量也要统一定义成应用内共享常量，两位工程师在两个类中分别定义了“YES”的变量：\n    类A中：public static final String YES = \"yes\";\n    类B中：public static final String YES = \"y\";\n    A.YES.equals(B.YES)，预期是true，但实际返回为false，导致线上问题。\n       3 ） 子工程内部共享常量：即在当前子工程的constant目录下。\n       4 ） 包内共享常量：即在当前包下单独的constant目录下。\n       5 ） 类内共享常量：直接在类内部private static final定义。\n5. 【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。\n    说明：如果存在名称之外的延伸属性应使用enum类型，下面正例中的数字就是延伸信息，表示一年中的\n    第几个季节。\n    正例：\n       public enum SeasonEnum {\n       SPRING( 1 ), SUMMER( 2 ), AUTUMN( 3 ), WINTER( 4 );\n       private int seq;\n       SeasonEnum(int seq) {\n\n\n```\nthis.seq = seq;\n}\npublic int getSeq() {\nreturn seq;\n}\n}\n```\n### (三) 代码格式\n\n1. 【强制】如果是大括号内为空，则简洁地写成{}即可，大括号中间无需换行和空格；如果是非\n    空代码块则：\n    1 ） 左大括号前不换行。\n    2 ） 左大括号后换行。\n    3 ） 右大括号前换行。\n    4 ） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。\n2. 【强制】左小括号和右边相邻字符之间不出现空格；右小括号和左边相邻字符之间也不出现空\n格；而左大括号前需要加空格。详见第 5 条下方正例提示。\n反例：if (空格a == b空格)\n3. 【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。\n4. 【强制】任何二目、三目运算符的左右两边都需要加一个空格。\n    说明：包括赋值运算符=、逻辑运算符&&、加减乘除符号等。\n5. 【强制】采用 4 个空格缩进，禁止使用Tab字符。\n说明：如果使用Tab缩进，必须设置 1 个Tab为 4 个空格。IDEA设置Tab为 4 个空格时，请勿勾选Use\ntab character；而在Eclipse中，必须勾选insert spaces for tabs。\n正例： （涉及 1 - 5 点）\npublic static void main(String[] args) {\n// 缩进 4 个空格\nString say = \"hello\";\n// 运算符的左右必须有一个空格\nint flag = 0 ;\n// 关键词if与括号之间必须有一个空格，括号内的f与左括号， 0 与右括号不需要空格\nif (flag == 0 ) {\nSystem.out.println(say);\n}\n// 左大括号前加空格且不换行；左大括号后换行\nif (flag == 1 ) {\nSystem.out.println(\"world\");\n// 右大括号前换行，右大括号后有else，不用换行\n} else {\nSystem.out.println(\"ok\");\n// 在右大括号后直接结束，则必须换行\n}\n}\n\n\n6. 【强制】注释的双斜线与注释内容之间有且仅有一个空格。\n    正例：\n       // 这是示例注释，请注意在双斜线之后有一个空格\n       String commentString = new String();\n7. 【强制】在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。\n    正例：\n       double first = 3.2d;\n       int second = (int)first + 2 ;\n8. 【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：\n    1 ）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。\n    2 ）运算符与下文一起换行。\n    3 ）方法调用的点符号与下文一起换行。\n    4 ）方法调用中的多个参数需要换行时，在逗号后进行。\n    5 ）在括号前不要换行，见反例。\n    正例：\n       StringBuilder sb = new StringBuilder();\n       // 超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点号一起换行\n       sb.append(\"yang\").append(\"hao\")...\n       .append(\"chen\")...\n       .append(\"chen\")...\n       .append(\"chen\");\n    反例：\n       StringBuilder sb = new StringBuilder();\n       // 超过 120 个字符的情况下，不要在括号前换行\n       sb.append(\"you\").append(\"are\")...append\n       (\"lucky\");\n       // 参数很多的方法调用可能超过 120 个字符，逗号后才是换行处\n       method(args1, args2, args3, ...\n       , argsX);\n9. 【强制】方法参数在定义和传入时，多个参数逗号后面必须加空格。\n    正例：下例中实参的args1，后边必须要有一个空格。\n       method(args1, args2, args3);\n10. 【强制】IDE的text file encoding设置为UTF-8; IDE中文件的换行符使用Unix格式，不要\n    使用Windows格式。\n11. 【推荐】单个方法的总行数不超过 80 行。\n    说明：除注释之外的方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过\n    80 行。\n    正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共\n    性逻辑抽取成为共性方法，便于复用和维护。\n\n\n12. 【推荐】没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐。\n    正例：\n       int one = 1 ;\n       long two = 2 L;\n       float three = 3F;\n       StringBuilder sb = new StringBuilder();\n说明：增加sb这个变量，如果需要对齐，则给one、two、three都要增加几个空格，在变量比较多的情\n况下，是非常累赘的事情。\n13. 【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。\n    说明：任何情形，没有必要插入多个空行进行隔开。\n\n### (四) OOP规约\n\n1. 【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成\n    本，直接用类名来访问即可。\n2. 【强制】所有的覆写方法，必须加@Override注解。\n    说明：getObject()与get0bject()的问题。一个是字母的O，一个是数字的 0 ，加@Override可以准确判\n    断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。\n3. 【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。\n说明：可变参数必须放置在参数列表的最后。（建议开发者尽量不用可变参数编程）\n正例：public List<User> listUsers(String type, Long... ids) {...}\n4. 【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生\n    影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。\n5. 【强制】不能使用过时的类或方法。\n    说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数\n    decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；\n    作为调用方来说，有义务去考证过时方法的新实现是什么。\n6. 【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。\n    正例：\"test\".equals(object);\n    反例：object.equals(\"test\");\n    说明：推荐使用JDK7引入的工具类java.util.Objects#equals(Object a, Object b)\n7. 【强制】所有整型包装类对象之间值的比较，全部使用equals方法比较。\n    说明：对于Integer var =? 在- 128 至 127 之间的赋值，Integer对象是在 IntegerCache.cache产生，\n    会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都\n    会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。\n\n\n8. 【强制】任何货币金额，均以最小货币单位且整型类型来进行存储。\n9. 【强制】浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用equals\n来判断。\n说明：浮点数采用“尾数+阶码”的编码方式，类似于科学计数法的“有效数字+指数”的表示方式。二进\n制无法精确表示大部分的十进制小数，具体原理参考《码出高效》。\n反例：\nfloat a = 1.0F - 0.9F;\nfloat b = 0.9F - 0.8F;\nif (a == b) {\n// 预期进入此代码块，执行其它业务逻辑\n// 但事实上a==b的结果为false\n}\nFloat x = Float.valueOf(a);\nFloat y = Float.valueOf(b);\nif (x.equals(y)) {\n// 预期进入此代码块，执行其它业务逻辑\n// 但事实上equals的结果为false\n}\n正例：\n(1) 指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。\nfloat a = 1.0F - 0.9F;\nfloat b = 0.9F - 0.8F;\nfloat diff = 1e- 6 F;\nif (Math.abs(a - b) < diff) {\nSystem.out.println(\"true\");\n}\n(2) 使用BigDecimal来定义值，再进行浮点数的运算操作。\nBigDecimal a = new BigDecimal(\"1.0\");\nBigDecimal b = new BigDecimal(\"0.9\");\nBigDecimal c = new BigDecimal(\"0.8\");\nBigDecimal x = a.subtract(b);\nBigDecimal y = b.subtract(c);\nif (x.compareTo(y) == 0 ) {\nSystem.out.println(\"true\");\n}\n10. 【强制】如上所示BigDecimal的等值比较应使用compareTo()方法，而不是equals()方法。\n    说明：equals()方法会比较值和精度（ 1 .0与 1 .00返回结果为false），而compareTo()则会忽略精度。\n11. 【强制】定义数据对象DO类时，属性类型要与数据库字段类型相匹配。\n    正例：数据库字段的bigint必须与类属性的Long类型相对应。\n    反例：某个案例的数据库表id字段定义类型bigint unsigned，实际类对象属性为Integer，随着id越来\n    越大，超过Integer的表示范围而溢出成为负数。\n\n\n12. 【强制】禁止使用构造方法BigDecimal(double)的方式把double值转化为BigDecimal对象。\n    说明：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。\n    如：BigDecimal g = new BigDecimal(0.1F); 实际的存储值为：0.\n    正例：优先推荐入参为String的构造方法，或使用BigDecimal的valueOf方法，此方法内部其实执行了\n    Double的toString，而Double的toString按double的实际能表达的精度对尾数进行了截断。\nBigDecimal recommend1 = new BigDecimal(\"0.1\");\nBigDecimal recommend2 = BigDecimal.valueOf(0.1);\n13. 关于基本数据类型与包装数据类型的使用标准如下：\n1 ） 【强制】所有的POJO类属性必须使用包装数据类型。\n2 ） 【强制】RPC方法的返回值和参数必须使用包装数据类型。\n3 ） 【推荐】所有的局部变量使用基本数据类型。\n说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或\n者入库检查，都由使用者来保证。\n正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。\n反例：某业务的交易报表上显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调\n用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线-。所以包装数据类型\n的null值，能够表示额外的信息，如：远程调用失败，异常退出。\n14. 【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。\n反例：POJO类的createTime默认值为new Date()，但是这个属性在数据提取时并没有置入具体值，在\n更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。\n15. 【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果\n完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。\n说明：注意serialVersionUID不一致会抛出序列化运行时异常。\n16. 【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。\n17. 【强制】POJO类必须写toString方法。使用IDE中的工具：source> generate toString\n时，如果继承了另一个POJO类，注意在前面加一下super.toString。\n说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。\n18. 【强制】禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法。\n说明：框架在调用属性xxx的提取方法时，并不能确定哪个方法一定是被优先调用到的。\n19. 【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容\n的检查，否则会有抛IndexOutOfBoundsException的风险。\n    说明：\n       String str = \"a,b,c,,\";\n       String[] ary = str.split(\",\");\n       // 预期大于 3 ，结果是 3\n       System.out.println(ary.length);\n\n\n20. 【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便\n    于阅读，此条规则优先于下一条。\n21. 【推荐】 类内方法定义的顺序依次是：公有方法或保护方法 > 私有方法 > getter / setter\n    方法。\n    说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可\n    能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载\n    的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。\n22. 【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在\ngetter/setter方法中，不要增加业务逻辑，增加排查问题的难度。\n反例：\npublic Integer getData () {\nif (condition) {\nreturn this.data + 100 ;\n} else {\nreturn this.data - 100 ;\n}\n}\n23. 【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。\n说明：下例中，反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append\n操作，最后通过toString方法返回String对象，造成内存资源浪费。\n反例：\nString str = \"start\";\nfor (int i = 0 ; i < 100 ; i++) {\nstr = str + \"hello\";\n}\n24. 【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字：\n1 ） 不允许被继承的类，如：String类。\n2 ） 不允许修改引用的域对象，如：POJO类的域变量。\n3 ） 不允许被覆写的方法，如：POJO类的setter方法。\n4 ） 不允许运行过程中重新赋值的局部变量。\n5 ） 避免上下文重复使用一个变量，使用final关键字可以强制重新定义一个变量，方便更好地进行重构。\n25. 【推荐】慎用Object的clone方法来拷贝对象。\n    说明：对象clone方法默认是浅拷贝，若想实现深拷贝，需覆写clone方法实现域对象的深度遍历式拷贝。\n26. 【推荐】类成员与方法访问控制从严：\n    1 ） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。\n    2 ） 工具类不允许有public或default构造方法。\n    3 ） 类非static成员变量并且与子类共享，必须是protected。\n    4 ） 类非static成员变量并且仅在本类使用，必须是private。\n\n\n```\n5 ） 类static成员变量如果仅在本类使用，必须是private。\n6 ） 若是static成员变量，考虑是否为final。\n7 ） 类成员方法只供类内部调用，必须是private。\n8 ） 类成员方法只对继承类公开，那么限制为protected。\n说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果\n是一个private的方法，想删除就删除，可是一个public的service成员方法或成员变量，删除一下，不\n得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你\n会担心的。\n```\n### (五) 日期时间\n\n1. 【强制】日期格式化时，传入pattern中表示年份统一使用小写的y。\n    说明：日期格式化时，yyyy表示当天所在的年，而大写的YYYY代表是week in which year（JDK7之后\n    引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY\n    就是下一年。\n    正例：表示日期和时间的格式如下所示：\n    new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n2. 【强制】在日期格式中分清楚大写的M和小写的m，大写的H和小写的h分别指代的意义。\n说明：日期格式中的这两对字母表意如下：\n1 ） 表示月份是大写的M；\n2 ） 表示分钟则是小写的m；\n3 ） 24 小时制的是大写的H；\n4 ） 12 小时制的则是小写的h。\n3. 【强制】获取当前毫秒数：System.currentTimeMillis(); 而不是new Date().getTime()。\n    说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间\n    等场景，推荐使用Instant类。\n4. 【强制】不允许在程序任何地方中使用： 1 ）java.sql.Date。 2 ）java.sql.Time。\n3 ）java.sql.Timestamp。\n说明：第 1 个不记录时间，getHours()抛出异常；第 2 个不记录日期，getYear()抛出异常；第 3 个在构造\n方法super((time/1000)*1000)，在Timestamp 属性fastTime和nanos分别存储秒和纳秒信息。\n反例： java.util.Date.after(Date)进行时间比较时，当入参是java.sql.Timestamp时，会触发JDK\nBUG(JDK9已修复)，可能导致比较时的意外结果。\n5. 【强制】不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑\n错误。\n\n\n```\n正例：\n// 获取今年的天数\nint daysOfThisYear = LocalDate.now().lengthOfYear();\n// 获取指定某年的天数\nLocalDate.of( 2011 , 1 , 1 ).lengthOfYear();\n反例：\n// 第一种情况：在闰年 366 天时，出现数组越界异常\nint[] dayArray = new int[ 365 ];\n// 第二种情况：一年有效期的会员制，今年 1 月 26 日注册，硬编码 365 返回的却是 1 月 25 日\nCalendar calendar = Calendar.getInstance();\ncalendar.set( 2020 , 1 , 26 );\ncalendar.add(Calendar.DATE, 365 );\n```\n6. 【推荐】避免公历闰年 2 月问题。闰年的 2 月份有 29 天，一年后的那一天不可能是 2 月 29\n    日。\n7. 【推荐】使用枚举值来指代月份。如果使用数字，注意Date，Calendar等日期相关类的月份\n    month取值在 0 - 11 之间。\n    说明：参考JDK原生注释，Month value is 0-based. e.g., 0 for January.\n    正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或\n    比较。\n\n### (六) 集合处理\n\n1. 【强制】关于hashCode和equals的处理，遵循如下规则：\n    1 ） 只要覆写equals，就必须覆写hashCode。\n    2 ） 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须覆写\n    这两种方法。\n    3 ） 如果自定义对象作为Map的键，那么必须覆写hashCode和equals。\n    说明：String因为覆写了hashCode和equals方法，所以可以愉快地将String对象作为key来使用。\n2. 【强制】判断所有集合内部的元素是否为空，使用isEmpty()方法，而不是size()==0的方式。\n    说明：在某些集合中，前者的时间复杂度为O(1)，而且可读性更好。\n    正例：\n       Map<String, Object> map = new HashMap<>( 16 );\n       if(map.isEmpty()) {\n       System.out.println(\"no element in this map.\");\n       }\n\n\n3. 【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要使\n    用含有参数类型为BinaryOperator，参数名为mergeFunction的方法，否则当出现相同key\n    值时会抛出IllegalStateException异常。\n    说明：参数mergeFunction的作用是当出现key重复时，自定义对value的处理策略。\n    正例：\n       List<Pair<String, Double>> pairArrayList = new ArrayList<>( 3 );\n       pairArrayList.add(new Pair<>(\"version\", 12.10));\n       pairArrayList.add(new Pair<>(\"version\", 12.19));\n       pairArrayList.add(new Pair<>(\"version\", 6.28));\n       Map<String, Double> map = pairArrayList.stream().collect(\n       // 生成的map集合中只有一个键值对：{version=6.2 8 }\n       Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - > v2));\n    反例：\n       String[] departments = new String[] {\"iERP\", \"iERP\", \"EIBU\"};\n       // 抛出IllegalStateException异常\n       Map<Integer, String> map = Arrays.stream(departments)\n       .collect(Collectors.toMap(String::hashCode, str -> str));\n4. 【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要注\n    意当value为null时会抛NPE异常。\n    说明：在java.util.HashMap的merge方法里会进行如下的判断：\n       if (value == null || remappingFunction == null)\n          throw new NullPointerException();\n    反例：\n       List<Pair<String, Double>> pairArrayList = new ArrayList<>( 2 );\n       pairArrayList.add(new Pair<>(\"version1\", 8. 3 ));\n       pairArrayList.add(new Pair<>(\"version2\", null));\n       Map<String, Double> map = pairArrayList.stream().collect(\n       // 抛出NullPointerException异常\n       Collectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - > v2));\n5. 【强制】ArrayList的subList结果不可强转成ArrayList，否则会抛出 ClassCastException异\n    常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。\n    说明：subList()返回的是ArrayList的内部类SubList，并不是 ArrayList本身，而是ArrayList 的一个视\n    图，对于SubList的所有操作最终会反映到原列表上。\n6. 【强制】使用Map的方法keySet()/values()/entrySet()返回集合对象时，不可以对其进行添\n    加元素操作，否则会抛出UnsupportedOperationException异常。\n7. 【强制】Collections类返回的对象，如：emptyList()/singletonList()等都是immutable list，\n不可对其进行添加或者删除元素的操作。\n反例：如果查询无结果，返回Collections.emptyList()空集合对象，调用方一旦进行了添加元素的操作，就\n会触发UnsupportedOperationException异常。\n\n\n8. 【强制】在subList场景中，高度注意对父集合元素的增加或删除，均会导致子列表的遍历、\n    增加、删除产生ConcurrentModificationException 异常。\n9. 【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一\n致、长度为 0 的空数组。\n反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现\nClassCastException错误。\n正例：\nList<String> list = new ArrayList<>( 2 );\nlist.add(\"guan\");\nlist.add(\"bao\");\nString[] array = list.toArray(new String[ 0 ]);\n说明：使用toArray带参方法，数组空间大小的length：\n1 ） 等于 0 ，动态创建与size相同的数组，性能最好。\n2 ） 大于 0 但小于size，重新创建大小等于size的数组，增加GC负担。\n3 ） 等于size，在高并发情况下，数组创建完成之后，size正在变大的情况下，负面影响与 2 相同。\n4 ） 大于size，空间浪费，且在size处插入null值，存在NPE隐患。\n10. 【强制】在使用Collection接口任何实现类的addAll()方法时，都要对输入的集合参数进行\nNPE判断。\n说明：在ArrayList#addAll方法的第一行代码即Object[] a = c.toArray(); 其中c为输入集合参数，如果\n为null，则直接抛出异常。\n11. 【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，\n它的add/remove/clear方法会抛出UnsupportedOperationException异常。\n说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配\n器模式，只是转换接口，后台的数据仍是数组。\nString[] str = new String[] { \"chen\", \"yang\", \"hao\" };\nList list = Arrays.asList(str);\n第一种情况：list.add(\"yangguanbao\"); 运行时异常。\n第二种情况：str[0] = \"change\"; 也会随之修改，反之亦然。\n12. 【强制】泛型通配符<? extends T>来接收返回的数据，此写法的泛型集合不能使用add方法，\n而<? super T>不能使用get方法，两者在接口调用赋值的场景中容易出错。\n说明：扩展说一下PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用\n<? extends T>。第二、经常往里插入的，适合用<? super T>\n13. 【强制】在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行\ninstanceof判断，避免抛出ClassCastException异常。\n说明：毕竟泛型是在JDK5后才出现，考虑到向前兼容，编译器是允许非泛型集合与泛型集合互相赋值。\n\n\n```\n反例：\nList<String> generics = null;\nList notGenerics = new ArrayList( 10 );\nnotGenerics.add(new Object());\nnotGenerics.add(new Integer( 1 ));\ngenerics = notGenerics;\n// 此处抛出ClassCastException异常\nString string = generics.get( 0 );\n```\n14. 【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator\n    方式，如果并发操作，需要对Iterator对象加锁。\n       正例：\n          List<String> list = new ArrayList<>();\n          list.add(\"1\");\n          list.add(\"2\");\n          Iterator<String> iterator = list.iterator();\n          while (iterator.hasNext()) {\n          String item = iterator.next();\n          if (删除元素的条件) {\n          iterator.remove();\n          }\n          }\n       反例：\n          for (String item : list) {\n          if (\"1\".equals(item)) {\n          list.remove(item);\n          }\n          }\n       说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？\n15. 【强制】在JDK 7 版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，\n    Collections.sort会抛IllegalArgumentException异常。\n    说明：三个条件如下\n    1 ） x，y的比较结果和y，x的比较结果相反。\n    2 ） x>y，y>z，则x>z。\n    3 ） x=y，则x，z比较结果和y，z比较结果相同。\n    反例：下例中没有处理相等的情况，交换两个对象判断结果并不互反，不符合第一个条件，在实际使用中\n    可能会出现异常。\n       new Comparator<Student>() {\n       @Override\n       public int compare(Student o1, Student o2) {\n       return o1.getId() > o2.getId()? 1 : - 1 ;\n       }\n       };\n16. 【推荐】集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。\n    说明：菱形泛型，即diamond，直接使用<>来指代前边已经指定的类型。\n\n\n```\n正例：\n// diamond方式，即<>\nHashMap<String, String> userCache = new HashMap<>( 16 );\n// 全省略方式\nArrayList<User> users = new ArrayList( 10 );\n```\n17. 【推荐】集合初始化时，指定集合初始值大小。\n    说明：HashMap使用HashMap(int initialCapacity) 初始化，如果暂时无法确定集合大小，那么指定默\n    认值（ 16 ）即可。\n    正例：initialCapacity = (需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loader factor）默认\n    为0.75，如果暂时无法确定初始值大小，请设置为 16 （即默认值）。\n       反例： HashMap需要放置 1024 个元素，由于没有设置容量初始大小，随着元素增加而被迫不断扩容，\n       resize()方法总共会调用 8 次，反复重建哈希表和数据迁移。当放置的集合元素个数达千万级时会影响程序\n       性能。\n18. 【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。\n说明：keySet其实是遍历了 2 次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的\nvalue。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用\nMap.forEach方法。\n正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对\n象；entrySet()返回的是K-V值组合集合。\n19. 【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格：\n\n```\n集合类 Key Value Super 说明\nHashtable 不允许为null 不允许为null Dictionary 线程安全\nConcurrentHashMap 不允许为null 不允许为null AbstractMap 锁分段技术（JDK8:CAS）\nTreeMap 不允许为null 允许为null AbstractMap 线程不安全\nHashMap 允许为null 允许为null AbstractMap 线程不安全\n反例：由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储\nnull值时会抛出NPE异常。\n```\n20. 【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳\n    定性(unorder)带来的负面影响。\n    说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。\n    如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。\n21. 【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的\n    contains()进行遍历去重或者判断包含操作。\n\n\n### (七) 并发处理\n\n1. 【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。\n    说明：资源驱动类、工具类、单例工厂类都需要注意。\n2. 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。\n正例：自定义线程工厂，并且根据外部特征进行分组，比如，来自同一机房的调用，把机房编号赋值给\nwhatFeatureOfGroup\npublic class UserThreadFactory implements ThreadFactory {\nprivate final String namePrefix;\nprivate final AtomicInteger nextId = new AtomicInteger( 1 );\n// 定义线程组名称，在利用jstack来排查问题时，非常有帮助\nUserThreadFactory(String whatFeatureOfGroup) {\nnamePrefix = \"From UserThreadFactory's \" + whatFeatureOfGroup + \"-Worker-\";\n}\n@Override\npublic Thread newThread(Runnable task) {\nString name = namePrefix + nextId.getAndIncrement();\nThread thread = new Thread(null, task, name, 0 , false);\nSystem.out.println(thread.getName());\nreturn thread;\n}\n}\n3. 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。\n说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。\n如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。\n4. 【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这\n样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。\n说明：Executors返回的线程池对象的弊端如下：\n1 ） FixedThreadPool和SingleThreadPool：\n允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。\n2 ） CachedThreadPool：\n允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。\n5. 【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，\n必须加锁，或者使用DateUtils工具类。\n正例：注意线程安全，使用DateUtils。亦推荐如下处理：\nprivate static final ThreadLocal<DateFormat> df = new ThreadLocal<DateFormat>() {\n@Override\nprotected DateFormat initialValue() {\nreturn new SimpleDateFormat(\"yyyy-MM-dd\");\n}\n};\n\n\n```\n说明：如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，\nDateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful strong immutable\nthread-safe。\n```\n6. 【强制】必须回收自定义的ThreadLocal变量，尤其在线程池场景下，线程经常会被复用，\n    如果不清理自定义的 ThreadLocal变量，可能会影响后续业务逻辑和造成内存泄露等问题。\n    尽量在代理中使用try-finally块进行回收。\n    正例：\n       objectThreadLocal.set(userInfo);\n       try {\n       // ...\n       } finally {\n       objectThreadLocal.remove();\n       }\n7. 【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能\n    锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。\n       说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。\n8. 【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造\n成死锁。\n说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、\nB、C，否则可能出现死锁。\n9. 【强制】在使用阻塞等待获取锁的方式中，必须在try代码块之外，并且在加锁方法与try代\n    码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在finally中无法解锁。\n    说明一：如果在lock方法与try代码块之间的方法调用抛出异常，那么无法解锁，造成其它线程无法成功\n    获取锁。\n    说明二：如果lock方法在try代码块之内，可能由于其它方法抛出异常，导致在finally代码块中，unlock\n    对未加锁的对象解锁，它会调用AQS的tryRelease方法（取决于具体实现类），抛出\n    IllegalMonitorStateException异常。\n    说明三：在Lock对象的lock方法实现中可能抛出unchecked异常，产生的后果与说明二相同。\n    正例：\n       Lock lock = new XxxLock();\n       // ...\n       lock.lock();\n       try {\n       doSomething();\n       doOthers();\n       } finally {\n       lock.unlock();\n       }\n反例：\nLock lock = new XxxLock();\n// ...\n\n\n```\ntry {\n// 如果此处抛出异常，则直接执行finally代码块\ndoSomething();\n// 无论加锁是否成功，finally代码块都会执行\nlock.lock();\ndoOthers();\n} finally {\nlock.unlock();\n}\n```\n10. 【强制】在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否\n    持有锁。锁的释放规则与锁的阻塞等待方式相同。\n    说明：Lock对象的unlock方法在执行时，它会调用AQS的tryRelease方法（取决于具体实现类），如果\n    当前线程不持有锁，则抛出IllegalMonitorStateException异常。\n    正例：\n       Lock lock = new XxxLock();\n       // ...\n       boolean isLocked = lock.tryLock();\n       if (isLocked) {\n       try {\n       doSomething();\n       doOthers();\n       } finally {\n       lock.unlock();\n       }\n       }\n11. 【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加\n锁，要么在数据库层使用乐观锁，使用version作为更新依据。\n说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于\n3 次。\n12. 【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛\n出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。\n13. 【推荐】资金相关的金融敏感信息，使用悲观锁策略。\n    说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策\n    略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观\n    锁更新。\n       正例：悲观锁遵循一锁、二判、三更新、四释放的原则。\n14. 【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方\n法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至\nawait方法，直到超时才返回结果。\n说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。\n\n\n15. 【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed\n    导致的性能下降。\n       说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。\n       正例：在JDK7之后，可以直接使用API ThreadLocalRandom，而在 JDK7之前，需要编码保证每个线\n       程持有一个单独的Random实例。\n16. 【推荐】通过双重检查锁（double-checked locking）（在并发场景下）存在延迟初始化的优化\n    问题隐患（可参考 The \"Double-Checked Locking is Broken\" Declaration），推荐解决方案中较\n    为简单一种（适用于JDK 5 及以上版本），将目标属性声明为 volatile型，比如将helper的属\n    性声明修改为`private volatile Helper helper = null;`。\n    正例：\n       public class LazyInitDemo {\n       private volatile Helper helper = null;\n       public Helper getHelper() {\n       if (helper == null) {\n       synchronized (this) {\n       if (helper == null) { helper = new Helper(); }\n       }\n       }\n       return helper;\n       }\n       // other methods and fields...\n       }\n17. 【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但\n    是如果多写，同样无法解决线程安全问题。\n       说明：如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger();\n       count.addAndGet(1); 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观\n       锁的重试次数）。\n18. 【参考】HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在\n开发过程中注意规避此风险。\n19. 【参考】ThreadLocal对象使用static修饰，ThreadLocal无法解决共享对象的更新问题。\n说明：这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量，\n也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可\n以操控这个变量。\n\n### (八) 控制语句\n\n1. 【强制】在一个switch块内，每个case要么通过continue/break/return等来终止，要么\n    注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default\n\n\n```\n语句并且放在最后，即使它什么代码也没有。\n说明：注意break是退出switch语句块，而return是退出方法体。\n```\n2. 【强制】当switch括号内的变量类型为String并且此变量为外部参数时，必须先进行null\n    判断。\n    反例：如下的代码输出是什么？\n       public class SwitchString {\n       public static void main(String[] args) {\n       method(null);\n       }\n       public static void method(String param) {\n       switch (param) {\n       // 肯定不是进入这里\n       case \"sth\":\n       System.out.println(\"it's sth\");\n       break;\n       // 也不是进入这里\n       case \"null\":\n       System.out.println(\"it's null\");\n       break;\n       // 也不是进入这里\n       default:\n       System.out.println(\"default\");\n       }\n       }\n       }\n3. 【强制】在if/else/for/while/do语句中必须使用大括号。\n    说明：即使只有一行代码，也禁止不采用大括号的编码方式：if (condition) statements;\n4. 【强制】三目运算符condition? 表达式1 : 表达式 2 中，高度注意表达式 1 和 2 在类型对齐\n    时，可能抛出因自动拆箱导致的NPE异常。\n    说明：以下两种场景会触发类型对齐的拆箱操作：\n    1 ） 表达式 1 或表达式 2 的值只要有一个是原始类型。\n    2 ） 表达式 1 或表达式 2 的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。\n       反例：\n          Integer a = 1 ;\n          Integer b = 2 ;\n          Integer c = null;\n          Boolean flag = false;\n          // a*b的结果是int类型，那么c会强制拆箱成int类型，抛出NPE异常\n          Integer result=(flag? a*b : c);\n5. 【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。\n说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件\n来代替。\n\n\n```\n反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，\n这样的话，活动无法终止。\n```\n6. 【推荐】当某个方法的代码总行数超过 10 行时，return / throw 等中断逻辑的右大括号后均\n    需要加一个空行。\n    说明：这样做逻辑清晰，有利于代码阅读时重点关注。\n7. 【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成：\nif (condition) {\n...\nreturn obj;\n}\n// 接着写else的业务逻辑代码;\n说明：如果非使用if()...else if()...else...方式表达逻辑，避免后续代码维护困难，请勿超过 3 层。\n正例：超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句\n示例如下：\npublic void findBoyfriend (Man man) {\nif (man.isUgly()) {\nSystem.out.println(\"本姑娘是外貌协会的资深会员\");\nreturn;\n}\nif (man.isPoor()) {\nSystem.out.println(\"贫贱夫妻百事哀\");\nreturn;\n}\nif (man.isBadTemper()) {\nSystem.out.println(\"银河有多远，你就给我滚多远\");\nreturn;\n}\nSystem.out.println(\"可以先交往一段时间看看\");\n}\n8. 【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复\n    杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。\n    说明：很多 if 语句内的逻辑表达式相当复杂，与、或、取反混合运算，甚至各种方法纵深调用，理解成本\n    非常高。如果赋值一个非常好理解的布尔变量名字，则是件令人爽心悦目的事情。\n    正例：\n       // 伪代码如下\n       final boolean existed = (file.open(fileName, \"w\") != null) && (...) || (...);\n       if (existed) {\n       ...\n       }\n反例：\npublic final void acquire ( long arg) {\nif (!tryAcquire(arg) &&\nacquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {\nselfInterrupt();\n}\n\n\n9. 【推荐】不要在其它表达式（尤其是条件表达式）中，插入赋值语句。\n    说明：赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行。\n    反例：\n       public Lock getLock(boolean fair) {\n       // 算术表达式中出现赋值操作，容易忽略count值已经被改变\n       threshold = (count = Integer.MAX_VALUE) - 1 ;\n       // 条件表达式中出现赋值操作，容易误认为是sync==fair\n       return (sync = fair)? new FairSync() : new NonfairSync();\n       }\n10. 【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、\n    获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。\n11. 【推荐】避免采用取反逻辑运算符。\n    说明：取反逻辑不利于快速理解，并且取反逻辑写法一般都存在对应的正向逻辑写法。\n    正例：使用if (x < 628) 来表达 x 小于 628 。\n    反例：使用if (!(x >= 628)) 来表达 x 小于 628 。\n12. 【推荐】公开接口需要进行入参保护，尤其是批量操作的接口。\n    反例：某业务系统，提供一个用户批量查询的接口，API文档上有说最多查多少个，但接口实现上没做任何\n    保护，导致调用方传了一个 1000 的用户id数组过来后，查询信息后，内存爆了。\n13. 【参考】下列情形，需要进行参数校验：\n    1 ） 调用频次低的方法。\n    2 ） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致\n    中间执行回退，或者错误，那得不偿失。\n    3 ） 需要极高稳定性和可用性的方法。\n    4 ） 对外提供的开放接口，不管是RPC/API/HTTP接口。\n       5 ） 敏感权限入口。\n14. 【参考】下列情形，不需要进行参数校验：\n1 ） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查。\n2 ） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露\n问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可\n以省略。\n3 ） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检\n查或者肯定不会有问题，此时可以不校验参数。\n\n\n### (九) 注释规约\n\n1. 【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/**内容*/格式，不得使用\n    // xxx方式。\n    说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE\n    中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。\n2. 【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、\n    异常说明外，还必须指出该方法做什么事情，实现什么功能。\n    说明：对子类的实现要求，或者调用注意事项，请一并说明。\n3. 【强制】所有的类都必须添加创建者和创建日期。\n说明：在设置模板时，注意IDEA的@author为`${USER}`，而eclipse的@author为`${user}`，大小写有\n区别，而日期的设置统一为yyyy/MM/dd的格式。\n正例：\n/**\n\n```\n* @author yangguanbao\n* @date 2016/10/31\n*/\n```\n4. 【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使\n    用/* */注释，注意与代码对齐。\n5. 【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。\n6. 【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持\n    英文原文即可。\n    反例：“TCP连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。\n7. 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑\n    等的修改。\n    说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了\n    导航的意义。\n8. 【推荐】在类中删除未使用的任何字段、方法、内部类；在方法中删除未使用的任何参数声明\n    与内部变量。\n9. 【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。\n    说明：代码被注释掉有两种可能性： 1 ）后续会恢复此段代码逻辑。 2 ）永久不用。前者如果没有备注信息，\n    难以知晓注释动机。后者建议直接删掉即可，假如需要查阅历史代码，登录代码仓库即可。\n\n\n10. 【参考】对于注释的要求：第一、能够准确反映设计思想和代码逻辑；第二、能够描述业务含\n    义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同\n    天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看\n    的，使其能够快速接替自己的工作。\n11. 【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一\n个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释又是相当大的负担。\n反例：\n// put elephant into fridge\nput(elephant, fridge);\n方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不\n需要额外的注释。\n12. 【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，\n经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。\n1 ） 待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）\n表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没\n有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）。\n2 ） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）\n在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。\n\n### (十) 前后端规约\n\n1. 【强制】前后端交互的API，需要明确协议、域名、路径、请求方法、请求内容、状态码、响\n    应体。\n    说明：\n       1 ） 协议：生产环境必须使用HTTPS。\n       2 ） 路径：每一个API需对应一个路径，表示API具体的请求地址：\n       a） 代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。\n       b） URL路径不能使用大写，单词如果需要分隔，统一使用下划线。\n       c） 路径禁止携带表示请求内容类型的后缀，比如\".json\",\".xml\"，通过accept头表达即可。\n       3 ） 请求方法：对具体操作的定义，常见的请求方法如下：\n       a） GET：从服务器取出资源。\n       b） POST：在服务器新建一个资源。\n       c） PUT：在服务器更新资源。\n       d） DELETE：从服务器删除资源。\n       4 ） 请求内容：URL带的参数必须无敏感信息或符合安全要求；body里带参数时必须设置Content-Type。\n       5 ） 响应体：响应体body可放置多种数据类型，由Content-Type头来确定。\n\n\n2. 【强制】前后端数据列表相关的接口返回，如果为空，则返回空数组[]或空集合{}。\n    说明：此条约定有利于数据层面上的协作更加高效，减少前端很多琐碎的null判断。\n3. 【强制】服务端发生错误时，返回给前端的响应信息必须包含HTTP状态码，errorCode、\n    errorMessage、用户提示信息四个部分。\n    说明：四个部分的涉众对象分别是浏览器、前端开发、错误排查人员、用户。其中输出给用户的提示信息\n    要求：简短清晰、提示友好，引导用户进行下一步操作或解释错误原因，提示信息可以包括错误原因、上\n    下文环境、推荐操作等。 errorCode：参考 **附表 3** 。errorMessage：简要描述后端出错原因，便于错误排\n    查人员快速定位问题，注意不要包含敏感数据信息。\n    正例：常见的HTTP状态码如下\n    1 ） 200 OK: 表明该请求被成功地完成，所请求的资源发送到客户端。\n    2 ） 401 Unauthorized: 请求要求身份验证，常见对于需要登录而用户未登录的情况。\n    3 ） 403 Forbidden：服务器拒绝请求，常见于机密信息或复制其它登录用户链接访问服务器的情况。\n    4 ） 404 Not Found: 服务器无法取得所请求的网页，请求资源不存在。\n    5 ） 500 Internal Server Error: 服务器内部错误。\n4. 【强制】在前后端交互的JSON格式数据中，所有的key必须为小写字母开始的\n    lowerCamelCase风格，符合英文表达习惯，且表意完整。\n    正例：errorCode / errorMessage / assetStatus / menuList / orderList / configFlag\n    反例：ERRORCODE / ERROR_CODE / error_message / error-message / errormessage /\n    ErrorMessage / msg\n5. 【强制】errorMessage是前后端错误追踪机制的体现，可以在前端输出到type=\"hidden\"\n文字类控件中，或者用户端的日志中，帮助我们快速地定位出问题。\n6. 【强制】对于需要使用超大整数的场景，服务端一律使用String字符串类型返回，禁止使用\nLong类型。\n说明：Java服务端如果直接返回Long整型数据给前端，JS会自动转换为Number类型（注：此类型为双\n精度浮点数，表示原理与取值范围等同于Java中的Double）。Long类型能表示的最大值是 2 的 63 次方\n- 1 ，在取值范围之内，超过 2 的 53 次方 (9007199254740992)的数值转化为JS的Number时，有些数\n值会有精度损失。扩展说明，在Long取值范围内，任何 2 的指数次整数都是绝对不会存在精度损失的，所\n以说精度损失是一个概率问题。若浮点数尾数位与指数位空间不限，则可以精确表示任何整数，但很不幸，\n双精度浮点数的尾数位只有 52 位。\n反例：通常在订单号或交易号大于等于 16 位，大概率会出现前后端单据不一致的情况，比如，\"orderId\":\n362909601374617692 ，前端拿到的值却是: 36290960137461766 0 。\n7. 【强制】HTTP请求通过URL传递参数时，不能超过 2048 字节。\n    说明：不同浏览器对于URL的最大长度限制略有不同，并且对超出最大长度的处理逻辑也有差异， 2048\n    字节是取所有浏览器的最小值。\n\n\n```\n反例：某业务将退货的商品id列表放在URL中作为参数传递，当一次退货商品数量过多时，URL参数超长，\n传递到后端的参数被截断，导致部分商品未能正确退货。\n```\n8. 【强制】HTTP请求通过body传递内容时，必须控制长度，超出最大长度后，后端解析会出\n    错。\n    说明：nginx默认限制是1MB，tomcat默认限制为2MB，当确实有业务需要传较大内容时，可以通过调\n    大服务器端的限制。\n9. 【强制】在翻页场景中，用户输入参数的小于 1 ，则前端返回第一页参数给后端；后端发现用\n户输入的参数大于总页数，直接返回最后一页。\n10. 【强制】服务器内部重定向必须使用forward；外部重定向地址必须使用URL统一代理模块\n生成，否则会因线上采用HTTPS协议而导致浏览器提示“不安全”，并且还会带来URL维护\n不一致的问题。\n11. 【推荐】服务器返回信息必须被标记是否可以缓存，如果缓存，客户端可能会重用之前的请求\n    结果。\n    说明：缓存有利于减少交互次数，减少交互的平均延迟。\n    正例：http 1.1中，s-maxage告诉服务器进行缓存，时间单位为秒，用法如下，\n    response.setHeader(\"Cache-Control\", \"s-maxage=\" + cacheSeconds);\n12. 【推荐】服务端返回的数据，使用JSON格式而非XML。\n    说明：尽管HTTP支持使用不同的输出格式，例如纯文本，JSON，CSV，XML，RSS甚至HTML。如果我\n    们使用的面向用户的服务，应该选择JSON作为通信中使用的标准数据交换格式，包括请求和响应。此外，\n    application/JSON是一种通用的MIME类型，具有实用、精简、易读的特点。\n13. 【推荐】前后端的时间格式统一为\"yyyy-MM-dd HH:mm:ss\"，统一为GMT。\n14. 【参考】在接口路径中不要加入版本号，版本控制在HTTP头信息中体现，有利于向前兼容。\n说明：当用户在低版本与高版本之间反复切换工作时，会导致迁移复杂度升高，存在数据错乱风险。\n\n### (十一) 其他\n\n1. 【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。\n    说明：不要在方法体内定义：Pattern pattern = Pattern.compile(“规则”);\n2. 【强制】避免用Apache Beanutils进行属性的copy。\n    说明：Apache BeanUtils性能较差，可以使用其他方案比如Spring BeanUtils, Cglib BeanCopier，注意\n    均是浅拷贝。\n\n\n3. 【强制】velocity调用POJO类的属性时，直接使用属性名取值即可，模板引擎会自动按规范\n    调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），\n    会自动调用isXxx()方法。\n    说明：注意如果是Boolean包装类对象，优先调用getXxx()的方法。\n4. 【强制】后台输送给页面的变量必须加$!{var}——中间的感叹号。\n    说明：如果var等于null或者不存在，那么${var}会直接显示在页面上。\n5. 【强制】注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x<1（能够\n    取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大 10 的若干倍然后\n    取整，直接使用Random对象的nextInt或者nextLong方法。\n6. 【推荐】不要在视图模板中加入任何复杂的逻辑。\n说明：根据MVC理论，视图的职责是展示，不要抢模型和控制器的活。\n7. 【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。\n8. 【推荐】及时清理不再使用的代码段或配置信息。\n说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。\n正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)\n来说明注释掉代码的理由。如：\npublic static void hello() {\n/// 业务方通知活动暂停\n// Business business = new Business();\n// business.active();\nSystem.out.println(\"it's finished\");\n}\n\n\n## 二、异常日志\n\n### (一) 错误码\n\n1. 【强制】错误码的制定原则：快速溯源、沟通标准化。\n    说明： 错误码想得过于完美和复杂，就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身\n    携带并且简单易懂。\n    正例：错误码回答的问题是谁的错？错在哪？ 1 ）错误码必须能够快速知晓错误来源，可快速判断是谁的问\n    题。 2 ）错误码必须能够进行清晰地比对（代码中容易equals）。 3 ）错误码有利于团队快速对错误原因达\n    到一致认知。\n2. 【强制】错误码不体现版本号和错误等级信息。\n    说明：错误码以不断追加的方式进行兼容。错误等级由日志和错误码本身的释义来决定。\n3. 【强制】全部正常，但不得不填充错误码时返回五个零： 00000 。\n4. 【强制】错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。\n    说明：错误产生来源分为A/B/C，A表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付\n    超时等问题；B表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；C表示错误来源\n    于第三方服务，比如CDN服务出错，消息投递超时等问题；四位数字编号从 0001 到 9999 ，大类之间的\n    步长间距预留 100 ，参考文末 **附表 3** 。\n5. 【强制】编号不与公司业务架构，更不与组织架构挂钩，以先到先得的原则在统一平台上进行，\n    审批生效，编号即被永久固定。\n6. 【强制】错误码使用者避免随意定义新的错误码。\n    说明：尽可能在原有错误码附表中找到语义相同或者相近的错误码在代码中使用即可。\n7. 【强制】错误码不能直接输出给用户作为提示信息使用。\n    说明：堆栈（stack_trace）、错误信息(error_message)、错误码（error_code）、提示信息（user_tip）\n    是一个有效关联并互相转义的和谐整体，但是请勿互相越俎代庖。\n8. 【推荐】错误码之外的业务独特信息由error_message来承载，而不是让错误码本身涵盖过\n    多具体业务属性。\n9. 【推荐】在获取第三方服务错误码时，向上抛出允许本系统转义，由C转为B，并且在错误信\n    息上带上原有的第三方错误码。\n10. 【参考】错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。\n    说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、\n\n\n```\nB0001（系统执行出错）、C0001（调用第三方服务出错）。\n正例：调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。\n```\n11. 【参考】错误码的后三位编号与HTTP状态码没有任何关系。\n12. 【参考】错误码有利于不同文化背景的开发者进行交流与代码协作。\n    说明：英文单词形式的错误码不利于非英语母语国家（如阿拉伯语、希伯来语、俄罗斯语等）之间的开发\n    者互相协作。\n13. 【参考】错误码即人性，感性认知+口口相传，使用纯数字来进行错误码编排不利于感性记忆\n    和分类。\n    说明：数字是一个整体，每位数字的地位和含义是相同的。\n    反例：一个五位数字 12345 ，第 1 位是错误等级，第 2 位是错误来源， 345 是编号，人的大脑不会主动地\n    拆开并分辨每位数字的不同含义。\n\n### (二) 异常处理\n\n1. 【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过\n    catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。\n    说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不\n    通过catch NumberFormatException来实现。\n    正例：if (obj != null) {...}\n    反例：try { obj.method(); } catch (NullPointerException e) {...}\n2. 【强制】异常捕获后不要用来做流程控制，条件控制。\n    说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。\n3. 【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。\n    对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。\n    说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，\n    这是一种不负责任的表现。\n    正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程\n    序上作出分门别类的判断，并提示给用户。\n4. 【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请\n    将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的\n    内容。\n5. 【强制】事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。\n\n\n6. 【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。\n    说明：如果JDK7及以上，可以使用try-with-resources方式。\n7. 【强制】不要在finally块中使用return。\n说明：try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存\n在return语句，则在此直接返回，无情丢弃掉try块中的返回点。\n反例：\nprivate int x = 0 ;\npublic int checkReturn() {\ntry {\n// x等于 1 ，此处不返回\nreturn ++x;\n} finally {\n// 返回的结果是 2\nreturn ++x;\n}\n}\n8. 【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。\n    说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。\n9. 【强制】在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable\n    类来进行拦截。\n    说明：通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出\n    NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，\n    或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代\n    码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。\n10. 【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说\n    明什么情况下会返回null值。\n    说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也\n    并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。\n11. 【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景：\n1 ） 返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。\n反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。\n2 ） 数据库的查询结果可能为null。\n3 ） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。\n4 ） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。\n5 ） 对于Session中获取的数据，建议进行NPE检查，避免空指针。\n6 ） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。\n正例：使用JDK8的Optional类来防止NPE问题。\n\n\n12. 【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，\n    更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定\n    义过的自定义异常，如：DAOException / ServiceException等。\n13. 【参考】对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；\n    跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、\n    errorMessage；而应用内部直接抛出异常即可。\n    说明：关于RPC方法返回方式使用Result方式的理由：\n    1 ）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。\n    2 ）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题\n    的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。\n\n### (三) 日志规约\n\n1. 【强制】应用中不可直接使用日志系统（Log 4 j、Logback）中的API，而应依赖使用日志框架\n    （SLF4J、JCL--Jakarta Commons Logging）中的API，使用门面模式的日志框架，有利于维护和\n    各个类的日志处理方式统一。\n    说明：日志框架（SLF4J、JCL--Jakarta Commons Logging）的使用方式（推荐使用SLF4J）\n使用SLF4J：\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nprivate static final Logger logger = LoggerFactory.getLogger(Test.class);\n使用JCL：\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nprivate static final Log log = LogFactory.getLog(Test.class);\n2. 【强制】所有日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。对于\n当天日志，以“应用名.log”来保存，保存在/home/admin/应用名/logs/目录下，过往日志\n格式为: {logname}.log.{保存日期}，日期格式：yyyy-MM-dd\n正例：以aap应用为例，日志保存在/home/admin/aapserver/logs/aap.log，历史日志名称为\naap.log.2016- 08 - 01\n3. 【强制】根据国家法律，网络运行状态、网络安全事件、个人敏感信息操作等相关记录，留存\n    的日志不少于六个月，并且进行网络多机备份。\n4. 【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：\n    appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描\n    述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查\n    找。\n\n\n```\n说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系\n统进行及时监控。\n正例：mppserver应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log\n```\n5. 【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式。\n    说明：因为String字符串的拼接会使用StringBuilder的append()方式，有一定的性能损耗。使用占位符仅\n    是替换动作，可以有效提升性能。\n    正例：logger.debug(\"Processing trade with id: {} and symbol: {}\", id, symbol);\n6. 【强制】对于trace/debug/info级别的日志输出，必须进行日志级别的开关判断。\n    说明：虽然在debug(参数)的方法体内第一行代码isDisabled(Level.DEBUG_INT)为真时（Slf4j的常见实现\n    Log4j和Logback），就直接return，但是参数可能会进行字符串拼接运算。此外，如果debug(getName())\n    这种参数内有getName()方法调用，无谓浪费方法调用的开销。\n    正例：\n       // 如果判断为真，那么可以输出trace和debug级别的日志\n       if (logger.isDebugEnabled()) {\n       logger.debug(\"Current ID is: {} and name is: {}\", id, getName());\n       }\n7. 【强制】避免重复打印日志，浪费磁盘空间，务必在日志配置文件中设置additivity=false。\n    正例：<logger name=\"com.taobao.dubbo.config\" additivity=\"false\">\n8. 【强制】生产环境禁止直接使用System.out 或System.err 输出日志或使用\n    e.printStackTrace()打印异常堆栈。\n    说明：标准日志输出与标准错误输出文件每次Jboss重启时才滚动，如果大量输出送往这两个文件，容易\n    造成文件大小超过操作系统大小限制。\n9. 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过\n关键字throws往上抛出。\n正例：logger.error(\"inputParams:{} and errorMessage:{}\", 各类参数或者对象toString(), e.getMessage(), e);\n10. 【强制】日志打印时禁止直接用JSON工具将对象转换成String。\n说明：如果对象里某些get方法被覆写，存在抛出异常的情况，则可能会因为打印日志而影响正常业务流\n程的执行。\n正例：打印日志时仅打印出业务相关属性值或者调用其对象的toString()方法。\n11. 【推荐】谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用\nwarn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑\n爆，并记得及时删除这些观察日志。\n说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些\n日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？\n\n\n12. 【推荐】可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适\n    从。如非必要，请不要在此场景打出error级别，避免频繁报警。\n    说明：注意日志输出的级别，error级别只记录系统逻辑出错、异常或者重要的错误信息。\n13. 【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用\n    中文描述即可，否则容易产生歧义。\n    说明：国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息。\n\n\n## 三、单元测试\n\n1. 【强制】好的单元测试必须遵守AIR原则。\n    说明：单元测试在线上运行时，感觉像空气（AIR）一样感觉不到，但在测试质量的保障上，却是非常关键\n    的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。\n       ⚫ A：Automatic（自动化）\n       ⚫ I：Independent（独立性）\n⚫ R：Repeatable（可重复）\n2. 【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执\n    行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元\n    测试中不准使用System.out来进行人肉验证，必须使用assert来验证。\n3. 【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间\n    决不能互相调用，也不能依赖执行的先后次序。\n    反例：method2需要依赖method1的执行，将执行结果作为method2的输入。\n4. 【强制】单元测试是可以重复执行的，不能受到外界环境的影响。\n    说明：单元测试通常会被放到持续集成中，每次有代码check in时单元测试都会被执行。如果单测对外部\n    环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。\n    正例：为了不受外界环境影响，要求设计代码时就把SUT的依赖改成注入，在测试时用spring 这样的DI\n    框架注入一个本地（内存）实现或者Mock实现。\n5. 【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级\n    别，一般是方法级别。\n    说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑，\n    那是集成测试的领域。\n6. 【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。\n    说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。\n7. 【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。\n说明：源码编译时会跳过此目录，而单元测试框架默认是扫描此目录。\n8. 【推荐】单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都\n    要达到100%\n    说明：在工程规约的应用分层中提到的DAO层，Manager层，可重用度高的Service，都应该进行单元测\n    试。\n\n\n9. 【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量。\n    ⚫ B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。\n    ⚫ C：Correct，正确的输入，并得到预期的结果。\n    ⚫ D：Design，与设计文档相结合，来编写单元测试。\n    ⚫ E：Error，强制错误信息输入（如：非法数据、异常流程、业务允许外等），并得到预期的结果。\n10. 【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或\n者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。\n反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数\n据并不符合业务插入规则，导致测试结果异常。\n11. 【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对\n    单元测试产生的数据有明确的前后缀标识。\n    正例：在阿里巴巴企业智能事业部的内部单元测试中，使用ENTERPRISE_INTELLIGENCE _UNIT_TEST_\n    的前缀来标识单元测试相关代码。\n12. 【推荐】对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试\n    要求而书写不规范测试代码。\n13. 【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆\n    盖所有测试用例（UC）。\n14. 【推荐】单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补\n    充单元测试用例。\n15. 【参考】为了更方便地进行单元测试，业务代码应避免以下情况：\n\n```\n⚫ 构造方法中做的事情过多。\n⚫ 存在过多的全局变量和静态方法。\n⚫ 存在过多的外部依赖。\n⚫ 存在过多的条件语句。\n说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。\n```\n16. 【参考】不要对单元测试存在如下误解：\n\n```\n⚫ 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。\n⚫ 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。\n⚫ 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。\n⚫ 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。\n```\n\n## 四、安全规约\n\n1. 【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。\n    说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容。\n2. 【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。\n    说明：中国大陆个人手机号码显示： 139 **** 1219 ，隐藏中间 4 位，防止隐私泄露。\n3. 【强制】用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，\n    禁止字符串拼接SQL访问数据库。\n    反例：某系统签名大量被恶意修改，即是因为对于危险字符 # --没有进行转义，导致数据库更新时，where\n    后边的信息被注释掉，对全库进行更新。\n4. 【强制】用户请求传入的任何参数必须做有效性验证。\n说明：忽略参数校验可能导致：\n⚫ page size过大导致内存溢出\n⚫ 恶意order by导致数据库慢查询\n⚫ 缓存击穿\n⚫ SSRF\n⚫ 任意重定向\n⚫ SQL注入，Shell注入，反序列化注入\n⚫ 正则输入源串拒绝服务ReDoS\n    Java代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用\n    的是特殊构造的字符串来验证，有可能导致死循环的结果。\n5. 【强制】禁止向HTML页面输出未经安全过滤或未正确转义的用户数据。\n6. 【强制】表单、AJAX提交必须执行CSRF安全验证。\n    说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF漏洞的应用/\n    网站，攻击者可以事先构造好URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用\n    户参数进行相应修改。\n7. 【强制】URL外部重定向传入的目标地址必须执行白名单过滤。\n8. 【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机\n    制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。\n    说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并\n    造成短信平台资源浪费。\n9. 【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过\n    滤等风控策略。\n\n\n## 五、MySQL数据库\n\n### (一) 建表规约\n\n1. 【强制】表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint\n    （ 1 表示是， 0 表示否）。\n    说明：任何字段如果为非负数，必须是unsigned。\n    注意：POJO类中的任何布尔类型的变量，都不要加is前缀，所以，需要在<resultMap>设置从is_xxx到\n    Xxx的映射关系。数据库表示是与否的值，使用tinyint类型，坚持is_xxx的命名方式是为了明确其取值含\n    义与取值范围。\n    正例：表达逻辑删除的字段名is_deleted， 1 表示删除， 0 表示未删除。\n2. 【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只\n    出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。\n       说明：MySQL在Windows下不区分大小写，但在Linux下默认是区分大小写。因此，数据库名、表名、\n       字段名，都不允许出现任何大写字母，避免节外生枝。\n       正例：aliyun_admin，rdc_config，level3_name\n       反例：AliyunAdmin，rdcConfig，level_3_name\n3. 【强制】表名不使用复数名词。\n说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于DO类名也是单数形式，符合\n表达习惯。\n4. 【强制】禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字。\n5. 【强制】主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。\n说明：pk_ 即primary key；uk_ 即 unique key；idx_ 即index的简称。\n6. 【强制】小数类型为decimal，禁止使用float和double。\n说明：在存储的时候，float 和 double 都存在精度损失的问题，很可能在比较值的时候，得到不正确的\n结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数并分开存储。\n7. 【强制】如果存储的字符串长度几乎相等，使用char定长字符串类型。\n8. 【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000 ，如果存储长度\n大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效\n率。\n9. 【强制】表必备三字段：id, create_time, update_time。\n说明：其中id必为主键，类型为bigint unsigned、单表时自增、步长为 1 。create_time, update_time\n的类型均为datetime类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。\n\n\n10. 【推荐】表的命名最好是遵循“业务名称_表的作用”。\n    正例：alipay_task / force_project / trade_config\n11. 【推荐】库名与应用名称尽量一致。\n12. 【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。\n13. 【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：\n1 ） 不是频繁修改的字段。\n2 ） 不是唯一索引的字段。\n3 ） 不是varchar超长字段，更不能是text字段。\n正例：各业务线经常冗余存储商品名称，避免查询时需要调用IC服务获取。\n14. 【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。\n    说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。\n15. 【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索\n    速度。\n    正例：无符号值可以避免误存负数，且扩大了表示范围。\n\n```\n对象 年龄区间 类型 字节 表示范围\n人 150 岁之内 tinyint unsigned 1 无符号值： 0 到 255\n龟 数百岁 smallint unsigned 2 无符号值： 0 到 65535\n恐龙化石 数千万年 int unsigned 4 无符号值： 0 到约 43 亿\n太阳 约 50 亿年 bigint unsigned 8 无符号值： 0 到约 10 的 19 次方\n```\n### (二) 索引规约\n\n1. 【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。\n    说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，\n    即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。\n2. 【强制】超过三个表禁止join。需要join的字段，数据类型保持绝对一致；多表关联查询时，\n    保证被关联的字段需要有索引。\n    说明：即使双表join也要注意表索引、SQL性能。\n3. 【强制】在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据\n    实际文本区分度决定索引长度。\n\n\n```\n说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%\n以上，可以使用count(distinct left(列名, 索引长度))/count(*)的区分度来确定。\n```\n4. 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。\n    说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。\n5. 【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索\n    引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。\n    正例：where a=? and b=? order by c; 索引：a_b_c\n    反例：索引如果存在范围查询，那么索引有序性无法利用，如：WHERE a>10 ORDER BY b; 索引a_b无\n    法排序。\n6. 【推荐】利用覆盖索引来进行查询操作，避免回表。\n    说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这\n    个目录就是起到覆盖索引的作用。\n    正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效\n    果，用explain的结果，extra列会出现：using index。\n7. 【推荐】利用延迟关联或者子查询优化超多分页场景。\n    说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当\n    offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL\n    改写。\n    正例：先快速定位需要获取的id段，然后再关联：\n    SELECT t1.* FROM 表 1 as t1, (select id from 表1 where 条件 LIMIT 100000,20 ) as t2 where t1.id=t2.id\n8. 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts\n    最好。\n    说明：\n    1 ） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。\n    2 ） ref 指的是使用普通的索引（normal index）。\n    3 ） range 对索引进行范围检索。\n    反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range\n    还低，与全表扫描是小巫见大巫。\n9. 【推荐】建组合索引的时候，区分度最高的在最左边。\n    正例：如果where a=? and b=?，a列的几乎接近于唯一值，那么只需要单建idx_a索引即可。\n    说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where c>? and d=?\n    那么即使c的区分度更高，也必须把d放在索引的最前列，即建立组合索引idx_d_c。\n10. 【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。\n\n\n11. 【参考】创建索引时避免有如下极端误解：\n    1 ） 索引宁滥勿缺。认为一个查询就需要建一个索引。\n    2 ） 吝啬索引的创建。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。\n    3 ） 抵制惟一索引。认为惟一索引一律需要在应用层通过“先查后插”方式解决。\n\n### (三) SQL语句\n\n1. 【强制】不要使用count(列名)或count(常量)来替代count(*)，count(*)是SQL92定义的标\n    准统计行数的语法，跟数据库无关，跟NULL和非NULL无关。\n    说明：count(*)会统计值为NULL的行，而count(列名)不会统计此列为NULL值的行。\n2. 【强制】count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1,\n    col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为 0 。\n3. 【强制】当某一列的值全是NULL时，count(col)的返回结果为 0 ，但sum(col)的返回结果为\n    NULL，因此使用sum()时需注意NPE问题。\n    正例：可以使用如下方式来避免sum的NPE问题：SELECT IFNULL(SUM(column), 0) FROM table;\n4. 【强制】使用ISNULL()来判断是否为NULL值。\n    说明：NULL与任何值的直接比较都为NULL。\n    1 ） NULL<>NULL的返回结果是NULL，而不是false。\n    2 ） NULL=NULL的返回结果是NULL，而不是true。\n    3 ） NULL<>1的返回结果是NULL，而不是true。\n    反例：在SQL语句中，如果在null前换行，影响可读性。select * from table where column1 is null and\n    column3 is not null; 而`ISNULL(column)`是一个整体，简洁易懂。从性能数据上分析，`ISNULL(column)`\n    执行效率更快一些。\n5. 【强制】代码中写分页查询逻辑时，若count为 0 应直接返回，避免执行后面的分页语句。\n6. 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。\n    说明：（概念解释）学生表中的student_id是主键，那么成绩表中的student_id则为外键。如果更新学\n    生表中的student_id，同时触发成绩表中的student_id更新，即为级联更新。外键与级联更新适用于单机\n    低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库\n    的插入速度。\n7. 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。\n8. 【强制】数据订正（特别是删除或修改记录操作）时，要先select，避免出现误删除，确认无\n    误才能执行更新语句。\n\n\n9. 【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或\n    表名）进行限定。\n    说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且\n    操作列在多个表中存在时，就会抛异常。\n    正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id;\n    反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在\n    某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column\n    'name' in field list is ambiguous。\n10. 【推荐】SQL语句中表的别名前加as，并且以t1、t2、t3、...的顺序依次命名。\n    说明： 1 ）别名可以是表的简称，或者是依照表在SQL语句中出现的顺序，以t1、t2、t3的方式命名。 2 ）\n    别名前加as使别名更容易识别。\n    正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id;\n11. 【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控\n    制在 1000 个之内。\n12. 【参考】因国际化需要，所有的字符存储与表示，均采用utf 8 字符集，那么字符计数方法需\n    要注意。\n    说明：\n    SELECT LENGTH(\"轻松工作\")； 返回为 12\n    SELECT CHARACTER_LENGTH(\"轻松工作\")； 返回为 4\n    如果需要存储表情，那么选择utf 8 mb4来进行存储，注意它与utf 8 编码的区别。\n13. 【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE\n    无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句。\n    说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。\n\n### (四) ORM映射\n\n1. 【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。\n    说明： 1 ）增加查询分析器解析成本。 2 ）增减字段容易与resultMap配置不一致。 3 ）无用字段增加网络\n    消耗，尤其是text类型的字段。\n2. 【强制】POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行\n    字段与属性之间的映射。\n    说明：参见定义POJO类以及数据库字段定义规定，在sql.xml增加映射，是必须的。\n\n\n3. 【强制】不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要\n    定义<resultMap>；反过来，每一个表也必然有一个<resultMap>与之对应。\n    说明：配置映射关系，使字段与DO类解耦，方便维护。\n4. 【强制】sql.xml配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现SQL注入。\n5. 【强制】iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用。\n说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取\nstart,size的子集合。\n正例：\nMap<String, Object> map = new HashMap<>( 16 );\nmap.put(\"start\", start);\nmap.put(\"size\", size);\n6. 【强制】不允许直接拿HashMap与Hashtable作为查询结果集的输出。\n    反例：某同学为避免写一个<resultMap>xxx</resultMap>，直接使用HashTable来接收数据库返回结\n    果，结果出现日常是把bigint转成Long值，而线上由于数据库版本不一样，解析成BigInteger，导致线\n    上问题。\n7. 【强制】更新数据表记录时，必须同时更新记录对应的update_time字段值为当前时间。\n8. 【推荐】不要写一个大而全的数据更新接口。传入为POJO类，不管是不是自己的目标更新字\n    段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，\n    不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储。\n9. 【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需\n    要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。\n10. 【参考】<isEqual>中的compareValue是与属性值对比的常量，一般是数字，表示相等时\n    带上此条件；<isNotEmpty>表示不为空且不为null时执行；<isNotNull>表示不为null值\n    时执行。\n\n\n## 六、工程结构\n\n### (一) 应用分层\n\n1. 【推荐】根据业务架构实践，结合业界分层规范与流行技术框架分析，推荐分层结构如图所示，\n    默认上层依赖于下层，箭头关系表示可直接依赖，如：开放API层可以依赖于Web层\n    （Controller层），也可以直接依赖于Service层，依此类推：\n       - 开放API层：可直接封装Service接口暴露成RPC接口；通过Web封装成http接口；网关控制层等。\n       - 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移\n          动端展示等。\n       - Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。\n       - Service层：相对具体的业务逻辑服务层。\n       - Manager层：通用业务处理层，它有如下特征：\n          1 ） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。\n          2 ） 对Service层通用能力的下沉，如缓存方案、中间件通用处理。\n          3 ） 与DAO层交互，对多个DAO的组合复用。\n       - DAO层：数据访问层，与底层MySQL、Oracle、Hbase、OB等进行数据交互。\n       - 第三方服务：包括其它部门RPC服务接口，基础平台，其它公司的HTTP接口，如淘宝开放平台、支\n          付宝付款服务、高德地图服务等。\n       - 外部数据接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。\n2. 【参考】（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进\n行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因\n为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，\n\n\n```\n浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，\n相当于保护案发现场。Manager层与Service同机部署，日志方式与DAO层处理一致，如果是\n单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处\n于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，\n尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。\n```\n3. 【参考】分层领域模型规约：\n    - DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。\n    - DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。\n    - BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。\n    - Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用Map类\n       来传输。\n    - VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。\n\n### (二) 二方库依赖\n\n1. 【强制】定义GAV遵从以下规则：\n    1 ） GroupID格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。\n    说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。\n    正例：com.taobao.jstorm 或 com.alibaba.dubbo.register\n    2 ） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。\n    正例：dubbo-client / fastjson-api / jstorm-tool\n    3 ） Version：详细规定参考下方。\n2. 【强制】二方库版本号命名方式：主版本号.次版本号.修订号\n1 ）主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。\n2 ） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。\n3 ） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。\n说明：注意起始版本号必须为：1.0.0，而不是0.0.1。\n反例：仓库内某二方库版本号从1.0.0.0开始，一直默默“升级”成1.0.0.64，完全失去版本的语义信息。\n3. 【强制】线上应用不要依赖SNAPSHOT版本（安全包除外）；正式发布的类库必须先去中央仓\n    库进行查证，使RELEASE版本号有延续性，且版本号不允许覆盖升级。\n    说明：不依赖SNAPSHOT版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。\n4. 【强制】二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，\n    必须明确评估和验证。\n\n\n```\n说明：在升级时，进行dependency:resolve前后信息比对，如果仲裁结果完全不一致，那么通过\ndependency:tree命令，找出差异点，进行<exclude>排除jar包。\n```\n5. 【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚\n    举类型或者包含枚举类型的POJO对象。\n6. 【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。\n    说明：依赖springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版\n    本：${spring.version}，定义依赖的时候，引用该版本。\n7. 【强制】禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的\n    Version。\n    说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个war，只能有一个版本号出现在最后的\n    lib目录中。曾经出现过线下调试是正确的，发布到线上却出故障的先例。\n8. 【推荐】底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现。\n9. 【推荐】所有pom文件中的依赖声明放在<dependencies>语句块中，所有版本仲裁放在\n    <dependencyManagement>语句块中。\n    说明：<dependencyManagement>里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，\n    version和scope都读取自父pom。而<dependencies>所有声明在主pom的<dependencies>里的依\n    赖都会自动引入，并默认被所有的子项目继承。\n10. 【推荐】二方库不要有配置项，最低限度不要再增加配置项。\n11. 【推荐】不要使用不稳定的工具包或者Utils类。\n    说明：不稳定指的是提供方无法做到向下兼容，在编译阶段正常，但在运行时产生异常，因此，尽量使用\n    业界稳定的二方工具包。\n12. 【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：\n    1 ） **精简可控原则** 。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、\n    常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log\n    具体实现，只依赖日志框架。\n    2 ） **稳定可追溯原则** 。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除\n    非用户主动升级版本，否则公共二方库的行为不应该发生变化。\n\n### (三) 服务器\n\n1. 【推荐】高并发服务器建议调小TCP协议的time_wait超时时间。\n    说明：操作系统默认 240 秒后，才会关闭处于time_wait状态的连接，在高并发访问下，服务器端会因为\n    处于time_wait的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。\n\n\n```\n正例：在linux服务器上请通过变更/etc/sysctl.conf文件去修改该缺省值（秒）：\nnet.ipv4.tcp_fin_timeout = 30\n```\n2. 【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）。\n    说明：主流操作系统的设计是将TCP/UDP连接采用与文件一样的方式去管理，即一个连接对应于一个fd。\n    主流的linux服务器默认所支持最大fd数量为 1024 ，当并发连接数很大时很容易因为fd不足而出现“open\n    too many files”错误，导致新的连接无法建立。建议将linux服务器所支持的最大句柄数调高数倍（与服\n    务器的内存数量相关）。\n3. 【推荐】给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM\n    场景时输出dump信息。\n    说明：OOM的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。\n4. 【推荐】在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整\n    堆大小带来的压力。\n5. 【参考】服务器内部重定向必须使用forward；外部重定向地址必须使用URL Broker生成，否\n    则因线上采用HTTPS协议而导致浏览器提示“不安全“。此外，还会带来URL维护不一致的\n    问题。\n\n\n## 七、设计规约\n\n1. 【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。\n    说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系\n    统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后，\n    需要进行double check。\n    正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发\n    展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段）\n    也需要进行评审通过后上线。\n2. 【强制】在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过 5 个，\n    使用用例图来表达更加清晰的结构化需求。\n3. 【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发\n    条件。\n    说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换\n    关系，再明确触发状态转换的条件是什么。\n    正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两\n    种状态之间是不可能有直接转换关系的。\n4. 【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确\n    各调用环节的输入与输出。\n    说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。\n5. 【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类\n    之间的关系。\n    说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造蚂蚁Z空间大楼，肯定需要详细\n    的施工图。\n6. 【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活\n    动图来表示。\n    说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。\n7. 【推荐】系统架构设计时明确以下目标：\n⚫ 确定系统边界。确定系统在技术层面上的做与不做。\n⚫ 确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。\n⚫ 确定指导后续设计与演化的原则。使后续的子系统或模块设计在一个既定的框架内和技术方向上继\n续演化。\n\n\n⚫ 确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。\n\n8. 【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。\n    反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演\n    练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。\n9. 【推荐】类在设计与实现时要符合单一原则。\n    说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。\n10. 【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。\n    说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现，\n    比如，“把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。\n11. 【推荐】系统设计阶段，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。\n    说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。\n12. 【推荐】系统设计阶段，注意对扩展开放，对修改闭合。\n    说明：极端情况下，交付的代码是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。\n13. 【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方\n法等，在系统中不出现重复代码的情况，即DRY原则（Don't Repeat Yourself）。\n说明：随着代码的重复次数不断增加，维护成本指数级上升。随意复制和粘贴代码，必然会导致代码的重复，\n在维护代码时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。\n正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取：\nprivate boolean checkParam(DTO dto) {...}\n14. 【推荐】避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布。\n说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上\n的必要设计和文档沉淀是需要的。\n反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样\n的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。\n15. 【参考】设计文档的作用是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。\n    说明：避免为了设计而设计，系统设计文档有助于后期的系统维护和重构，所以设计结果需要进行分类归\n    档保存。\n16. 【参考】可扩展性的本质是找到系统的变化点，并隔离变化点。\n    说明：世间众多设计模式其实就是一种设计模式即隔离变化点的模式。\n    正例：极致扩展性的标志，就是需求的新增，不会在原有代码交付物上进行任何形式的修改。\n\n\n17. 【参考】设计的本质就是识别和表达系统难点。\n    说明：识别和表达完全是两回事，很多人错误地认为识别到系统难点在哪里，表达只是自然而然的事情，\n    但是大家在设计评审中经常出现语焉不详，甚至是词不达意的情况。准确地表达系统难点需要具备如下能\n    力： 表达规则和表达工具的熟练性。抽象思维和总结能力的局限性。基础知识体系的完备性。深入浅出的\n    生动表达力。\n18. 【参考】代码即文档的观点是错误的，清晰的代码只是文档的某个片断，而不是全部。\n    说明：代码的深度调用，模块层面上的依赖关系网，业务场景逻辑，非功能性需求等问题是需要相应的文\n    档来完整地呈现的。\n19. 【参考】在做无障碍产品设计时，需要考虑到：\n\n```\n⚫ 所有可交互的控件元素必须能被tab键聚焦，并且焦点顺序需符合自然操作逻辑。\n⚫ 用于登录校验和请求拦截的验证码均需提供图形验证以外的其它方式。\n⚫ 自定义的控件类型需明确交互方式。\n正例：用户登录场景中，输入框的按钮都需要考虑tab键聚焦，符合自然逻辑的操作顺序如下，“输入用\n户名，输入密码，输入验证码，点击登录”，其中验证码实现语音验证方式。如果有自定义标签实现的控\n件设置控件类型可使用role属性。\n```\n\n## 附 1 ：版本历史\n\n#### 版本号 版本名 发布日期 备注\n\n#### -- - - 2 016.12.07 试读版本首次对外发布\n\n#### 1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布\n\n#### 1.0.1 - - 2017. 0 2. 13\n\n```\n1 ）修正String[]的前后矛盾。\n2 ）vm修正成velocity。\n3 ）修正countdown描述错误。\n```\n#### 1.0.2 - - 2017. 0 2.20\n\n#### 1 ）去除文底水印。\n\n#### 2 ）数据类型中引用太阳系年龄问题。\n\n#### 3 ）修正关于异常和方法签名的部分描述。\n\n```\n4 ）修正final描述。\n5 ）去除Comparator部分描述。\n```\n#### 1 .1.0 - - 2017. 0 2.27\n\n#### 1 ）增加前言。\n\n```\n2 ）增加<? extends T>描述和说明。\n3 ）增加版本历史。\n4 ）增加专有名词解释。\n```\n#### 1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。\n\n#### 1.2.0 完美版 2017. 0 5.20\n\n#### 1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\n\n```\n2 ）增加final的适用场景描述。\n3 ）增加关于锁的粒度的说明。\n4 ）增加“指定集合大小”的详细说明以及正反例。\n5 ）增加卫语句的示例代码。\n6 ）明确数据库表示删除概念的字段名为is_deleted\n```\n#### 1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\n\n```\n1.3.1 纪念版 2017.11.30 修正部分描述；采用和P3C开源IDE检测插件相同的Apache2.0协议。\n1.4.0 详尽版 2018. 0 5.20 增加设计规约大类，共 16 条。\n```\n\n#### 版本号 版本名 发布日期 备注\n\n#### 1 .5.0 华山版 2 019.0 6. 19\n\n```\n1 ）鉴于本手册是社区开发者集体智慧的结晶，本版本移除阿里巴巴Java开发手册的\n限定词“阿里巴巴”。\n2 ）新增 21 条新规约。比如，switch的NPE问题、浮点数的比较、无泛型限制、锁的\n使用方式、判断表达式、日期格式等。\n3 ）修改描述 112 处。比如，IFNULL的判断、集合的toArray、日志处理等。\n4 ）完善若干处示例。比如，命名示例、卫语句示例、enum示例、finally的return\n示例等。\n```\n#### 1.6.0\n\n#### 泰山版\n\n#### 2020.04.22\n\n#### 1 ）发布错误码统一解决方案，详细参考 附表 3 。\n\n#### 2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\n\n```\n查询的表别名限定，Collectors类的toMap()方法使用注意等。\n3 ）修改描述 90 处。比如，阻塞等待锁、建表的小数类型等。\n4 ）完善若干处示例。比如，ISNULL的示例等。\n```\n#### 1. 7. 0 嵩山版 2020.0 8. 03\n\n#### 1 ）新增前后端规约 14 条。\n\n#### 2 ）新增禁止任何歧视性用语的约定。\n\n#### 3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。\n\n```\n4 ）修正BigDecimal类中关于compareTo和equals的等值比较。\n5 ）修正HashMap关于 1024 个元素扩容的次数。\n6 ）修正架构分层规范与相关说明。\n7 ）修正泰山版中部分格式错误和描述错误。\n```\n\n## 附 2 ：专有名词解释\n\n1. POJO（Plain Ordinary Java Object）: 在本规约中，POJO专指只有setter/getter/toString的\n    简单类，包括DO/DTO/BO/VO等。\n2. DO（Data Object）：阿里巴巴专指数据库表一一对应的POJO类。此对象与数据库表结构一\n    一对应，通过DAO层向上传输数据源对象。\n3. DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。\n4. BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。\n5. Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用\n    Map类来传输。\n6. VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。\n7. AO（Application Object）: 阿里巴巴专指Application Object，即在Service层上，极为贴近\n    业务的复用代码。\n8. CAS（Compare And Swap）：解决多线程并行情况下使用锁造成性能损耗的一种机制，这是\n    硬件实现的原子操作。CAS操作包含三个操作数：内存位置、预期原值和新值。如果内存位\n    置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何\n    操作。\n9. GAV（GroupId、ArtifactId、Version）: Maven坐标，是用来唯一标识jar包。\n10. OOP（Object Oriented Programming）: 本文泛指类、对象的编程处理方式。\n11. AQS（AbstractQueuedSynchronizer）: 利用先进先出队列实现的底层同步工具类，它是很多上\n    层同步实现类的基础，比如：ReentrantLock、CountDownLatch、Semaphore等，它们通\n    过继承AQS实现其模版方法，然后将AQS子类作为同步组件的内部类，通常命名为Sync。\n12. ORM（Object Relation Mapping）: 对象关系映射，对象领域模型与底层数据之间的转换，本\n    文泛指iBATIS, mybatis等框架。\n13. NPE（java.lang.NullPointerException）: 空指针异常。\n14. OOM（Out Of Memory）: 源于 java.lang.OutOfMemoryError，当 JVM 没有足够的内存\n    来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。\n15. 一方库: 本工程内部子项目模块依赖的库（jar 包）。\n16. 二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar 包）。\n17. 三方库: 公司之外的开源库（jar 包）。\n\n\n## 附 3 ：错误码列表\n\n#### 错误码 中文描述 说明\n\n```\n00000 一切ok 正确执行后的返回\nA0001 用户端错误 一级宏观错误码\nA0100 用户注册错误 二级宏观错误码\nA0101 用户未同意隐私协议\nA0102 注册国家或地区受限\nA0110 用户名校验失败\nA0111 用户名已存在\nA0112 用户名包含敏感词\nA0113 用户名包含特殊字符\nA0120 密码校验失败\nA0121 密码长度不够\nA0122 密码强度不够\nA0130 校验码输入错误\nA0131 短信校验码输入错误\nA0132 邮件校验码输入错误\nA0133 语音校验码输入错误\nA0140 用户证件异常\nA0141 用户证件类型未选择\nA0142 大陆身份证编号校验非法\nA0143 护照编号校验非法\nA0144 军官证编号校验非法\nA0150 用户基本信息校验失败\nA0151 手机格式校验失败\nA0152 地址格式校验失败\nA0153 邮箱格式校验失败\nA0200 用户登录异常 二级宏观错误码\nA0201 用户账户不存在\n```\n\n#### A0202 用户账户被冻结\n\n#### A0203 用户账户已作废\n\n#### A0210 用户密码错误\n\n#### A0211 用户输入密码错误次数超限\n\n#### A0220 用户身份校验失败\n\n#### A0221 用户指纹识别失败\n\n#### A0222 用户面容识别失败\n\n#### A0223 用户未获得第三方登录授权\n\n#### A0230 用户登录已过期\n\n#### A0240 用户验证码错误\n\n#### A0241 用户验证码尝试次数超限\n\nA0300 访问权限异常 二级宏观错误码\n\nA0301 访问未授权\n\nA0302 正在授权中\n\nA0303 用户授权申请被拒绝\n\nA0310 因访问对象隐私设置被拦截\n\nA0311 授权已过期\n\nA0312 无权限使用API\n\nA0320 用户访问被拦截\n\nA0321 黑名单用户\n\nA0322 账号被冻结\n\nA0323 非法IP地址\n\nA0324 网关访问受限\n\nA0325 地域黑名单\n\nA0330 服务已欠费\n\nA0340 用户签名异常\n\nA0341 RSA签名错误\n\nA0400 用户请求参数错误 二级宏观错误码\n\nA0401 包含非法恶意跳转链接\n\nA0402 无效的用户输入\n\n\n#### A0410 请求必填参数为空\n\n#### A0411 用户订单号为空\n\n#### A0412 订购数量为空\n\n#### A0413 缺少时间戳参数\n\n#### A0414 非法的时间戳参数\n\n#### A0420 请求参数值超出允许的范围\n\n#### A0421 参数格式不匹配\n\n#### A0422 地址不在服务范围\n\n#### A0423 时间不在服务范围\n\n#### A0424 金额超出限制\n\n#### A0425 数量超出限制\n\n#### A0426 请求批量处理总个数超出限制\n\n#### A0427 请求JSON解析失败\n\n#### A0430 用户输入内容非法\n\n#### A0431 包含违禁敏感词\n\n#### A0432 图片包含违禁信息\n\n#### A0433 文件侵犯版权\n\n#### A0440 用户操作异常\n\n#### A0441 用户支付超时\n\n#### A0442 确认订单超时\n\n#### A0443 订单已关闭\n\nA0500 用户请求服务异常 二级宏观错误码\n\nA0501 请求次数超出限制\n\nA0502 请求并发数超出限制\n\nA0503 用户操作请等待\n\nA0504 WebSocket连接异常\n\nA0505 WebSocket连接断开\n\nA0506 用户重复请求\n\nA0600 用户资源异常 二级宏观错误码\n\nA0601 账户余额不足\n\n\n#### A0602 用户磁盘空间不足\n\n#### A0603 用户内存空间不足\n\n#### A0604 用户OSS容量不足\n\n#### A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数\n\n#### A0700 用户上传文件异常 二级宏观错误码\n\n#### A0701 用户上传文件类型不匹配\n\n#### A0702 用户上传文件太大\n\n#### A0703 用户上传图片太大\n\n#### A0704 用户上传视频太大\n\n#### A0705 用户上传压缩文件太大\n\n#### A0800 用户当前版本异常 二级宏观错误码\n\n#### A0801 用户安装版本与系统不匹配\n\n#### A0802 用户安装版本过低\n\n#### A0803 用户安装版本过高\n\n#### A0804 用户安装版本已过期\n\n#### A0805 用户API请求版本不匹配\n\n#### A0806 用户API请求版本过高\n\n#### A0807 用户API请求版本过低\n\n#### A0900 用户隐私未授权 二级宏观错误码\n\n#### A0901 用户隐私未签署\n\n#### A0902 用户摄像头未授权\n\n#### A0903 用户相机未授权\n\n#### A0904 用户图片库未授权\n\n#### A0905 用户文件未授权\n\n#### A0906 用户位置信息未授权\n\n#### A0907 用户通讯录未授权\n\n#### A1000 用户设备异常 二级宏观错误码\n\n#### A1001 用户相机异常\n\n#### A1002 用户麦克风异常\n\n#### A1003 用户听筒异常\n\n\n#### A1004 用户扬声器异常\n\n#### A1005 用户GPS定位异常\n\n#### -\n\n-\n\n#### B0001 系统执行出错 一级宏观错误码\n\n#### B0100 系统执行超时 二级宏观错误码\n\n#### B0101 系统订单处理超时\n\n#### B0200 系统容灾功能被触发 二级宏观错误码\n\n#### B0210 系统限流\n\n#### B0220 系统功能降级\n\n#### B0300 系统资源异常 二级宏观错误码\n\n#### B0310 系统资源耗尽\n\n#### B0311 系统磁盘空间耗尽\n\n#### B0312 系统内存耗尽\n\n#### B0313 文件句柄耗尽\n\n#### B0314 系统连接池耗尽\n\n#### B0315 系统线程池耗尽\n\n#### B0320 系统资源访问异常\n\n#### B0321 系统读取磁盘文件失败\n\n#### -\n\n#### -\n\n#### C0001 调用第三方服务出错 一级宏观错误码\n\n#### C0100 中间件服务出错 二级宏观错误码\n\n#### C0110 RPC服务出错\n\n#### C0111 RPC服务未找到\n\n#### C0112 RPC服务未注册\n\n#### C0113 接口不存在\n\n#### C0120 消息服务出错\n\n#### C0121 消息投递出错\n\n#### C0122 消息消费出错\n\n#### C0123 消息订阅出错\n\n#### C0124 消息分组未查到\n\n\n#### C0130 缓存服务出错\n\nC0131 key长度超过限制\n\nC0132 value长度超过限制\n\nC0133 存储容量已满\n\nC0134 不支持的数据格式\n\nC0140 配置服务出错\n\nC0150 网络资源服务出错\n\nC0151 VPN服务出错\n\nC0152 CDN服务出错\n\nC0153 域名解析服务出错\n\nC0154 网关服务出错\n\nC0200 第三方系统执行超时 二级宏观错误码\n\nC0210 RPC执行超时\n\nC0220 消息投递超时\n\nC0230 缓存服务超时\n\nC0240 配置服务超时\n\nC0250 数据库服务超时\n\nC0300 数据库服务出错 二级宏观错误码\n\nC0311 表不存在\n\nC0312 列不存在\n\nC0321 多表关联中存在多个相同名称的列\n\nC0331 数据库死锁\n\nC0341 主键冲突\n\nC0400 第三方容灾系统被触发 二级宏观错误码\n\nC0401 第三方系统限流\n\nC0402 第三方功能降级\n\nC0500 通知服务出错 二级宏观错误码\n\nC0501 短信提醒服务失败\n\nC0502 语音提醒服务失败\n\nC0503 邮件提醒服务失败\n\n\n\n","slug":"阿里巴巴java开发手册-嵩山版","published":1,"updated":"2022-09-28T02:19:12.015Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl8lhl0l3000xekwe3q9ueif7","content":"<p>阿里巴巴java开发手册-嵩山版<span id=\"more\"></span></p>\n<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>《Java开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一</p>\n<p>线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理</p>\n<p>成册，当前的版本是 <strong>嵩山版</strong> 。现代软件行业的高速发展对开发者的综合素质要求越来越高，因为不仅</p>\n<p>是编程知识点，其它维度的知识点也会影响到软件的最终交付质量。比如：五花八门的错误码人为地</p>\n<p>增加排查问题的难度；数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险；工程结构混</p>\n<p>乱导致后续项目维护艰难；没有鉴权的漏洞代码易被黑客攻击等等。所以本手册以Java开发者为中</p>\n<p>心视角，划分为编程规约、异常日志、单元测试、安全规约、MySQL数据库、工程结构、设计规约</p>\n<p>七个维度，再根据内容特征，细分成若干二级子目录。另外，依据约束力强弱及故障敏感性，规约依</p>\n<p>次分为【强制】、【推荐】、【参考】三大类。在延伸信息中，“说明”对规约做了适当扩展和解释；</p>\n<p>“正例”提倡什么样的编码和实现方式；“反例”说明需要提防的雷区，以及真实的错误案例。</p>\n<p>手册的愿景是 <strong>码出高效，码出质量</strong> 。现代软件架构的复杂性需要协同开发完成，如何高效地协</p>\n<p>同呢？无规矩不成方圆，无规范难以协同，比如，制订交通法规表面上是要限制行车权，实际上是保</p>\n<p>障公众的人身安全，试想如果没有限速，没有红绿灯，谁还敢上路行驶？对软件来说，适当的规范和</p>\n<p>标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的统一方式一起</p>\n<p>做事，提升协作效率，降低沟通成本。代码的字里行间流淌的是软件系统的血液，质量的提升是尽可</p>\n<p>能少踩坑，杜绝踩重复的坑，切实提升系统稳定性，码出质量。</p>\n<p>我们已经在 2017 杭州云栖大会上发布了配套的Java开发规约IDE插件，下载量达到 162 万人</p>\n<p>次，阿里云效也集成了代码规约扫描引擎。次年，发布 36 万字的配套详解图书《码出高效》，本书</p>\n<p>秉持“图胜于表，表胜于言”的理念，深入浅出地将计算机基础、面向对象思想、JVM探源、数据</p>\n<p>结构与集合、并发与多线程、单元测试等知识客观、立体地呈现出来。紧扣学以致用、学以精进的目</p>\n<p>标，结合阿里巴巴实践经验和故障案例，与底层源码解析融会贯通，娓娓道来。《码出高效》和《Java</p>\n<p>开发手册》稿费所得收入均捐赠公益事情，希望用技术情怀帮助更多的人。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li>一、编程规约<ul>\n<li>(一) 命名风格</li>\n<li>(二) 常量定义</li>\n<li>(三) 代码格式</li>\n<li>(四) OOP规约</li>\n<li>(五) 日期时间</li>\n<li>(六) 集合处理</li>\n<li>(七) 并发处理</li>\n<li>(八) 控制语句</li>\n<li>(九) 注释规约</li>\n<li>(十) 前后端规约</li>\n<li>(十一) 其他</li>\n</ul>\n</li>\n<li>二、异常日志<ul>\n<li>(一) 错误码</li>\n<li>(二) 异常处理</li>\n<li>(三) 日志规约</li>\n</ul>\n</li>\n<li>三、单元测试</li>\n<li>四、安全规约</li>\n<li>五、MySQL数据库<ul>\n<li>(一) 建表规约</li>\n<li>(二) 索引规约</li>\n<li>(三) SQL语句</li>\n<li>(四) ORM映射</li>\n</ul>\n</li>\n<li>六、工程结构<ul>\n<li>(一) 应用分层</li>\n<li>(二) 二方库依赖</li>\n<li>(三) 服务器</li>\n</ul>\n</li>\n<li>七、设计规约</li>\n<li>附 1 ：版本历史</li>\n<li>附 2 ：专有名词解释</li>\n<li>附 3 ：错误码列表</li>\n</ul>\n<h2 id=\"一、编程规约\"><a href=\"#一、编程规约\" class=\"headerlink\" title=\"一、编程规约\"></a>一、编程规约</h2><h3 id=\"一-命名风格\"><a href=\"#一-命名风格\" class=\"headerlink\" title=\"(一) 命名风格\"></a>(一) 命名风格</h3><ol>\n<li>【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。<br> 反例：<em>name / <em><em>name / $name / name</em> / name$ / name</em></em></li>\n<li>【强制】所有编程相关的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。<br>说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，纯拼音命名方式更要避免采用。<br>正例：ali / alibaba / taobao / cainiao/ aliyun/ youku / hangzhou 等国际通用的名称，可视同英文。<br>反例：DaZhePromotion [打折] / getPingfenByName() [评分] / String fw[福娃] / int 某变量 = 3</li>\n<li>【强制】代码和注释中都要避免使用任何语言的种族歧视性词语。<br> 正例：日本人 / 印度人 / blockList / allowList / secondary<br> 反例：RIBENGUIZI / Asan / blackList / whiteList / slave</li>\n<li>【强制】类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO /<br> PO / UID等。<br> 正例：ForceCode / UserDO / HtmlDTO / XmlService / TcpUdpDeal / TaPromotion<br> 反例：forcecode / UserDo / HTMLDto / XMLService / TCPUDPDeal / TAPromotion</li>\n<li>【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格。<br> 正例： localValue / getHttpMessage() / inputUserId</li>\n<li>【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。<br> 正例：MAX_STOCK_COUNT / CACHE_EXPIRED_TIME<br> 反例：MAX_COUNT / EXPIRED_TIME</li>\n<li>【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类<br> 命名以它要测试的类的名称开始，以Test结尾。</li>\n<li>【强制】类型与中括号紧挨相连来表示数组。<br> 正例：定义整形数组int[] arrayDemo。<br> 反例：在main参数中，使用String args[]来定义。</li>\n<li>【强制】POJO类中的任何布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列<br> 化错误。</li>\n</ol>\n<h4 id=\"版本号-制定团队-更新日期-备注\"><a href=\"#版本号-制定团队-更新日期-备注\" class=\"headerlink\" title=\"版本号 制定团队 更新日期 备注\"></a>版本号 制定团队 更新日期 备注</h4><pre><code>1. 7. 0 阿里巴巴与全球Java社区开发者 2020. 08. 03 嵩山版，首次发布前后端规约\n</code></pre>\n<pre><code>说明：在本文MySQL规约中的建表约定第一条，表达是与否的变量采用is_xxx的命名方式，所以，需要\n在&lt;resultMap&gt;设置从is_xxx到xxx的映射关系。\n反例：定义为基本数据类型Boolean isDeleted的属性，它的方法也是isDeleted()，框架在反向解析的时\n候，“误以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。\n</code></pre>\n<ol start=\"10\">\n<li>【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用<br>单数形式，但是类名如果有复数含义，类名可以使用复数形式。<br>正例：应用工具类包名为com.alibaba.ei.kunlun.aap.util、类名为MessageUtils（此规则参考spring的<br>框架结构）</li>\n<li>【强制】避免在子父类的成员变量之间、或者不同代码块的局部变量之间采用完全相同的命名，<br>使可理解性降低。<br>说明：子类、父类成员变量名相同，即使是public类型的变量也能够通过编译，另外，局部变量在同一方<br>法内的不同代码块中同名也是合法的，这些情况都要避免。对于非setter/getter的参数名称也要避免与成<br>员变量名称相同。<br>反例：<br>public class ConfusingName {<br>public int stock;<br>// 非setter/getter的参数名称，不允许与本类成员变量同名<br>public void get(String alibaba) {<br>if (condition) {<br>final int money = 666 ;<br>// …<br>}<br>for (int i = 0 ; i &lt; 10 ; i++) {<br>// 在同一方法体中，不允许与其它代码块中的money命名相同<br>final int money = 15978 ;<br>// …<br>}<br>}<br>}<br>class Son extends ConfusingName {<br>// 不允许与父类的成员变量名称相同<br>public int stock;<br>}</li>\n<li>【强制】杜绝完全不规范的缩写，避免望文不知义。<br>反例：AbstractClass“缩写”成AbsClass；condition“缩写”成 condi；Function缩写”成Fu，此类<br>随意缩写严重降低了代码的可阅读性。</li>\n<li>【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组<br>合来表达。</li>\n</ol>\n<pre><code>正例：对某个对象引用的volatile字段进行原子更新的类名为AtomicReferenceFieldUpdater。\n反例：常见的方法内变量为int a;的定义方式。\n</code></pre>\n<ol start=\"14\">\n<li>【推荐】在常量与变量的命名时，表示类型的名词放在词尾，以提升辨识度。<br>正例：startTime / workQueue / nameList / TERMINATED_THREAD_COUNT<br>反例：startedAt / QueueOfWork / listName / COUNT_TERMINATED_THREAD</li>\n<li>【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。<br>说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。<br>正例： public class OrderFactory;<br>public class LoginProxy;<br>public class ResourceObserver;</li>\n<li>【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁<br>性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，确定<br>与接口方法相关，并且是整个应用的基础常量。<br>正例：接口方法签名 void commit();<br>接口基础常量 String COMPANY = “alibaba”;<br>反例：接口方法定义 public abstract void f();<br>说明：JDK8中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。</li>\n<li>接口和实现类的命名有两套规则：<br>1 ）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用<br>Impl的后缀与接口区别。<br>正例：CacheServiceImpl实现CacheService接口。<br>2 ）【推荐】如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able的形容词）。<br>正例：AbstractTranslator实现 Translatable接口。</li>\n<li>【参考】枚举类名带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。<br>说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。<br>正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS / UNKNOWN_REASON。</li>\n<li>【参考】各层命名规约：<br>A) Service/DAO层方法命名规约<br>1 ） 获取单个对象的方法用get做前缀。<br>2 ） 获取多个对象的方法用list做前缀，复数结尾，如：listObjects。<br>3 ） 获取统计值的方法用count做前缀。<br>4 ） 插入的方法用save/insert做前缀。<br>5 ） 删除的方法用remove/delete做前缀。<br>6 ） 修改的方法用update做前缀。<br>B) 领域模型命名规约</li>\n</ol>\n<pre><code>1 ） 数据对象：xxxDO，xxx即为数据表名。\n2 ） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。\n3 ） 展示对象：xxxVO，xxx一般为网页名称。\n4 ） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。\n</code></pre>\n<h3 id=\"二-常量定义\"><a href=\"#二-常量定义\" class=\"headerlink\" title=\"(二) 常量定义\"></a>(二) 常量定义</h3><ol>\n<li>【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。<br> 反例：<pre><code>// 本例中，开发者A定义了缓存的key，然后开发者B使用缓存时少了下划线，即key是&quot;Id#taobao&quot;+tradeId，导致\n出现故障\nString key = &quot;Id#taobao_&quot; + tradeId;\ncache.put(key, value);\n</code></pre>\n</li>\n<li>【强制】在long或者Long赋值时，数值后使用大写字母L，不能是小写字母l，小写容易跟<br>数字混淆，造成误解。<br>说明：Long a = 2l; 写的是数字的 21 ，还是Long型的 2 ？</li>\n<li>【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。<br> 说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解，也不利于维护。<pre><code>正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类SystemConfigConsts下。\n</code></pre>\n</li>\n<li>【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包<br> 内共享常量、类内共享常量。<br> 1 ） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。<br> 2 ） 应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。<br> 反例：易懂变量也要统一定义成应用内共享常量，两位工程师在两个类中分别定义了“YES”的变量：<br> 类A中：public static final String YES = “yes”;<br> 类B中：public static final String YES = “y”;<br> A.YES.equals(B.YES)，预期是true，但实际返回为false，导致线上问题。<pre><code>3 ） 子工程内部共享常量：即在当前子工程的constant目录下。\n4 ） 包内共享常量：即在当前包下单独的constant目录下。\n5 ） 类内共享常量：直接在类内部private static final定义。\n</code></pre>\n</li>\n<li>【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。<br> 说明：如果存在名称之外的延伸属性应使用enum类型，下面正例中的数字就是延伸信息，表示一年中的<br> 第几个季节。<br> 正例：<pre><code>public enum SeasonEnum &#123;\nSPRING( 1 ), SUMMER( 2 ), AUTUMN( 3 ), WINTER( 4 );\nprivate int seq;\nSeasonEnum(int seq) &#123;\n</code></pre>\n</li>\n</ol>\n<pre><code>this.seq = seq;\n&#125;\npublic int getSeq() &#123;\nreturn seq;\n&#125;\n&#125;\n</code></pre>\n<h3 id=\"三-代码格式\"><a href=\"#三-代码格式\" class=\"headerlink\" title=\"(三) 代码格式\"></a>(三) 代码格式</h3><ol>\n<li>【强制】如果是大括号内为空，则简洁地写成{}即可，大括号中间无需换行和空格；如果是非<br> 空代码块则：<br> 1 ） 左大括号前不换行。<br> 2 ） 左大括号后换行。<br> 3 ） 右大括号前换行。<br> 4 ） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。</li>\n<li>【强制】左小括号和右边相邻字符之间不出现空格；右小括号和左边相邻字符之间也不出现空<br>格；而左大括号前需要加空格。详见第 5 条下方正例提示。<br>反例：if (空格a == b空格)</li>\n<li>【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。</li>\n<li>【强制】任何二目、三目运算符的左右两边都需要加一个空格。<br> 说明：包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号等。</li>\n<li>【强制】采用 4 个空格缩进，禁止使用Tab字符。<br>说明：如果使用Tab缩进，必须设置 1 个Tab为 4 个空格。IDEA设置Tab为 4 个空格时，请勿勾选Use<br>tab character；而在Eclipse中，必须勾选insert spaces for tabs。<br>正例： （涉及 1 - 5 点）<br>public static void main(String[] args) {<br>// 缩进 4 个空格<br>String say = “hello”;<br>// 运算符的左右必须有一个空格<br>int flag = 0 ;<br>// 关键词if与括号之间必须有一个空格，括号内的f与左括号， 0 与右括号不需要空格<br>if (flag == 0 ) {<br>System.out.println(say);<br>}<br>// 左大括号前加空格且不换行；左大括号后换行<br>if (flag == 1 ) {<br>System.out.println(“world”);<br>// 右大括号前换行，右大括号后有else，不用换行<br>} else {<br>System.out.println(“ok”);<br>// 在右大括号后直接结束，则必须换行<br>}<br>}</li>\n</ol>\n<ol start=\"6\">\n<li>【强制】注释的双斜线与注释内容之间有且仅有一个空格。<br> 正例：<pre><code>// 这是示例注释，请注意在双斜线之后有一个空格\nString commentString = new String();\n</code></pre>\n</li>\n<li>【强制】在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。<br> 正例：<pre><code>double first = 3.2d;\nint second = (int)first + 2 ;\n</code></pre>\n</li>\n<li>【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：<br> 1 ）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。<br> 2 ）运算符与下文一起换行。<br> 3 ）方法调用的点符号与下文一起换行。<br> 4 ）方法调用中的多个参数需要换行时，在逗号后进行。<br> 5 ）在括号前不要换行，见反例。<br> 正例：<pre><code>StringBuilder sb = new StringBuilder();\n// 超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点号一起换行\nsb.append(&quot;yang&quot;).append(&quot;hao&quot;)...\n.append(&quot;chen&quot;)...\n.append(&quot;chen&quot;)...\n.append(&quot;chen&quot;);\n</code></pre>\n 反例：<pre><code>StringBuilder sb = new StringBuilder();\n// 超过 120 个字符的情况下，不要在括号前换行\nsb.append(&quot;you&quot;).append(&quot;are&quot;)...append\n(&quot;lucky&quot;);\n// 参数很多的方法调用可能超过 120 个字符，逗号后才是换行处\nmethod(args1, args2, args3, ...\n, argsX);\n</code></pre>\n</li>\n<li>【强制】方法参数在定义和传入时，多个参数逗号后面必须加空格。<br> 正例：下例中实参的args1，后边必须要有一个空格。<pre><code>method(args1, args2, args3);\n</code></pre>\n</li>\n<li>【强制】IDE的text file encoding设置为UTF-8; IDE中文件的换行符使用Unix格式，不要<br>使用Windows格式。</li>\n<li>【推荐】单个方法的总行数不超过 80 行。<br>说明：除注释之外的方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过<br>80 行。<br>正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共<br>性逻辑抽取成为共性方法，便于复用和维护。</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐。<br>正例：<br>   int one = 1 ;<br>   long two = 2 L;<br>   float three = 3F;<br>   StringBuilder sb = new StringBuilder();<br>说明：增加sb这个变量，如果需要对齐，则给one、two、three都要增加几个空格，在变量比较多的情<br>况下，是非常累赘的事情。</li>\n<li>【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。<br>说明：任何情形，没有必要插入多个空行进行隔开。</li>\n</ol>\n<h3 id=\"四-OOP规约\"><a href=\"#四-OOP规约\" class=\"headerlink\" title=\"(四) OOP规约\"></a>(四) OOP规约</h3><ol>\n<li>【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成<br> 本，直接用类名来访问即可。</li>\n<li>【强制】所有的覆写方法，必须加@Override注解。<br> 说明：getObject()与get0bject()的问题。一个是字母的O，一个是数字的 0 ，加@Override可以准确判<br> 断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。</li>\n<li>【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。<br>说明：可变参数必须放置在参数列表的最后。（建议开发者尽量不用可变参数编程）<br>正例：public List<User> listUsers(String type, Long… ids) {…}</li>\n<li>【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生<br> 影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。</li>\n<li>【强制】不能使用过时的类或方法。<br> 说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数<br> decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；<br> 作为调用方来说，有义务去考证过时方法的新实现是什么。</li>\n<li>【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。<br> 正例：”test”.equals(object);<br> 反例：object.equals(“test”);<br> 说明：推荐使用JDK7引入的工具类java.util.Objects#equals(Object a, Object b)</li>\n<li>【强制】所有整型包装类对象之间值的比较，全部使用equals方法比较。<br> 说明：对于Integer var =? 在- 128 至 127 之间的赋值，Integer对象是在 IntegerCache.cache产生，<br> 会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都<br> 会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。</li>\n</ol>\n<ol start=\"8\">\n<li>【强制】任何货币金额，均以最小货币单位且整型类型来进行存储。</li>\n<li>【强制】浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用equals<br>来判断。<br>说明：浮点数采用“尾数+阶码”的编码方式，类似于科学计数法的“有效数字+指数”的表示方式。二进<br>制无法精确表示大部分的十进制小数，具体原理参考《码出高效》。<br>反例：<br>float a = 1.0F - 0.9F;<br>float b = 0.9F - 0.8F;<br>if (a == b) {<br>// 预期进入此代码块，执行其它业务逻辑<br>// 但事实上a==b的结果为false<br>}<br>Float x = Float.valueOf(a);<br>Float y = Float.valueOf(b);<br>if (x.equals(y)) {<br>// 预期进入此代码块，执行其它业务逻辑<br>// 但事实上equals的结果为false<br>}<br>正例：<br>(1) 指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。<br>float a = 1.0F - 0.9F;<br>float b = 0.9F - 0.8F;<br>float diff = 1e- 6 F;<br>if (Math.abs(a - b) &lt; diff) {<br>System.out.println(“true”);<br>}<br>(2) 使用BigDecimal来定义值，再进行浮点数的运算操作。<br>BigDecimal a = new BigDecimal(“1.0”);<br>BigDecimal b = new BigDecimal(“0.9”);<br>BigDecimal c = new BigDecimal(“0.8”);<br>BigDecimal x = a.subtract(b);<br>BigDecimal y = b.subtract(c);<br>if (x.compareTo(y) == 0 ) {<br>System.out.println(“true”);<br>}</li>\n<li>【强制】如上所示BigDecimal的等值比较应使用compareTo()方法，而不是equals()方法。<br>说明：equals()方法会比较值和精度（ 1 .0与 1 .00返回结果为false），而compareTo()则会忽略精度。</li>\n<li>【强制】定义数据对象DO类时，属性类型要与数据库字段类型相匹配。<br>正例：数据库字段的bigint必须与类属性的Long类型相对应。<br>反例：某个案例的数据库表id字段定义类型bigint unsigned，实际类对象属性为Integer，随着id越来<br>越大，超过Integer的表示范围而溢出成为负数。</li>\n</ol>\n<ol start=\"12\">\n<li>【强制】禁止使用构造方法BigDecimal(double)的方式把double值转化为BigDecimal对象。<br>说明：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。<br>如：BigDecimal g = new BigDecimal(0.1F); 实际的存储值为：0.<br>正例：优先推荐入参为String的构造方法，或使用BigDecimal的valueOf方法，此方法内部其实执行了<br>Double的toString，而Double的toString按double的实际能表达的精度对尾数进行了截断。<br>BigDecimal recommend1 = new BigDecimal(“0.1”);<br>BigDecimal recommend2 = BigDecimal.valueOf(0.1);</li>\n<li>关于基本数据类型与包装数据类型的使用标准如下：<br>1 ） 【强制】所有的POJO类属性必须使用包装数据类型。<br>2 ） 【强制】RPC方法的返回值和参数必须使用包装数据类型。<br>3 ） 【推荐】所有的局部变量使用基本数据类型。<br>说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或<br>者入库检查，都由使用者来保证。<br>正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。<br>反例：某业务的交易报表上显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调<br>用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线-。所以包装数据类型<br>的null值，能够表示额外的信息，如：远程调用失败，异常退出。</li>\n<li>【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。<br>反例：POJO类的createTime默认值为new Date()，但是这个属性在数据提取时并没有置入具体值，在<br>更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。</li>\n<li>【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果<br>完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。<br>说明：注意serialVersionUID不一致会抛出序列化运行时异常。</li>\n<li>【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。</li>\n<li>【强制】POJO类必须写toString方法。使用IDE中的工具：source&gt; generate toString<br>时，如果继承了另一个POJO类，注意在前面加一下super.toString。<br>说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。</li>\n<li>【强制】禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法。<br>说明：框架在调用属性xxx的提取方法时，并不能确定哪个方法一定是被优先调用到的。</li>\n<li>【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容<br>的检查，否则会有抛IndexOutOfBoundsException的风险。<br>说明：<br>   String str = “a,b,c,,”;<br>   String[] ary = str.split(“,”);<br>   // 预期大于 3 ，结果是 3<br>   System.out.println(ary.length);</li>\n</ol>\n<ol start=\"20\">\n<li>【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便<br>于阅读，此条规则优先于下一条。</li>\n<li>【推荐】 类内方法定义的顺序依次是：公有方法或保护方法 &gt; 私有方法 &gt; getter / setter<br>方法。<br>说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可<br>能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载<br>的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。</li>\n<li>【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在<br>getter/setter方法中，不要增加业务逻辑，增加排查问题的难度。<br>反例：<br>public Integer getData () {<br>if (condition) {<br>return this.data + 100 ;<br>} else {<br>return this.data - 100 ;<br>}<br>}</li>\n<li>【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。<br>说明：下例中，反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append<br>操作，最后通过toString方法返回String对象，造成内存资源浪费。<br>反例：<br>String str = “start”;<br>for (int i = 0 ; i &lt; 100 ; i++) {<br>str = str + “hello”;<br>}</li>\n<li>【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字：<br>1 ） 不允许被继承的类，如：String类。<br>2 ） 不允许修改引用的域对象，如：POJO类的域变量。<br>3 ） 不允许被覆写的方法，如：POJO类的setter方法。<br>4 ） 不允许运行过程中重新赋值的局部变量。<br>5 ） 避免上下文重复使用一个变量，使用final关键字可以强制重新定义一个变量，方便更好地进行重构。</li>\n<li>【推荐】慎用Object的clone方法来拷贝对象。<br>说明：对象clone方法默认是浅拷贝，若想实现深拷贝，需覆写clone方法实现域对象的深度遍历式拷贝。</li>\n<li>【推荐】类成员与方法访问控制从严：<br>1 ） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。<br>2 ） 工具类不允许有public或default构造方法。<br>3 ） 类非static成员变量并且与子类共享，必须是protected。<br>4 ） 类非static成员变量并且仅在本类使用，必须是private。</li>\n</ol>\n<pre><code>5 ） 类static成员变量如果仅在本类使用，必须是private。\n6 ） 若是static成员变量，考虑是否为final。\n7 ） 类成员方法只供类内部调用，必须是private。\n8 ） 类成员方法只对继承类公开，那么限制为protected。\n说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果\n是一个private的方法，想删除就删除，可是一个public的service成员方法或成员变量，删除一下，不\n得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你\n会担心的。\n</code></pre>\n<h3 id=\"五-日期时间\"><a href=\"#五-日期时间\" class=\"headerlink\" title=\"(五) 日期时间\"></a>(五) 日期时间</h3><ol>\n<li>【强制】日期格式化时，传入pattern中表示年份统一使用小写的y。<br> 说明：日期格式化时，yyyy表示当天所在的年，而大写的YYYY代表是week in which year（JDK7之后<br> 引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY<br> 就是下一年。<br> 正例：表示日期和时间的格式如下所示：<br> new SimpleDateFormat(“yyyy-MM-dd HH:mm:ss”)</li>\n<li>【强制】在日期格式中分清楚大写的M和小写的m，大写的H和小写的h分别指代的意义。<br>说明：日期格式中的这两对字母表意如下：<br>1 ） 表示月份是大写的M；<br>2 ） 表示分钟则是小写的m；<br>3 ） 24 小时制的是大写的H；<br>4 ） 12 小时制的则是小写的h。</li>\n<li>【强制】获取当前毫秒数：System.currentTimeMillis(); 而不是new Date().getTime()。<br> 说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间<br> 等场景，推荐使用Instant类。</li>\n<li>【强制】不允许在程序任何地方中使用： 1 ）java.sql.Date。 2 ）java.sql.Time。<br>3 ）java.sql.Timestamp。<br>说明：第 1 个不记录时间，getHours()抛出异常；第 2 个不记录日期，getYear()抛出异常；第 3 个在构造<br>方法super((time/1000)*1000)，在Timestamp 属性fastTime和nanos分别存储秒和纳秒信息。<br>反例： java.util.Date.after(Date)进行时间比较时，当入参是java.sql.Timestamp时，会触发JDK<br>BUG(JDK9已修复)，可能导致比较时的意外结果。</li>\n<li>【强制】不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑<br>错误。</li>\n</ol>\n<pre><code>正例：\n// 获取今年的天数\nint daysOfThisYear = LocalDate.now().lengthOfYear();\n// 获取指定某年的天数\nLocalDate.of( 2011 , 1 , 1 ).lengthOfYear();\n反例：\n// 第一种情况：在闰年 366 天时，出现数组越界异常\nint[] dayArray = new int[ 365 ];\n// 第二种情况：一年有效期的会员制，今年 1 月 26 日注册，硬编码 365 返回的却是 1 月 25 日\nCalendar calendar = Calendar.getInstance();\ncalendar.set( 2020 , 1 , 26 );\ncalendar.add(Calendar.DATE, 365 );\n</code></pre>\n<ol start=\"6\">\n<li>【推荐】避免公历闰年 2 月问题。闰年的 2 月份有 29 天，一年后的那一天不可能是 2 月 29<br> 日。</li>\n<li>【推荐】使用枚举值来指代月份。如果使用数字，注意Date，Calendar等日期相关类的月份<br> month取值在 0 - 11 之间。<br> 说明：参考JDK原生注释，Month value is 0-based. e.g., 0 for January.<br> 正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或<br> 比较。</li>\n</ol>\n<h3 id=\"六-集合处理\"><a href=\"#六-集合处理\" class=\"headerlink\" title=\"(六) 集合处理\"></a>(六) 集合处理</h3><ol>\n<li>【强制】关于hashCode和equals的处理，遵循如下规则：<br> 1 ） 只要覆写equals，就必须覆写hashCode。<br> 2 ） 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须覆写<br> 这两种方法。<br> 3 ） 如果自定义对象作为Map的键，那么必须覆写hashCode和equals。<br> 说明：String因为覆写了hashCode和equals方法，所以可以愉快地将String对象作为key来使用。</li>\n<li>【强制】判断所有集合内部的元素是否为空，使用isEmpty()方法，而不是size()==0的方式。<br> 说明：在某些集合中，前者的时间复杂度为O(1)，而且可读性更好。<br> 正例：<pre><code>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;( 16 );\nif(map.isEmpty()) &#123;\nSystem.out.println(&quot;no element in this map.&quot;);\n&#125;\n</code></pre>\n</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要使<br> 用含有参数类型为BinaryOperator，参数名为mergeFunction的方法，否则当出现相同key<br> 值时会抛出IllegalStateException异常。<br> 说明：参数mergeFunction的作用是当出现key重复时，自定义对value的处理策略。<br> 正例：<pre><code>List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;( 3 );\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 12.10));\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 12.19));\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 6.28));\nMap&lt;String, Double&gt; map = pairArrayList.stream().collect(\n// 生成的map集合中只有一个键值对：&#123;version=6.2 8 &#125;\nCollectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - &gt; v2));\n</code></pre>\n 反例：<pre><code>String[] departments = new String[] &#123;&quot;iERP&quot;, &quot;iERP&quot;, &quot;EIBU&quot;&#125;;\n// 抛出IllegalStateException异常\nMap&lt;Integer, String&gt; map = Arrays.stream(departments)\n.collect(Collectors.toMap(String::hashCode, str -&gt; str));\n</code></pre>\n</li>\n<li>【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要注<br> 意当value为null时会抛NPE异常。<br> 说明：在java.util.HashMap的merge方法里会进行如下的判断：<pre><code>if (value == null || remappingFunction == null)\n   throw new NullPointerException();\n</code></pre>\n 反例：<pre><code>List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;( 2 );\npairArrayList.add(new Pair&lt;&gt;(&quot;version1&quot;, 8. 3 ));\npairArrayList.add(new Pair&lt;&gt;(&quot;version2&quot;, null));\nMap&lt;String, Double&gt; map = pairArrayList.stream().collect(\n// 抛出NullPointerException异常\nCollectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - &gt; v2));\n</code></pre>\n</li>\n<li>【强制】ArrayList的subList结果不可强转成ArrayList，否则会抛出 ClassCastException异<br> 常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。<br> 说明：subList()返回的是ArrayList的内部类SubList，并不是 ArrayList本身，而是ArrayList 的一个视<br> 图，对于SubList的所有操作最终会反映到原列表上。</li>\n<li>【强制】使用Map的方法keySet()/values()/entrySet()返回集合对象时，不可以对其进行添<br> 加元素操作，否则会抛出UnsupportedOperationException异常。</li>\n<li>【强制】Collections类返回的对象，如：emptyList()/singletonList()等都是immutable list，<br>不可对其进行添加或者删除元素的操作。<br>反例：如果查询无结果，返回Collections.emptyList()空集合对象，调用方一旦进行了添加元素的操作，就<br>会触发UnsupportedOperationException异常。</li>\n</ol>\n<ol start=\"8\">\n<li>【强制】在subList场景中，高度注意对父集合元素的增加或删除，均会导致子列表的遍历、<br> 增加、删除产生ConcurrentModificationException 异常。</li>\n<li>【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一<br>致、长度为 0 的空数组。<br>反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现<br>ClassCastException错误。<br>正例：<br>List<String> list = new ArrayList&lt;&gt;( 2 );<br>list.add(“guan”);<br>list.add(“bao”);<br>String[] array = list.toArray(new String[ 0 ]);<br>说明：使用toArray带参方法，数组空间大小的length：<br>1 ） 等于 0 ，动态创建与size相同的数组，性能最好。<br>2 ） 大于 0 但小于size，重新创建大小等于size的数组，增加GC负担。<br>3 ） 等于size，在高并发情况下，数组创建完成之后，size正在变大的情况下，负面影响与 2 相同。<br>4 ） 大于size，空间浪费，且在size处插入null值，存在NPE隐患。</li>\n<li>【强制】在使用Collection接口任何实现类的addAll()方法时，都要对输入的集合参数进行<br>NPE判断。<br>说明：在ArrayList#addAll方法的第一行代码即Object[] a = c.toArray(); 其中c为输入集合参数，如果<br>为null，则直接抛出异常。</li>\n<li>【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，<br>它的add/remove/clear方法会抛出UnsupportedOperationException异常。<br>说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配<br>器模式，只是转换接口，后台的数据仍是数组。<br>String[] str = new String[] { “chen”, “yang”, “hao” };<br>List list = Arrays.asList(str);<br>第一种情况：list.add(“yangguanbao”); 运行时异常。<br>第二种情况：str[0] = “change”; 也会随之修改，反之亦然。</li>\n<li>【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，<br>而&lt;? super T&gt;不能使用get方法，两者在接口调用赋值的场景中容易出错。<br>说明：扩展说一下PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用<? extends T>。第二、经常往里插入的，适合用<? super T></li>\n<li>【强制】在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行<br>instanceof判断，避免抛出ClassCastException异常。<br>说明：毕竟泛型是在JDK5后才出现，考虑到向前兼容，编译器是允许非泛型集合与泛型集合互相赋值。</li>\n</ol>\n<pre><code>反例：\nList&lt;String&gt; generics = null;\nList notGenerics = new ArrayList( 10 );\nnotGenerics.add(new Object());\nnotGenerics.add(new Integer( 1 ));\ngenerics = notGenerics;\n// 此处抛出ClassCastException异常\nString string = generics.get( 0 );\n</code></pre>\n<ol start=\"14\">\n<li>【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator<br>方式，如果并发操作，需要对Iterator对象加锁。<br>   正例：<pre><code>  List&lt;String&gt; list = new ArrayList&lt;&gt;();\n  list.add(&quot;1&quot;);\n  list.add(&quot;2&quot;);\n  Iterator&lt;String&gt; iterator = list.iterator();\n  while (iterator.hasNext()) &#123;\n  String item = iterator.next();\n  if (删除元素的条件) &#123;\n  iterator.remove();\n  &#125;\n  &#125;\n</code></pre>\n   反例：<pre><code>  for (String item : list) &#123;\n  if (&quot;1&quot;.equals(item)) &#123;\n  list.remove(item);\n  &#125;\n  &#125;\n</code></pre>\n   说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？</li>\n<li>【强制】在JDK 7 版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，<br>Collections.sort会抛IllegalArgumentException异常。<br>说明：三个条件如下<br>1 ） x，y的比较结果和y，x的比较结果相反。<br>2 ） x&gt;y，y&gt;z，则x&gt;z。<br>3 ） x=y，则x，z比较结果和y，z比较结果相同。<br>反例：下例中没有处理相等的情况，交换两个对象判断结果并不互反，不符合第一个条件，在实际使用中<br>可能会出现异常。<br>   new Comparator<Student>() {<br>   @Override<br>   public int compare(Student o1, Student o2) {<br>   return o1.getId() &gt; o2.getId()? 1 : - 1 ;<br>   }<br>   };</li>\n<li>【推荐】集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。<br>说明：菱形泛型，即diamond，直接使用&lt;&gt;来指代前边已经指定的类型。</li>\n</ol>\n<pre><code>正例：\n// diamond方式，即&lt;&gt;\nHashMap&lt;String, String&gt; userCache = new HashMap&lt;&gt;( 16 );\n// 全省略方式\nArrayList&lt;User&gt; users = new ArrayList( 10 );\n</code></pre>\n<ol start=\"17\">\n<li>【推荐】集合初始化时，指定集合初始值大小。<br>说明：HashMap使用HashMap(int initialCapacity) 初始化，如果暂时无法确定集合大小，那么指定默<br>认值（ 16 ）即可。<br>正例：initialCapacity = (需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loader factor）默认<br>为0.75，如果暂时无法确定初始值大小，请设置为 16 （即默认值）。<br>   反例： HashMap需要放置 1024 个元素，由于没有设置容量初始大小，随着元素增加而被迫不断扩容，<br>   resize()方法总共会调用 8 次，反复重建哈希表和数据迁移。当放置的集合元素个数达千万级时会影响程序<br>   性能。</li>\n<li>【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。<br>说明：keySet其实是遍历了 2 次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的<br>value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用<br>Map.forEach方法。<br>正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对<br>象；entrySet()返回的是K-V值组合集合。</li>\n<li>【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格：</li>\n</ol>\n<pre><code>集合类 Key Value Super 说明\nHashtable 不允许为null 不允许为null Dictionary 线程安全\nConcurrentHashMap 不允许为null 不允许为null AbstractMap 锁分段技术（JDK8:CAS）\nTreeMap 不允许为null 允许为null AbstractMap 线程不安全\nHashMap 允许为null 允许为null AbstractMap 线程不安全\n反例：由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储\nnull值时会抛出NPE异常。\n</code></pre>\n<ol start=\"20\">\n<li>【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳<br>定性(unorder)带来的负面影响。<br>说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。<br>如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。</li>\n<li>【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的<br>contains()进行遍历去重或者判断包含操作。</li>\n</ol>\n<h3 id=\"七-并发处理\"><a href=\"#七-并发处理\" class=\"headerlink\" title=\"(七) 并发处理\"></a>(七) 并发处理</h3><ol>\n<li>【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。<br> 说明：资源驱动类、工具类、单例工厂类都需要注意。</li>\n<li>【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。<br>正例：自定义线程工厂，并且根据外部特征进行分组，比如，来自同一机房的调用，把机房编号赋值给<br>whatFeatureOfGroup<br>public class UserThreadFactory implements ThreadFactory {<br>private final String namePrefix;<br>private final AtomicInteger nextId = new AtomicInteger( 1 );<br>// 定义线程组名称，在利用jstack来排查问题时，非常有帮助<br>UserThreadFactory(String whatFeatureOfGroup) {<br>namePrefix = “From UserThreadFactory’s “ + whatFeatureOfGroup + “-Worker-“;<br>}<br>@Override<br>public Thread newThread(Runnable task) {<br>String name = namePrefix + nextId.getAndIncrement();<br>Thread thread = new Thread(null, task, name, 0 , false);<br>System.out.println(thread.getName());<br>return thread;<br>}<br>}</li>\n<li>【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。<br>说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。<br>如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。</li>\n<li>【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这<br>样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。<br>说明：Executors返回的线程池对象的弊端如下：<br>1 ） FixedThreadPool和SingleThreadPool：<br>允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。<br>2 ） CachedThreadPool：<br>允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。</li>\n<li>【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，<br>必须加锁，或者使用DateUtils工具类。<br>正例：注意线程安全，使用DateUtils。亦推荐如下处理：<br>private static final ThreadLocal<DateFormat> df = new ThreadLocal<DateFormat>() {<br>@Override<br>protected DateFormat initialValue() {<br>return new SimpleDateFormat(“yyyy-MM-dd”);<br>}<br>};</li>\n</ol>\n<pre><code>说明：如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，\nDateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful strong immutable\nthread-safe。\n</code></pre>\n<ol start=\"6\">\n<li>【强制】必须回收自定义的ThreadLocal变量，尤其在线程池场景下，线程经常会被复用，<br> 如果不清理自定义的 ThreadLocal变量，可能会影响后续业务逻辑和造成内存泄露等问题。<br> 尽量在代理中使用try-finally块进行回收。<br> 正例：<pre><code>objectThreadLocal.set(userInfo);\ntry &#123;\n// ...\n&#125; finally &#123;\nobjectThreadLocal.remove();\n&#125;\n</code></pre>\n</li>\n<li>【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能<br> 锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。<pre><code>说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。\n</code></pre>\n</li>\n<li>【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造<br>成死锁。<br>说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、<br>B、C，否则可能出现死锁。</li>\n<li>【强制】在使用阻塞等待获取锁的方式中，必须在try代码块之外，并且在加锁方法与try代<br> 码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在finally中无法解锁。<br> 说明一：如果在lock方法与try代码块之间的方法调用抛出异常，那么无法解锁，造成其它线程无法成功<br> 获取锁。<br> 说明二：如果lock方法在try代码块之内，可能由于其它方法抛出异常，导致在finally代码块中，unlock<br> 对未加锁的对象解锁，它会调用AQS的tryRelease方法（取决于具体实现类），抛出<br> IllegalMonitorStateException异常。<br> 说明三：在Lock对象的lock方法实现中可能抛出unchecked异常，产生的后果与说明二相同。<br> 正例：<pre><code>Lock lock = new XxxLock();\n// ...\nlock.lock();\ntry &#123;\ndoSomething();\ndoOthers();\n&#125; finally &#123;\nlock.unlock();\n&#125;\n</code></pre>\n反例：<br>Lock lock = new XxxLock();<br>// …</li>\n</ol>\n<pre><code>try &#123;\n// 如果此处抛出异常，则直接执行finally代码块\ndoSomething();\n// 无论加锁是否成功，finally代码块都会执行\nlock.lock();\ndoOthers();\n&#125; finally &#123;\nlock.unlock();\n&#125;\n</code></pre>\n<ol start=\"10\">\n<li>【强制】在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否<br>持有锁。锁的释放规则与锁的阻塞等待方式相同。<br>说明：Lock对象的unlock方法在执行时，它会调用AQS的tryRelease方法（取决于具体实现类），如果<br>当前线程不持有锁，则抛出IllegalMonitorStateException异常。<br>正例：<br>   Lock lock = new XxxLock();<br>   // …<br>   boolean isLocked = lock.tryLock();<br>   if (isLocked) {<br>   try {<br>   doSomething();<br>   doOthers();<br>   } finally {<br>   lock.unlock();<br>   }<br>   }</li>\n<li>【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加<br>锁，要么在数据库层使用乐观锁，使用version作为更新依据。<br>说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于<br>3 次。</li>\n<li>【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛<br>出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。</li>\n<li>【推荐】资金相关的金融敏感信息，使用悲观锁策略。<br>说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策<br>略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观<br>锁更新。<br>   正例：悲观锁遵循一锁、二判、三更新、四释放的原则。</li>\n<li>【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方<br>法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至<br>await方法，直到超时才返回结果。<br>说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。</li>\n</ol>\n<ol start=\"15\">\n<li>【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed<br>导致的性能下降。<br>   说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。<br>   正例：在JDK7之后，可以直接使用API ThreadLocalRandom，而在 JDK7之前，需要编码保证每个线<br>   程持有一个单独的Random实例。</li>\n<li>【推荐】通过双重检查锁（double-checked locking）（在并发场景下）存在延迟初始化的优化<br>问题隐患（可参考 The “Double-Checked Locking is Broken” Declaration），推荐解决方案中较<br>为简单一种（适用于JDK 5 及以上版本），将目标属性声明为 volatile型，比如将helper的属<br>性声明修改为<code>private volatile Helper helper = null;</code>。<br>正例：<br>   public class LazyInitDemo {<br>   private volatile Helper helper = null;<br>   public Helper getHelper() {<br>   if (helper == null) {<br>   synchronized (this) {<br>   if (helper == null) { helper = new Helper(); }<br>   }<br>   }<br>   return helper;<br>   }<br>   // other methods and fields…<br>   }</li>\n<li>【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但<br>是如果多写，同样无法解决线程安全问题。<br>   说明：如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger();<br>   count.addAndGet(1); 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观<br>   锁的重试次数）。</li>\n<li>【参考】HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在<br>开发过程中注意规避此风险。</li>\n<li>【参考】ThreadLocal对象使用static修饰，ThreadLocal无法解决共享对象的更新问题。<br>说明：这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量，<br>也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可<br>以操控这个变量。</li>\n</ol>\n<h3 id=\"八-控制语句\"><a href=\"#八-控制语句\" class=\"headerlink\" title=\"(八) 控制语句\"></a>(八) 控制语句</h3><ol>\n<li>【强制】在一个switch块内，每个case要么通过continue/break/return等来终止，要么<br> 注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default</li>\n</ol>\n<pre><code>语句并且放在最后，即使它什么代码也没有。\n说明：注意break是退出switch语句块，而return是退出方法体。\n</code></pre>\n<ol start=\"2\">\n<li>【强制】当switch括号内的变量类型为String并且此变量为外部参数时，必须先进行null<br> 判断。<br> 反例：如下的代码输出是什么？<pre><code>public class SwitchString &#123;\npublic static void main(String[] args) &#123;\nmethod(null);\n&#125;\npublic static void method(String param) &#123;\nswitch (param) &#123;\n// 肯定不是进入这里\ncase &quot;sth&quot;:\nSystem.out.println(&quot;it&#39;s sth&quot;);\nbreak;\n// 也不是进入这里\ncase &quot;null&quot;:\nSystem.out.println(&quot;it&#39;s null&quot;);\nbreak;\n// 也不是进入这里\ndefault:\nSystem.out.println(&quot;default&quot;);\n&#125;\n&#125;\n&#125;\n</code></pre>\n</li>\n<li>【强制】在if/else/for/while/do语句中必须使用大括号。<br> 说明：即使只有一行代码，也禁止不采用大括号的编码方式：if (condition) statements;</li>\n<li>【强制】三目运算符condition? 表达式1 : 表达式 2 中，高度注意表达式 1 和 2 在类型对齐<br> 时，可能抛出因自动拆箱导致的NPE异常。<br> 说明：以下两种场景会触发类型对齐的拆箱操作：<br> 1 ） 表达式 1 或表达式 2 的值只要有一个是原始类型。<br> 2 ） 表达式 1 或表达式 2 的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。<pre><code>反例：\n   Integer a = 1 ;\n   Integer b = 2 ;\n   Integer c = null;\n   Boolean flag = false;\n   // a*b的结果是int类型，那么c会强制拆箱成int类型，抛出NPE异常\n   Integer result=(flag? a*b : c);\n</code></pre>\n</li>\n<li>【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。<br>说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件<br>来代替。</li>\n</ol>\n<pre><code>反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，\n这样的话，活动无法终止。\n</code></pre>\n<ol start=\"6\">\n<li>【推荐】当某个方法的代码总行数超过 10 行时，return / throw 等中断逻辑的右大括号后均<br> 需要加一个空行。<br> 说明：这样做逻辑清晰，有利于代码阅读时重点关注。</li>\n<li>【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成：<br>if (condition) {<br>…<br>return obj;<br>}<br>// 接着写else的业务逻辑代码;<br>说明：如果非使用if()…else if()…else…方式表达逻辑，避免后续代码维护困难，请勿超过 3 层。<br>正例：超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句<br>示例如下：<br>public void findBoyfriend (Man man) {<br>if (man.isUgly()) {<br>System.out.println(“本姑娘是外貌协会的资深会员”);<br>return;<br>}<br>if (man.isPoor()) {<br>System.out.println(“贫贱夫妻百事哀”);<br>return;<br>}<br>if (man.isBadTemper()) {<br>System.out.println(“银河有多远，你就给我滚多远”);<br>return;<br>}<br>System.out.println(“可以先交往一段时间看看”);<br>}</li>\n<li>【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复<br> 杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。<br> 说明：很多 if 语句内的逻辑表达式相当复杂，与、或、取反混合运算，甚至各种方法纵深调用，理解成本<br> 非常高。如果赋值一个非常好理解的布尔变量名字，则是件令人爽心悦目的事情。<br> 正例：<pre><code>// 伪代码如下\nfinal boolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...);\nif (existed) &#123;\n...\n&#125;\n</code></pre>\n反例：<br>public final void acquire ( long arg) {<br>if (!tryAcquire(arg) &amp;&amp;<br>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {<br>selfInterrupt();<br>}</li>\n</ol>\n<ol start=\"9\">\n<li>【推荐】不要在其它表达式（尤其是条件表达式）中，插入赋值语句。<br> 说明：赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行。<br> 反例：<pre><code>public Lock getLock(boolean fair) &#123;\n// 算术表达式中出现赋值操作，容易忽略count值已经被改变\nthreshold = (count = Integer.MAX_VALUE) - 1 ;\n// 条件表达式中出现赋值操作，容易误认为是sync==fair\nreturn (sync = fair)? new FairSync() : new NonfairSync();\n&#125;\n</code></pre>\n</li>\n<li>【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、<br>获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。</li>\n<li>【推荐】避免采用取反逻辑运算符。<br>说明：取反逻辑不利于快速理解，并且取反逻辑写法一般都存在对应的正向逻辑写法。<br>正例：使用if (x &lt; 628) 来表达 x 小于 628 。<br>反例：使用if (!(x &gt;= 628)) 来表达 x 小于 628 。</li>\n<li>【推荐】公开接口需要进行入参保护，尤其是批量操作的接口。<br>反例：某业务系统，提供一个用户批量查询的接口，API文档上有说最多查多少个，但接口实现上没做任何<br>保护，导致调用方传了一个 1000 的用户id数组过来后，查询信息后，内存爆了。</li>\n<li>【参考】下列情形，需要进行参数校验：<br>1 ） 调用频次低的方法。<br>2 ） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致<br>中间执行回退，或者错误，那得不偿失。<br>3 ） 需要极高稳定性和可用性的方法。<br>4 ） 对外提供的开放接口，不管是RPC/API/HTTP接口。<br>   5 ） 敏感权限入口。</li>\n<li>【参考】下列情形，不需要进行参数校验：<br>1 ） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查。<br>2 ） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露<br>问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可<br>以省略。<br>3 ） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检<br>查或者肯定不会有问题，此时可以不校验参数。</li>\n</ol>\n<h3 id=\"九-注释规约\"><a href=\"#九-注释规约\" class=\"headerlink\" title=\"(九) 注释规约\"></a>(九) 注释规约</h3><ol>\n<li>【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/*<em>内容</em>/格式，不得使用<br> // xxx方式。<br> 说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE<br> 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。</li>\n<li>【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、<br> 异常说明外，还必须指出该方法做什么事情，实现什么功能。<br> 说明：对子类的实现要求，或者调用注意事项，请一并说明。</li>\n<li>【强制】所有的类都必须添加创建者和创建日期。<br>说明：在设置模板时，注意IDEA的@author为<code>$&#123;USER&#125;</code>，而eclipse的@author为<code>$&#123;user&#125;</code>，大小写有<br>区别，而日期的设置统一为yyyy/MM/dd的格式。<br>正例：<br>/**</li>\n</ol>\n<pre><code>* @author yangguanbao\n* @date 2016/10/31\n*/\n</code></pre>\n<ol start=\"4\">\n<li>【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使<br> 用/* */注释，注意与代码对齐。</li>\n<li>【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。</li>\n<li>【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持<br> 英文原文即可。<br> 反例：“TCP连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。</li>\n<li>【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑<br> 等的修改。<br> 说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了<br> 导航的意义。</li>\n<li>【推荐】在类中删除未使用的任何字段、方法、内部类；在方法中删除未使用的任何参数声明<br> 与内部变量。</li>\n<li>【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。<br> 说明：代码被注释掉有两种可能性： 1 ）后续会恢复此段代码逻辑。 2 ）永久不用。前者如果没有备注信息，<br> 难以知晓注释动机。后者建议直接删掉即可，假如需要查阅历史代码，登录代码仓库即可。</li>\n</ol>\n<ol start=\"10\">\n<li>【参考】对于注释的要求：第一、能够准确反映设计思想和代码逻辑；第二、能够描述业务含<br>义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同<br>天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看<br>的，使其能够快速接替自己的工作。</li>\n<li>【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一<br>个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释又是相当大的负担。<br>反例：<br>// put elephant into fridge<br>put(elephant, fridge);<br>方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不<br>需要额外的注释。</li>\n<li>【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，<br>经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。<br>1 ） 待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）<br>表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没<br>有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）。<br>2 ） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）<br>在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。</li>\n</ol>\n<h3 id=\"十-前后端规约\"><a href=\"#十-前后端规约\" class=\"headerlink\" title=\"(十) 前后端规约\"></a>(十) 前后端规约</h3><ol>\n<li>【强制】前后端交互的API，需要明确协议、域名、路径、请求方法、请求内容、状态码、响<br> 应体。<br> 说明：<pre><code>1 ） 协议：生产环境必须使用HTTPS。\n2 ） 路径：每一个API需对应一个路径，表示API具体的请求地址：\na） 代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。\nb） URL路径不能使用大写，单词如果需要分隔，统一使用下划线。\nc） 路径禁止携带表示请求内容类型的后缀，比如&quot;.json&quot;,&quot;.xml&quot;，通过accept头表达即可。\n3 ） 请求方法：对具体操作的定义，常见的请求方法如下：\na） GET：从服务器取出资源。\nb） POST：在服务器新建一个资源。\nc） PUT：在服务器更新资源。\nd） DELETE：从服务器删除资源。\n4 ） 请求内容：URL带的参数必须无敏感信息或符合安全要求；body里带参数时必须设置Content-Type。\n5 ） 响应体：响应体body可放置多种数据类型，由Content-Type头来确定。\n</code></pre>\n</li>\n</ol>\n<ol start=\"2\">\n<li>【强制】前后端数据列表相关的接口返回，如果为空，则返回空数组[]或空集合{}。<br> 说明：此条约定有利于数据层面上的协作更加高效，减少前端很多琐碎的null判断。</li>\n<li>【强制】服务端发生错误时，返回给前端的响应信息必须包含HTTP状态码，errorCode、<br> errorMessage、用户提示信息四个部分。<br> 说明：四个部分的涉众对象分别是浏览器、前端开发、错误排查人员、用户。其中输出给用户的提示信息<br> 要求：简短清晰、提示友好，引导用户进行下一步操作或解释错误原因，提示信息可以包括错误原因、上<br> 下文环境、推荐操作等。 errorCode：参考 <strong>附表 3</strong> 。errorMessage：简要描述后端出错原因，便于错误排<br> 查人员快速定位问题，注意不要包含敏感数据信息。<br> 正例：常见的HTTP状态码如下<br> 1 ） 200 OK: 表明该请求被成功地完成，所请求的资源发送到客户端。<br> 2 ） 401 Unauthorized: 请求要求身份验证，常见对于需要登录而用户未登录的情况。<br> 3 ） 403 Forbidden：服务器拒绝请求，常见于机密信息或复制其它登录用户链接访问服务器的情况。<br> 4 ） 404 Not Found: 服务器无法取得所请求的网页，请求资源不存在。<br> 5 ） 500 Internal Server Error: 服务器内部错误。</li>\n<li>【强制】在前后端交互的JSON格式数据中，所有的key必须为小写字母开始的<br> lowerCamelCase风格，符合英文表达习惯，且表意完整。<br> 正例：errorCode / errorMessage / assetStatus / menuList / orderList / configFlag<br> 反例：ERRORCODE / ERROR_CODE / error_message / error-message / errormessage /<br> ErrorMessage / msg</li>\n<li>【强制】errorMessage是前后端错误追踪机制的体现，可以在前端输出到type=”hidden”<br>文字类控件中，或者用户端的日志中，帮助我们快速地定位出问题。</li>\n<li>【强制】对于需要使用超大整数的场景，服务端一律使用String字符串类型返回，禁止使用<br>Long类型。<br>说明：Java服务端如果直接返回Long整型数据给前端，JS会自动转换为Number类型（注：此类型为双<br>精度浮点数，表示原理与取值范围等同于Java中的Double）。Long类型能表示的最大值是 2 的 63 次方</li>\n</ol>\n<ul>\n<li>1 ，在取值范围之内，超过 2 的 53 次方 (9007199254740992)的数值转化为JS的Number时，有些数<br>值会有精度损失。扩展说明，在Long取值范围内，任何 2 的指数次整数都是绝对不会存在精度损失的，所<br>以说精度损失是一个概率问题。若浮点数尾数位与指数位空间不限，则可以精确表示任何整数，但很不幸，<br>双精度浮点数的尾数位只有 52 位。<br>反例：通常在订单号或交易号大于等于 16 位，大概率会出现前后端单据不一致的情况，比如，”orderId”:<br>362909601374617692 ，前端拿到的值却是: 36290960137461766 0 。</li>\n</ul>\n<ol start=\"7\">\n<li>【强制】HTTP请求通过URL传递参数时，不能超过 2048 字节。<br> 说明：不同浏览器对于URL的最大长度限制略有不同，并且对超出最大长度的处理逻辑也有差异， 2048<br> 字节是取所有浏览器的最小值。</li>\n</ol>\n<pre><code>反例：某业务将退货的商品id列表放在URL中作为参数传递，当一次退货商品数量过多时，URL参数超长，\n传递到后端的参数被截断，导致部分商品未能正确退货。\n</code></pre>\n<ol start=\"8\">\n<li>【强制】HTTP请求通过body传递内容时，必须控制长度，超出最大长度后，后端解析会出<br> 错。<br> 说明：nginx默认限制是1MB，tomcat默认限制为2MB，当确实有业务需要传较大内容时，可以通过调<br> 大服务器端的限制。</li>\n<li>【强制】在翻页场景中，用户输入参数的小于 1 ，则前端返回第一页参数给后端；后端发现用<br>户输入的参数大于总页数，直接返回最后一页。</li>\n<li>【强制】服务器内部重定向必须使用forward；外部重定向地址必须使用URL统一代理模块<br>生成，否则会因线上采用HTTPS协议而导致浏览器提示“不安全”，并且还会带来URL维护<br>不一致的问题。</li>\n<li>【推荐】服务器返回信息必须被标记是否可以缓存，如果缓存，客户端可能会重用之前的请求<br>结果。<br>说明：缓存有利于减少交互次数，减少交互的平均延迟。<br>正例：http 1.1中，s-maxage告诉服务器进行缓存，时间单位为秒，用法如下，<br>response.setHeader(“Cache-Control”, “s-maxage=” + cacheSeconds);</li>\n<li>【推荐】服务端返回的数据，使用JSON格式而非XML。<br>说明：尽管HTTP支持使用不同的输出格式，例如纯文本，JSON，CSV，XML，RSS甚至HTML。如果我<br>们使用的面向用户的服务，应该选择JSON作为通信中使用的标准数据交换格式，包括请求和响应。此外，<br>application/JSON是一种通用的MIME类型，具有实用、精简、易读的特点。</li>\n<li>【推荐】前后端的时间格式统一为”yyyy-MM-dd HH:mm:ss”，统一为GMT。</li>\n<li>【参考】在接口路径中不要加入版本号，版本控制在HTTP头信息中体现，有利于向前兼容。<br>说明：当用户在低版本与高版本之间反复切换工作时，会导致迁移复杂度升高，存在数据错乱风险。</li>\n</ol>\n<h3 id=\"十一-其他\"><a href=\"#十一-其他\" class=\"headerlink\" title=\"(十一) 其他\"></a>(十一) 其他</h3><ol>\n<li>【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。<br> 说明：不要在方法体内定义：Pattern pattern = Pattern.compile(“规则”);</li>\n<li>【强制】避免用Apache Beanutils进行属性的copy。<br> 说明：Apache BeanUtils性能较差，可以使用其他方案比如Spring BeanUtils, Cglib BeanCopier，注意<br> 均是浅拷贝。</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】velocity调用POJO类的属性时，直接使用属性名取值即可，模板引擎会自动按规范<br> 调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），<br> 会自动调用isXxx()方法。<br> 说明：注意如果是Boolean包装类对象，优先调用getXxx()的方法。</li>\n<li>【强制】后台输送给页面的变量必须加$!{var}——中间的感叹号。<br> 说明：如果var等于null或者不存在，那么${var}会直接显示在页面上。</li>\n<li>【强制】注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x&lt;1（能够<br> 取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大 10 的若干倍然后<br> 取整，直接使用Random对象的nextInt或者nextLong方法。</li>\n<li>【推荐】不要在视图模板中加入任何复杂的逻辑。<br>说明：根据MVC理论，视图的职责是展示，不要抢模型和控制器的活。</li>\n<li>【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。</li>\n<li>【推荐】及时清理不再使用的代码段或配置信息。<br>说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。<br>正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)<br>来说明注释掉代码的理由。如：<br>public static void hello() {<br>/// 业务方通知活动暂停<br>// Business business = new Business();<br>// business.active();<br>System.out.println(“it’s finished”);<br>}</li>\n</ol>\n<h2 id=\"二、异常日志\"><a href=\"#二、异常日志\" class=\"headerlink\" title=\"二、异常日志\"></a>二、异常日志</h2><h3 id=\"一-错误码\"><a href=\"#一-错误码\" class=\"headerlink\" title=\"(一) 错误码\"></a>(一) 错误码</h3><ol>\n<li>【强制】错误码的制定原则：快速溯源、沟通标准化。<br> 说明： 错误码想得过于完美和复杂，就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身<br> 携带并且简单易懂。<br> 正例：错误码回答的问题是谁的错？错在哪？ 1 ）错误码必须能够快速知晓错误来源，可快速判断是谁的问<br> 题。 2 ）错误码必须能够进行清晰地比对（代码中容易equals）。 3 ）错误码有利于团队快速对错误原因达<br> 到一致认知。</li>\n<li>【强制】错误码不体现版本号和错误等级信息。<br> 说明：错误码以不断追加的方式进行兼容。错误等级由日志和错误码本身的释义来决定。</li>\n<li>【强制】全部正常，但不得不填充错误码时返回五个零： 00000 。</li>\n<li>【强制】错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。<br> 说明：错误产生来源分为A/B/C，A表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付<br> 超时等问题；B表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；C表示错误来源<br> 于第三方服务，比如CDN服务出错，消息投递超时等问题；四位数字编号从 0001 到 9999 ，大类之间的<br> 步长间距预留 100 ，参考文末 <strong>附表 3</strong> 。</li>\n<li>【强制】编号不与公司业务架构，更不与组织架构挂钩，以先到先得的原则在统一平台上进行，<br> 审批生效，编号即被永久固定。</li>\n<li>【强制】错误码使用者避免随意定义新的错误码。<br> 说明：尽可能在原有错误码附表中找到语义相同或者相近的错误码在代码中使用即可。</li>\n<li>【强制】错误码不能直接输出给用户作为提示信息使用。<br> 说明：堆栈（stack_trace）、错误信息(error_message)、错误码（error_code）、提示信息（user_tip）<br> 是一个有效关联并互相转义的和谐整体，但是请勿互相越俎代庖。</li>\n<li>【推荐】错误码之外的业务独特信息由error_message来承载，而不是让错误码本身涵盖过<br> 多具体业务属性。</li>\n<li>【推荐】在获取第三方服务错误码时，向上抛出允许本系统转义，由C转为B，并且在错误信<br> 息上带上原有的第三方错误码。</li>\n<li>【参考】错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。<br>说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、</li>\n</ol>\n<pre><code>B0001（系统执行出错）、C0001（调用第三方服务出错）。\n正例：调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。\n</code></pre>\n<ol start=\"11\">\n<li>【参考】错误码的后三位编号与HTTP状态码没有任何关系。</li>\n<li>【参考】错误码有利于不同文化背景的开发者进行交流与代码协作。<br>说明：英文单词形式的错误码不利于非英语母语国家（如阿拉伯语、希伯来语、俄罗斯语等）之间的开发<br>者互相协作。</li>\n<li>【参考】错误码即人性，感性认知+口口相传，使用纯数字来进行错误码编排不利于感性记忆<br>和分类。<br>说明：数字是一个整体，每位数字的地位和含义是相同的。<br>反例：一个五位数字 12345 ，第 1 位是错误等级，第 2 位是错误来源， 345 是编号，人的大脑不会主动地<br>拆开并分辨每位数字的不同含义。</li>\n</ol>\n<h3 id=\"二-异常处理\"><a href=\"#二-异常处理\" class=\"headerlink\" title=\"(二) 异常处理\"></a>(二) 异常处理</h3><ol>\n<li>【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过<br> catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。<br> 说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不<br> 通过catch NumberFormatException来实现。<br> 正例：if (obj != null) {…}<br> 反例：try { obj.method(); } catch (NullPointerException e) {…}</li>\n<li>【强制】异常捕获后不要用来做流程控制，条件控制。<br> 说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。</li>\n<li>【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。<br> 对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。<br> 说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，<br> 这是一种不负责任的表现。<br> 正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程<br> 序上作出分门别类的判断，并提示给用户。</li>\n<li>【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请<br> 将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的<br> 内容。</li>\n<li>【强制】事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。</li>\n</ol>\n<ol start=\"6\">\n<li>【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。<br> 说明：如果JDK7及以上，可以使用try-with-resources方式。</li>\n<li>【强制】不要在finally块中使用return。<br>说明：try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存<br>在return语句，则在此直接返回，无情丢弃掉try块中的返回点。<br>反例：<br>private int x = 0 ;<br>public int checkReturn() {<br>try {<br>// x等于 1 ，此处不返回<br>return ++x;<br>} finally {<br>// 返回的结果是 2<br>return ++x;<br>}<br>}</li>\n<li>【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。<br> 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。</li>\n<li>【强制】在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable<br> 类来进行拦截。<br> 说明：通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出<br> NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，<br> 或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代<br> 码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。</li>\n<li>【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说<br>明什么情况下会返回null值。<br>说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也<br>并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。</li>\n<li>【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景：<br>1 ） 返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。<br>反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。<br>2 ） 数据库的查询结果可能为null。<br>3 ） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。<br>4 ） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。<br>5 ） 对于Session中获取的数据，建议进行NPE检查，避免空指针。<br>6 ） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。<br>正例：使用JDK8的Optional类来防止NPE问题。</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，<br>更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定<br>义过的自定义异常，如：DAOException / ServiceException等。</li>\n<li>【参考】对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；<br>跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、<br>errorMessage；而应用内部直接抛出异常即可。<br>说明：关于RPC方法返回方式使用Result方式的理由：<br>1 ）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。<br>2 ）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题<br>的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。</li>\n</ol>\n<h3 id=\"三-日志规约\"><a href=\"#三-日志规约\" class=\"headerlink\" title=\"(三) 日志规约\"></a>(三) 日志规约</h3><ol>\n<li>【强制】应用中不可直接使用日志系统（Log 4 j、Logback）中的API，而应依赖使用日志框架<br> （SLF4J、JCL–Jakarta Commons Logging）中的API，使用门面模式的日志框架，有利于维护和<br> 各个类的日志处理方式统一。<br> 说明：日志框架（SLF4J、JCL–Jakarta Commons Logging）的使用方式（推荐使用SLF4J）<br>使用SLF4J：<br>import org.slf4j.Logger;<br>import org.slf4j.LoggerFactory;<br>private static final Logger logger = LoggerFactory.getLogger(Test.class);<br>使用JCL：<br>import org.apache.commons.logging.Log;<br>import org.apache.commons.logging.LogFactory;<br>private static final Log log = LogFactory.getLog(Test.class);</li>\n<li>【强制】所有日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。对于<br>当天日志，以“应用名.log”来保存，保存在/home/admin/应用名/logs/目录下，过往日志<br>格式为: {logname}.log.{保存日期}，日期格式：yyyy-MM-dd<br>正例：以aap应用为例，日志保存在/home/admin/aapserver/logs/aap.log，历史日志名称为<br>aap.log.2016- 08 - 01</li>\n<li>【强制】根据国家法律，网络运行状态、网络安全事件、个人敏感信息操作等相关记录，留存<br> 的日志不少于六个月，并且进行网络多机备份。</li>\n<li>【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：<br> appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描<br> 述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查<br> 找。</li>\n</ol>\n<pre><code>说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系\n统进行及时监控。\n正例：mppserver应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log\n</code></pre>\n<ol start=\"5\">\n<li>【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式。<br> 说明：因为String字符串的拼接会使用StringBuilder的append()方式，有一定的性能损耗。使用占位符仅<br> 是替换动作，可以有效提升性能。<br> 正例：logger.debug(“Processing trade with id: {} and symbol: {}”, id, symbol);</li>\n<li>【强制】对于trace/debug/info级别的日志输出，必须进行日志级别的开关判断。<br> 说明：虽然在debug(参数)的方法体内第一行代码isDisabled(Level.DEBUG_INT)为真时（Slf4j的常见实现<br> Log4j和Logback），就直接return，但是参数可能会进行字符串拼接运算。此外，如果debug(getName())<br> 这种参数内有getName()方法调用，无谓浪费方法调用的开销。<br> 正例：<pre><code>// 如果判断为真，那么可以输出trace和debug级别的日志\nif (logger.isDebugEnabled()) &#123;\nlogger.debug(&quot;Current ID is: &#123;&#125; and name is: &#123;&#125;&quot;, id, getName());\n&#125;\n</code></pre>\n</li>\n<li>【强制】避免重复打印日志，浪费磁盘空间，务必在日志配置文件中设置additivity=false。<br> 正例：<logger name=\"com.taobao.dubbo.config\" additivity=\"false\"></li>\n<li>【强制】生产环境禁止直接使用System.out 或System.err 输出日志或使用<br> e.printStackTrace()打印异常堆栈。<br> 说明：标准日志输出与标准错误输出文件每次Jboss重启时才滚动，如果大量输出送往这两个文件，容易<br> 造成文件大小超过操作系统大小限制。</li>\n<li>【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过<br>关键字throws往上抛出。<br>正例：logger.error(“inputParams:{} and errorMessage:{}”, 各类参数或者对象toString(), e.getMessage(), e);</li>\n<li>【强制】日志打印时禁止直接用JSON工具将对象转换成String。<br>说明：如果对象里某些get方法被覆写，存在抛出异常的情况，则可能会因为打印日志而影响正常业务流<br>程的执行。<br>正例：打印日志时仅打印出业务相关属性值或者调用其对象的toString()方法。</li>\n<li>【推荐】谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用<br>warn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑<br>爆，并记得及时删除这些观察日志。<br>说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些<br>日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适<br>从。如非必要，请不要在此场景打出error级别，避免频繁报警。<br>说明：注意日志输出的级别，error级别只记录系统逻辑出错、异常或者重要的错误信息。</li>\n<li>【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用<br>中文描述即可，否则容易产生歧义。<br>说明：国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息。</li>\n</ol>\n<h2 id=\"三、单元测试\"><a href=\"#三、单元测试\" class=\"headerlink\" title=\"三、单元测试\"></a>三、单元测试</h2><ol>\n<li>【强制】好的单元测试必须遵守AIR原则。<br> 说明：单元测试在线上运行时，感觉像空气（AIR）一样感觉不到，但在测试质量的保障上，却是非常关键<br> 的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。<pre><code>⚫ A：Automatic（自动化）\n⚫ I：Independent（独立性）\n</code></pre>\n⚫ R：Repeatable（可重复）</li>\n<li>【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执<br> 行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元<br> 测试中不准使用System.out来进行人肉验证，必须使用assert来验证。</li>\n<li>【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间<br> 决不能互相调用，也不能依赖执行的先后次序。<br> 反例：method2需要依赖method1的执行，将执行结果作为method2的输入。</li>\n<li>【强制】单元测试是可以重复执行的，不能受到外界环境的影响。<br> 说明：单元测试通常会被放到持续集成中，每次有代码check in时单元测试都会被执行。如果单测对外部<br> 环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。<br> 正例：为了不受外界环境影响，要求设计代码时就把SUT的依赖改成注入，在测试时用spring 这样的DI<br> 框架注入一个本地（内存）实现或者Mock实现。</li>\n<li>【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级<br> 别，一般是方法级别。<br> 说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑，<br> 那是集成测试的领域。</li>\n<li>【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。<br> 说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。</li>\n<li>【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。<br>说明：源码编译时会跳过此目录，而单元测试框架默认是扫描此目录。</li>\n<li>【推荐】单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都<br> 要达到100%<br> 说明：在工程规约的应用分层中提到的DAO层，Manager层，可重用度高的Service，都应该进行单元测<br> 试。</li>\n</ol>\n<ol start=\"9\">\n<li>【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量。<br> ⚫ B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。<br> ⚫ C：Correct，正确的输入，并得到预期的结果。<br> ⚫ D：Design，与设计文档相结合，来编写单元测试。<br> ⚫ E：Error，强制错误信息输入（如：非法数据、异常流程、业务允许外等），并得到预期的结果。</li>\n<li>【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或<br>者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。<br>反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数<br>据并不符合业务插入规则，导致测试结果异常。</li>\n<li>【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对<br>单元测试产生的数据有明确的前后缀标识。<br>正例：在阿里巴巴企业智能事业部的内部单元测试中，使用ENTERPRISE_INTELLIGENCE <em>UNIT_TEST</em><br>的前缀来标识单元测试相关代码。</li>\n<li>【推荐】对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试<br>要求而书写不规范测试代码。</li>\n<li>【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆<br>盖所有测试用例（UC）。</li>\n<li>【推荐】单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补<br>充单元测试用例。</li>\n<li>【参考】为了更方便地进行单元测试，业务代码应避免以下情况：</li>\n</ol>\n<pre><code>⚫ 构造方法中做的事情过多。\n⚫ 存在过多的全局变量和静态方法。\n⚫ 存在过多的外部依赖。\n⚫ 存在过多的条件语句。\n说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。\n</code></pre>\n<ol start=\"16\">\n<li>【参考】不要对单元测试存在如下误解：</li>\n</ol>\n<pre><code>⚫ 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。\n⚫ 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。\n⚫ 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。\n⚫ 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。\n</code></pre>\n<h2 id=\"四、安全规约\"><a href=\"#四、安全规约\" class=\"headerlink\" title=\"四、安全规约\"></a>四、安全规约</h2><ol>\n<li>【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。<br> 说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容。</li>\n<li>【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。<br> 说明：中国大陆个人手机号码显示： 139 **** 1219 ，隐藏中间 4 位，防止隐私泄露。</li>\n<li>【强制】用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，<br> 禁止字符串拼接SQL访问数据库。<br> 反例：某系统签名大量被恶意修改，即是因为对于危险字符 # –没有进行转义，导致数据库更新时，where<br> 后边的信息被注释掉，对全库进行更新。</li>\n<li>【强制】用户请求传入的任何参数必须做有效性验证。<br>说明：忽略参数校验可能导致：<br>⚫ page size过大导致内存溢出<br>⚫ 恶意order by导致数据库慢查询<br>⚫ 缓存击穿<br>⚫ SSRF<br>⚫ 任意重定向<br>⚫ SQL注入，Shell注入，反序列化注入<br>⚫ 正则输入源串拒绝服务ReDoS<br> Java代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用<br> 的是特殊构造的字符串来验证，有可能导致死循环的结果。</li>\n<li>【强制】禁止向HTML页面输出未经安全过滤或未正确转义的用户数据。</li>\n<li>【强制】表单、AJAX提交必须执行CSRF安全验证。<br> 说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF漏洞的应用/<br> 网站，攻击者可以事先构造好URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用<br> 户参数进行相应修改。</li>\n<li>【强制】URL外部重定向传入的目标地址必须执行白名单过滤。</li>\n<li>【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机<br> 制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。<br> 说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并<br> 造成短信平台资源浪费。</li>\n<li>【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过<br> 滤等风控策略。</li>\n</ol>\n<h2 id=\"五、MySQL数据库\"><a href=\"#五、MySQL数据库\" class=\"headerlink\" title=\"五、MySQL数据库\"></a>五、MySQL数据库</h2><h3 id=\"一-建表规约\"><a href=\"#一-建表规约\" class=\"headerlink\" title=\"(一) 建表规约\"></a>(一) 建表规约</h3><ol>\n<li>【强制】表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint<br> （ 1 表示是， 0 表示否）。<br> 说明：任何字段如果为非负数，必须是unsigned。<br> 注意：POJO类中的任何布尔类型的变量，都不要加is前缀，所以，需要在<resultMap>设置从is_xxx到<br> Xxx的映射关系。数据库表示是与否的值，使用tinyint类型，坚持is_xxx的命名方式是为了明确其取值含<br> 义与取值范围。<br> 正例：表达逻辑删除的字段名is_deleted， 1 表示删除， 0 表示未删除。</li>\n<li>【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只<br> 出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。<pre><code>说明：MySQL在Windows下不区分大小写，但在Linux下默认是区分大小写。因此，数据库名、表名、\n字段名，都不允许出现任何大写字母，避免节外生枝。\n正例：aliyun_admin，rdc_config，level3_name\n反例：AliyunAdmin，rdcConfig，level_3_name\n</code></pre>\n</li>\n<li>【强制】表名不使用复数名词。<br>说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于DO类名也是单数形式，符合<br>表达习惯。</li>\n<li>【强制】禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字。</li>\n<li>【强制】主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。<br>说明：pk_ 即primary key；uk_ 即 unique key；idx_ 即index的简称。</li>\n<li>【强制】小数类型为decimal，禁止使用float和double。<br>说明：在存储的时候，float 和 double 都存在精度损失的问题，很可能在比较值的时候，得到不正确的<br>结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数并分开存储。</li>\n<li>【强制】如果存储的字符串长度几乎相等，使用char定长字符串类型。</li>\n<li>【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000 ，如果存储长度<br>大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效<br>率。</li>\n<li>【强制】表必备三字段：id, create_time, update_time。<br>说明：其中id必为主键，类型为bigint unsigned、单表时自增、步长为 1 。create_time, update_time<br>的类型均为datetime类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。</li>\n</ol>\n<ol start=\"10\">\n<li>【推荐】表的命名最好是遵循“业务名称_表的作用”。<br>正例：alipay_task / force_project / trade_config</li>\n<li>【推荐】库名与应用名称尽量一致。</li>\n<li>【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。</li>\n<li>【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：<br>1 ） 不是频繁修改的字段。<br>2 ） 不是唯一索引的字段。<br>3 ） 不是varchar超长字段，更不能是text字段。<br>正例：各业务线经常冗余存储商品名称，避免查询时需要调用IC服务获取。</li>\n<li>【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。<br>说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。</li>\n<li>【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索<br>速度。<br>正例：无符号值可以避免误存负数，且扩大了表示范围。</li>\n</ol>\n<pre><code>对象 年龄区间 类型 字节 表示范围\n人 150 岁之内 tinyint unsigned 1 无符号值： 0 到 255\n龟 数百岁 smallint unsigned 2 无符号值： 0 到 65535\n恐龙化石 数千万年 int unsigned 4 无符号值： 0 到约 43 亿\n太阳 约 50 亿年 bigint unsigned 8 无符号值： 0 到约 10 的 19 次方\n</code></pre>\n<h3 id=\"二-索引规约\"><a href=\"#二-索引规约\" class=\"headerlink\" title=\"(二) 索引规约\"></a>(二) 索引规约</h3><ol>\n<li>【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。<br> 说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，<br> 即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。</li>\n<li>【强制】超过三个表禁止join。需要join的字段，数据类型保持绝对一致；多表关联查询时，<br> 保证被关联的字段需要有索引。<br> 说明：即使双表join也要注意表索引、SQL性能。</li>\n<li>【强制】在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据<br> 实际文本区分度决定索引长度。</li>\n</ol>\n<pre><code>说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%\n以上，可以使用count(distinct left(列名, 索引长度))/count(*)的区分度来确定。\n</code></pre>\n<ol start=\"4\">\n<li>【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。<br> 说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。</li>\n<li>【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索<br> 引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。<br> 正例：where a=? and b=? order by c; 索引：a_b_c<br> 反例：索引如果存在范围查询，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b无<br> 法排序。</li>\n<li>【推荐】利用覆盖索引来进行查询操作，避免回表。<br> 说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这<br> 个目录就是起到覆盖索引的作用。<br> 正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效<br> 果，用explain的结果，extra列会出现：using index。</li>\n<li>【推荐】利用延迟关联或者子查询优化超多分页场景。<br> 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当<br> offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL<br> 改写。<br> 正例：先快速定位需要获取的id段，然后再关联：<br> SELECT t1.* FROM 表 1 as t1, (select id from 表1 where 条件 LIMIT 100000,20 ) as t2 where t1.id=t2.id</li>\n<li>【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts<br> 最好。<br> 说明：<br> 1 ） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。<br> 2 ） ref 指的是使用普通的索引（normal index）。<br> 3 ） range 对索引进行范围检索。<br> 反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range<br> 还低，与全表扫描是小巫见大巫。</li>\n<li>【推荐】建组合索引的时候，区分度最高的在最左边。<br> 正例：如果where a=? and b=?，a列的几乎接近于唯一值，那么只需要单建idx_a索引即可。<br> 说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where c&gt;? and d=?<br> 那么即使c的区分度更高，也必须把d放在索引的最前列，即建立组合索引idx_d_c。</li>\n<li>【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。</li>\n</ol>\n<ol start=\"11\">\n<li>【参考】创建索引时避免有如下极端误解：<br>1 ） 索引宁滥勿缺。认为一个查询就需要建一个索引。<br>2 ） 吝啬索引的创建。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。<br>3 ） 抵制惟一索引。认为惟一索引一律需要在应用层通过“先查后插”方式解决。</li>\n</ol>\n<h3 id=\"三-SQL语句\"><a href=\"#三-SQL语句\" class=\"headerlink\" title=\"(三) SQL语句\"></a>(三) SQL语句</h3><ol>\n<li>【强制】不要使用count(列名)或count(常量)来替代count(<em>)，count(</em>)是SQL92定义的标<br> 准统计行数的语法，跟数据库无关，跟NULL和非NULL无关。<br> 说明：count(*)会统计值为NULL的行，而count(列名)不会统计此列为NULL值的行。</li>\n<li>【强制】count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1,<br> col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为 0 。</li>\n<li>【强制】当某一列的值全是NULL时，count(col)的返回结果为 0 ，但sum(col)的返回结果为<br> NULL，因此使用sum()时需注意NPE问题。<br> 正例：可以使用如下方式来避免sum的NPE问题：SELECT IFNULL(SUM(column), 0) FROM table;</li>\n<li>【强制】使用ISNULL()来判断是否为NULL值。<br> 说明：NULL与任何值的直接比较都为NULL。<br> 1 ） NULL&lt;&gt;NULL的返回结果是NULL，而不是false。<br> 2 ） NULL=NULL的返回结果是NULL，而不是true。<br> 3 ） NULL&lt;&gt;1的返回结果是NULL，而不是true。<br> 反例：在SQL语句中，如果在null前换行，影响可读性。select * from table where column1 is null and<br> column3 is not null; 而<code>ISNULL(column)</code>是一个整体，简洁易懂。从性能数据上分析，<code>ISNULL(column)</code><br> 执行效率更快一些。</li>\n<li>【强制】代码中写分页查询逻辑时，若count为 0 应直接返回，避免执行后面的分页语句。</li>\n<li>【强制】不得使用外键与级联，一切外键概念必须在应用层解决。<br> 说明：（概念解释）学生表中的student_id是主键，那么成绩表中的student_id则为外键。如果更新学<br> 生表中的student_id，同时触发成绩表中的student_id更新，即为级联更新。外键与级联更新适用于单机<br> 低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库<br> 的插入速度。</li>\n<li>【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。</li>\n<li>【强制】数据订正（特别是删除或修改记录操作）时，要先select，避免出现误删除，确认无<br> 误才能执行更新语句。</li>\n</ol>\n<ol start=\"9\">\n<li>【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或<br> 表名）进行限定。<br> 说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且<br> 操作列在多个表中存在时，就会抛异常。<br> 正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id;<br> 反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在<br> 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column<br> ‘name’ in field list is ambiguous。</li>\n<li>【推荐】SQL语句中表的别名前加as，并且以t1、t2、t3、…的顺序依次命名。<br>说明： 1 ）别名可以是表的简称，或者是依照表在SQL语句中出现的顺序，以t1、t2、t3的方式命名。 2 ）<br>别名前加as使别名更容易识别。<br>正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id;</li>\n<li>【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控<br>制在 1000 个之内。</li>\n<li>【参考】因国际化需要，所有的字符存储与表示，均采用utf 8 字符集，那么字符计数方法需<br>要注意。<br>说明：<br>SELECT LENGTH(“轻松工作”)； 返回为 12<br>SELECT CHARACTER_LENGTH(“轻松工作”)； 返回为 4<br>如果需要存储表情，那么选择utf 8 mb4来进行存储，注意它与utf 8 编码的区别。</li>\n<li>【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE<br>无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句。<br>说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。</li>\n</ol>\n<h3 id=\"四-ORM映射\"><a href=\"#四-ORM映射\" class=\"headerlink\" title=\"(四) ORM映射\"></a>(四) ORM映射</h3><ol>\n<li>【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。<br> 说明： 1 ）增加查询分析器解析成本。 2 ）增减字段容易与resultMap配置不一致。 3 ）无用字段增加网络<br> 消耗，尤其是text类型的字段。</li>\n<li>【强制】POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行<br> 字段与属性之间的映射。<br> 说明：参见定义POJO类以及数据库字段定义规定，在sql.xml增加映射，是必须的。</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要<br> 定义<resultMap>；反过来，每一个表也必然有一个<resultMap>与之对应。<br> 说明：配置映射关系，使字段与DO类解耦，方便维护。</li>\n<li>【强制】sql.xml配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现SQL注入。</li>\n<li>【强制】iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用。<br>说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取<br>start,size的子集合。<br>正例：<br>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;( 16 );<br>map.put(“start”, start);<br>map.put(“size”, size);</li>\n<li>【强制】不允许直接拿HashMap与Hashtable作为查询结果集的输出。<br> 反例：某同学为避免写一个<resultMap>xxx</resultMap>，直接使用HashTable来接收数据库返回结<br> 果，结果出现日常是把bigint转成Long值，而线上由于数据库版本不一样，解析成BigInteger，导致线<br> 上问题。</li>\n<li>【强制】更新数据表记录时，必须同时更新记录对应的update_time字段值为当前时间。</li>\n<li>【推荐】不要写一个大而全的数据更新接口。传入为POJO类，不管是不是自己的目标更新字<br> 段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，<br> 不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储。</li>\n<li>【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需<br> 要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。</li>\n<li>【参考】<isEqual>中的compareValue是与属性值对比的常量，一般是数字，表示相等时<br>带上此条件；<isNotEmpty>表示不为空且不为null时执行；<isNotNull>表示不为null值<br>时执行。</li>\n</ol>\n<h2 id=\"六、工程结构\"><a href=\"#六、工程结构\" class=\"headerlink\" title=\"六、工程结构\"></a>六、工程结构</h2><h3 id=\"一-应用分层\"><a href=\"#一-应用分层\" class=\"headerlink\" title=\"(一) 应用分层\"></a>(一) 应用分层</h3><ol>\n<li>【推荐】根据业务架构实践，结合业界分层规范与流行技术框架分析，推荐分层结构如图所示，<br> 默认上层依赖于下层，箭头关系表示可直接依赖，如：开放API层可以依赖于Web层<br> （Controller层），也可以直接依赖于Service层，依此类推：<pre><code>- 开放API层：可直接封装Service接口暴露成RPC接口；通过Web封装成http接口；网关控制层等。\n- 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移\n   动端展示等。\n- Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。\n- Service层：相对具体的业务逻辑服务层。\n- Manager层：通用业务处理层，它有如下特征：\n   1 ） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。\n   2 ） 对Service层通用能力的下沉，如缓存方案、中间件通用处理。\n   3 ） 与DAO层交互，对多个DAO的组合复用。\n- DAO层：数据访问层，与底层MySQL、Oracle、Hbase、OB等进行数据交互。\n- 第三方服务：包括其它部门RPC服务接口，基础平台，其它公司的HTTP接口，如淘宝开放平台、支\n   付宝付款服务、高德地图服务等。\n- 外部数据接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。\n</code></pre>\n</li>\n<li>【参考】（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进<br>行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因<br>为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，</li>\n</ol>\n<pre><code>浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，\n相当于保护案发现场。Manager层与Service同机部署，日志方式与DAO层处理一致，如果是\n单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处\n于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，\n尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。\n</code></pre>\n<ol start=\"3\">\n<li>【参考】分层领域模型规约：<ul>\n<li>DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。</li>\n<li>DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。</li>\n<li>BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。</li>\n<li>Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用Map类<br> 来传输。</li>\n<li>VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"二-二方库依赖\"><a href=\"#二-二方库依赖\" class=\"headerlink\" title=\"(二) 二方库依赖\"></a>(二) 二方库依赖</h3><ol>\n<li>【强制】定义GAV遵从以下规则：<br> 1 ） GroupID格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。<br> 说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。<br> 正例：com.taobao.jstorm 或 com.alibaba.dubbo.register<br> 2 ） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。<br> 正例：dubbo-client / fastjson-api / jstorm-tool<br> 3 ） Version：详细规定参考下方。</li>\n<li>【强制】二方库版本号命名方式：主版本号.次版本号.修订号<br>1 ）主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。<br>2 ） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。<br>3 ） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。<br>说明：注意起始版本号必须为：1.0.0，而不是0.0.1。<br>反例：仓库内某二方库版本号从1.0.0.0开始，一直默默“升级”成1.0.0.64，完全失去版本的语义信息。</li>\n<li>【强制】线上应用不要依赖SNAPSHOT版本（安全包除外）；正式发布的类库必须先去中央仓<br> 库进行查证，使RELEASE版本号有延续性，且版本号不允许覆盖升级。<br> 说明：不依赖SNAPSHOT版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。</li>\n<li>【强制】二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，<br> 必须明确评估和验证。</li>\n</ol>\n<pre><code>说明：在升级时，进行dependency:resolve前后信息比对，如果仲裁结果完全不一致，那么通过\ndependency:tree命令，找出差异点，进行&lt;exclude&gt;排除jar包。\n</code></pre>\n<ol start=\"5\">\n<li>【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚<br> 举类型或者包含枚举类型的POJO对象。</li>\n<li>【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。<br> 说明：依赖springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版<br> 本：${spring.version}，定义依赖的时候，引用该版本。</li>\n<li>【强制】禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的<br> Version。<br> 说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个war，只能有一个版本号出现在最后的<br> lib目录中。曾经出现过线下调试是正确的，发布到线上却出故障的先例。</li>\n<li>【推荐】底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现。</li>\n<li>【推荐】所有pom文件中的依赖声明放在<dependencies>语句块中，所有版本仲裁放在<br> <dependencyManagement>语句块中。<br> 说明：<dependencyManagement>里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，<br> version和scope都读取自父pom。而<dependencies>所有声明在主pom的<dependencies>里的依<br> 赖都会自动引入，并默认被所有的子项目继承。</li>\n<li>【推荐】二方库不要有配置项，最低限度不要再增加配置项。</li>\n<li>【推荐】不要使用不稳定的工具包或者Utils类。<br>说明：不稳定指的是提供方无法做到向下兼容，在编译阶段正常，但在运行时产生异常，因此，尽量使用<br>业界稳定的二方工具包。</li>\n<li>【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：<br>1 ） <strong>精简可控原则</strong> 。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、<br>常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log<br>具体实现，只依赖日志框架。<br>2 ） <strong>稳定可追溯原则</strong> 。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除<br>非用户主动升级版本，否则公共二方库的行为不应该发生变化。</li>\n</ol>\n<h3 id=\"三-服务器\"><a href=\"#三-服务器\" class=\"headerlink\" title=\"(三) 服务器\"></a>(三) 服务器</h3><ol>\n<li>【推荐】高并发服务器建议调小TCP协议的time_wait超时时间。<br> 说明：操作系统默认 240 秒后，才会关闭处于time_wait状态的连接，在高并发访问下，服务器端会因为<br> 处于time_wait的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。</li>\n</ol>\n<pre><code>正例：在linux服务器上请通过变更/etc/sysctl.conf文件去修改该缺省值（秒）：\nnet.ipv4.tcp_fin_timeout = 30\n</code></pre>\n<ol start=\"2\">\n<li>【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）。<br> 说明：主流操作系统的设计是将TCP/UDP连接采用与文件一样的方式去管理，即一个连接对应于一个fd。<br> 主流的linux服务器默认所支持最大fd数量为 1024 ，当并发连接数很大时很容易因为fd不足而出现“open<br> too many files”错误，导致新的连接无法建立。建议将linux服务器所支持的最大句柄数调高数倍（与服<br> 务器的内存数量相关）。</li>\n<li>【推荐】给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM<br> 场景时输出dump信息。<br> 说明：OOM的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。</li>\n<li>【推荐】在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整<br> 堆大小带来的压力。</li>\n<li>【参考】服务器内部重定向必须使用forward；外部重定向地址必须使用URL Broker生成，否<br> 则因线上采用HTTPS协议而导致浏览器提示“不安全“。此外，还会带来URL维护不一致的<br> 问题。</li>\n</ol>\n<h2 id=\"七、设计规约\"><a href=\"#七、设计规约\" class=\"headerlink\" title=\"七、设计规约\"></a>七、设计规约</h2><ol>\n<li>【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。<br> 说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系<br> 统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后，<br> 需要进行double check。<br> 正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发<br> 展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段）<br> 也需要进行评审通过后上线。</li>\n<li>【强制】在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过 5 个，<br> 使用用例图来表达更加清晰的结构化需求。</li>\n<li>【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发<br> 条件。<br> 说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换<br> 关系，再明确触发状态转换的条件是什么。<br> 正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两<br> 种状态之间是不可能有直接转换关系的。</li>\n<li>【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确<br> 各调用环节的输入与输出。<br> 说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。</li>\n<li>【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类<br> 之间的关系。<br> 说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造蚂蚁Z空间大楼，肯定需要详细<br> 的施工图。</li>\n<li>【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活<br> 动图来表示。<br> 说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。</li>\n<li>【推荐】系统架构设计时明确以下目标：<br>⚫ 确定系统边界。确定系统在技术层面上的做与不做。<br>⚫ 确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。<br>⚫ 确定指导后续设计与演化的原则。使后续的子系统或模块设计在一个既定的框架内和技术方向上继<br>续演化。</li>\n</ol>\n<p>⚫ 确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。</p>\n<ol start=\"8\">\n<li>【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。<br> 反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演<br> 练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。</li>\n<li>【推荐】类在设计与实现时要符合单一原则。<br> 说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。</li>\n<li>【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。<br>说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现，<br>比如，“把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。</li>\n<li>【推荐】系统设计阶段，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。<br>说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。</li>\n<li>【推荐】系统设计阶段，注意对扩展开放，对修改闭合。<br>说明：极端情况下，交付的代码是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。</li>\n<li>【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方<br>法等，在系统中不出现重复代码的情况，即DRY原则（Don’t Repeat Yourself）。<br>说明：随着代码的重复次数不断增加，维护成本指数级上升。随意复制和粘贴代码，必然会导致代码的重复，<br>在维护代码时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。<br>正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取：<br>private boolean checkParam(DTO dto) {…}</li>\n<li>【推荐】避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布。<br>说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上<br>的必要设计和文档沉淀是需要的。<br>反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样<br>的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。</li>\n<li>【参考】设计文档的作用是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。<br>说明：避免为了设计而设计，系统设计文档有助于后期的系统维护和重构，所以设计结果需要进行分类归<br>档保存。</li>\n<li>【参考】可扩展性的本质是找到系统的变化点，并隔离变化点。<br>说明：世间众多设计模式其实就是一种设计模式即隔离变化点的模式。<br>正例：极致扩展性的标志，就是需求的新增，不会在原有代码交付物上进行任何形式的修改。</li>\n</ol>\n<ol start=\"17\">\n<li>【参考】设计的本质就是识别和表达系统难点。<br>说明：识别和表达完全是两回事，很多人错误地认为识别到系统难点在哪里，表达只是自然而然的事情，<br>但是大家在设计评审中经常出现语焉不详，甚至是词不达意的情况。准确地表达系统难点需要具备如下能<br>力： 表达规则和表达工具的熟练性。抽象思维和总结能力的局限性。基础知识体系的完备性。深入浅出的<br>生动表达力。</li>\n<li>【参考】代码即文档的观点是错误的，清晰的代码只是文档的某个片断，而不是全部。<br>说明：代码的深度调用，模块层面上的依赖关系网，业务场景逻辑，非功能性需求等问题是需要相应的文<br>档来完整地呈现的。</li>\n<li>【参考】在做无障碍产品设计时，需要考虑到：</li>\n</ol>\n<pre><code>⚫ 所有可交互的控件元素必须能被tab键聚焦，并且焦点顺序需符合自然操作逻辑。\n⚫ 用于登录校验和请求拦截的验证码均需提供图形验证以外的其它方式。\n⚫ 自定义的控件类型需明确交互方式。\n正例：用户登录场景中，输入框的按钮都需要考虑tab键聚焦，符合自然逻辑的操作顺序如下，“输入用\n户名，输入密码，输入验证码，点击登录”，其中验证码实现语音验证方式。如果有自定义标签实现的控\n件设置控件类型可使用role属性。\n</code></pre>\n<h2 id=\"附-1-：版本历史\"><a href=\"#附-1-：版本历史\" class=\"headerlink\" title=\"附 1 ：版本历史\"></a>附 1 ：版本历史</h2><h4 id=\"版本号-版本名-发布日期-备注\"><a href=\"#版本号-版本名-发布日期-备注\" class=\"headerlink\" title=\"版本号 版本名 发布日期 备注\"></a>版本号 版本名 发布日期 备注</h4><h4 id=\"–-2-016-12-07-试读版本首次对外发布\"><a href=\"#–-2-016-12-07-试读版本首次对外发布\" class=\"headerlink\" title=\"– - - 2 016.12.07 试读版本首次对外发布\"></a>– - - 2 016.12.07 试读版本首次对外发布</h4><h4 id=\"1-0-0-正式版-2017-0-2-09-阿里巴巴集团正式对外发布\"><a href=\"#1-0-0-正式版-2017-0-2-09-阿里巴巴集团正式对外发布\" class=\"headerlink\" title=\"1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布\"></a>1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布</h4><h4 id=\"1-0-1-2017-0-2-13\"><a href=\"#1-0-1-2017-0-2-13\" class=\"headerlink\" title=\"1.0.1 - - 2017. 0 2. 13\"></a>1.0.1 - - 2017. 0 2. 13</h4><pre><code>1 ）修正String[]的前后矛盾。\n2 ）vm修正成velocity。\n3 ）修正countdown描述错误。\n</code></pre>\n<h4 id=\"1-0-2-2017-0-2-20\"><a href=\"#1-0-2-2017-0-2-20\" class=\"headerlink\" title=\"1.0.2 - - 2017. 0 2.20\"></a>1.0.2 - - 2017. 0 2.20</h4><h4 id=\"1-）去除文底水印。\"><a href=\"#1-）去除文底水印。\" class=\"headerlink\" title=\"1 ）去除文底水印。\"></a>1 ）去除文底水印。</h4><h4 id=\"2-）数据类型中引用太阳系年龄问题。\"><a href=\"#2-）数据类型中引用太阳系年龄问题。\" class=\"headerlink\" title=\"2 ）数据类型中引用太阳系年龄问题。\"></a>2 ）数据类型中引用太阳系年龄问题。</h4><h4 id=\"3-）修正关于异常和方法签名的部分描述。\"><a href=\"#3-）修正关于异常和方法签名的部分描述。\" class=\"headerlink\" title=\"3 ）修正关于异常和方法签名的部分描述。\"></a>3 ）修正关于异常和方法签名的部分描述。</h4><pre><code>4 ）修正final描述。\n5 ）去除Comparator部分描述。\n</code></pre>\n<h4 id=\"1-1-0-2017-0-2-27\"><a href=\"#1-1-0-2017-0-2-27\" class=\"headerlink\" title=\"1 .1.0 - - 2017. 0 2.27\"></a>1 .1.0 - - 2017. 0 2.27</h4><h4 id=\"1-）增加前言。\"><a href=\"#1-）增加前言。\" class=\"headerlink\" title=\"1 ）增加前言。\"></a>1 ）增加前言。</h4><pre><code>2 ）增加&lt;? extends T&gt;描述和说明。\n3 ）增加版本历史。\n4 ）增加专有名词解释。\n</code></pre>\n<h4 id=\"1-1-1-2017-0-3-31-修正页码总数和部分示例。\"><a href=\"#1-1-1-2017-0-3-31-修正页码总数和部分示例。\" class=\"headerlink\" title=\"1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。\"></a>1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。</h4><h4 id=\"1-2-0-完美版-2017-0-5-20\"><a href=\"#1-2-0-完美版-2017-0-5-20\" class=\"headerlink\" title=\"1.2.0 完美版 2017. 0 5.20\"></a>1.2.0 完美版 2017. 0 5.20</h4><h4 id=\"1-）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\"><a href=\"#1-）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\" class=\"headerlink\" title=\"1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\"></a>1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。</h4><pre><code>2 ）增加final的适用场景描述。\n3 ）增加关于锁的粒度的说明。\n4 ）增加“指定集合大小”的详细说明以及正反例。\n5 ）增加卫语句的示例代码。\n6 ）明确数据库表示删除概念的字段名为is_deleted\n</code></pre>\n<h4 id=\"1-3-0-终极版-2017-0-9-25-增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\"><a href=\"#1-3-0-终极版-2017-0-9-25-增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\" class=\"headerlink\" title=\"1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\"></a>1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载</h4><pre><code>1.3.1 纪念版 2017.11.30 修正部分描述；采用和P3C开源IDE检测插件相同的Apache2.0协议。\n1.4.0 详尽版 2018. 0 5.20 增加设计规约大类，共 16 条。\n</code></pre>\n<h4 id=\"版本号-版本名-发布日期-备注-1\"><a href=\"#版本号-版本名-发布日期-备注-1\" class=\"headerlink\" title=\"版本号 版本名 发布日期 备注\"></a>版本号 版本名 发布日期 备注</h4><h4 id=\"1-5-0-华山版-2-019-0-6-19\"><a href=\"#1-5-0-华山版-2-019-0-6-19\" class=\"headerlink\" title=\"1 .5.0 华山版 2 019.0 6. 19\"></a>1 .5.0 华山版 2 019.0 6. 19</h4><pre><code>1 ）鉴于本手册是社区开发者集体智慧的结晶，本版本移除阿里巴巴Java开发手册的\n限定词“阿里巴巴”。\n2 ）新增 21 条新规约。比如，switch的NPE问题、浮点数的比较、无泛型限制、锁的\n使用方式、判断表达式、日期格式等。\n3 ）修改描述 112 处。比如，IFNULL的判断、集合的toArray、日志处理等。\n4 ）完善若干处示例。比如，命名示例、卫语句示例、enum示例、finally的return\n示例等。\n</code></pre>\n<h4 id=\"1-6-0\"><a href=\"#1-6-0\" class=\"headerlink\" title=\"1.6.0\"></a>1.6.0</h4><h4 id=\"泰山版\"><a href=\"#泰山版\" class=\"headerlink\" title=\"泰山版\"></a>泰山版</h4><h4 id=\"2020-04-22\"><a href=\"#2020-04-22\" class=\"headerlink\" title=\"2020.04.22\"></a>2020.04.22</h4><h4 id=\"1-）发布错误码统一解决方案，详细参考-附表-3-。\"><a href=\"#1-）发布错误码统一解决方案，详细参考-附表-3-。\" class=\"headerlink\" title=\"1 ）发布错误码统一解决方案，详细参考 附表 3 。\"></a>1 ）发布错误码统一解决方案，详细参考 附表 3 。</h4><h4 id=\"2-）新增-34-条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\"><a href=\"#2-）新增-34-条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\" class=\"headerlink\" title=\"2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\"></a>2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL</h4><pre><code>查询的表别名限定，Collectors类的toMap()方法使用注意等。\n3 ）修改描述 90 处。比如，阻塞等待锁、建表的小数类型等。\n4 ）完善若干处示例。比如，ISNULL的示例等。\n</code></pre>\n<h4 id=\"1-7-0-嵩山版-2020-0-8-03\"><a href=\"#1-7-0-嵩山版-2020-0-8-03\" class=\"headerlink\" title=\"1. 7. 0 嵩山版 2020.0 8. 03\"></a>1. 7. 0 嵩山版 2020.0 8. 03</h4><h4 id=\"1-）新增前后端规约-14-条。\"><a href=\"#1-）新增前后端规约-14-条。\" class=\"headerlink\" title=\"1 ）新增前后端规约 14 条。\"></a>1 ）新增前后端规约 14 条。</h4><h4 id=\"2-）新增禁止任何歧视性用语的约定。\"><a href=\"#2-）新增禁止任何歧视性用语的约定。\" class=\"headerlink\" title=\"2 ）新增禁止任何歧视性用语的约定。\"></a>2 ）新增禁止任何歧视性用语的约定。</h4><h4 id=\"3-）新增涉及敏感操作的情况下日志需要保存六个月的约定。\"><a href=\"#3-）新增涉及敏感操作的情况下日志需要保存六个月的约定。\" class=\"headerlink\" title=\"3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。\"></a>3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。</h4><pre><code>4 ）修正BigDecimal类中关于compareTo和equals的等值比较。\n5 ）修正HashMap关于 1024 个元素扩容的次数。\n6 ）修正架构分层规范与相关说明。\n7 ）修正泰山版中部分格式错误和描述错误。\n</code></pre>\n<h2 id=\"附-2-：专有名词解释\"><a href=\"#附-2-：专有名词解释\" class=\"headerlink\" title=\"附 2 ：专有名词解释\"></a>附 2 ：专有名词解释</h2><ol>\n<li>POJO（Plain Ordinary Java Object）: 在本规约中，POJO专指只有setter/getter/toString的<br> 简单类，包括DO/DTO/BO/VO等。</li>\n<li>DO（Data Object）：阿里巴巴专指数据库表一一对应的POJO类。此对象与数据库表结构一<br> 一对应，通过DAO层向上传输数据源对象。</li>\n<li>DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。</li>\n<li>BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。</li>\n<li>Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用<br> Map类来传输。</li>\n<li>VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。</li>\n<li>AO（Application Object）: 阿里巴巴专指Application Object，即在Service层上，极为贴近<br> 业务的复用代码。</li>\n<li>CAS（Compare And Swap）：解决多线程并行情况下使用锁造成性能损耗的一种机制，这是<br> 硬件实现的原子操作。CAS操作包含三个操作数：内存位置、预期原值和新值。如果内存位<br> 置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何<br> 操作。</li>\n<li>GAV（GroupId、ArtifactId、Version）: Maven坐标，是用来唯一标识jar包。</li>\n<li>OOP（Object Oriented Programming）: 本文泛指类、对象的编程处理方式。</li>\n<li>AQS（AbstractQueuedSynchronizer）: 利用先进先出队列实现的底层同步工具类，它是很多上<br>层同步实现类的基础，比如：ReentrantLock、CountDownLatch、Semaphore等，它们通<br>过继承AQS实现其模版方法，然后将AQS子类作为同步组件的内部类，通常命名为Sync。</li>\n<li>ORM（Object Relation Mapping）: 对象关系映射，对象领域模型与底层数据之间的转换，本<br>文泛指iBATIS, mybatis等框架。</li>\n<li>NPE（java.lang.NullPointerException）: 空指针异常。</li>\n<li>OOM（Out Of Memory）: 源于 java.lang.OutOfMemoryError，当 JVM 没有足够的内存<br>来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。</li>\n<li>一方库: 本工程内部子项目模块依赖的库（jar 包）。</li>\n<li>二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar 包）。</li>\n<li>三方库: 公司之外的开源库（jar 包）。</li>\n</ol>\n<h2 id=\"附-3-：错误码列表\"><a href=\"#附-3-：错误码列表\" class=\"headerlink\" title=\"附 3 ：错误码列表\"></a>附 3 ：错误码列表</h2><h4 id=\"错误码-中文描述-说明\"><a href=\"#错误码-中文描述-说明\" class=\"headerlink\" title=\"错误码 中文描述 说明\"></a>错误码 中文描述 说明</h4><pre><code>00000 一切ok 正确执行后的返回\nA0001 用户端错误 一级宏观错误码\nA0100 用户注册错误 二级宏观错误码\nA0101 用户未同意隐私协议\nA0102 注册国家或地区受限\nA0110 用户名校验失败\nA0111 用户名已存在\nA0112 用户名包含敏感词\nA0113 用户名包含特殊字符\nA0120 密码校验失败\nA0121 密码长度不够\nA0122 密码强度不够\nA0130 校验码输入错误\nA0131 短信校验码输入错误\nA0132 邮件校验码输入错误\nA0133 语音校验码输入错误\nA0140 用户证件异常\nA0141 用户证件类型未选择\nA0142 大陆身份证编号校验非法\nA0143 护照编号校验非法\nA0144 军官证编号校验非法\nA0150 用户基本信息校验失败\nA0151 手机格式校验失败\nA0152 地址格式校验失败\nA0153 邮箱格式校验失败\nA0200 用户登录异常 二级宏观错误码\nA0201 用户账户不存在\n</code></pre>\n<h4 id=\"A0202-用户账户被冻结\"><a href=\"#A0202-用户账户被冻结\" class=\"headerlink\" title=\"A0202 用户账户被冻结\"></a>A0202 用户账户被冻结</h4><h4 id=\"A0203-用户账户已作废\"><a href=\"#A0203-用户账户已作废\" class=\"headerlink\" title=\"A0203 用户账户已作废\"></a>A0203 用户账户已作废</h4><h4 id=\"A0210-用户密码错误\"><a href=\"#A0210-用户密码错误\" class=\"headerlink\" title=\"A0210 用户密码错误\"></a>A0210 用户密码错误</h4><h4 id=\"A0211-用户输入密码错误次数超限\"><a href=\"#A0211-用户输入密码错误次数超限\" class=\"headerlink\" title=\"A0211 用户输入密码错误次数超限\"></a>A0211 用户输入密码错误次数超限</h4><h4 id=\"A0220-用户身份校验失败\"><a href=\"#A0220-用户身份校验失败\" class=\"headerlink\" title=\"A0220 用户身份校验失败\"></a>A0220 用户身份校验失败</h4><h4 id=\"A0221-用户指纹识别失败\"><a href=\"#A0221-用户指纹识别失败\" class=\"headerlink\" title=\"A0221 用户指纹识别失败\"></a>A0221 用户指纹识别失败</h4><h4 id=\"A0222-用户面容识别失败\"><a href=\"#A0222-用户面容识别失败\" class=\"headerlink\" title=\"A0222 用户面容识别失败\"></a>A0222 用户面容识别失败</h4><h4 id=\"A0223-用户未获得第三方登录授权\"><a href=\"#A0223-用户未获得第三方登录授权\" class=\"headerlink\" title=\"A0223 用户未获得第三方登录授权\"></a>A0223 用户未获得第三方登录授权</h4><h4 id=\"A0230-用户登录已过期\"><a href=\"#A0230-用户登录已过期\" class=\"headerlink\" title=\"A0230 用户登录已过期\"></a>A0230 用户登录已过期</h4><h4 id=\"A0240-用户验证码错误\"><a href=\"#A0240-用户验证码错误\" class=\"headerlink\" title=\"A0240 用户验证码错误\"></a>A0240 用户验证码错误</h4><h4 id=\"A0241-用户验证码尝试次数超限\"><a href=\"#A0241-用户验证码尝试次数超限\" class=\"headerlink\" title=\"A0241 用户验证码尝试次数超限\"></a>A0241 用户验证码尝试次数超限</h4><p>A0300 访问权限异常 二级宏观错误码</p>\n<p>A0301 访问未授权</p>\n<p>A0302 正在授权中</p>\n<p>A0303 用户授权申请被拒绝</p>\n<p>A0310 因访问对象隐私设置被拦截</p>\n<p>A0311 授权已过期</p>\n<p>A0312 无权限使用API</p>\n<p>A0320 用户访问被拦截</p>\n<p>A0321 黑名单用户</p>\n<p>A0322 账号被冻结</p>\n<p>A0323 非法IP地址</p>\n<p>A0324 网关访问受限</p>\n<p>A0325 地域黑名单</p>\n<p>A0330 服务已欠费</p>\n<p>A0340 用户签名异常</p>\n<p>A0341 RSA签名错误</p>\n<p>A0400 用户请求参数错误 二级宏观错误码</p>\n<p>A0401 包含非法恶意跳转链接</p>\n<p>A0402 无效的用户输入</p>\n<h4 id=\"A0410-请求必填参数为空\"><a href=\"#A0410-请求必填参数为空\" class=\"headerlink\" title=\"A0410 请求必填参数为空\"></a>A0410 请求必填参数为空</h4><h4 id=\"A0411-用户订单号为空\"><a href=\"#A0411-用户订单号为空\" class=\"headerlink\" title=\"A0411 用户订单号为空\"></a>A0411 用户订单号为空</h4><h4 id=\"A0412-订购数量为空\"><a href=\"#A0412-订购数量为空\" class=\"headerlink\" title=\"A0412 订购数量为空\"></a>A0412 订购数量为空</h4><h4 id=\"A0413-缺少时间戳参数\"><a href=\"#A0413-缺少时间戳参数\" class=\"headerlink\" title=\"A0413 缺少时间戳参数\"></a>A0413 缺少时间戳参数</h4><h4 id=\"A0414-非法的时间戳参数\"><a href=\"#A0414-非法的时间戳参数\" class=\"headerlink\" title=\"A0414 非法的时间戳参数\"></a>A0414 非法的时间戳参数</h4><h4 id=\"A0420-请求参数值超出允许的范围\"><a href=\"#A0420-请求参数值超出允许的范围\" class=\"headerlink\" title=\"A0420 请求参数值超出允许的范围\"></a>A0420 请求参数值超出允许的范围</h4><h4 id=\"A0421-参数格式不匹配\"><a href=\"#A0421-参数格式不匹配\" class=\"headerlink\" title=\"A0421 参数格式不匹配\"></a>A0421 参数格式不匹配</h4><h4 id=\"A0422-地址不在服务范围\"><a href=\"#A0422-地址不在服务范围\" class=\"headerlink\" title=\"A0422 地址不在服务范围\"></a>A0422 地址不在服务范围</h4><h4 id=\"A0423-时间不在服务范围\"><a href=\"#A0423-时间不在服务范围\" class=\"headerlink\" title=\"A0423 时间不在服务范围\"></a>A0423 时间不在服务范围</h4><h4 id=\"A0424-金额超出限制\"><a href=\"#A0424-金额超出限制\" class=\"headerlink\" title=\"A0424 金额超出限制\"></a>A0424 金额超出限制</h4><h4 id=\"A0425-数量超出限制\"><a href=\"#A0425-数量超出限制\" class=\"headerlink\" title=\"A0425 数量超出限制\"></a>A0425 数量超出限制</h4><h4 id=\"A0426-请求批量处理总个数超出限制\"><a href=\"#A0426-请求批量处理总个数超出限制\" class=\"headerlink\" title=\"A0426 请求批量处理总个数超出限制\"></a>A0426 请求批量处理总个数超出限制</h4><h4 id=\"A0427-请求JSON解析失败\"><a href=\"#A0427-请求JSON解析失败\" class=\"headerlink\" title=\"A0427 请求JSON解析失败\"></a>A0427 请求JSON解析失败</h4><h4 id=\"A0430-用户输入内容非法\"><a href=\"#A0430-用户输入内容非法\" class=\"headerlink\" title=\"A0430 用户输入内容非法\"></a>A0430 用户输入内容非法</h4><h4 id=\"A0431-包含违禁敏感词\"><a href=\"#A0431-包含违禁敏感词\" class=\"headerlink\" title=\"A0431 包含违禁敏感词\"></a>A0431 包含违禁敏感词</h4><h4 id=\"A0432-图片包含违禁信息\"><a href=\"#A0432-图片包含违禁信息\" class=\"headerlink\" title=\"A0432 图片包含违禁信息\"></a>A0432 图片包含违禁信息</h4><h4 id=\"A0433-文件侵犯版权\"><a href=\"#A0433-文件侵犯版权\" class=\"headerlink\" title=\"A0433 文件侵犯版权\"></a>A0433 文件侵犯版权</h4><h4 id=\"A0440-用户操作异常\"><a href=\"#A0440-用户操作异常\" class=\"headerlink\" title=\"A0440 用户操作异常\"></a>A0440 用户操作异常</h4><h4 id=\"A0441-用户支付超时\"><a href=\"#A0441-用户支付超时\" class=\"headerlink\" title=\"A0441 用户支付超时\"></a>A0441 用户支付超时</h4><h4 id=\"A0442-确认订单超时\"><a href=\"#A0442-确认订单超时\" class=\"headerlink\" title=\"A0442 确认订单超时\"></a>A0442 确认订单超时</h4><h4 id=\"A0443-订单已关闭\"><a href=\"#A0443-订单已关闭\" class=\"headerlink\" title=\"A0443 订单已关闭\"></a>A0443 订单已关闭</h4><p>A0500 用户请求服务异常 二级宏观错误码</p>\n<p>A0501 请求次数超出限制</p>\n<p>A0502 请求并发数超出限制</p>\n<p>A0503 用户操作请等待</p>\n<p>A0504 WebSocket连接异常</p>\n<p>A0505 WebSocket连接断开</p>\n<p>A0506 用户重复请求</p>\n<p>A0600 用户资源异常 二级宏观错误码</p>\n<p>A0601 账户余额不足</p>\n<h4 id=\"A0602-用户磁盘空间不足\"><a href=\"#A0602-用户磁盘空间不足\" class=\"headerlink\" title=\"A0602 用户磁盘空间不足\"></a>A0602 用户磁盘空间不足</h4><h4 id=\"A0603-用户内存空间不足\"><a href=\"#A0603-用户内存空间不足\" class=\"headerlink\" title=\"A0603 用户内存空间不足\"></a>A0603 用户内存空间不足</h4><h4 id=\"A0604-用户OSS容量不足\"><a href=\"#A0604-用户OSS容量不足\" class=\"headerlink\" title=\"A0604 用户OSS容量不足\"></a>A0604 用户OSS容量不足</h4><h4 id=\"A0605-用户配额已用光-蚂蚁森林浇水数或每天抽奖数\"><a href=\"#A0605-用户配额已用光-蚂蚁森林浇水数或每天抽奖数\" class=\"headerlink\" title=\"A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数\"></a>A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数</h4><h4 id=\"A0700-用户上传文件异常-二级宏观错误码\"><a href=\"#A0700-用户上传文件异常-二级宏观错误码\" class=\"headerlink\" title=\"A0700 用户上传文件异常 二级宏观错误码\"></a>A0700 用户上传文件异常 二级宏观错误码</h4><h4 id=\"A0701-用户上传文件类型不匹配\"><a href=\"#A0701-用户上传文件类型不匹配\" class=\"headerlink\" title=\"A0701 用户上传文件类型不匹配\"></a>A0701 用户上传文件类型不匹配</h4><h4 id=\"A0702-用户上传文件太大\"><a href=\"#A0702-用户上传文件太大\" class=\"headerlink\" title=\"A0702 用户上传文件太大\"></a>A0702 用户上传文件太大</h4><h4 id=\"A0703-用户上传图片太大\"><a href=\"#A0703-用户上传图片太大\" class=\"headerlink\" title=\"A0703 用户上传图片太大\"></a>A0703 用户上传图片太大</h4><h4 id=\"A0704-用户上传视频太大\"><a href=\"#A0704-用户上传视频太大\" class=\"headerlink\" title=\"A0704 用户上传视频太大\"></a>A0704 用户上传视频太大</h4><h4 id=\"A0705-用户上传压缩文件太大\"><a href=\"#A0705-用户上传压缩文件太大\" class=\"headerlink\" title=\"A0705 用户上传压缩文件太大\"></a>A0705 用户上传压缩文件太大</h4><h4 id=\"A0800-用户当前版本异常-二级宏观错误码\"><a href=\"#A0800-用户当前版本异常-二级宏观错误码\" class=\"headerlink\" title=\"A0800 用户当前版本异常 二级宏观错误码\"></a>A0800 用户当前版本异常 二级宏观错误码</h4><h4 id=\"A0801-用户安装版本与系统不匹配\"><a href=\"#A0801-用户安装版本与系统不匹配\" class=\"headerlink\" title=\"A0801 用户安装版本与系统不匹配\"></a>A0801 用户安装版本与系统不匹配</h4><h4 id=\"A0802-用户安装版本过低\"><a href=\"#A0802-用户安装版本过低\" class=\"headerlink\" title=\"A0802 用户安装版本过低\"></a>A0802 用户安装版本过低</h4><h4 id=\"A0803-用户安装版本过高\"><a href=\"#A0803-用户安装版本过高\" class=\"headerlink\" title=\"A0803 用户安装版本过高\"></a>A0803 用户安装版本过高</h4><h4 id=\"A0804-用户安装版本已过期\"><a href=\"#A0804-用户安装版本已过期\" class=\"headerlink\" title=\"A0804 用户安装版本已过期\"></a>A0804 用户安装版本已过期</h4><h4 id=\"A0805-用户API请求版本不匹配\"><a href=\"#A0805-用户API请求版本不匹配\" class=\"headerlink\" title=\"A0805 用户API请求版本不匹配\"></a>A0805 用户API请求版本不匹配</h4><h4 id=\"A0806-用户API请求版本过高\"><a href=\"#A0806-用户API请求版本过高\" class=\"headerlink\" title=\"A0806 用户API请求版本过高\"></a>A0806 用户API请求版本过高</h4><h4 id=\"A0807-用户API请求版本过低\"><a href=\"#A0807-用户API请求版本过低\" class=\"headerlink\" title=\"A0807 用户API请求版本过低\"></a>A0807 用户API请求版本过低</h4><h4 id=\"A0900-用户隐私未授权-二级宏观错误码\"><a href=\"#A0900-用户隐私未授权-二级宏观错误码\" class=\"headerlink\" title=\"A0900 用户隐私未授权 二级宏观错误码\"></a>A0900 用户隐私未授权 二级宏观错误码</h4><h4 id=\"A0901-用户隐私未签署\"><a href=\"#A0901-用户隐私未签署\" class=\"headerlink\" title=\"A0901 用户隐私未签署\"></a>A0901 用户隐私未签署</h4><h4 id=\"A0902-用户摄像头未授权\"><a href=\"#A0902-用户摄像头未授权\" class=\"headerlink\" title=\"A0902 用户摄像头未授权\"></a>A0902 用户摄像头未授权</h4><h4 id=\"A0903-用户相机未授权\"><a href=\"#A0903-用户相机未授权\" class=\"headerlink\" title=\"A0903 用户相机未授权\"></a>A0903 用户相机未授权</h4><h4 id=\"A0904-用户图片库未授权\"><a href=\"#A0904-用户图片库未授权\" class=\"headerlink\" title=\"A0904 用户图片库未授权\"></a>A0904 用户图片库未授权</h4><h4 id=\"A0905-用户文件未授权\"><a href=\"#A0905-用户文件未授权\" class=\"headerlink\" title=\"A0905 用户文件未授权\"></a>A0905 用户文件未授权</h4><h4 id=\"A0906-用户位置信息未授权\"><a href=\"#A0906-用户位置信息未授权\" class=\"headerlink\" title=\"A0906 用户位置信息未授权\"></a>A0906 用户位置信息未授权</h4><h4 id=\"A0907-用户通讯录未授权\"><a href=\"#A0907-用户通讯录未授权\" class=\"headerlink\" title=\"A0907 用户通讯录未授权\"></a>A0907 用户通讯录未授权</h4><h4 id=\"A1000-用户设备异常-二级宏观错误码\"><a href=\"#A1000-用户设备异常-二级宏观错误码\" class=\"headerlink\" title=\"A1000 用户设备异常 二级宏观错误码\"></a>A1000 用户设备异常 二级宏观错误码</h4><h4 id=\"A1001-用户相机异常\"><a href=\"#A1001-用户相机异常\" class=\"headerlink\" title=\"A1001 用户相机异常\"></a>A1001 用户相机异常</h4><h4 id=\"A1002-用户麦克风异常\"><a href=\"#A1002-用户麦克风异常\" class=\"headerlink\" title=\"A1002 用户麦克风异常\"></a>A1002 用户麦克风异常</h4><h4 id=\"A1003-用户听筒异常\"><a href=\"#A1003-用户听筒异常\" class=\"headerlink\" title=\"A1003 用户听筒异常\"></a>A1003 用户听筒异常</h4><h4 id=\"A1004-用户扬声器异常\"><a href=\"#A1004-用户扬声器异常\" class=\"headerlink\" title=\"A1004 用户扬声器异常\"></a>A1004 用户扬声器异常</h4><h4 id=\"A1005-用户GPS定位异常\"><a href=\"#A1005-用户GPS定位异常\" class=\"headerlink\" title=\"A1005 用户GPS定位异常\"></a>A1005 用户GPS定位异常</h4><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"-\"></a>-</h4><p>-</p>\n<h4 id=\"B0001-系统执行出错-一级宏观错误码\"><a href=\"#B0001-系统执行出错-一级宏观错误码\" class=\"headerlink\" title=\"B0001 系统执行出错 一级宏观错误码\"></a>B0001 系统执行出错 一级宏观错误码</h4><h4 id=\"B0100-系统执行超时-二级宏观错误码\"><a href=\"#B0100-系统执行超时-二级宏观错误码\" class=\"headerlink\" title=\"B0100 系统执行超时 二级宏观错误码\"></a>B0100 系统执行超时 二级宏观错误码</h4><h4 id=\"B0101-系统订单处理超时\"><a href=\"#B0101-系统订单处理超时\" class=\"headerlink\" title=\"B0101 系统订单处理超时\"></a>B0101 系统订单处理超时</h4><h4 id=\"B0200-系统容灾功能被触发-二级宏观错误码\"><a href=\"#B0200-系统容灾功能被触发-二级宏观错误码\" class=\"headerlink\" title=\"B0200 系统容灾功能被触发 二级宏观错误码\"></a>B0200 系统容灾功能被触发 二级宏观错误码</h4><h4 id=\"B0210-系统限流\"><a href=\"#B0210-系统限流\" class=\"headerlink\" title=\"B0210 系统限流\"></a>B0210 系统限流</h4><h4 id=\"B0220-系统功能降级\"><a href=\"#B0220-系统功能降级\" class=\"headerlink\" title=\"B0220 系统功能降级\"></a>B0220 系统功能降级</h4><h4 id=\"B0300-系统资源异常-二级宏观错误码\"><a href=\"#B0300-系统资源异常-二级宏观错误码\" class=\"headerlink\" title=\"B0300 系统资源异常 二级宏观错误码\"></a>B0300 系统资源异常 二级宏观错误码</h4><h4 id=\"B0310-系统资源耗尽\"><a href=\"#B0310-系统资源耗尽\" class=\"headerlink\" title=\"B0310 系统资源耗尽\"></a>B0310 系统资源耗尽</h4><h4 id=\"B0311-系统磁盘空间耗尽\"><a href=\"#B0311-系统磁盘空间耗尽\" class=\"headerlink\" title=\"B0311 系统磁盘空间耗尽\"></a>B0311 系统磁盘空间耗尽</h4><h4 id=\"B0312-系统内存耗尽\"><a href=\"#B0312-系统内存耗尽\" class=\"headerlink\" title=\"B0312 系统内存耗尽\"></a>B0312 系统内存耗尽</h4><h4 id=\"B0313-文件句柄耗尽\"><a href=\"#B0313-文件句柄耗尽\" class=\"headerlink\" title=\"B0313 文件句柄耗尽\"></a>B0313 文件句柄耗尽</h4><h4 id=\"B0314-系统连接池耗尽\"><a href=\"#B0314-系统连接池耗尽\" class=\"headerlink\" title=\"B0314 系统连接池耗尽\"></a>B0314 系统连接池耗尽</h4><h4 id=\"B0315-系统线程池耗尽\"><a href=\"#B0315-系统线程池耗尽\" class=\"headerlink\" title=\"B0315 系统线程池耗尽\"></a>B0315 系统线程池耗尽</h4><h4 id=\"B0320-系统资源访问异常\"><a href=\"#B0320-系统资源访问异常\" class=\"headerlink\" title=\"B0320 系统资源访问异常\"></a>B0320 系统资源访问异常</h4><h4 id=\"B0321-系统读取磁盘文件失败\"><a href=\"#B0321-系统读取磁盘文件失败\" class=\"headerlink\" title=\"B0321 系统读取磁盘文件失败\"></a>B0321 系统读取磁盘文件失败</h4><h4 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"-\"></a>-</h4><h4 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"-\"></a>-</h4><h4 id=\"C0001-调用第三方服务出错-一级宏观错误码\"><a href=\"#C0001-调用第三方服务出错-一级宏观错误码\" class=\"headerlink\" title=\"C0001 调用第三方服务出错 一级宏观错误码\"></a>C0001 调用第三方服务出错 一级宏观错误码</h4><h4 id=\"C0100-中间件服务出错-二级宏观错误码\"><a href=\"#C0100-中间件服务出错-二级宏观错误码\" class=\"headerlink\" title=\"C0100 中间件服务出错 二级宏观错误码\"></a>C0100 中间件服务出错 二级宏观错误码</h4><h4 id=\"C0110-RPC服务出错\"><a href=\"#C0110-RPC服务出错\" class=\"headerlink\" title=\"C0110 RPC服务出错\"></a>C0110 RPC服务出错</h4><h4 id=\"C0111-RPC服务未找到\"><a href=\"#C0111-RPC服务未找到\" class=\"headerlink\" title=\"C0111 RPC服务未找到\"></a>C0111 RPC服务未找到</h4><h4 id=\"C0112-RPC服务未注册\"><a href=\"#C0112-RPC服务未注册\" class=\"headerlink\" title=\"C0112 RPC服务未注册\"></a>C0112 RPC服务未注册</h4><h4 id=\"C0113-接口不存在\"><a href=\"#C0113-接口不存在\" class=\"headerlink\" title=\"C0113 接口不存在\"></a>C0113 接口不存在</h4><h4 id=\"C0120-消息服务出错\"><a href=\"#C0120-消息服务出错\" class=\"headerlink\" title=\"C0120 消息服务出错\"></a>C0120 消息服务出错</h4><h4 id=\"C0121-消息投递出错\"><a href=\"#C0121-消息投递出错\" class=\"headerlink\" title=\"C0121 消息投递出错\"></a>C0121 消息投递出错</h4><h4 id=\"C0122-消息消费出错\"><a href=\"#C0122-消息消费出错\" class=\"headerlink\" title=\"C0122 消息消费出错\"></a>C0122 消息消费出错</h4><h4 id=\"C0123-消息订阅出错\"><a href=\"#C0123-消息订阅出错\" class=\"headerlink\" title=\"C0123 消息订阅出错\"></a>C0123 消息订阅出错</h4><h4 id=\"C0124-消息分组未查到\"><a href=\"#C0124-消息分组未查到\" class=\"headerlink\" title=\"C0124 消息分组未查到\"></a>C0124 消息分组未查到</h4><h4 id=\"C0130-缓存服务出错\"><a href=\"#C0130-缓存服务出错\" class=\"headerlink\" title=\"C0130 缓存服务出错\"></a>C0130 缓存服务出错</h4><p>C0131 key长度超过限制</p>\n<p>C0132 value长度超过限制</p>\n<p>C0133 存储容量已满</p>\n<p>C0134 不支持的数据格式</p>\n<p>C0140 配置服务出错</p>\n<p>C0150 网络资源服务出错</p>\n<p>C0151 VPN服务出错</p>\n<p>C0152 CDN服务出错</p>\n<p>C0153 域名解析服务出错</p>\n<p>C0154 网关服务出错</p>\n<p>C0200 第三方系统执行超时 二级宏观错误码</p>\n<p>C0210 RPC执行超时</p>\n<p>C0220 消息投递超时</p>\n<p>C0230 缓存服务超时</p>\n<p>C0240 配置服务超时</p>\n<p>C0250 数据库服务超时</p>\n<p>C0300 数据库服务出错 二级宏观错误码</p>\n<p>C0311 表不存在</p>\n<p>C0312 列不存在</p>\n<p>C0321 多表关联中存在多个相同名称的列</p>\n<p>C0331 数据库死锁</p>\n<p>C0341 主键冲突</p>\n<p>C0400 第三方容灾系统被触发 二级宏观错误码</p>\n<p>C0401 第三方系统限流</p>\n<p>C0402 第三方功能降级</p>\n<p>C0500 通知服务出错 二级宏观错误码</p>\n<p>C0501 短信提醒服务失败</p>\n<p>C0502 语音提醒服务失败</p>\n<p>C0503 邮件提醒服务失败</p>\n","site":{"data":{}},"excerpt":"<p>阿里巴巴java开发手册-嵩山版","more":"</p>\n<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>《Java开发手册》是阿里巴巴集团技术团队的集体智慧结晶和经验总结，经历了多次大规模一</p>\n<p>线实战的检验及不断完善，公开到业界后，众多社区开发者踊跃参与，共同打磨完善，系统化地整理</p>\n<p>成册，当前的版本是 <strong>嵩山版</strong> 。现代软件行业的高速发展对开发者的综合素质要求越来越高，因为不仅</p>\n<p>是编程知识点，其它维度的知识点也会影响到软件的最终交付质量。比如：五花八门的错误码人为地</p>\n<p>增加排查问题的难度；数据库的表结构和索引设计缺陷带来的系统架构缺陷或性能风险；工程结构混</p>\n<p>乱导致后续项目维护艰难；没有鉴权的漏洞代码易被黑客攻击等等。所以本手册以Java开发者为中</p>\n<p>心视角，划分为编程规约、异常日志、单元测试、安全规约、MySQL数据库、工程结构、设计规约</p>\n<p>七个维度，再根据内容特征，细分成若干二级子目录。另外，依据约束力强弱及故障敏感性，规约依</p>\n<p>次分为【强制】、【推荐】、【参考】三大类。在延伸信息中，“说明”对规约做了适当扩展和解释；</p>\n<p>“正例”提倡什么样的编码和实现方式；“反例”说明需要提防的雷区，以及真实的错误案例。</p>\n<p>手册的愿景是 <strong>码出高效，码出质量</strong> 。现代软件架构的复杂性需要协同开发完成，如何高效地协</p>\n<p>同呢？无规矩不成方圆，无规范难以协同，比如，制订交通法规表面上是要限制行车权，实际上是保</p>\n<p>障公众的人身安全，试想如果没有限速，没有红绿灯，谁还敢上路行驶？对软件来说，适当的规范和</p>\n<p>标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的统一方式一起</p>\n<p>做事，提升协作效率，降低沟通成本。代码的字里行间流淌的是软件系统的血液，质量的提升是尽可</p>\n<p>能少踩坑，杜绝踩重复的坑，切实提升系统稳定性，码出质量。</p>\n<p>我们已经在 2017 杭州云栖大会上发布了配套的Java开发规约IDE插件，下载量达到 162 万人</p>\n<p>次，阿里云效也集成了代码规约扫描引擎。次年，发布 36 万字的配套详解图书《码出高效》，本书</p>\n<p>秉持“图胜于表，表胜于言”的理念，深入浅出地将计算机基础、面向对象思想、JVM探源、数据</p>\n<p>结构与集合、并发与多线程、单元测试等知识客观、立体地呈现出来。紧扣学以致用、学以精进的目</p>\n<p>标，结合阿里巴巴实践经验和故障案例，与底层源码解析融会贯通，娓娓道来。《码出高效》和《Java</p>\n<p>开发手册》稿费所得收入均捐赠公益事情，希望用技术情怀帮助更多的人。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li>一、编程规约<ul>\n<li>(一) 命名风格</li>\n<li>(二) 常量定义</li>\n<li>(三) 代码格式</li>\n<li>(四) OOP规约</li>\n<li>(五) 日期时间</li>\n<li>(六) 集合处理</li>\n<li>(七) 并发处理</li>\n<li>(八) 控制语句</li>\n<li>(九) 注释规约</li>\n<li>(十) 前后端规约</li>\n<li>(十一) 其他</li>\n</ul>\n</li>\n<li>二、异常日志<ul>\n<li>(一) 错误码</li>\n<li>(二) 异常处理</li>\n<li>(三) 日志规约</li>\n</ul>\n</li>\n<li>三、单元测试</li>\n<li>四、安全规约</li>\n<li>五、MySQL数据库<ul>\n<li>(一) 建表规约</li>\n<li>(二) 索引规约</li>\n<li>(三) SQL语句</li>\n<li>(四) ORM映射</li>\n</ul>\n</li>\n<li>六、工程结构<ul>\n<li>(一) 应用分层</li>\n<li>(二) 二方库依赖</li>\n<li>(三) 服务器</li>\n</ul>\n</li>\n<li>七、设计规约</li>\n<li>附 1 ：版本历史</li>\n<li>附 2 ：专有名词解释</li>\n<li>附 3 ：错误码列表</li>\n</ul>\n<h2 id=\"一、编程规约\"><a href=\"#一、编程规约\" class=\"headerlink\" title=\"一、编程规约\"></a>一、编程规约</h2><h3 id=\"一-命名风格\"><a href=\"#一-命名风格\" class=\"headerlink\" title=\"(一) 命名风格\"></a>(一) 命名风格</h3><ol>\n<li>【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。<br> 反例：<em>name / <em><em>name / $name / name</em> / name$ / name</em></em></li>\n<li>【强制】所有编程相关的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。<br>说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，纯拼音命名方式更要避免采用。<br>正例：ali / alibaba / taobao / cainiao/ aliyun/ youku / hangzhou 等国际通用的名称，可视同英文。<br>反例：DaZhePromotion [打折] / getPingfenByName() [评分] / String fw[福娃] / int 某变量 = 3</li>\n<li>【强制】代码和注释中都要避免使用任何语言的种族歧视性词语。<br> 正例：日本人 / 印度人 / blockList / allowList / secondary<br> 反例：RIBENGUIZI / Asan / blackList / whiteList / slave</li>\n<li>【强制】类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO /<br> PO / UID等。<br> 正例：ForceCode / UserDO / HtmlDTO / XmlService / TcpUdpDeal / TaPromotion<br> 反例：forcecode / UserDo / HTMLDto / XMLService / TCPUDPDeal / TAPromotion</li>\n<li>【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格。<br> 正例： localValue / getHttpMessage() / inputUserId</li>\n<li>【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。<br> 正例：MAX_STOCK_COUNT / CACHE_EXPIRED_TIME<br> 反例：MAX_COUNT / EXPIRED_TIME</li>\n<li>【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类<br> 命名以它要测试的类的名称开始，以Test结尾。</li>\n<li>【强制】类型与中括号紧挨相连来表示数组。<br> 正例：定义整形数组int[] arrayDemo。<br> 反例：在main参数中，使用String args[]来定义。</li>\n<li>【强制】POJO类中的任何布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列<br> 化错误。</li>\n</ol>\n<h4 id=\"版本号-制定团队-更新日期-备注\"><a href=\"#版本号-制定团队-更新日期-备注\" class=\"headerlink\" title=\"版本号 制定团队 更新日期 备注\"></a>版本号 制定团队 更新日期 备注</h4><pre><code>1. 7. 0 阿里巴巴与全球Java社区开发者 2020. 08. 03 嵩山版，首次发布前后端规约\n</code></pre>\n<pre><code>说明：在本文MySQL规约中的建表约定第一条，表达是与否的变量采用is_xxx的命名方式，所以，需要\n在&lt;resultMap&gt;设置从is_xxx到xxx的映射关系。\n反例：定义为基本数据类型Boolean isDeleted的属性，它的方法也是isDeleted()，框架在反向解析的时\n候，“误以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。\n</code></pre>\n<ol start=\"10\">\n<li>【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用<br>单数形式，但是类名如果有复数含义，类名可以使用复数形式。<br>正例：应用工具类包名为com.alibaba.ei.kunlun.aap.util、类名为MessageUtils（此规则参考spring的<br>框架结构）</li>\n<li>【强制】避免在子父类的成员变量之间、或者不同代码块的局部变量之间采用完全相同的命名，<br>使可理解性降低。<br>说明：子类、父类成员变量名相同，即使是public类型的变量也能够通过编译，另外，局部变量在同一方<br>法内的不同代码块中同名也是合法的，这些情况都要避免。对于非setter/getter的参数名称也要避免与成<br>员变量名称相同。<br>反例：<br>public class ConfusingName {<br>public int stock;<br>// 非setter/getter的参数名称，不允许与本类成员变量同名<br>public void get(String alibaba) {<br>if (condition) {<br>final int money = 666 ;<br>// …<br>}<br>for (int i = 0 ; i &lt; 10 ; i++) {<br>// 在同一方法体中，不允许与其它代码块中的money命名相同<br>final int money = 15978 ;<br>// …<br>}<br>}<br>}<br>class Son extends ConfusingName {<br>// 不允许与父类的成员变量名称相同<br>public int stock;<br>}</li>\n<li>【强制】杜绝完全不规范的缩写，避免望文不知义。<br>反例：AbstractClass“缩写”成AbsClass；condition“缩写”成 condi；Function缩写”成Fu，此类<br>随意缩写严重降低了代码的可阅读性。</li>\n<li>【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组<br>合来表达。</li>\n</ol>\n<pre><code>正例：对某个对象引用的volatile字段进行原子更新的类名为AtomicReferenceFieldUpdater。\n反例：常见的方法内变量为int a;的定义方式。\n</code></pre>\n<ol start=\"14\">\n<li>【推荐】在常量与变量的命名时，表示类型的名词放在词尾，以提升辨识度。<br>正例：startTime / workQueue / nameList / TERMINATED_THREAD_COUNT<br>反例：startedAt / QueueOfWork / listName / COUNT_TERMINATED_THREAD</li>\n<li>【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。<br>说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。<br>正例： public class OrderFactory;<br>public class LoginProxy;<br>public class ResourceObserver;</li>\n<li>【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁<br>性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，确定<br>与接口方法相关，并且是整个应用的基础常量。<br>正例：接口方法签名 void commit();<br>接口基础常量 String COMPANY = “alibaba”;<br>反例：接口方法定义 public abstract void f();<br>说明：JDK8中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。</li>\n<li>接口和实现类的命名有两套规则：<br>1 ）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用<br>Impl的后缀与接口区别。<br>正例：CacheServiceImpl实现CacheService接口。<br>2 ）【推荐】如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able的形容词）。<br>正例：AbstractTranslator实现 Translatable接口。</li>\n<li>【参考】枚举类名带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。<br>说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。<br>正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS / UNKNOWN_REASON。</li>\n<li>【参考】各层命名规约：<br>A) Service/DAO层方法命名规约<br>1 ） 获取单个对象的方法用get做前缀。<br>2 ） 获取多个对象的方法用list做前缀，复数结尾，如：listObjects。<br>3 ） 获取统计值的方法用count做前缀。<br>4 ） 插入的方法用save/insert做前缀。<br>5 ） 删除的方法用remove/delete做前缀。<br>6 ） 修改的方法用update做前缀。<br>B) 领域模型命名规约</li>\n</ol>\n<pre><code>1 ） 数据对象：xxxDO，xxx即为数据表名。\n2 ） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。\n3 ） 展示对象：xxxVO，xxx一般为网页名称。\n4 ） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。\n</code></pre>\n<h3 id=\"二-常量定义\"><a href=\"#二-常量定义\" class=\"headerlink\" title=\"(二) 常量定义\"></a>(二) 常量定义</h3><ol>\n<li>【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。<br> 反例：<pre><code>// 本例中，开发者A定义了缓存的key，然后开发者B使用缓存时少了下划线，即key是&quot;Id#taobao&quot;+tradeId，导致\n出现故障\nString key = &quot;Id#taobao_&quot; + tradeId;\ncache.put(key, value);\n</code></pre>\n</li>\n<li>【强制】在long或者Long赋值时，数值后使用大写字母L，不能是小写字母l，小写容易跟<br>数字混淆，造成误解。<br>说明：Long a = 2l; 写的是数字的 21 ，还是Long型的 2 ？</li>\n<li>【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。<br> 说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解，也不利于维护。<pre><code>正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类SystemConfigConsts下。\n</code></pre>\n</li>\n<li>【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包<br> 内共享常量、类内共享常量。<br> 1 ） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。<br> 2 ） 应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。<br> 反例：易懂变量也要统一定义成应用内共享常量，两位工程师在两个类中分别定义了“YES”的变量：<br> 类A中：public static final String YES = “yes”;<br> 类B中：public static final String YES = “y”;<br> A.YES.equals(B.YES)，预期是true，但实际返回为false，导致线上问题。<pre><code>3 ） 子工程内部共享常量：即在当前子工程的constant目录下。\n4 ） 包内共享常量：即在当前包下单独的constant目录下。\n5 ） 类内共享常量：直接在类内部private static final定义。\n</code></pre>\n</li>\n<li>【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。<br> 说明：如果存在名称之外的延伸属性应使用enum类型，下面正例中的数字就是延伸信息，表示一年中的<br> 第几个季节。<br> 正例：<pre><code>public enum SeasonEnum &#123;\nSPRING( 1 ), SUMMER( 2 ), AUTUMN( 3 ), WINTER( 4 );\nprivate int seq;\nSeasonEnum(int seq) &#123;\n</code></pre>\n</li>\n</ol>\n<pre><code>this.seq = seq;\n&#125;\npublic int getSeq() &#123;\nreturn seq;\n&#125;\n&#125;\n</code></pre>\n<h3 id=\"三-代码格式\"><a href=\"#三-代码格式\" class=\"headerlink\" title=\"(三) 代码格式\"></a>(三) 代码格式</h3><ol>\n<li>【强制】如果是大括号内为空，则简洁地写成{}即可，大括号中间无需换行和空格；如果是非<br> 空代码块则：<br> 1 ） 左大括号前不换行。<br> 2 ） 左大括号后换行。<br> 3 ） 右大括号前换行。<br> 4 ） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。</li>\n<li>【强制】左小括号和右边相邻字符之间不出现空格；右小括号和左边相邻字符之间也不出现空<br>格；而左大括号前需要加空格。详见第 5 条下方正例提示。<br>反例：if (空格a == b空格)</li>\n<li>【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。</li>\n<li>【强制】任何二目、三目运算符的左右两边都需要加一个空格。<br> 说明：包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号等。</li>\n<li>【强制】采用 4 个空格缩进，禁止使用Tab字符。<br>说明：如果使用Tab缩进，必须设置 1 个Tab为 4 个空格。IDEA设置Tab为 4 个空格时，请勿勾选Use<br>tab character；而在Eclipse中，必须勾选insert spaces for tabs。<br>正例： （涉及 1 - 5 点）<br>public static void main(String[] args) {<br>// 缩进 4 个空格<br>String say = “hello”;<br>// 运算符的左右必须有一个空格<br>int flag = 0 ;<br>// 关键词if与括号之间必须有一个空格，括号内的f与左括号， 0 与右括号不需要空格<br>if (flag == 0 ) {<br>System.out.println(say);<br>}<br>// 左大括号前加空格且不换行；左大括号后换行<br>if (flag == 1 ) {<br>System.out.println(“world”);<br>// 右大括号前换行，右大括号后有else，不用换行<br>} else {<br>System.out.println(“ok”);<br>// 在右大括号后直接结束，则必须换行<br>}<br>}</li>\n</ol>\n<ol start=\"6\">\n<li>【强制】注释的双斜线与注释内容之间有且仅有一个空格。<br> 正例：<pre><code>// 这是示例注释，请注意在双斜线之后有一个空格\nString commentString = new String();\n</code></pre>\n</li>\n<li>【强制】在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。<br> 正例：<pre><code>double first = 3.2d;\nint second = (int)first + 2 ;\n</code></pre>\n</li>\n<li>【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：<br> 1 ）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。<br> 2 ）运算符与下文一起换行。<br> 3 ）方法调用的点符号与下文一起换行。<br> 4 ）方法调用中的多个参数需要换行时，在逗号后进行。<br> 5 ）在括号前不要换行，见反例。<br> 正例：<pre><code>StringBuilder sb = new StringBuilder();\n// 超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点号一起换行\nsb.append(&quot;yang&quot;).append(&quot;hao&quot;)...\n.append(&quot;chen&quot;)...\n.append(&quot;chen&quot;)...\n.append(&quot;chen&quot;);\n</code></pre>\n 反例：<pre><code>StringBuilder sb = new StringBuilder();\n// 超过 120 个字符的情况下，不要在括号前换行\nsb.append(&quot;you&quot;).append(&quot;are&quot;)...append\n(&quot;lucky&quot;);\n// 参数很多的方法调用可能超过 120 个字符，逗号后才是换行处\nmethod(args1, args2, args3, ...\n, argsX);\n</code></pre>\n</li>\n<li>【强制】方法参数在定义和传入时，多个参数逗号后面必须加空格。<br> 正例：下例中实参的args1，后边必须要有一个空格。<pre><code>method(args1, args2, args3);\n</code></pre>\n</li>\n<li>【强制】IDE的text file encoding设置为UTF-8; IDE中文件的换行符使用Unix格式，不要<br>使用Windows格式。</li>\n<li>【推荐】单个方法的总行数不超过 80 行。<br>说明：除注释之外的方法签名、左右大括号、方法内代码、空行、回车及任何不可见字符的总行数不超过<br>80 行。<br>正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共<br>性逻辑抽取成为共性方法，便于复用和维护。</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐。<br>正例：<br>   int one = 1 ;<br>   long two = 2 L;<br>   float three = 3F;<br>   StringBuilder sb = new StringBuilder();<br>说明：增加sb这个变量，如果需要对齐，则给one、two、three都要增加几个空格，在变量比较多的情<br>况下，是非常累赘的事情。</li>\n<li>【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。<br>说明：任何情形，没有必要插入多个空行进行隔开。</li>\n</ol>\n<h3 id=\"四-OOP规约\"><a href=\"#四-OOP规约\" class=\"headerlink\" title=\"(四) OOP规约\"></a>(四) OOP规约</h3><ol>\n<li>【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成<br> 本，直接用类名来访问即可。</li>\n<li>【强制】所有的覆写方法，必须加@Override注解。<br> 说明：getObject()与get0bject()的问题。一个是字母的O，一个是数字的 0 ，加@Override可以准确判<br> 断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。</li>\n<li>【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。<br>说明：可变参数必须放置在参数列表的最后。（建议开发者尽量不用可变参数编程）<br>正例：public List<User> listUsers(String type, Long… ids) {…}</li>\n<li>【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生<br> 影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。</li>\n<li>【强制】不能使用过时的类或方法。<br> 说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数<br> decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；<br> 作为调用方来说，有义务去考证过时方法的新实现是什么。</li>\n<li>【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。<br> 正例：”test”.equals(object);<br> 反例：object.equals(“test”);<br> 说明：推荐使用JDK7引入的工具类java.util.Objects#equals(Object a, Object b)</li>\n<li>【强制】所有整型包装类对象之间值的比较，全部使用equals方法比较。<br> 说明：对于Integer var =? 在- 128 至 127 之间的赋值，Integer对象是在 IntegerCache.cache产生，<br> 会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都<br> 会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。</li>\n</ol>\n<ol start=\"8\">\n<li>【强制】任何货币金额，均以最小货币单位且整型类型来进行存储。</li>\n<li>【强制】浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用equals<br>来判断。<br>说明：浮点数采用“尾数+阶码”的编码方式，类似于科学计数法的“有效数字+指数”的表示方式。二进<br>制无法精确表示大部分的十进制小数，具体原理参考《码出高效》。<br>反例：<br>float a = 1.0F - 0.9F;<br>float b = 0.9F - 0.8F;<br>if (a == b) {<br>// 预期进入此代码块，执行其它业务逻辑<br>// 但事实上a==b的结果为false<br>}<br>Float x = Float.valueOf(a);<br>Float y = Float.valueOf(b);<br>if (x.equals(y)) {<br>// 预期进入此代码块，执行其它业务逻辑<br>// 但事实上equals的结果为false<br>}<br>正例：<br>(1) 指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。<br>float a = 1.0F - 0.9F;<br>float b = 0.9F - 0.8F;<br>float diff = 1e- 6 F;<br>if (Math.abs(a - b) &lt; diff) {<br>System.out.println(“true”);<br>}<br>(2) 使用BigDecimal来定义值，再进行浮点数的运算操作。<br>BigDecimal a = new BigDecimal(“1.0”);<br>BigDecimal b = new BigDecimal(“0.9”);<br>BigDecimal c = new BigDecimal(“0.8”);<br>BigDecimal x = a.subtract(b);<br>BigDecimal y = b.subtract(c);<br>if (x.compareTo(y) == 0 ) {<br>System.out.println(“true”);<br>}</li>\n<li>【强制】如上所示BigDecimal的等值比较应使用compareTo()方法，而不是equals()方法。<br>说明：equals()方法会比较值和精度（ 1 .0与 1 .00返回结果为false），而compareTo()则会忽略精度。</li>\n<li>【强制】定义数据对象DO类时，属性类型要与数据库字段类型相匹配。<br>正例：数据库字段的bigint必须与类属性的Long类型相对应。<br>反例：某个案例的数据库表id字段定义类型bigint unsigned，实际类对象属性为Integer，随着id越来<br>越大，超过Integer的表示范围而溢出成为负数。</li>\n</ol>\n<ol start=\"12\">\n<li>【强制】禁止使用构造方法BigDecimal(double)的方式把double值转化为BigDecimal对象。<br>说明：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。<br>如：BigDecimal g = new BigDecimal(0.1F); 实际的存储值为：0.<br>正例：优先推荐入参为String的构造方法，或使用BigDecimal的valueOf方法，此方法内部其实执行了<br>Double的toString，而Double的toString按double的实际能表达的精度对尾数进行了截断。<br>BigDecimal recommend1 = new BigDecimal(“0.1”);<br>BigDecimal recommend2 = BigDecimal.valueOf(0.1);</li>\n<li>关于基本数据类型与包装数据类型的使用标准如下：<br>1 ） 【强制】所有的POJO类属性必须使用包装数据类型。<br>2 ） 【强制】RPC方法的返回值和参数必须使用包装数据类型。<br>3 ） 【推荐】所有的局部变量使用基本数据类型。<br>说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或<br>者入库检查，都由使用者来保证。<br>正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。<br>反例：某业务的交易报表上显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调<br>用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线-。所以包装数据类型<br>的null值，能够表示额外的信息，如：远程调用失败，异常退出。</li>\n<li>【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。<br>反例：POJO类的createTime默认值为new Date()，但是这个属性在数据提取时并没有置入具体值，在<br>更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。</li>\n<li>【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果<br>完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。<br>说明：注意serialVersionUID不一致会抛出序列化运行时异常。</li>\n<li>【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。</li>\n<li>【强制】POJO类必须写toString方法。使用IDE中的工具：source&gt; generate toString<br>时，如果继承了另一个POJO类，注意在前面加一下super.toString。<br>说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。</li>\n<li>【强制】禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法。<br>说明：框架在调用属性xxx的提取方法时，并不能确定哪个方法一定是被优先调用到的。</li>\n<li>【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容<br>的检查，否则会有抛IndexOutOfBoundsException的风险。<br>说明：<br>   String str = “a,b,c,,”;<br>   String[] ary = str.split(“,”);<br>   // 预期大于 3 ，结果是 3<br>   System.out.println(ary.length);</li>\n</ol>\n<ol start=\"20\">\n<li>【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便<br>于阅读，此条规则优先于下一条。</li>\n<li>【推荐】 类内方法定义的顺序依次是：公有方法或保护方法 &gt; 私有方法 &gt; getter / setter<br>方法。<br>说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可<br>能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载<br>的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。</li>\n<li>【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在<br>getter/setter方法中，不要增加业务逻辑，增加排查问题的难度。<br>反例：<br>public Integer getData () {<br>if (condition) {<br>return this.data + 100 ;<br>} else {<br>return this.data - 100 ;<br>}<br>}</li>\n<li>【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。<br>说明：下例中，反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append<br>操作，最后通过toString方法返回String对象，造成内存资源浪费。<br>反例：<br>String str = “start”;<br>for (int i = 0 ; i &lt; 100 ; i++) {<br>str = str + “hello”;<br>}</li>\n<li>【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字：<br>1 ） 不允许被继承的类，如：String类。<br>2 ） 不允许修改引用的域对象，如：POJO类的域变量。<br>3 ） 不允许被覆写的方法，如：POJO类的setter方法。<br>4 ） 不允许运行过程中重新赋值的局部变量。<br>5 ） 避免上下文重复使用一个变量，使用final关键字可以强制重新定义一个变量，方便更好地进行重构。</li>\n<li>【推荐】慎用Object的clone方法来拷贝对象。<br>说明：对象clone方法默认是浅拷贝，若想实现深拷贝，需覆写clone方法实现域对象的深度遍历式拷贝。</li>\n<li>【推荐】类成员与方法访问控制从严：<br>1 ） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。<br>2 ） 工具类不允许有public或default构造方法。<br>3 ） 类非static成员变量并且与子类共享，必须是protected。<br>4 ） 类非static成员变量并且仅在本类使用，必须是private。</li>\n</ol>\n<pre><code>5 ） 类static成员变量如果仅在本类使用，必须是private。\n6 ） 若是static成员变量，考虑是否为final。\n7 ） 类成员方法只供类内部调用，必须是private。\n8 ） 类成员方法只对继承类公开，那么限制为protected。\n说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果\n是一个private的方法，想删除就删除，可是一个public的service成员方法或成员变量，删除一下，不\n得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你\n会担心的。\n</code></pre>\n<h3 id=\"五-日期时间\"><a href=\"#五-日期时间\" class=\"headerlink\" title=\"(五) 日期时间\"></a>(五) 日期时间</h3><ol>\n<li>【强制】日期格式化时，传入pattern中表示年份统一使用小写的y。<br> 说明：日期格式化时，yyyy表示当天所在的年，而大写的YYYY代表是week in which year（JDK7之后<br> 引入的概念），意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY<br> 就是下一年。<br> 正例：表示日期和时间的格式如下所示：<br> new SimpleDateFormat(“yyyy-MM-dd HH:mm:ss”)</li>\n<li>【强制】在日期格式中分清楚大写的M和小写的m，大写的H和小写的h分别指代的意义。<br>说明：日期格式中的这两对字母表意如下：<br>1 ） 表示月份是大写的M；<br>2 ） 表示分钟则是小写的m；<br>3 ） 24 小时制的是大写的H；<br>4 ） 12 小时制的则是小写的h。</li>\n<li>【强制】获取当前毫秒数：System.currentTimeMillis(); 而不是new Date().getTime()。<br> 说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间<br> 等场景，推荐使用Instant类。</li>\n<li>【强制】不允许在程序任何地方中使用： 1 ）java.sql.Date。 2 ）java.sql.Time。<br>3 ）java.sql.Timestamp。<br>说明：第 1 个不记录时间，getHours()抛出异常；第 2 个不记录日期，getYear()抛出异常；第 3 个在构造<br>方法super((time/1000)*1000)，在Timestamp 属性fastTime和nanos分别存储秒和纳秒信息。<br>反例： java.util.Date.after(Date)进行时间比较时，当入参是java.sql.Timestamp时，会触发JDK<br>BUG(JDK9已修复)，可能导致比较时的意外结果。</li>\n<li>【强制】不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑<br>错误。</li>\n</ol>\n<pre><code>正例：\n// 获取今年的天数\nint daysOfThisYear = LocalDate.now().lengthOfYear();\n// 获取指定某年的天数\nLocalDate.of( 2011 , 1 , 1 ).lengthOfYear();\n反例：\n// 第一种情况：在闰年 366 天时，出现数组越界异常\nint[] dayArray = new int[ 365 ];\n// 第二种情况：一年有效期的会员制，今年 1 月 26 日注册，硬编码 365 返回的却是 1 月 25 日\nCalendar calendar = Calendar.getInstance();\ncalendar.set( 2020 , 1 , 26 );\ncalendar.add(Calendar.DATE, 365 );\n</code></pre>\n<ol start=\"6\">\n<li>【推荐】避免公历闰年 2 月问题。闰年的 2 月份有 29 天，一年后的那一天不可能是 2 月 29<br> 日。</li>\n<li>【推荐】使用枚举值来指代月份。如果使用数字，注意Date，Calendar等日期相关类的月份<br> month取值在 0 - 11 之间。<br> 说明：参考JDK原生注释，Month value is 0-based. e.g., 0 for January.<br> 正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或<br> 比较。</li>\n</ol>\n<h3 id=\"六-集合处理\"><a href=\"#六-集合处理\" class=\"headerlink\" title=\"(六) 集合处理\"></a>(六) 集合处理</h3><ol>\n<li>【强制】关于hashCode和equals的处理，遵循如下规则：<br> 1 ） 只要覆写equals，就必须覆写hashCode。<br> 2 ） 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须覆写<br> 这两种方法。<br> 3 ） 如果自定义对象作为Map的键，那么必须覆写hashCode和equals。<br> 说明：String因为覆写了hashCode和equals方法，所以可以愉快地将String对象作为key来使用。</li>\n<li>【强制】判断所有集合内部的元素是否为空，使用isEmpty()方法，而不是size()==0的方式。<br> 说明：在某些集合中，前者的时间复杂度为O(1)，而且可读性更好。<br> 正例：<pre><code>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;( 16 );\nif(map.isEmpty()) &#123;\nSystem.out.println(&quot;no element in this map.&quot;);\n&#125;\n</code></pre>\n</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要使<br> 用含有参数类型为BinaryOperator，参数名为mergeFunction的方法，否则当出现相同key<br> 值时会抛出IllegalStateException异常。<br> 说明：参数mergeFunction的作用是当出现key重复时，自定义对value的处理策略。<br> 正例：<pre><code>List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;( 3 );\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 12.10));\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 12.19));\npairArrayList.add(new Pair&lt;&gt;(&quot;version&quot;, 6.28));\nMap&lt;String, Double&gt; map = pairArrayList.stream().collect(\n// 生成的map集合中只有一个键值对：&#123;version=6.2 8 &#125;\nCollectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - &gt; v2));\n</code></pre>\n 反例：<pre><code>String[] departments = new String[] &#123;&quot;iERP&quot;, &quot;iERP&quot;, &quot;EIBU&quot;&#125;;\n// 抛出IllegalStateException异常\nMap&lt;Integer, String&gt; map = Arrays.stream(departments)\n.collect(Collectors.toMap(String::hashCode, str -&gt; str));\n</code></pre>\n</li>\n<li>【强制】在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要注<br> 意当value为null时会抛NPE异常。<br> 说明：在java.util.HashMap的merge方法里会进行如下的判断：<pre><code>if (value == null || remappingFunction == null)\n   throw new NullPointerException();\n</code></pre>\n 反例：<pre><code>List&lt;Pair&lt;String, Double&gt;&gt; pairArrayList = new ArrayList&lt;&gt;( 2 );\npairArrayList.add(new Pair&lt;&gt;(&quot;version1&quot;, 8. 3 ));\npairArrayList.add(new Pair&lt;&gt;(&quot;version2&quot;, null));\nMap&lt;String, Double&gt; map = pairArrayList.stream().collect(\n// 抛出NullPointerException异常\nCollectors.toMap(Pair::getKey, Pair::getValue, (v1, v2) - &gt; v2));\n</code></pre>\n</li>\n<li>【强制】ArrayList的subList结果不可强转成ArrayList，否则会抛出 ClassCastException异<br> 常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。<br> 说明：subList()返回的是ArrayList的内部类SubList，并不是 ArrayList本身，而是ArrayList 的一个视<br> 图，对于SubList的所有操作最终会反映到原列表上。</li>\n<li>【强制】使用Map的方法keySet()/values()/entrySet()返回集合对象时，不可以对其进行添<br> 加元素操作，否则会抛出UnsupportedOperationException异常。</li>\n<li>【强制】Collections类返回的对象，如：emptyList()/singletonList()等都是immutable list，<br>不可对其进行添加或者删除元素的操作。<br>反例：如果查询无结果，返回Collections.emptyList()空集合对象，调用方一旦进行了添加元素的操作，就<br>会触发UnsupportedOperationException异常。</li>\n</ol>\n<ol start=\"8\">\n<li>【强制】在subList场景中，高度注意对父集合元素的增加或删除，均会导致子列表的遍历、<br> 增加、删除产生ConcurrentModificationException 异常。</li>\n<li>【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一<br>致、长度为 0 的空数组。<br>反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现<br>ClassCastException错误。<br>正例：<br>List<String> list = new ArrayList&lt;&gt;( 2 );<br>list.add(“guan”);<br>list.add(“bao”);<br>String[] array = list.toArray(new String[ 0 ]);<br>说明：使用toArray带参方法，数组空间大小的length：<br>1 ） 等于 0 ，动态创建与size相同的数组，性能最好。<br>2 ） 大于 0 但小于size，重新创建大小等于size的数组，增加GC负担。<br>3 ） 等于size，在高并发情况下，数组创建完成之后，size正在变大的情况下，负面影响与 2 相同。<br>4 ） 大于size，空间浪费，且在size处插入null值，存在NPE隐患。</li>\n<li>【强制】在使用Collection接口任何实现类的addAll()方法时，都要对输入的集合参数进行<br>NPE判断。<br>说明：在ArrayList#addAll方法的第一行代码即Object[] a = c.toArray(); 其中c为输入集合参数，如果<br>为null，则直接抛出异常。</li>\n<li>【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，<br>它的add/remove/clear方法会抛出UnsupportedOperationException异常。<br>说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配<br>器模式，只是转换接口，后台的数据仍是数组。<br>String[] str = new String[] { “chen”, “yang”, “hao” };<br>List list = Arrays.asList(str);<br>第一种情况：list.add(“yangguanbao”); 运行时异常。<br>第二种情况：str[0] = “change”; 也会随之修改，反之亦然。</li>\n<li>【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，<br>而&lt;? super T&gt;不能使用get方法，两者在接口调用赋值的场景中容易出错。<br>说明：扩展说一下PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用<? extends T>。第二、经常往里插入的，适合用<? super T></li>\n<li>【强制】在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行<br>instanceof判断，避免抛出ClassCastException异常。<br>说明：毕竟泛型是在JDK5后才出现，考虑到向前兼容，编译器是允许非泛型集合与泛型集合互相赋值。</li>\n</ol>\n<pre><code>反例：\nList&lt;String&gt; generics = null;\nList notGenerics = new ArrayList( 10 );\nnotGenerics.add(new Object());\nnotGenerics.add(new Integer( 1 ));\ngenerics = notGenerics;\n// 此处抛出ClassCastException异常\nString string = generics.get( 0 );\n</code></pre>\n<ol start=\"14\">\n<li>【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator<br>方式，如果并发操作，需要对Iterator对象加锁。<br>   正例：<pre><code>  List&lt;String&gt; list = new ArrayList&lt;&gt;();\n  list.add(&quot;1&quot;);\n  list.add(&quot;2&quot;);\n  Iterator&lt;String&gt; iterator = list.iterator();\n  while (iterator.hasNext()) &#123;\n  String item = iterator.next();\n  if (删除元素的条件) &#123;\n  iterator.remove();\n  &#125;\n  &#125;\n</code></pre>\n   反例：<pre><code>  for (String item : list) &#123;\n  if (&quot;1&quot;.equals(item)) &#123;\n  list.remove(item);\n  &#125;\n  &#125;\n</code></pre>\n   说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？</li>\n<li>【强制】在JDK 7 版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，<br>Collections.sort会抛IllegalArgumentException异常。<br>说明：三个条件如下<br>1 ） x，y的比较结果和y，x的比较结果相反。<br>2 ） x&gt;y，y&gt;z，则x&gt;z。<br>3 ） x=y，则x，z比较结果和y，z比较结果相同。<br>反例：下例中没有处理相等的情况，交换两个对象判断结果并不互反，不符合第一个条件，在实际使用中<br>可能会出现异常。<br>   new Comparator<Student>() {<br>   @Override<br>   public int compare(Student o1, Student o2) {<br>   return o1.getId() &gt; o2.getId()? 1 : - 1 ;<br>   }<br>   };</li>\n<li>【推荐】集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。<br>说明：菱形泛型，即diamond，直接使用&lt;&gt;来指代前边已经指定的类型。</li>\n</ol>\n<pre><code>正例：\n// diamond方式，即&lt;&gt;\nHashMap&lt;String, String&gt; userCache = new HashMap&lt;&gt;( 16 );\n// 全省略方式\nArrayList&lt;User&gt; users = new ArrayList( 10 );\n</code></pre>\n<ol start=\"17\">\n<li>【推荐】集合初始化时，指定集合初始值大小。<br>说明：HashMap使用HashMap(int initialCapacity) 初始化，如果暂时无法确定集合大小，那么指定默<br>认值（ 16 ）即可。<br>正例：initialCapacity = (需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loader factor）默认<br>为0.75，如果暂时无法确定初始值大小，请设置为 16 （即默认值）。<br>   反例： HashMap需要放置 1024 个元素，由于没有设置容量初始大小，随着元素增加而被迫不断扩容，<br>   resize()方法总共会调用 8 次，反复重建哈希表和数据迁移。当放置的集合元素个数达千万级时会影响程序<br>   性能。</li>\n<li>【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。<br>说明：keySet其实是遍历了 2 次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的<br>value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用<br>Map.forEach方法。<br>正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对<br>象；entrySet()返回的是K-V值组合集合。</li>\n<li>【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格：</li>\n</ol>\n<pre><code>集合类 Key Value Super 说明\nHashtable 不允许为null 不允许为null Dictionary 线程安全\nConcurrentHashMap 不允许为null 不允许为null AbstractMap 锁分段技术（JDK8:CAS）\nTreeMap 不允许为null 允许为null AbstractMap 线程不安全\nHashMap 允许为null 允许为null AbstractMap 线程不安全\n反例：由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储\nnull值时会抛出NPE异常。\n</code></pre>\n<ol start=\"20\">\n<li>【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳<br>定性(unorder)带来的负面影响。<br>说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。<br>如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。</li>\n<li>【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的<br>contains()进行遍历去重或者判断包含操作。</li>\n</ol>\n<h3 id=\"七-并发处理\"><a href=\"#七-并发处理\" class=\"headerlink\" title=\"(七) 并发处理\"></a>(七) 并发处理</h3><ol>\n<li>【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。<br> 说明：资源驱动类、工具类、单例工厂类都需要注意。</li>\n<li>【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。<br>正例：自定义线程工厂，并且根据外部特征进行分组，比如，来自同一机房的调用，把机房编号赋值给<br>whatFeatureOfGroup<br>public class UserThreadFactory implements ThreadFactory {<br>private final String namePrefix;<br>private final AtomicInteger nextId = new AtomicInteger( 1 );<br>// 定义线程组名称，在利用jstack来排查问题时，非常有帮助<br>UserThreadFactory(String whatFeatureOfGroup) {<br>namePrefix = “From UserThreadFactory’s “ + whatFeatureOfGroup + “-Worker-“;<br>}<br>@Override<br>public Thread newThread(Runnable task) {<br>String name = namePrefix + nextId.getAndIncrement();<br>Thread thread = new Thread(null, task, name, 0 , false);<br>System.out.println(thread.getName());<br>return thread;<br>}<br>}</li>\n<li>【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。<br>说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。<br>如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。</li>\n<li>【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这<br>样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。<br>说明：Executors返回的线程池对象的弊端如下：<br>1 ） FixedThreadPool和SingleThreadPool：<br>允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。<br>2 ） CachedThreadPool：<br>允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。</li>\n<li>【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，<br>必须加锁，或者使用DateUtils工具类。<br>正例：注意线程安全，使用DateUtils。亦推荐如下处理：<br>private static final ThreadLocal<DateFormat> df = new ThreadLocal<DateFormat>() {<br>@Override<br>protected DateFormat initialValue() {<br>return new SimpleDateFormat(“yyyy-MM-dd”);<br>}<br>};</li>\n</ol>\n<pre><code>说明：如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，\nDateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful strong immutable\nthread-safe。\n</code></pre>\n<ol start=\"6\">\n<li>【强制】必须回收自定义的ThreadLocal变量，尤其在线程池场景下，线程经常会被复用，<br> 如果不清理自定义的 ThreadLocal变量，可能会影响后续业务逻辑和造成内存泄露等问题。<br> 尽量在代理中使用try-finally块进行回收。<br> 正例：<pre><code>objectThreadLocal.set(userInfo);\ntry &#123;\n// ...\n&#125; finally &#123;\nobjectThreadLocal.remove();\n&#125;\n</code></pre>\n</li>\n<li>【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能<br> 锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。<pre><code>说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。\n</code></pre>\n</li>\n<li>【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造<br>成死锁。<br>说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、<br>B、C，否则可能出现死锁。</li>\n<li>【强制】在使用阻塞等待获取锁的方式中，必须在try代码块之外，并且在加锁方法与try代<br> 码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在finally中无法解锁。<br> 说明一：如果在lock方法与try代码块之间的方法调用抛出异常，那么无法解锁，造成其它线程无法成功<br> 获取锁。<br> 说明二：如果lock方法在try代码块之内，可能由于其它方法抛出异常，导致在finally代码块中，unlock<br> 对未加锁的对象解锁，它会调用AQS的tryRelease方法（取决于具体实现类），抛出<br> IllegalMonitorStateException异常。<br> 说明三：在Lock对象的lock方法实现中可能抛出unchecked异常，产生的后果与说明二相同。<br> 正例：<pre><code>Lock lock = new XxxLock();\n// ...\nlock.lock();\ntry &#123;\ndoSomething();\ndoOthers();\n&#125; finally &#123;\nlock.unlock();\n&#125;\n</code></pre>\n反例：<br>Lock lock = new XxxLock();<br>// …</li>\n</ol>\n<pre><code>try &#123;\n// 如果此处抛出异常，则直接执行finally代码块\ndoSomething();\n// 无论加锁是否成功，finally代码块都会执行\nlock.lock();\ndoOthers();\n&#125; finally &#123;\nlock.unlock();\n&#125;\n</code></pre>\n<ol start=\"10\">\n<li>【强制】在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否<br>持有锁。锁的释放规则与锁的阻塞等待方式相同。<br>说明：Lock对象的unlock方法在执行时，它会调用AQS的tryRelease方法（取决于具体实现类），如果<br>当前线程不持有锁，则抛出IllegalMonitorStateException异常。<br>正例：<br>   Lock lock = new XxxLock();<br>   // …<br>   boolean isLocked = lock.tryLock();<br>   if (isLocked) {<br>   try {<br>   doSomething();<br>   doOthers();<br>   } finally {<br>   lock.unlock();<br>   }<br>   }</li>\n<li>【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加<br>锁，要么在数据库层使用乐观锁，使用version作为更新依据。<br>说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于<br>3 次。</li>\n<li>【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛<br>出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。</li>\n<li>【推荐】资金相关的金融敏感信息，使用悲观锁策略。<br>说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策<br>略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观<br>锁更新。<br>   正例：悲观锁遵循一锁、二判、三更新、四释放的原则。</li>\n<li>【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方<br>法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至<br>await方法，直到超时才返回结果。<br>说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。</li>\n</ol>\n<ol start=\"15\">\n<li>【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed<br>导致的性能下降。<br>   说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。<br>   正例：在JDK7之后，可以直接使用API ThreadLocalRandom，而在 JDK7之前，需要编码保证每个线<br>   程持有一个单独的Random实例。</li>\n<li>【推荐】通过双重检查锁（double-checked locking）（在并发场景下）存在延迟初始化的优化<br>问题隐患（可参考 The “Double-Checked Locking is Broken” Declaration），推荐解决方案中较<br>为简单一种（适用于JDK 5 及以上版本），将目标属性声明为 volatile型，比如将helper的属<br>性声明修改为<code>private volatile Helper helper = null;</code>。<br>正例：<br>   public class LazyInitDemo {<br>   private volatile Helper helper = null;<br>   public Helper getHelper() {<br>   if (helper == null) {<br>   synchronized (this) {<br>   if (helper == null) { helper = new Helper(); }<br>   }<br>   }<br>   return helper;<br>   }<br>   // other methods and fields…<br>   }</li>\n<li>【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但<br>是如果多写，同样无法解决线程安全问题。<br>   说明：如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger();<br>   count.addAndGet(1); 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观<br>   锁的重试次数）。</li>\n<li>【参考】HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在<br>开发过程中注意规避此风险。</li>\n<li>【参考】ThreadLocal对象使用static修饰，ThreadLocal无法解决共享对象的更新问题。<br>说明：这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量，<br>也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可<br>以操控这个变量。</li>\n</ol>\n<h3 id=\"八-控制语句\"><a href=\"#八-控制语句\" class=\"headerlink\" title=\"(八) 控制语句\"></a>(八) 控制语句</h3><ol>\n<li>【强制】在一个switch块内，每个case要么通过continue/break/return等来终止，要么<br> 注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default</li>\n</ol>\n<pre><code>语句并且放在最后，即使它什么代码也没有。\n说明：注意break是退出switch语句块，而return是退出方法体。\n</code></pre>\n<ol start=\"2\">\n<li>【强制】当switch括号内的变量类型为String并且此变量为外部参数时，必须先进行null<br> 判断。<br> 反例：如下的代码输出是什么？<pre><code>public class SwitchString &#123;\npublic static void main(String[] args) &#123;\nmethod(null);\n&#125;\npublic static void method(String param) &#123;\nswitch (param) &#123;\n// 肯定不是进入这里\ncase &quot;sth&quot;:\nSystem.out.println(&quot;it&#39;s sth&quot;);\nbreak;\n// 也不是进入这里\ncase &quot;null&quot;:\nSystem.out.println(&quot;it&#39;s null&quot;);\nbreak;\n// 也不是进入这里\ndefault:\nSystem.out.println(&quot;default&quot;);\n&#125;\n&#125;\n&#125;\n</code></pre>\n</li>\n<li>【强制】在if/else/for/while/do语句中必须使用大括号。<br> 说明：即使只有一行代码，也禁止不采用大括号的编码方式：if (condition) statements;</li>\n<li>【强制】三目运算符condition? 表达式1 : 表达式 2 中，高度注意表达式 1 和 2 在类型对齐<br> 时，可能抛出因自动拆箱导致的NPE异常。<br> 说明：以下两种场景会触发类型对齐的拆箱操作：<br> 1 ） 表达式 1 或表达式 2 的值只要有一个是原始类型。<br> 2 ） 表达式 1 或表达式 2 的值的类型不一致，会强制拆箱升级成表示范围更大的那个类型。<pre><code>反例：\n   Integer a = 1 ;\n   Integer b = 2 ;\n   Integer c = null;\n   Boolean flag = false;\n   // a*b的结果是int类型，那么c会强制拆箱成int类型，抛出NPE异常\n   Integer result=(flag? a*b : c);\n</code></pre>\n</li>\n<li>【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。<br>说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件<br>来代替。</li>\n</ol>\n<pre><code>反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，\n这样的话，活动无法终止。\n</code></pre>\n<ol start=\"6\">\n<li>【推荐】当某个方法的代码总行数超过 10 行时，return / throw 等中断逻辑的右大括号后均<br> 需要加一个空行。<br> 说明：这样做逻辑清晰，有利于代码阅读时重点关注。</li>\n<li>【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成：<br>if (condition) {<br>…<br>return obj;<br>}<br>// 接着写else的业务逻辑代码;<br>说明：如果非使用if()…else if()…else…方式表达逻辑，避免后续代码维护困难，请勿超过 3 层。<br>正例：超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句<br>示例如下：<br>public void findBoyfriend (Man man) {<br>if (man.isUgly()) {<br>System.out.println(“本姑娘是外貌协会的资深会员”);<br>return;<br>}<br>if (man.isPoor()) {<br>System.out.println(“贫贱夫妻百事哀”);<br>return;<br>}<br>if (man.isBadTemper()) {<br>System.out.println(“银河有多远，你就给我滚多远”);<br>return;<br>}<br>System.out.println(“可以先交往一段时间看看”);<br>}</li>\n<li>【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复<br> 杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。<br> 说明：很多 if 语句内的逻辑表达式相当复杂，与、或、取反混合运算，甚至各种方法纵深调用，理解成本<br> 非常高。如果赋值一个非常好理解的布尔变量名字，则是件令人爽心悦目的事情。<br> 正例：<pre><code>// 伪代码如下\nfinal boolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...);\nif (existed) &#123;\n...\n&#125;\n</code></pre>\n反例：<br>public final void acquire ( long arg) {<br>if (!tryAcquire(arg) &amp;&amp;<br>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {<br>selfInterrupt();<br>}</li>\n</ol>\n<ol start=\"9\">\n<li>【推荐】不要在其它表达式（尤其是条件表达式）中，插入赋值语句。<br> 说明：赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行。<br> 反例：<pre><code>public Lock getLock(boolean fair) &#123;\n// 算术表达式中出现赋值操作，容易忽略count值已经被改变\nthreshold = (count = Integer.MAX_VALUE) - 1 ;\n// 条件表达式中出现赋值操作，容易误认为是sync==fair\nreturn (sync = fair)? new FairSync() : new NonfairSync();\n&#125;\n</code></pre>\n</li>\n<li>【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、<br>获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。</li>\n<li>【推荐】避免采用取反逻辑运算符。<br>说明：取反逻辑不利于快速理解，并且取反逻辑写法一般都存在对应的正向逻辑写法。<br>正例：使用if (x &lt; 628) 来表达 x 小于 628 。<br>反例：使用if (!(x &gt;= 628)) 来表达 x 小于 628 。</li>\n<li>【推荐】公开接口需要进行入参保护，尤其是批量操作的接口。<br>反例：某业务系统，提供一个用户批量查询的接口，API文档上有说最多查多少个，但接口实现上没做任何<br>保护，导致调用方传了一个 1000 的用户id数组过来后，查询信息后，内存爆了。</li>\n<li>【参考】下列情形，需要进行参数校验：<br>1 ） 调用频次低的方法。<br>2 ） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致<br>中间执行回退，或者错误，那得不偿失。<br>3 ） 需要极高稳定性和可用性的方法。<br>4 ） 对外提供的开放接口，不管是RPC/API/HTTP接口。<br>   5 ） 敏感权限入口。</li>\n<li>【参考】下列情形，不需要进行参数校验：<br>1 ） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查。<br>2 ） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露<br>问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可<br>以省略。<br>3 ） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检<br>查或者肯定不会有问题，此时可以不校验参数。</li>\n</ol>\n<h3 id=\"九-注释规约\"><a href=\"#九-注释规约\" class=\"headerlink\" title=\"(九) 注释规约\"></a>(九) 注释规约</h3><ol>\n<li>【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/*<em>内容</em>/格式，不得使用<br> // xxx方式。<br> 说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE<br> 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。</li>\n<li>【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、<br> 异常说明外，还必须指出该方法做什么事情，实现什么功能。<br> 说明：对子类的实现要求，或者调用注意事项，请一并说明。</li>\n<li>【强制】所有的类都必须添加创建者和创建日期。<br>说明：在设置模板时，注意IDEA的@author为<code>$&#123;USER&#125;</code>，而eclipse的@author为<code>$&#123;user&#125;</code>，大小写有<br>区别，而日期的设置统一为yyyy/MM/dd的格式。<br>正例：<br>/**</li>\n</ol>\n<pre><code>* @author yangguanbao\n* @date 2016/10/31\n*/\n</code></pre>\n<ol start=\"4\">\n<li>【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使<br> 用/* */注释，注意与代码对齐。</li>\n<li>【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。</li>\n<li>【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持<br> 英文原文即可。<br> 反例：“TCP连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。</li>\n<li>【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑<br> 等的修改。<br> 说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了<br> 导航的意义。</li>\n<li>【推荐】在类中删除未使用的任何字段、方法、内部类；在方法中删除未使用的任何参数声明<br> 与内部变量。</li>\n<li>【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。<br> 说明：代码被注释掉有两种可能性： 1 ）后续会恢复此段代码逻辑。 2 ）永久不用。前者如果没有备注信息，<br> 难以知晓注释动机。后者建议直接删掉即可，假如需要查阅历史代码，登录代码仓库即可。</li>\n</ol>\n<ol start=\"10\">\n<li>【参考】对于注释的要求：第一、能够准确反映设计思想和代码逻辑；第二、能够描述业务含<br>义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同<br>天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看<br>的，使其能够快速接替自己的工作。</li>\n<li>【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一<br>个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释又是相当大的负担。<br>反例：<br>// put elephant into fridge<br>put(elephant, fridge);<br>方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不<br>需要额外的注释。</li>\n<li>【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，<br>经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。<br>1 ） 待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）<br>表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没<br>有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）。<br>2 ） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）<br>在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。</li>\n</ol>\n<h3 id=\"十-前后端规约\"><a href=\"#十-前后端规约\" class=\"headerlink\" title=\"(十) 前后端规约\"></a>(十) 前后端规约</h3><ol>\n<li>【强制】前后端交互的API，需要明确协议、域名、路径、请求方法、请求内容、状态码、响<br> 应体。<br> 说明：<pre><code>1 ） 协议：生产环境必须使用HTTPS。\n2 ） 路径：每一个API需对应一个路径，表示API具体的请求地址：\na） 代表一种资源，只能为名词，推荐使用复数，不能为动词，请求方法已经表达动作意义。\nb） URL路径不能使用大写，单词如果需要分隔，统一使用下划线。\nc） 路径禁止携带表示请求内容类型的后缀，比如&quot;.json&quot;,&quot;.xml&quot;，通过accept头表达即可。\n3 ） 请求方法：对具体操作的定义，常见的请求方法如下：\na） GET：从服务器取出资源。\nb） POST：在服务器新建一个资源。\nc） PUT：在服务器更新资源。\nd） DELETE：从服务器删除资源。\n4 ） 请求内容：URL带的参数必须无敏感信息或符合安全要求；body里带参数时必须设置Content-Type。\n5 ） 响应体：响应体body可放置多种数据类型，由Content-Type头来确定。\n</code></pre>\n</li>\n</ol>\n<ol start=\"2\">\n<li>【强制】前后端数据列表相关的接口返回，如果为空，则返回空数组[]或空集合{}。<br> 说明：此条约定有利于数据层面上的协作更加高效，减少前端很多琐碎的null判断。</li>\n<li>【强制】服务端发生错误时，返回给前端的响应信息必须包含HTTP状态码，errorCode、<br> errorMessage、用户提示信息四个部分。<br> 说明：四个部分的涉众对象分别是浏览器、前端开发、错误排查人员、用户。其中输出给用户的提示信息<br> 要求：简短清晰、提示友好，引导用户进行下一步操作或解释错误原因，提示信息可以包括错误原因、上<br> 下文环境、推荐操作等。 errorCode：参考 <strong>附表 3</strong> 。errorMessage：简要描述后端出错原因，便于错误排<br> 查人员快速定位问题，注意不要包含敏感数据信息。<br> 正例：常见的HTTP状态码如下<br> 1 ） 200 OK: 表明该请求被成功地完成，所请求的资源发送到客户端。<br> 2 ） 401 Unauthorized: 请求要求身份验证，常见对于需要登录而用户未登录的情况。<br> 3 ） 403 Forbidden：服务器拒绝请求，常见于机密信息或复制其它登录用户链接访问服务器的情况。<br> 4 ） 404 Not Found: 服务器无法取得所请求的网页，请求资源不存在。<br> 5 ） 500 Internal Server Error: 服务器内部错误。</li>\n<li>【强制】在前后端交互的JSON格式数据中，所有的key必须为小写字母开始的<br> lowerCamelCase风格，符合英文表达习惯，且表意完整。<br> 正例：errorCode / errorMessage / assetStatus / menuList / orderList / configFlag<br> 反例：ERRORCODE / ERROR_CODE / error_message / error-message / errormessage /<br> ErrorMessage / msg</li>\n<li>【强制】errorMessage是前后端错误追踪机制的体现，可以在前端输出到type=”hidden”<br>文字类控件中，或者用户端的日志中，帮助我们快速地定位出问题。</li>\n<li>【强制】对于需要使用超大整数的场景，服务端一律使用String字符串类型返回，禁止使用<br>Long类型。<br>说明：Java服务端如果直接返回Long整型数据给前端，JS会自动转换为Number类型（注：此类型为双<br>精度浮点数，表示原理与取值范围等同于Java中的Double）。Long类型能表示的最大值是 2 的 63 次方</li>\n</ol>\n<ul>\n<li>1 ，在取值范围之内，超过 2 的 53 次方 (9007199254740992)的数值转化为JS的Number时，有些数<br>值会有精度损失。扩展说明，在Long取值范围内，任何 2 的指数次整数都是绝对不会存在精度损失的，所<br>以说精度损失是一个概率问题。若浮点数尾数位与指数位空间不限，则可以精确表示任何整数，但很不幸，<br>双精度浮点数的尾数位只有 52 位。<br>反例：通常在订单号或交易号大于等于 16 位，大概率会出现前后端单据不一致的情况，比如，”orderId”:<br>362909601374617692 ，前端拿到的值却是: 36290960137461766 0 。</li>\n</ul>\n<ol start=\"7\">\n<li>【强制】HTTP请求通过URL传递参数时，不能超过 2048 字节。<br> 说明：不同浏览器对于URL的最大长度限制略有不同，并且对超出最大长度的处理逻辑也有差异， 2048<br> 字节是取所有浏览器的最小值。</li>\n</ol>\n<pre><code>反例：某业务将退货的商品id列表放在URL中作为参数传递，当一次退货商品数量过多时，URL参数超长，\n传递到后端的参数被截断，导致部分商品未能正确退货。\n</code></pre>\n<ol start=\"8\">\n<li>【强制】HTTP请求通过body传递内容时，必须控制长度，超出最大长度后，后端解析会出<br> 错。<br> 说明：nginx默认限制是1MB，tomcat默认限制为2MB，当确实有业务需要传较大内容时，可以通过调<br> 大服务器端的限制。</li>\n<li>【强制】在翻页场景中，用户输入参数的小于 1 ，则前端返回第一页参数给后端；后端发现用<br>户输入的参数大于总页数，直接返回最后一页。</li>\n<li>【强制】服务器内部重定向必须使用forward；外部重定向地址必须使用URL统一代理模块<br>生成，否则会因线上采用HTTPS协议而导致浏览器提示“不安全”，并且还会带来URL维护<br>不一致的问题。</li>\n<li>【推荐】服务器返回信息必须被标记是否可以缓存，如果缓存，客户端可能会重用之前的请求<br>结果。<br>说明：缓存有利于减少交互次数，减少交互的平均延迟。<br>正例：http 1.1中，s-maxage告诉服务器进行缓存，时间单位为秒，用法如下，<br>response.setHeader(“Cache-Control”, “s-maxage=” + cacheSeconds);</li>\n<li>【推荐】服务端返回的数据，使用JSON格式而非XML。<br>说明：尽管HTTP支持使用不同的输出格式，例如纯文本，JSON，CSV，XML，RSS甚至HTML。如果我<br>们使用的面向用户的服务，应该选择JSON作为通信中使用的标准数据交换格式，包括请求和响应。此外，<br>application/JSON是一种通用的MIME类型，具有实用、精简、易读的特点。</li>\n<li>【推荐】前后端的时间格式统一为”yyyy-MM-dd HH:mm:ss”，统一为GMT。</li>\n<li>【参考】在接口路径中不要加入版本号，版本控制在HTTP头信息中体现，有利于向前兼容。<br>说明：当用户在低版本与高版本之间反复切换工作时，会导致迁移复杂度升高，存在数据错乱风险。</li>\n</ol>\n<h3 id=\"十一-其他\"><a href=\"#十一-其他\" class=\"headerlink\" title=\"(十一) 其他\"></a>(十一) 其他</h3><ol>\n<li>【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。<br> 说明：不要在方法体内定义：Pattern pattern = Pattern.compile(“规则”);</li>\n<li>【强制】避免用Apache Beanutils进行属性的copy。<br> 说明：Apache BeanUtils性能较差，可以使用其他方案比如Spring BeanUtils, Cglib BeanCopier，注意<br> 均是浅拷贝。</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】velocity调用POJO类的属性时，直接使用属性名取值即可，模板引擎会自动按规范<br> 调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），<br> 会自动调用isXxx()方法。<br> 说明：注意如果是Boolean包装类对象，优先调用getXxx()的方法。</li>\n<li>【强制】后台输送给页面的变量必须加$!{var}——中间的感叹号。<br> 说明：如果var等于null或者不存在，那么${var}会直接显示在页面上。</li>\n<li>【强制】注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x&lt;1（能够<br> 取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大 10 的若干倍然后<br> 取整，直接使用Random对象的nextInt或者nextLong方法。</li>\n<li>【推荐】不要在视图模板中加入任何复杂的逻辑。<br>说明：根据MVC理论，视图的职责是展示，不要抢模型和控制器的活。</li>\n<li>【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。</li>\n<li>【推荐】及时清理不再使用的代码段或配置信息。<br>说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。<br>正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)<br>来说明注释掉代码的理由。如：<br>public static void hello() {<br>/// 业务方通知活动暂停<br>// Business business = new Business();<br>// business.active();<br>System.out.println(“it’s finished”);<br>}</li>\n</ol>\n<h2 id=\"二、异常日志\"><a href=\"#二、异常日志\" class=\"headerlink\" title=\"二、异常日志\"></a>二、异常日志</h2><h3 id=\"一-错误码\"><a href=\"#一-错误码\" class=\"headerlink\" title=\"(一) 错误码\"></a>(一) 错误码</h3><ol>\n<li>【强制】错误码的制定原则：快速溯源、沟通标准化。<br> 说明： 错误码想得过于完美和复杂，就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身<br> 携带并且简单易懂。<br> 正例：错误码回答的问题是谁的错？错在哪？ 1 ）错误码必须能够快速知晓错误来源，可快速判断是谁的问<br> 题。 2 ）错误码必须能够进行清晰地比对（代码中容易equals）。 3 ）错误码有利于团队快速对错误原因达<br> 到一致认知。</li>\n<li>【强制】错误码不体现版本号和错误等级信息。<br> 说明：错误码以不断追加的方式进行兼容。错误等级由日志和错误码本身的释义来决定。</li>\n<li>【强制】全部正常，但不得不填充错误码时返回五个零： 00000 。</li>\n<li>【强制】错误码为字符串类型，共 5 位，分成两个部分：错误产生来源+四位数字编号。<br> 说明：错误产生来源分为A/B/C，A表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付<br> 超时等问题；B表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；C表示错误来源<br> 于第三方服务，比如CDN服务出错，消息投递超时等问题；四位数字编号从 0001 到 9999 ，大类之间的<br> 步长间距预留 100 ，参考文末 <strong>附表 3</strong> 。</li>\n<li>【强制】编号不与公司业务架构，更不与组织架构挂钩，以先到先得的原则在统一平台上进行，<br> 审批生效，编号即被永久固定。</li>\n<li>【强制】错误码使用者避免随意定义新的错误码。<br> 说明：尽可能在原有错误码附表中找到语义相同或者相近的错误码在代码中使用即可。</li>\n<li>【强制】错误码不能直接输出给用户作为提示信息使用。<br> 说明：堆栈（stack_trace）、错误信息(error_message)、错误码（error_code）、提示信息（user_tip）<br> 是一个有效关联并互相转义的和谐整体，但是请勿互相越俎代庖。</li>\n<li>【推荐】错误码之外的业务独特信息由error_message来承载，而不是让错误码本身涵盖过<br> 多具体业务属性。</li>\n<li>【推荐】在获取第三方服务错误码时，向上抛出允许本系统转义，由C转为B，并且在错误信<br> 息上带上原有的第三方错误码。</li>\n<li>【参考】错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。<br>说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、</li>\n</ol>\n<pre><code>B0001（系统执行出错）、C0001（调用第三方服务出错）。\n正例：调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。\n</code></pre>\n<ol start=\"11\">\n<li>【参考】错误码的后三位编号与HTTP状态码没有任何关系。</li>\n<li>【参考】错误码有利于不同文化背景的开发者进行交流与代码协作。<br>说明：英文单词形式的错误码不利于非英语母语国家（如阿拉伯语、希伯来语、俄罗斯语等）之间的开发<br>者互相协作。</li>\n<li>【参考】错误码即人性，感性认知+口口相传，使用纯数字来进行错误码编排不利于感性记忆<br>和分类。<br>说明：数字是一个整体，每位数字的地位和含义是相同的。<br>反例：一个五位数字 12345 ，第 1 位是错误等级，第 2 位是错误来源， 345 是编号，人的大脑不会主动地<br>拆开并分辨每位数字的不同含义。</li>\n</ol>\n<h3 id=\"二-异常处理\"><a href=\"#二-异常处理\" class=\"headerlink\" title=\"(二) 异常处理\"></a>(二) 异常处理</h3><ol>\n<li>【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过<br> catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。<br> 说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不<br> 通过catch NumberFormatException来实现。<br> 正例：if (obj != null) {…}<br> 反例：try { obj.method(); } catch (NullPointerException e) {…}</li>\n<li>【强制】异常捕获后不要用来做流程控制，条件控制。<br> 说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。</li>\n<li>【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。<br> 对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。<br> 说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，<br> 这是一种不负责任的表现。<br> 正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程<br> 序上作出分门别类的判断，并提示给用户。</li>\n<li>【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请<br> 将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的<br> 内容。</li>\n<li>【强制】事务场景中，抛出异常被catch后，如果需要回滚，一定要注意手动回滚事务。</li>\n</ol>\n<ol start=\"6\">\n<li>【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。<br> 说明：如果JDK7及以上，可以使用try-with-resources方式。</li>\n<li>【强制】不要在finally块中使用return。<br>说明：try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存<br>在return语句，则在此直接返回，无情丢弃掉try块中的返回点。<br>反例：<br>private int x = 0 ;<br>public int checkReturn() {<br>try {<br>// x等于 1 ，此处不返回<br>return ++x;<br>} finally {<br>// 返回的结果是 2<br>return ++x;<br>}<br>}</li>\n<li>【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。<br> 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。</li>\n<li>【强制】在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable<br> 类来进行拦截。<br> 说明：通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出<br> NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，<br> 或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代<br> 码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。</li>\n<li>【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说<br>明什么情况下会返回null值。<br>说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也<br>并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。</li>\n<li>【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景：<br>1 ） 返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。<br>反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。<br>2 ） 数据库的查询结果可能为null。<br>3 ） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。<br>4 ） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。<br>5 ） 对于Session中获取的数据，建议进行NPE检查，避免空指针。<br>6 ） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。<br>正例：使用JDK8的Optional类来防止NPE问题。</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，<br>更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定<br>义过的自定义异常，如：DAOException / ServiceException等。</li>\n<li>【参考】对于公司外的http/api开放接口必须使用errorCode；而应用内部推荐异常抛出；<br>跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、errorCode、<br>errorMessage；而应用内部直接抛出异常即可。<br>说明：关于RPC方法返回方式使用Result方式的理由：<br>1 ）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。<br>2 ）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题<br>的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。</li>\n</ol>\n<h3 id=\"三-日志规约\"><a href=\"#三-日志规约\" class=\"headerlink\" title=\"(三) 日志规约\"></a>(三) 日志规约</h3><ol>\n<li>【强制】应用中不可直接使用日志系统（Log 4 j、Logback）中的API，而应依赖使用日志框架<br> （SLF4J、JCL–Jakarta Commons Logging）中的API，使用门面模式的日志框架，有利于维护和<br> 各个类的日志处理方式统一。<br> 说明：日志框架（SLF4J、JCL–Jakarta Commons Logging）的使用方式（推荐使用SLF4J）<br>使用SLF4J：<br>import org.slf4j.Logger;<br>import org.slf4j.LoggerFactory;<br>private static final Logger logger = LoggerFactory.getLogger(Test.class);<br>使用JCL：<br>import org.apache.commons.logging.Log;<br>import org.apache.commons.logging.LogFactory;<br>private static final Log log = LogFactory.getLog(Test.class);</li>\n<li>【强制】所有日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。对于<br>当天日志，以“应用名.log”来保存，保存在/home/admin/应用名/logs/目录下，过往日志<br>格式为: {logname}.log.{保存日期}，日期格式：yyyy-MM-dd<br>正例：以aap应用为例，日志保存在/home/admin/aapserver/logs/aap.log，历史日志名称为<br>aap.log.2016- 08 - 01</li>\n<li>【强制】根据国家法律，网络运行状态、网络安全事件、个人敏感信息操作等相关记录，留存<br> 的日志不少于六个月，并且进行网络多机备份。</li>\n<li>【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：<br> appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描<br> 述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查<br> 找。</li>\n</ol>\n<pre><code>说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系\n统进行及时监控。\n正例：mppserver应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log\n</code></pre>\n<ol start=\"5\">\n<li>【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式。<br> 说明：因为String字符串的拼接会使用StringBuilder的append()方式，有一定的性能损耗。使用占位符仅<br> 是替换动作，可以有效提升性能。<br> 正例：logger.debug(“Processing trade with id: {} and symbol: {}”, id, symbol);</li>\n<li>【强制】对于trace/debug/info级别的日志输出，必须进行日志级别的开关判断。<br> 说明：虽然在debug(参数)的方法体内第一行代码isDisabled(Level.DEBUG_INT)为真时（Slf4j的常见实现<br> Log4j和Logback），就直接return，但是参数可能会进行字符串拼接运算。此外，如果debug(getName())<br> 这种参数内有getName()方法调用，无谓浪费方法调用的开销。<br> 正例：<pre><code>// 如果判断为真，那么可以输出trace和debug级别的日志\nif (logger.isDebugEnabled()) &#123;\nlogger.debug(&quot;Current ID is: &#123;&#125; and name is: &#123;&#125;&quot;, id, getName());\n&#125;\n</code></pre>\n</li>\n<li>【强制】避免重复打印日志，浪费磁盘空间，务必在日志配置文件中设置additivity=false。<br> 正例：<logger name=\"com.taobao.dubbo.config\" additivity=\"false\"></li>\n<li>【强制】生产环境禁止直接使用System.out 或System.err 输出日志或使用<br> e.printStackTrace()打印异常堆栈。<br> 说明：标准日志输出与标准错误输出文件每次Jboss重启时才滚动，如果大量输出送往这两个文件，容易<br> 造成文件大小超过操作系统大小限制。</li>\n<li>【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过<br>关键字throws往上抛出。<br>正例：logger.error(“inputParams:{} and errorMessage:{}”, 各类参数或者对象toString(), e.getMessage(), e);</li>\n<li>【强制】日志打印时禁止直接用JSON工具将对象转换成String。<br>说明：如果对象里某些get方法被覆写，存在抛出异常的情况，则可能会因为打印日志而影响正常业务流<br>程的执行。<br>正例：打印日志时仅打印出业务相关属性值或者调用其对象的toString()方法。</li>\n<li>【推荐】谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用<br>warn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑<br>爆，并记得及时删除这些观察日志。<br>说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些<br>日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？</li>\n</ol>\n<ol start=\"12\">\n<li>【推荐】可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适<br>从。如非必要，请不要在此场景打出error级别，避免频繁报警。<br>说明：注意日志输出的级别，error级别只记录系统逻辑出错、异常或者重要的错误信息。</li>\n<li>【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用<br>中文描述即可，否则容易产生歧义。<br>说明：国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息。</li>\n</ol>\n<h2 id=\"三、单元测试\"><a href=\"#三、单元测试\" class=\"headerlink\" title=\"三、单元测试\"></a>三、单元测试</h2><ol>\n<li>【强制】好的单元测试必须遵守AIR原则。<br> 说明：单元测试在线上运行时，感觉像空气（AIR）一样感觉不到，但在测试质量的保障上，却是非常关键<br> 的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。<pre><code>⚫ A：Automatic（自动化）\n⚫ I：Independent（独立性）\n</code></pre>\n⚫ R：Repeatable（可重复）</li>\n<li>【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执<br> 行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元<br> 测试中不准使用System.out来进行人肉验证，必须使用assert来验证。</li>\n<li>【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间<br> 决不能互相调用，也不能依赖执行的先后次序。<br> 反例：method2需要依赖method1的执行，将执行结果作为method2的输入。</li>\n<li>【强制】单元测试是可以重复执行的，不能受到外界环境的影响。<br> 说明：单元测试通常会被放到持续集成中，每次有代码check in时单元测试都会被执行。如果单测对外部<br> 环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。<br> 正例：为了不受外界环境影响，要求设计代码时就把SUT的依赖改成注入，在测试时用spring 这样的DI<br> 框架注入一个本地（内存）实现或者Mock实现。</li>\n<li>【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级<br> 别，一般是方法级别。<br> 说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑，<br> 那是集成测试的领域。</li>\n<li>【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。<br> 说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。</li>\n<li>【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。<br>说明：源码编译时会跳过此目录，而单元测试框架默认是扫描此目录。</li>\n<li>【推荐】单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都<br> 要达到100%<br> 说明：在工程规约的应用分层中提到的DAO层，Manager层，可重用度高的Service，都应该进行单元测<br> 试。</li>\n</ol>\n<ol start=\"9\">\n<li>【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量。<br> ⚫ B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。<br> ⚫ C：Correct，正确的输入，并得到预期的结果。<br> ⚫ D：Design，与设计文档相结合，来编写单元测试。<br> ⚫ E：Error，强制错误信息输入（如：非法数据、异常流程、业务允许外等），并得到预期的结果。</li>\n<li>【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或<br>者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。<br>反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数<br>据并不符合业务插入规则，导致测试结果异常。</li>\n<li>【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对<br>单元测试产生的数据有明确的前后缀标识。<br>正例：在阿里巴巴企业智能事业部的内部单元测试中，使用ENTERPRISE_INTELLIGENCE <em>UNIT_TEST</em><br>的前缀来标识单元测试相关代码。</li>\n<li>【推荐】对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试<br>要求而书写不规范测试代码。</li>\n<li>【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆<br>盖所有测试用例（UC）。</li>\n<li>【推荐】单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补<br>充单元测试用例。</li>\n<li>【参考】为了更方便地进行单元测试，业务代码应避免以下情况：</li>\n</ol>\n<pre><code>⚫ 构造方法中做的事情过多。\n⚫ 存在过多的全局变量和静态方法。\n⚫ 存在过多的外部依赖。\n⚫ 存在过多的条件语句。\n说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。\n</code></pre>\n<ol start=\"16\">\n<li>【参考】不要对单元测试存在如下误解：</li>\n</ol>\n<pre><code>⚫ 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。\n⚫ 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。\n⚫ 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。\n⚫ 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。\n</code></pre>\n<h2 id=\"四、安全规约\"><a href=\"#四、安全规约\" class=\"headerlink\" title=\"四、安全规约\"></a>四、安全规约</h2><ol>\n<li>【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。<br> 说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容。</li>\n<li>【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。<br> 说明：中国大陆个人手机号码显示： 139 **** 1219 ，隐藏中间 4 位，防止隐私泄露。</li>\n<li>【强制】用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，<br> 禁止字符串拼接SQL访问数据库。<br> 反例：某系统签名大量被恶意修改，即是因为对于危险字符 # –没有进行转义，导致数据库更新时，where<br> 后边的信息被注释掉，对全库进行更新。</li>\n<li>【强制】用户请求传入的任何参数必须做有效性验证。<br>说明：忽略参数校验可能导致：<br>⚫ page size过大导致内存溢出<br>⚫ 恶意order by导致数据库慢查询<br>⚫ 缓存击穿<br>⚫ SSRF<br>⚫ 任意重定向<br>⚫ SQL注入，Shell注入，反序列化注入<br>⚫ 正则输入源串拒绝服务ReDoS<br> Java代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用<br> 的是特殊构造的字符串来验证，有可能导致死循环的结果。</li>\n<li>【强制】禁止向HTML页面输出未经安全过滤或未正确转义的用户数据。</li>\n<li>【强制】表单、AJAX提交必须执行CSRF安全验证。<br> 说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF漏洞的应用/<br> 网站，攻击者可以事先构造好URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用<br> 户参数进行相应修改。</li>\n<li>【强制】URL外部重定向传入的目标地址必须执行白名单过滤。</li>\n<li>【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机<br> 制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。<br> 说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并<br> 造成短信平台资源浪费。</li>\n<li>【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过<br> 滤等风控策略。</li>\n</ol>\n<h2 id=\"五、MySQL数据库\"><a href=\"#五、MySQL数据库\" class=\"headerlink\" title=\"五、MySQL数据库\"></a>五、MySQL数据库</h2><h3 id=\"一-建表规约\"><a href=\"#一-建表规约\" class=\"headerlink\" title=\"(一) 建表规约\"></a>(一) 建表规约</h3><ol>\n<li>【强制】表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint<br> （ 1 表示是， 0 表示否）。<br> 说明：任何字段如果为非负数，必须是unsigned。<br> 注意：POJO类中的任何布尔类型的变量，都不要加is前缀，所以，需要在<resultMap>设置从is_xxx到<br> Xxx的映射关系。数据库表示是与否的值，使用tinyint类型，坚持is_xxx的命名方式是为了明确其取值含<br> 义与取值范围。<br> 正例：表达逻辑删除的字段名is_deleted， 1 表示删除， 0 表示未删除。</li>\n<li>【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只<br> 出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。<pre><code>说明：MySQL在Windows下不区分大小写，但在Linux下默认是区分大小写。因此，数据库名、表名、\n字段名，都不允许出现任何大写字母，避免节外生枝。\n正例：aliyun_admin，rdc_config，level3_name\n反例：AliyunAdmin，rdcConfig，level_3_name\n</code></pre>\n</li>\n<li>【强制】表名不使用复数名词。<br>说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于DO类名也是单数形式，符合<br>表达习惯。</li>\n<li>【强制】禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字。</li>\n<li>【强制】主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。<br>说明：pk_ 即primary key；uk_ 即 unique key；idx_ 即index的简称。</li>\n<li>【强制】小数类型为decimal，禁止使用float和double。<br>说明：在存储的时候，float 和 double 都存在精度损失的问题，很可能在比较值的时候，得到不正确的<br>结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数并分开存储。</li>\n<li>【强制】如果存储的字符串长度几乎相等，使用char定长字符串类型。</li>\n<li>【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000 ，如果存储长度<br>大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效<br>率。</li>\n<li>【强制】表必备三字段：id, create_time, update_time。<br>说明：其中id必为主键，类型为bigint unsigned、单表时自增、步长为 1 。create_time, update_time<br>的类型均为datetime类型，前者现在时表示主动式创建，后者过去分词表示被动式更新。</li>\n</ol>\n<ol start=\"10\">\n<li>【推荐】表的命名最好是遵循“业务名称_表的作用”。<br>正例：alipay_task / force_project / trade_config</li>\n<li>【推荐】库名与应用名称尽量一致。</li>\n<li>【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。</li>\n<li>【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：<br>1 ） 不是频繁修改的字段。<br>2 ） 不是唯一索引的字段。<br>3 ） 不是varchar超长字段，更不能是text字段。<br>正例：各业务线经常冗余存储商品名称，避免查询时需要调用IC服务获取。</li>\n<li>【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。<br>说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。</li>\n<li>【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索<br>速度。<br>正例：无符号值可以避免误存负数，且扩大了表示范围。</li>\n</ol>\n<pre><code>对象 年龄区间 类型 字节 表示范围\n人 150 岁之内 tinyint unsigned 1 无符号值： 0 到 255\n龟 数百岁 smallint unsigned 2 无符号值： 0 到 65535\n恐龙化石 数千万年 int unsigned 4 无符号值： 0 到约 43 亿\n太阳 约 50 亿年 bigint unsigned 8 无符号值： 0 到约 10 的 19 次方\n</code></pre>\n<h3 id=\"二-索引规约\"><a href=\"#二-索引规约\" class=\"headerlink\" title=\"(二) 索引规约\"></a>(二) 索引规约</h3><ol>\n<li>【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。<br> 说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，<br> 即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。</li>\n<li>【强制】超过三个表禁止join。需要join的字段，数据类型保持绝对一致；多表关联查询时，<br> 保证被关联的字段需要有索引。<br> 说明：即使双表join也要注意表索引、SQL性能。</li>\n<li>【强制】在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据<br> 实际文本区分度决定索引长度。</li>\n</ol>\n<pre><code>说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%\n以上，可以使用count(distinct left(列名, 索引长度))/count(*)的区分度来确定。\n</code></pre>\n<ol start=\"4\">\n<li>【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。<br> 说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。</li>\n<li>【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索<br> 引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。<br> 正例：where a=? and b=? order by c; 索引：a_b_c<br> 反例：索引如果存在范围查询，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b无<br> 法排序。</li>\n<li>【推荐】利用覆盖索引来进行查询操作，避免回表。<br> 说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这<br> 个目录就是起到覆盖索引的作用。<br> 正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效<br> 果，用explain的结果，extra列会出现：using index。</li>\n<li>【推荐】利用延迟关联或者子查询优化超多分页场景。<br> 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当<br> offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL<br> 改写。<br> 正例：先快速定位需要获取的id段，然后再关联：<br> SELECT t1.* FROM 表 1 as t1, (select id from 表1 where 条件 LIMIT 100000,20 ) as t2 where t1.id=t2.id</li>\n<li>【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts<br> 最好。<br> 说明：<br> 1 ） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。<br> 2 ） ref 指的是使用普通的索引（normal index）。<br> 3 ） range 对索引进行范围检索。<br> 反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range<br> 还低，与全表扫描是小巫见大巫。</li>\n<li>【推荐】建组合索引的时候，区分度最高的在最左边。<br> 正例：如果where a=? and b=?，a列的几乎接近于唯一值，那么只需要单建idx_a索引即可。<br> 说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where c&gt;? and d=?<br> 那么即使c的区分度更高，也必须把d放在索引的最前列，即建立组合索引idx_d_c。</li>\n<li>【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。</li>\n</ol>\n<ol start=\"11\">\n<li>【参考】创建索引时避免有如下极端误解：<br>1 ） 索引宁滥勿缺。认为一个查询就需要建一个索引。<br>2 ） 吝啬索引的创建。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。<br>3 ） 抵制惟一索引。认为惟一索引一律需要在应用层通过“先查后插”方式解决。</li>\n</ol>\n<h3 id=\"三-SQL语句\"><a href=\"#三-SQL语句\" class=\"headerlink\" title=\"(三) SQL语句\"></a>(三) SQL语句</h3><ol>\n<li>【强制】不要使用count(列名)或count(常量)来替代count(<em>)，count(</em>)是SQL92定义的标<br> 准统计行数的语法，跟数据库无关，跟NULL和非NULL无关。<br> 说明：count(*)会统计值为NULL的行，而count(列名)不会统计此列为NULL值的行。</li>\n<li>【强制】count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1,<br> col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为 0 。</li>\n<li>【强制】当某一列的值全是NULL时，count(col)的返回结果为 0 ，但sum(col)的返回结果为<br> NULL，因此使用sum()时需注意NPE问题。<br> 正例：可以使用如下方式来避免sum的NPE问题：SELECT IFNULL(SUM(column), 0) FROM table;</li>\n<li>【强制】使用ISNULL()来判断是否为NULL值。<br> 说明：NULL与任何值的直接比较都为NULL。<br> 1 ） NULL&lt;&gt;NULL的返回结果是NULL，而不是false。<br> 2 ） NULL=NULL的返回结果是NULL，而不是true。<br> 3 ） NULL&lt;&gt;1的返回结果是NULL，而不是true。<br> 反例：在SQL语句中，如果在null前换行，影响可读性。select * from table where column1 is null and<br> column3 is not null; 而<code>ISNULL(column)</code>是一个整体，简洁易懂。从性能数据上分析，<code>ISNULL(column)</code><br> 执行效率更快一些。</li>\n<li>【强制】代码中写分页查询逻辑时，若count为 0 应直接返回，避免执行后面的分页语句。</li>\n<li>【强制】不得使用外键与级联，一切外键概念必须在应用层解决。<br> 说明：（概念解释）学生表中的student_id是主键，那么成绩表中的student_id则为外键。如果更新学<br> 生表中的student_id，同时触发成绩表中的student_id更新，即为级联更新。外键与级联更新适用于单机<br> 低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库<br> 的插入速度。</li>\n<li>【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。</li>\n<li>【强制】数据订正（特别是删除或修改记录操作）时，要先select，避免出现误删除，确认无<br> 误才能执行更新语句。</li>\n</ol>\n<ol start=\"9\">\n<li>【强制】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或<br> 表名）进行限定。<br> 说明：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且<br> 操作列在多个表中存在时，就会抛异常。<br> 正例：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id;<br> 反例：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在<br> 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column<br> ‘name’ in field list is ambiguous。</li>\n<li>【推荐】SQL语句中表的别名前加as，并且以t1、t2、t3、…的顺序依次命名。<br>说明： 1 ）别名可以是表的简称，或者是依照表在SQL语句中出现的顺序，以t1、t2、t3的方式命名。 2 ）<br>别名前加as使别名更容易识别。<br>正例：select t1.name from table_first as t1, table_second as t2 where t1.id=t2.id;</li>\n<li>【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控<br>制在 1000 个之内。</li>\n<li>【参考】因国际化需要，所有的字符存储与表示，均采用utf 8 字符集，那么字符计数方法需<br>要注意。<br>说明：<br>SELECT LENGTH(“轻松工作”)； 返回为 12<br>SELECT CHARACTER_LENGTH(“轻松工作”)； 返回为 4<br>如果需要存储表情，那么选择utf 8 mb4来进行存储，注意它与utf 8 编码的区别。</li>\n<li>【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE<br>无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句。<br>说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。</li>\n</ol>\n<h3 id=\"四-ORM映射\"><a href=\"#四-ORM映射\" class=\"headerlink\" title=\"(四) ORM映射\"></a>(四) ORM映射</h3><ol>\n<li>【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。<br> 说明： 1 ）增加查询分析器解析成本。 2 ）增减字段容易与resultMap配置不一致。 3 ）无用字段增加网络<br> 消耗，尤其是text类型的字段。</li>\n<li>【强制】POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行<br> 字段与属性之间的映射。<br> 说明：参见定义POJO类以及数据库字段定义规定，在sql.xml增加映射，是必须的。</li>\n</ol>\n<ol start=\"3\">\n<li>【强制】不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要<br> 定义<resultMap>；反过来，每一个表也必然有一个<resultMap>与之对应。<br> 说明：配置映射关系，使字段与DO类解耦，方便维护。</li>\n<li>【强制】sql.xml配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现SQL注入。</li>\n<li>【强制】iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用。<br>说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取<br>start,size的子集合。<br>正例：<br>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;( 16 );<br>map.put(“start”, start);<br>map.put(“size”, size);</li>\n<li>【强制】不允许直接拿HashMap与Hashtable作为查询结果集的输出。<br> 反例：某同学为避免写一个<resultMap>xxx</resultMap>，直接使用HashTable来接收数据库返回结<br> 果，结果出现日常是把bigint转成Long值，而线上由于数据库版本不一样，解析成BigInteger，导致线<br> 上问题。</li>\n<li>【强制】更新数据表记录时，必须同时更新记录对应的update_time字段值为当前时间。</li>\n<li>【推荐】不要写一个大而全的数据更新接口。传入为POJO类，不管是不是自己的目标更新字<br> 段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，<br> 不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储。</li>\n<li>【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需<br> 要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。</li>\n<li>【参考】<isEqual>中的compareValue是与属性值对比的常量，一般是数字，表示相等时<br>带上此条件；<isNotEmpty>表示不为空且不为null时执行；<isNotNull>表示不为null值<br>时执行。</li>\n</ol>\n<h2 id=\"六、工程结构\"><a href=\"#六、工程结构\" class=\"headerlink\" title=\"六、工程结构\"></a>六、工程结构</h2><h3 id=\"一-应用分层\"><a href=\"#一-应用分层\" class=\"headerlink\" title=\"(一) 应用分层\"></a>(一) 应用分层</h3><ol>\n<li>【推荐】根据业务架构实践，结合业界分层规范与流行技术框架分析，推荐分层结构如图所示，<br> 默认上层依赖于下层，箭头关系表示可直接依赖，如：开放API层可以依赖于Web层<br> （Controller层），也可以直接依赖于Service层，依此类推：<pre><code>- 开放API层：可直接封装Service接口暴露成RPC接口；通过Web封装成http接口；网关控制层等。\n- 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移\n   动端展示等。\n- Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。\n- Service层：相对具体的业务逻辑服务层。\n- Manager层：通用业务处理层，它有如下特征：\n   1 ） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。\n   2 ） 对Service层通用能力的下沉，如缓存方案、中间件通用处理。\n   3 ） 与DAO层交互，对多个DAO的组合复用。\n- DAO层：数据访问层，与底层MySQL、Oracle、Hbase、OB等进行数据交互。\n- 第三方服务：包括其它部门RPC服务接口，基础平台，其它公司的HTTP接口，如淘宝开放平台、支\n   付宝付款服务、高德地图服务等。\n- 外部数据接口：外部（应用）数据存储服务提供的接口，多见于数据迁移场景中。\n</code></pre>\n</li>\n<li>【参考】（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进<br>行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因<br>为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，</li>\n</ol>\n<pre><code>浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，\n相当于保护案发现场。Manager层与Service同机部署，日志方式与DAO层处理一致，如果是\n单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处\n于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，\n尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。\n</code></pre>\n<ol start=\"3\">\n<li>【参考】分层领域模型规约：<ul>\n<li>DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。</li>\n<li>DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。</li>\n<li>BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。</li>\n<li>Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用Map类<br> 来传输。</li>\n<li>VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"二-二方库依赖\"><a href=\"#二-二方库依赖\" class=\"headerlink\" title=\"(二) 二方库依赖\"></a>(二) 二方库依赖</h3><ol>\n<li>【强制】定义GAV遵从以下规则：<br> 1 ） GroupID格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。<br> 说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。<br> 正例：com.taobao.jstorm 或 com.alibaba.dubbo.register<br> 2 ） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。<br> 正例：dubbo-client / fastjson-api / jstorm-tool<br> 3 ） Version：详细规定参考下方。</li>\n<li>【强制】二方库版本号命名方式：主版本号.次版本号.修订号<br>1 ）主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。<br>2 ） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。<br>3 ） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。<br>说明：注意起始版本号必须为：1.0.0，而不是0.0.1。<br>反例：仓库内某二方库版本号从1.0.0.0开始，一直默默“升级”成1.0.0.64，完全失去版本的语义信息。</li>\n<li>【强制】线上应用不要依赖SNAPSHOT版本（安全包除外）；正式发布的类库必须先去中央仓<br> 库进行查证，使RELEASE版本号有延续性，且版本号不允许覆盖升级。<br> 说明：不依赖SNAPSHOT版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。</li>\n<li>【强制】二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，<br> 必须明确评估和验证。</li>\n</ol>\n<pre><code>说明：在升级时，进行dependency:resolve前后信息比对，如果仲裁结果完全不一致，那么通过\ndependency:tree命令，找出差异点，进行&lt;exclude&gt;排除jar包。\n</code></pre>\n<ol start=\"5\">\n<li>【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚<br> 举类型或者包含枚举类型的POJO对象。</li>\n<li>【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。<br> 说明：依赖springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版<br> 本：${spring.version}，定义依赖的时候，引用该版本。</li>\n<li>【强制】禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的<br> Version。<br> 说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个war，只能有一个版本号出现在最后的<br> lib目录中。曾经出现过线下调试是正确的，发布到线上却出故障的先例。</li>\n<li>【推荐】底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现。</li>\n<li>【推荐】所有pom文件中的依赖声明放在<dependencies>语句块中，所有版本仲裁放在<br> <dependencyManagement>语句块中。<br> 说明：<dependencyManagement>里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，<br> version和scope都读取自父pom。而<dependencies>所有声明在主pom的<dependencies>里的依<br> 赖都会自动引入，并默认被所有的子项目继承。</li>\n<li>【推荐】二方库不要有配置项，最低限度不要再增加配置项。</li>\n<li>【推荐】不要使用不稳定的工具包或者Utils类。<br>说明：不稳定指的是提供方无法做到向下兼容，在编译阶段正常，但在运行时产生异常，因此，尽量使用<br>业界稳定的二方工具包。</li>\n<li>【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：<br>1 ） <strong>精简可控原则</strong> 。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、<br>常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log<br>具体实现，只依赖日志框架。<br>2 ） <strong>稳定可追溯原则</strong> 。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除<br>非用户主动升级版本，否则公共二方库的行为不应该发生变化。</li>\n</ol>\n<h3 id=\"三-服务器\"><a href=\"#三-服务器\" class=\"headerlink\" title=\"(三) 服务器\"></a>(三) 服务器</h3><ol>\n<li>【推荐】高并发服务器建议调小TCP协议的time_wait超时时间。<br> 说明：操作系统默认 240 秒后，才会关闭处于time_wait状态的连接，在高并发访问下，服务器端会因为<br> 处于time_wait的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。</li>\n</ol>\n<pre><code>正例：在linux服务器上请通过变更/etc/sysctl.conf文件去修改该缺省值（秒）：\nnet.ipv4.tcp_fin_timeout = 30\n</code></pre>\n<ol start=\"2\">\n<li>【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）。<br> 说明：主流操作系统的设计是将TCP/UDP连接采用与文件一样的方式去管理，即一个连接对应于一个fd。<br> 主流的linux服务器默认所支持最大fd数量为 1024 ，当并发连接数很大时很容易因为fd不足而出现“open<br> too many files”错误，导致新的连接无法建立。建议将linux服务器所支持的最大句柄数调高数倍（与服<br> 务器的内存数量相关）。</li>\n<li>【推荐】给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM<br> 场景时输出dump信息。<br> 说明：OOM的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。</li>\n<li>【推荐】在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整<br> 堆大小带来的压力。</li>\n<li>【参考】服务器内部重定向必须使用forward；外部重定向地址必须使用URL Broker生成，否<br> 则因线上采用HTTPS协议而导致浏览器提示“不安全“。此外，还会带来URL维护不一致的<br> 问题。</li>\n</ol>\n<h2 id=\"七、设计规约\"><a href=\"#七、设计规约\" class=\"headerlink\" title=\"七、设计规约\"></a>七、设计规约</h2><ol>\n<li>【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。<br> 说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系<br> 统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后，<br> 需要进行double check。<br> 正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发<br> 展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段）<br> 也需要进行评审通过后上线。</li>\n<li>【强制】在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过 5 个，<br> 使用用例图来表达更加清晰的结构化需求。</li>\n<li>【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发<br> 条件。<br> 说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换<br> 关系，再明确触发状态转换的条件是什么。<br> 正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两<br> 种状态之间是不可能有直接转换关系的。</li>\n<li>【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确<br> 各调用环节的输入与输出。<br> 说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。</li>\n<li>【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类<br> 之间的关系。<br> 说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造蚂蚁Z空间大楼，肯定需要详细<br> 的施工图。</li>\n<li>【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活<br> 动图来表示。<br> 说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。</li>\n<li>【推荐】系统架构设计时明确以下目标：<br>⚫ 确定系统边界。确定系统在技术层面上的做与不做。<br>⚫ 确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。<br>⚫ 确定指导后续设计与演化的原则。使后续的子系统或模块设计在一个既定的框架内和技术方向上继<br>续演化。</li>\n</ol>\n<p>⚫ 确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。</p>\n<ol start=\"8\">\n<li>【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。<br> 反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演<br> 练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。</li>\n<li>【推荐】类在设计与实现时要符合单一原则。<br> 说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。</li>\n<li>【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。<br>说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现，<br>比如，“把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。</li>\n<li>【推荐】系统设计阶段，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。<br>说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。</li>\n<li>【推荐】系统设计阶段，注意对扩展开放，对修改闭合。<br>说明：极端情况下，交付的代码是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。</li>\n<li>【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方<br>法等，在系统中不出现重复代码的情况，即DRY原则（Don’t Repeat Yourself）。<br>说明：随着代码的重复次数不断增加，维护成本指数级上升。随意复制和粘贴代码，必然会导致代码的重复，<br>在维护代码时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。<br>正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取：<br>private boolean checkParam(DTO dto) {…}</li>\n<li>【推荐】避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布。<br>说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上<br>的必要设计和文档沉淀是需要的。<br>反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样<br>的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。</li>\n<li>【参考】设计文档的作用是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。<br>说明：避免为了设计而设计，系统设计文档有助于后期的系统维护和重构，所以设计结果需要进行分类归<br>档保存。</li>\n<li>【参考】可扩展性的本质是找到系统的变化点，并隔离变化点。<br>说明：世间众多设计模式其实就是一种设计模式即隔离变化点的模式。<br>正例：极致扩展性的标志，就是需求的新增，不会在原有代码交付物上进行任何形式的修改。</li>\n</ol>\n<ol start=\"17\">\n<li>【参考】设计的本质就是识别和表达系统难点。<br>说明：识别和表达完全是两回事，很多人错误地认为识别到系统难点在哪里，表达只是自然而然的事情，<br>但是大家在设计评审中经常出现语焉不详，甚至是词不达意的情况。准确地表达系统难点需要具备如下能<br>力： 表达规则和表达工具的熟练性。抽象思维和总结能力的局限性。基础知识体系的完备性。深入浅出的<br>生动表达力。</li>\n<li>【参考】代码即文档的观点是错误的，清晰的代码只是文档的某个片断，而不是全部。<br>说明：代码的深度调用，模块层面上的依赖关系网，业务场景逻辑，非功能性需求等问题是需要相应的文<br>档来完整地呈现的。</li>\n<li>【参考】在做无障碍产品设计时，需要考虑到：</li>\n</ol>\n<pre><code>⚫ 所有可交互的控件元素必须能被tab键聚焦，并且焦点顺序需符合自然操作逻辑。\n⚫ 用于登录校验和请求拦截的验证码均需提供图形验证以外的其它方式。\n⚫ 自定义的控件类型需明确交互方式。\n正例：用户登录场景中，输入框的按钮都需要考虑tab键聚焦，符合自然逻辑的操作顺序如下，“输入用\n户名，输入密码，输入验证码，点击登录”，其中验证码实现语音验证方式。如果有自定义标签实现的控\n件设置控件类型可使用role属性。\n</code></pre>\n<h2 id=\"附-1-：版本历史\"><a href=\"#附-1-：版本历史\" class=\"headerlink\" title=\"附 1 ：版本历史\"></a>附 1 ：版本历史</h2><h4 id=\"版本号-版本名-发布日期-备注\"><a href=\"#版本号-版本名-发布日期-备注\" class=\"headerlink\" title=\"版本号 版本名 发布日期 备注\"></a>版本号 版本名 发布日期 备注</h4><h4 id=\"–-2-016-12-07-试读版本首次对外发布\"><a href=\"#–-2-016-12-07-试读版本首次对外发布\" class=\"headerlink\" title=\"– - - 2 016.12.07 试读版本首次对外发布\"></a>– - - 2 016.12.07 试读版本首次对外发布</h4><h4 id=\"1-0-0-正式版-2017-0-2-09-阿里巴巴集团正式对外发布\"><a href=\"#1-0-0-正式版-2017-0-2-09-阿里巴巴集团正式对外发布\" class=\"headerlink\" title=\"1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布\"></a>1.0.0 正式版 2017. 0 2. 09 阿里巴巴集团正式对外发布</h4><h4 id=\"1-0-1-2017-0-2-13\"><a href=\"#1-0-1-2017-0-2-13\" class=\"headerlink\" title=\"1.0.1 - - 2017. 0 2. 13\"></a>1.0.1 - - 2017. 0 2. 13</h4><pre><code>1 ）修正String[]的前后矛盾。\n2 ）vm修正成velocity。\n3 ）修正countdown描述错误。\n</code></pre>\n<h4 id=\"1-0-2-2017-0-2-20\"><a href=\"#1-0-2-2017-0-2-20\" class=\"headerlink\" title=\"1.0.2 - - 2017. 0 2.20\"></a>1.0.2 - - 2017. 0 2.20</h4><h4 id=\"1-）去除文底水印。\"><a href=\"#1-）去除文底水印。\" class=\"headerlink\" title=\"1 ）去除文底水印。\"></a>1 ）去除文底水印。</h4><h4 id=\"2-）数据类型中引用太阳系年龄问题。\"><a href=\"#2-）数据类型中引用太阳系年龄问题。\" class=\"headerlink\" title=\"2 ）数据类型中引用太阳系年龄问题。\"></a>2 ）数据类型中引用太阳系年龄问题。</h4><h4 id=\"3-）修正关于异常和方法签名的部分描述。\"><a href=\"#3-）修正关于异常和方法签名的部分描述。\" class=\"headerlink\" title=\"3 ）修正关于异常和方法签名的部分描述。\"></a>3 ）修正关于异常和方法签名的部分描述。</h4><pre><code>4 ）修正final描述。\n5 ）去除Comparator部分描述。\n</code></pre>\n<h4 id=\"1-1-0-2017-0-2-27\"><a href=\"#1-1-0-2017-0-2-27\" class=\"headerlink\" title=\"1 .1.0 - - 2017. 0 2.27\"></a>1 .1.0 - - 2017. 0 2.27</h4><h4 id=\"1-）增加前言。\"><a href=\"#1-）增加前言。\" class=\"headerlink\" title=\"1 ）增加前言。\"></a>1 ）增加前言。</h4><pre><code>2 ）增加&lt;? extends T&gt;描述和说明。\n3 ）增加版本历史。\n4 ）增加专有名词解释。\n</code></pre>\n<h4 id=\"1-1-1-2017-0-3-31-修正页码总数和部分示例。\"><a href=\"#1-1-1-2017-0-3-31-修正页码总数和部分示例。\" class=\"headerlink\" title=\"1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。\"></a>1.1.1 - - 2017. 0 3.31 修正页码总数和部分示例。</h4><h4 id=\"1-2-0-完美版-2017-0-5-20\"><a href=\"#1-2-0-完美版-2017-0-5-20\" class=\"headerlink\" title=\"1.2.0 完美版 2017. 0 5.20\"></a>1.2.0 完美版 2017. 0 5.20</h4><h4 id=\"1-）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\"><a href=\"#1-）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\" class=\"headerlink\" title=\"1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。\"></a>1 ）根据云栖社区的“聚能聊”活动反馈，对手册的页码、排版、描述进行修正。</h4><pre><code>2 ）增加final的适用场景描述。\n3 ）增加关于锁的粒度的说明。\n4 ）增加“指定集合大小”的详细说明以及正反例。\n5 ）增加卫语句的示例代码。\n6 ）明确数据库表示删除概念的字段名为is_deleted\n</code></pre>\n<h4 id=\"1-3-0-终极版-2017-0-9-25-增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\"><a href=\"#1-3-0-终极版-2017-0-9-25-增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\" class=\"headerlink\" title=\"1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载\"></a>1.3.0 终极版 2017. 0 9.25 增加单元测试规约，阿里开源的IDE代码规约检测插件：点此下载</h4><pre><code>1.3.1 纪念版 2017.11.30 修正部分描述；采用和P3C开源IDE检测插件相同的Apache2.0协议。\n1.4.0 详尽版 2018. 0 5.20 增加设计规约大类，共 16 条。\n</code></pre>\n<h4 id=\"版本号-版本名-发布日期-备注-1\"><a href=\"#版本号-版本名-发布日期-备注-1\" class=\"headerlink\" title=\"版本号 版本名 发布日期 备注\"></a>版本号 版本名 发布日期 备注</h4><h4 id=\"1-5-0-华山版-2-019-0-6-19\"><a href=\"#1-5-0-华山版-2-019-0-6-19\" class=\"headerlink\" title=\"1 .5.0 华山版 2 019.0 6. 19\"></a>1 .5.0 华山版 2 019.0 6. 19</h4><pre><code>1 ）鉴于本手册是社区开发者集体智慧的结晶，本版本移除阿里巴巴Java开发手册的\n限定词“阿里巴巴”。\n2 ）新增 21 条新规约。比如，switch的NPE问题、浮点数的比较、无泛型限制、锁的\n使用方式、判断表达式、日期格式等。\n3 ）修改描述 112 处。比如，IFNULL的判断、集合的toArray、日志处理等。\n4 ）完善若干处示例。比如，命名示例、卫语句示例、enum示例、finally的return\n示例等。\n</code></pre>\n<h4 id=\"1-6-0\"><a href=\"#1-6-0\" class=\"headerlink\" title=\"1.6.0\"></a>1.6.0</h4><h4 id=\"泰山版\"><a href=\"#泰山版\" class=\"headerlink\" title=\"泰山版\"></a>泰山版</h4><h4 id=\"2020-04-22\"><a href=\"#2020-04-22\" class=\"headerlink\" title=\"2020.04.22\"></a>2020.04.22</h4><h4 id=\"1-）发布错误码统一解决方案，详细参考-附表-3-。\"><a href=\"#1-）发布错误码统一解决方案，详细参考-附表-3-。\" class=\"headerlink\" title=\"1 ）发布错误码统一解决方案，详细参考 附表 3 。\"></a>1 ）发布错误码统一解决方案，详细参考 附表 3 。</h4><h4 id=\"2-）新增-34-条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\"><a href=\"#2-）新增-34-条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\" class=\"headerlink\" title=\"2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL\"></a>2 ）新增 34 条新规约。比如，日期时间的闰年、闰月问题，三目运算的自动拆箱，SQL</h4><pre><code>查询的表别名限定，Collectors类的toMap()方法使用注意等。\n3 ）修改描述 90 处。比如，阻塞等待锁、建表的小数类型等。\n4 ）完善若干处示例。比如，ISNULL的示例等。\n</code></pre>\n<h4 id=\"1-7-0-嵩山版-2020-0-8-03\"><a href=\"#1-7-0-嵩山版-2020-0-8-03\" class=\"headerlink\" title=\"1. 7. 0 嵩山版 2020.0 8. 03\"></a>1. 7. 0 嵩山版 2020.0 8. 03</h4><h4 id=\"1-）新增前后端规约-14-条。\"><a href=\"#1-）新增前后端规约-14-条。\" class=\"headerlink\" title=\"1 ）新增前后端规约 14 条。\"></a>1 ）新增前后端规约 14 条。</h4><h4 id=\"2-）新增禁止任何歧视性用语的约定。\"><a href=\"#2-）新增禁止任何歧视性用语的约定。\" class=\"headerlink\" title=\"2 ）新增禁止任何歧视性用语的约定。\"></a>2 ）新增禁止任何歧视性用语的约定。</h4><h4 id=\"3-）新增涉及敏感操作的情况下日志需要保存六个月的约定。\"><a href=\"#3-）新增涉及敏感操作的情况下日志需要保存六个月的约定。\" class=\"headerlink\" title=\"3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。\"></a>3 ）新增涉及敏感操作的情况下日志需要保存六个月的约定。</h4><pre><code>4 ）修正BigDecimal类中关于compareTo和equals的等值比较。\n5 ）修正HashMap关于 1024 个元素扩容的次数。\n6 ）修正架构分层规范与相关说明。\n7 ）修正泰山版中部分格式错误和描述错误。\n</code></pre>\n<h2 id=\"附-2-：专有名词解释\"><a href=\"#附-2-：专有名词解释\" class=\"headerlink\" title=\"附 2 ：专有名词解释\"></a>附 2 ：专有名词解释</h2><ol>\n<li>POJO（Plain Ordinary Java Object）: 在本规约中，POJO专指只有setter/getter/toString的<br> 简单类，包括DO/DTO/BO/VO等。</li>\n<li>DO（Data Object）：阿里巴巴专指数据库表一一对应的POJO类。此对象与数据库表结构一<br> 一对应，通过DAO层向上传输数据源对象。</li>\n<li>DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。</li>\n<li>BO（Business Object）：业务对象，可以由Service层输出的封装业务逻辑的对象。</li>\n<li>Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用<br> Map类来传输。</li>\n<li>VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。</li>\n<li>AO（Application Object）: 阿里巴巴专指Application Object，即在Service层上，极为贴近<br> 业务的复用代码。</li>\n<li>CAS（Compare And Swap）：解决多线程并行情况下使用锁造成性能损耗的一种机制，这是<br> 硬件实现的原子操作。CAS操作包含三个操作数：内存位置、预期原值和新值。如果内存位<br> 置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何<br> 操作。</li>\n<li>GAV（GroupId、ArtifactId、Version）: Maven坐标，是用来唯一标识jar包。</li>\n<li>OOP（Object Oriented Programming）: 本文泛指类、对象的编程处理方式。</li>\n<li>AQS（AbstractQueuedSynchronizer）: 利用先进先出队列实现的底层同步工具类，它是很多上<br>层同步实现类的基础，比如：ReentrantLock、CountDownLatch、Semaphore等，它们通<br>过继承AQS实现其模版方法，然后将AQS子类作为同步组件的内部类，通常命名为Sync。</li>\n<li>ORM（Object Relation Mapping）: 对象关系映射，对象领域模型与底层数据之间的转换，本<br>文泛指iBATIS, mybatis等框架。</li>\n<li>NPE（java.lang.NullPointerException）: 空指针异常。</li>\n<li>OOM（Out Of Memory）: 源于 java.lang.OutOfMemoryError，当 JVM 没有足够的内存<br>来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。</li>\n<li>一方库: 本工程内部子项目模块依赖的库（jar 包）。</li>\n<li>二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar 包）。</li>\n<li>三方库: 公司之外的开源库（jar 包）。</li>\n</ol>\n<h2 id=\"附-3-：错误码列表\"><a href=\"#附-3-：错误码列表\" class=\"headerlink\" title=\"附 3 ：错误码列表\"></a>附 3 ：错误码列表</h2><h4 id=\"错误码-中文描述-说明\"><a href=\"#错误码-中文描述-说明\" class=\"headerlink\" title=\"错误码 中文描述 说明\"></a>错误码 中文描述 说明</h4><pre><code>00000 一切ok 正确执行后的返回\nA0001 用户端错误 一级宏观错误码\nA0100 用户注册错误 二级宏观错误码\nA0101 用户未同意隐私协议\nA0102 注册国家或地区受限\nA0110 用户名校验失败\nA0111 用户名已存在\nA0112 用户名包含敏感词\nA0113 用户名包含特殊字符\nA0120 密码校验失败\nA0121 密码长度不够\nA0122 密码强度不够\nA0130 校验码输入错误\nA0131 短信校验码输入错误\nA0132 邮件校验码输入错误\nA0133 语音校验码输入错误\nA0140 用户证件异常\nA0141 用户证件类型未选择\nA0142 大陆身份证编号校验非法\nA0143 护照编号校验非法\nA0144 军官证编号校验非法\nA0150 用户基本信息校验失败\nA0151 手机格式校验失败\nA0152 地址格式校验失败\nA0153 邮箱格式校验失败\nA0200 用户登录异常 二级宏观错误码\nA0201 用户账户不存在\n</code></pre>\n<h4 id=\"A0202-用户账户被冻结\"><a href=\"#A0202-用户账户被冻结\" class=\"headerlink\" title=\"A0202 用户账户被冻结\"></a>A0202 用户账户被冻结</h4><h4 id=\"A0203-用户账户已作废\"><a href=\"#A0203-用户账户已作废\" class=\"headerlink\" title=\"A0203 用户账户已作废\"></a>A0203 用户账户已作废</h4><h4 id=\"A0210-用户密码错误\"><a href=\"#A0210-用户密码错误\" class=\"headerlink\" title=\"A0210 用户密码错误\"></a>A0210 用户密码错误</h4><h4 id=\"A0211-用户输入密码错误次数超限\"><a href=\"#A0211-用户输入密码错误次数超限\" class=\"headerlink\" title=\"A0211 用户输入密码错误次数超限\"></a>A0211 用户输入密码错误次数超限</h4><h4 id=\"A0220-用户身份校验失败\"><a href=\"#A0220-用户身份校验失败\" class=\"headerlink\" title=\"A0220 用户身份校验失败\"></a>A0220 用户身份校验失败</h4><h4 id=\"A0221-用户指纹识别失败\"><a href=\"#A0221-用户指纹识别失败\" class=\"headerlink\" title=\"A0221 用户指纹识别失败\"></a>A0221 用户指纹识别失败</h4><h4 id=\"A0222-用户面容识别失败\"><a href=\"#A0222-用户面容识别失败\" class=\"headerlink\" title=\"A0222 用户面容识别失败\"></a>A0222 用户面容识别失败</h4><h4 id=\"A0223-用户未获得第三方登录授权\"><a href=\"#A0223-用户未获得第三方登录授权\" class=\"headerlink\" title=\"A0223 用户未获得第三方登录授权\"></a>A0223 用户未获得第三方登录授权</h4><h4 id=\"A0230-用户登录已过期\"><a href=\"#A0230-用户登录已过期\" class=\"headerlink\" title=\"A0230 用户登录已过期\"></a>A0230 用户登录已过期</h4><h4 id=\"A0240-用户验证码错误\"><a href=\"#A0240-用户验证码错误\" class=\"headerlink\" title=\"A0240 用户验证码错误\"></a>A0240 用户验证码错误</h4><h4 id=\"A0241-用户验证码尝试次数超限\"><a href=\"#A0241-用户验证码尝试次数超限\" class=\"headerlink\" title=\"A0241 用户验证码尝试次数超限\"></a>A0241 用户验证码尝试次数超限</h4><p>A0300 访问权限异常 二级宏观错误码</p>\n<p>A0301 访问未授权</p>\n<p>A0302 正在授权中</p>\n<p>A0303 用户授权申请被拒绝</p>\n<p>A0310 因访问对象隐私设置被拦截</p>\n<p>A0311 授权已过期</p>\n<p>A0312 无权限使用API</p>\n<p>A0320 用户访问被拦截</p>\n<p>A0321 黑名单用户</p>\n<p>A0322 账号被冻结</p>\n<p>A0323 非法IP地址</p>\n<p>A0324 网关访问受限</p>\n<p>A0325 地域黑名单</p>\n<p>A0330 服务已欠费</p>\n<p>A0340 用户签名异常</p>\n<p>A0341 RSA签名错误</p>\n<p>A0400 用户请求参数错误 二级宏观错误码</p>\n<p>A0401 包含非法恶意跳转链接</p>\n<p>A0402 无效的用户输入</p>\n<h4 id=\"A0410-请求必填参数为空\"><a href=\"#A0410-请求必填参数为空\" class=\"headerlink\" title=\"A0410 请求必填参数为空\"></a>A0410 请求必填参数为空</h4><h4 id=\"A0411-用户订单号为空\"><a href=\"#A0411-用户订单号为空\" class=\"headerlink\" title=\"A0411 用户订单号为空\"></a>A0411 用户订单号为空</h4><h4 id=\"A0412-订购数量为空\"><a href=\"#A0412-订购数量为空\" class=\"headerlink\" title=\"A0412 订购数量为空\"></a>A0412 订购数量为空</h4><h4 id=\"A0413-缺少时间戳参数\"><a href=\"#A0413-缺少时间戳参数\" class=\"headerlink\" title=\"A0413 缺少时间戳参数\"></a>A0413 缺少时间戳参数</h4><h4 id=\"A0414-非法的时间戳参数\"><a href=\"#A0414-非法的时间戳参数\" class=\"headerlink\" title=\"A0414 非法的时间戳参数\"></a>A0414 非法的时间戳参数</h4><h4 id=\"A0420-请求参数值超出允许的范围\"><a href=\"#A0420-请求参数值超出允许的范围\" class=\"headerlink\" title=\"A0420 请求参数值超出允许的范围\"></a>A0420 请求参数值超出允许的范围</h4><h4 id=\"A0421-参数格式不匹配\"><a href=\"#A0421-参数格式不匹配\" class=\"headerlink\" title=\"A0421 参数格式不匹配\"></a>A0421 参数格式不匹配</h4><h4 id=\"A0422-地址不在服务范围\"><a href=\"#A0422-地址不在服务范围\" class=\"headerlink\" title=\"A0422 地址不在服务范围\"></a>A0422 地址不在服务范围</h4><h4 id=\"A0423-时间不在服务范围\"><a href=\"#A0423-时间不在服务范围\" class=\"headerlink\" title=\"A0423 时间不在服务范围\"></a>A0423 时间不在服务范围</h4><h4 id=\"A0424-金额超出限制\"><a href=\"#A0424-金额超出限制\" class=\"headerlink\" title=\"A0424 金额超出限制\"></a>A0424 金额超出限制</h4><h4 id=\"A0425-数量超出限制\"><a href=\"#A0425-数量超出限制\" class=\"headerlink\" title=\"A0425 数量超出限制\"></a>A0425 数量超出限制</h4><h4 id=\"A0426-请求批量处理总个数超出限制\"><a href=\"#A0426-请求批量处理总个数超出限制\" class=\"headerlink\" title=\"A0426 请求批量处理总个数超出限制\"></a>A0426 请求批量处理总个数超出限制</h4><h4 id=\"A0427-请求JSON解析失败\"><a href=\"#A0427-请求JSON解析失败\" class=\"headerlink\" title=\"A0427 请求JSON解析失败\"></a>A0427 请求JSON解析失败</h4><h4 id=\"A0430-用户输入内容非法\"><a href=\"#A0430-用户输入内容非法\" class=\"headerlink\" title=\"A0430 用户输入内容非法\"></a>A0430 用户输入内容非法</h4><h4 id=\"A0431-包含违禁敏感词\"><a href=\"#A0431-包含违禁敏感词\" class=\"headerlink\" title=\"A0431 包含违禁敏感词\"></a>A0431 包含违禁敏感词</h4><h4 id=\"A0432-图片包含违禁信息\"><a href=\"#A0432-图片包含违禁信息\" class=\"headerlink\" title=\"A0432 图片包含违禁信息\"></a>A0432 图片包含违禁信息</h4><h4 id=\"A0433-文件侵犯版权\"><a href=\"#A0433-文件侵犯版权\" class=\"headerlink\" title=\"A0433 文件侵犯版权\"></a>A0433 文件侵犯版权</h4><h4 id=\"A0440-用户操作异常\"><a href=\"#A0440-用户操作异常\" class=\"headerlink\" title=\"A0440 用户操作异常\"></a>A0440 用户操作异常</h4><h4 id=\"A0441-用户支付超时\"><a href=\"#A0441-用户支付超时\" class=\"headerlink\" title=\"A0441 用户支付超时\"></a>A0441 用户支付超时</h4><h4 id=\"A0442-确认订单超时\"><a href=\"#A0442-确认订单超时\" class=\"headerlink\" title=\"A0442 确认订单超时\"></a>A0442 确认订单超时</h4><h4 id=\"A0443-订单已关闭\"><a href=\"#A0443-订单已关闭\" class=\"headerlink\" title=\"A0443 订单已关闭\"></a>A0443 订单已关闭</h4><p>A0500 用户请求服务异常 二级宏观错误码</p>\n<p>A0501 请求次数超出限制</p>\n<p>A0502 请求并发数超出限制</p>\n<p>A0503 用户操作请等待</p>\n<p>A0504 WebSocket连接异常</p>\n<p>A0505 WebSocket连接断开</p>\n<p>A0506 用户重复请求</p>\n<p>A0600 用户资源异常 二级宏观错误码</p>\n<p>A0601 账户余额不足</p>\n<h4 id=\"A0602-用户磁盘空间不足\"><a href=\"#A0602-用户磁盘空间不足\" class=\"headerlink\" title=\"A0602 用户磁盘空间不足\"></a>A0602 用户磁盘空间不足</h4><h4 id=\"A0603-用户内存空间不足\"><a href=\"#A0603-用户内存空间不足\" class=\"headerlink\" title=\"A0603 用户内存空间不足\"></a>A0603 用户内存空间不足</h4><h4 id=\"A0604-用户OSS容量不足\"><a href=\"#A0604-用户OSS容量不足\" class=\"headerlink\" title=\"A0604 用户OSS容量不足\"></a>A0604 用户OSS容量不足</h4><h4 id=\"A0605-用户配额已用光-蚂蚁森林浇水数或每天抽奖数\"><a href=\"#A0605-用户配额已用光-蚂蚁森林浇水数或每天抽奖数\" class=\"headerlink\" title=\"A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数\"></a>A0605 用户配额已用光 蚂蚁森林浇水数或每天抽奖数</h4><h4 id=\"A0700-用户上传文件异常-二级宏观错误码\"><a href=\"#A0700-用户上传文件异常-二级宏观错误码\" class=\"headerlink\" title=\"A0700 用户上传文件异常 二级宏观错误码\"></a>A0700 用户上传文件异常 二级宏观错误码</h4><h4 id=\"A0701-用户上传文件类型不匹配\"><a href=\"#A0701-用户上传文件类型不匹配\" class=\"headerlink\" title=\"A0701 用户上传文件类型不匹配\"></a>A0701 用户上传文件类型不匹配</h4><h4 id=\"A0702-用户上传文件太大\"><a href=\"#A0702-用户上传文件太大\" class=\"headerlink\" title=\"A0702 用户上传文件太大\"></a>A0702 用户上传文件太大</h4><h4 id=\"A0703-用户上传图片太大\"><a href=\"#A0703-用户上传图片太大\" class=\"headerlink\" title=\"A0703 用户上传图片太大\"></a>A0703 用户上传图片太大</h4><h4 id=\"A0704-用户上传视频太大\"><a href=\"#A0704-用户上传视频太大\" class=\"headerlink\" title=\"A0704 用户上传视频太大\"></a>A0704 用户上传视频太大</h4><h4 id=\"A0705-用户上传压缩文件太大\"><a href=\"#A0705-用户上传压缩文件太大\" class=\"headerlink\" title=\"A0705 用户上传压缩文件太大\"></a>A0705 用户上传压缩文件太大</h4><h4 id=\"A0800-用户当前版本异常-二级宏观错误码\"><a href=\"#A0800-用户当前版本异常-二级宏观错误码\" class=\"headerlink\" title=\"A0800 用户当前版本异常 二级宏观错误码\"></a>A0800 用户当前版本异常 二级宏观错误码</h4><h4 id=\"A0801-用户安装版本与系统不匹配\"><a href=\"#A0801-用户安装版本与系统不匹配\" class=\"headerlink\" title=\"A0801 用户安装版本与系统不匹配\"></a>A0801 用户安装版本与系统不匹配</h4><h4 id=\"A0802-用户安装版本过低\"><a href=\"#A0802-用户安装版本过低\" class=\"headerlink\" title=\"A0802 用户安装版本过低\"></a>A0802 用户安装版本过低</h4><h4 id=\"A0803-用户安装版本过高\"><a href=\"#A0803-用户安装版本过高\" class=\"headerlink\" title=\"A0803 用户安装版本过高\"></a>A0803 用户安装版本过高</h4><h4 id=\"A0804-用户安装版本已过期\"><a href=\"#A0804-用户安装版本已过期\" class=\"headerlink\" title=\"A0804 用户安装版本已过期\"></a>A0804 用户安装版本已过期</h4><h4 id=\"A0805-用户API请求版本不匹配\"><a href=\"#A0805-用户API请求版本不匹配\" class=\"headerlink\" title=\"A0805 用户API请求版本不匹配\"></a>A0805 用户API请求版本不匹配</h4><h4 id=\"A0806-用户API请求版本过高\"><a href=\"#A0806-用户API请求版本过高\" class=\"headerlink\" title=\"A0806 用户API请求版本过高\"></a>A0806 用户API请求版本过高</h4><h4 id=\"A0807-用户API请求版本过低\"><a href=\"#A0807-用户API请求版本过低\" class=\"headerlink\" title=\"A0807 用户API请求版本过低\"></a>A0807 用户API请求版本过低</h4><h4 id=\"A0900-用户隐私未授权-二级宏观错误码\"><a href=\"#A0900-用户隐私未授权-二级宏观错误码\" class=\"headerlink\" title=\"A0900 用户隐私未授权 二级宏观错误码\"></a>A0900 用户隐私未授权 二级宏观错误码</h4><h4 id=\"A0901-用户隐私未签署\"><a href=\"#A0901-用户隐私未签署\" class=\"headerlink\" title=\"A0901 用户隐私未签署\"></a>A0901 用户隐私未签署</h4><h4 id=\"A0902-用户摄像头未授权\"><a href=\"#A0902-用户摄像头未授权\" class=\"headerlink\" title=\"A0902 用户摄像头未授权\"></a>A0902 用户摄像头未授权</h4><h4 id=\"A0903-用户相机未授权\"><a href=\"#A0903-用户相机未授权\" class=\"headerlink\" title=\"A0903 用户相机未授权\"></a>A0903 用户相机未授权</h4><h4 id=\"A0904-用户图片库未授权\"><a href=\"#A0904-用户图片库未授权\" class=\"headerlink\" title=\"A0904 用户图片库未授权\"></a>A0904 用户图片库未授权</h4><h4 id=\"A0905-用户文件未授权\"><a href=\"#A0905-用户文件未授权\" class=\"headerlink\" title=\"A0905 用户文件未授权\"></a>A0905 用户文件未授权</h4><h4 id=\"A0906-用户位置信息未授权\"><a href=\"#A0906-用户位置信息未授权\" class=\"headerlink\" title=\"A0906 用户位置信息未授权\"></a>A0906 用户位置信息未授权</h4><h4 id=\"A0907-用户通讯录未授权\"><a href=\"#A0907-用户通讯录未授权\" class=\"headerlink\" title=\"A0907 用户通讯录未授权\"></a>A0907 用户通讯录未授权</h4><h4 id=\"A1000-用户设备异常-二级宏观错误码\"><a href=\"#A1000-用户设备异常-二级宏观错误码\" class=\"headerlink\" title=\"A1000 用户设备异常 二级宏观错误码\"></a>A1000 用户设备异常 二级宏观错误码</h4><h4 id=\"A1001-用户相机异常\"><a href=\"#A1001-用户相机异常\" class=\"headerlink\" title=\"A1001 用户相机异常\"></a>A1001 用户相机异常</h4><h4 id=\"A1002-用户麦克风异常\"><a href=\"#A1002-用户麦克风异常\" class=\"headerlink\" title=\"A1002 用户麦克风异常\"></a>A1002 用户麦克风异常</h4><h4 id=\"A1003-用户听筒异常\"><a href=\"#A1003-用户听筒异常\" class=\"headerlink\" title=\"A1003 用户听筒异常\"></a>A1003 用户听筒异常</h4><h4 id=\"A1004-用户扬声器异常\"><a href=\"#A1004-用户扬声器异常\" class=\"headerlink\" title=\"A1004 用户扬声器异常\"></a>A1004 用户扬声器异常</h4><h4 id=\"A1005-用户GPS定位异常\"><a href=\"#A1005-用户GPS定位异常\" class=\"headerlink\" title=\"A1005 用户GPS定位异常\"></a>A1005 用户GPS定位异常</h4><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"-\"></a>-</h4><p>-</p>\n<h4 id=\"B0001-系统执行出错-一级宏观错误码\"><a href=\"#B0001-系统执行出错-一级宏观错误码\" class=\"headerlink\" title=\"B0001 系统执行出错 一级宏观错误码\"></a>B0001 系统执行出错 一级宏观错误码</h4><h4 id=\"B0100-系统执行超时-二级宏观错误码\"><a href=\"#B0100-系统执行超时-二级宏观错误码\" class=\"headerlink\" title=\"B0100 系统执行超时 二级宏观错误码\"></a>B0100 系统执行超时 二级宏观错误码</h4><h4 id=\"B0101-系统订单处理超时\"><a href=\"#B0101-系统订单处理超时\" class=\"headerlink\" title=\"B0101 系统订单处理超时\"></a>B0101 系统订单处理超时</h4><h4 id=\"B0200-系统容灾功能被触发-二级宏观错误码\"><a href=\"#B0200-系统容灾功能被触发-二级宏观错误码\" class=\"headerlink\" title=\"B0200 系统容灾功能被触发 二级宏观错误码\"></a>B0200 系统容灾功能被触发 二级宏观错误码</h4><h4 id=\"B0210-系统限流\"><a href=\"#B0210-系统限流\" class=\"headerlink\" title=\"B0210 系统限流\"></a>B0210 系统限流</h4><h4 id=\"B0220-系统功能降级\"><a href=\"#B0220-系统功能降级\" class=\"headerlink\" title=\"B0220 系统功能降级\"></a>B0220 系统功能降级</h4><h4 id=\"B0300-系统资源异常-二级宏观错误码\"><a href=\"#B0300-系统资源异常-二级宏观错误码\" class=\"headerlink\" title=\"B0300 系统资源异常 二级宏观错误码\"></a>B0300 系统资源异常 二级宏观错误码</h4><h4 id=\"B0310-系统资源耗尽\"><a href=\"#B0310-系统资源耗尽\" class=\"headerlink\" title=\"B0310 系统资源耗尽\"></a>B0310 系统资源耗尽</h4><h4 id=\"B0311-系统磁盘空间耗尽\"><a href=\"#B0311-系统磁盘空间耗尽\" class=\"headerlink\" title=\"B0311 系统磁盘空间耗尽\"></a>B0311 系统磁盘空间耗尽</h4><h4 id=\"B0312-系统内存耗尽\"><a href=\"#B0312-系统内存耗尽\" class=\"headerlink\" title=\"B0312 系统内存耗尽\"></a>B0312 系统内存耗尽</h4><h4 id=\"B0313-文件句柄耗尽\"><a href=\"#B0313-文件句柄耗尽\" class=\"headerlink\" title=\"B0313 文件句柄耗尽\"></a>B0313 文件句柄耗尽</h4><h4 id=\"B0314-系统连接池耗尽\"><a href=\"#B0314-系统连接池耗尽\" class=\"headerlink\" title=\"B0314 系统连接池耗尽\"></a>B0314 系统连接池耗尽</h4><h4 id=\"B0315-系统线程池耗尽\"><a href=\"#B0315-系统线程池耗尽\" class=\"headerlink\" title=\"B0315 系统线程池耗尽\"></a>B0315 系统线程池耗尽</h4><h4 id=\"B0320-系统资源访问异常\"><a href=\"#B0320-系统资源访问异常\" class=\"headerlink\" title=\"B0320 系统资源访问异常\"></a>B0320 系统资源访问异常</h4><h4 id=\"B0321-系统读取磁盘文件失败\"><a href=\"#B0321-系统读取磁盘文件失败\" class=\"headerlink\" title=\"B0321 系统读取磁盘文件失败\"></a>B0321 系统读取磁盘文件失败</h4><h4 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"-\"></a>-</h4><h4 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"-\"></a>-</h4><h4 id=\"C0001-调用第三方服务出错-一级宏观错误码\"><a href=\"#C0001-调用第三方服务出错-一级宏观错误码\" class=\"headerlink\" title=\"C0001 调用第三方服务出错 一级宏观错误码\"></a>C0001 调用第三方服务出错 一级宏观错误码</h4><h4 id=\"C0100-中间件服务出错-二级宏观错误码\"><a href=\"#C0100-中间件服务出错-二级宏观错误码\" class=\"headerlink\" title=\"C0100 中间件服务出错 二级宏观错误码\"></a>C0100 中间件服务出错 二级宏观错误码</h4><h4 id=\"C0110-RPC服务出错\"><a href=\"#C0110-RPC服务出错\" class=\"headerlink\" title=\"C0110 RPC服务出错\"></a>C0110 RPC服务出错</h4><h4 id=\"C0111-RPC服务未找到\"><a href=\"#C0111-RPC服务未找到\" class=\"headerlink\" title=\"C0111 RPC服务未找到\"></a>C0111 RPC服务未找到</h4><h4 id=\"C0112-RPC服务未注册\"><a href=\"#C0112-RPC服务未注册\" class=\"headerlink\" title=\"C0112 RPC服务未注册\"></a>C0112 RPC服务未注册</h4><h4 id=\"C0113-接口不存在\"><a href=\"#C0113-接口不存在\" class=\"headerlink\" title=\"C0113 接口不存在\"></a>C0113 接口不存在</h4><h4 id=\"C0120-消息服务出错\"><a href=\"#C0120-消息服务出错\" class=\"headerlink\" title=\"C0120 消息服务出错\"></a>C0120 消息服务出错</h4><h4 id=\"C0121-消息投递出错\"><a href=\"#C0121-消息投递出错\" class=\"headerlink\" title=\"C0121 消息投递出错\"></a>C0121 消息投递出错</h4><h4 id=\"C0122-消息消费出错\"><a href=\"#C0122-消息消费出错\" class=\"headerlink\" title=\"C0122 消息消费出错\"></a>C0122 消息消费出错</h4><h4 id=\"C0123-消息订阅出错\"><a href=\"#C0123-消息订阅出错\" class=\"headerlink\" title=\"C0123 消息订阅出错\"></a>C0123 消息订阅出错</h4><h4 id=\"C0124-消息分组未查到\"><a href=\"#C0124-消息分组未查到\" class=\"headerlink\" title=\"C0124 消息分组未查到\"></a>C0124 消息分组未查到</h4><h4 id=\"C0130-缓存服务出错\"><a href=\"#C0130-缓存服务出错\" class=\"headerlink\" title=\"C0130 缓存服务出错\"></a>C0130 缓存服务出错</h4><p>C0131 key长度超过限制</p>\n<p>C0132 value长度超过限制</p>\n<p>C0133 存储容量已满</p>\n<p>C0134 不支持的数据格式</p>\n<p>C0140 配置服务出错</p>\n<p>C0150 网络资源服务出错</p>\n<p>C0151 VPN服务出错</p>\n<p>C0152 CDN服务出错</p>\n<p>C0153 域名解析服务出错</p>\n<p>C0154 网关服务出错</p>\n<p>C0200 第三方系统执行超时 二级宏观错误码</p>\n<p>C0210 RPC执行超时</p>\n<p>C0220 消息投递超时</p>\n<p>C0230 缓存服务超时</p>\n<p>C0240 配置服务超时</p>\n<p>C0250 数据库服务超时</p>\n<p>C0300 数据库服务出错 二级宏观错误码</p>\n<p>C0311 表不存在</p>\n<p>C0312 列不存在</p>\n<p>C0321 多表关联中存在多个相同名称的列</p>\n<p>C0331 数据库死锁</p>\n<p>C0341 主键冲突</p>\n<p>C0400 第三方容灾系统被触发 二级宏观错误码</p>\n<p>C0401 第三方系统限流</p>\n<p>C0402 第三方功能降级</p>\n<p>C0500 通知服务出错 二级宏观错误码</p>\n<p>C0501 短信提醒服务失败</p>\n<p>C0502 语音提醒服务失败</p>\n<p>C0503 邮件提醒服务失败</p>"}],"PostAsset":[{"_id":"source/_posts/Lucene和ES的前世今生/es-cluster-0.png","slug":"es-cluster-0.png","post":"cl8lhl0k60000ekwe39nf24oh","modified":0,"renderable":0},{"_id":"source/_posts/JAVA核心知识点/JAVA核心知识点.pdf","slug":"JAVA核心知识点.pdf","post":"cl8lhl0kq0001ekweabkl0bvx","modified":0,"renderable":0},{"_id":"source/_posts/分库分表/database-split-horizon.png","slug":"database-split-horizon.png","post":"cl8lhl0ku0008ekwe5d620dp3","modified":0,"renderable":0},{"_id":"source/_posts/分库分表/database-split-vertically.png","slug":"database-split-vertically.png","post":"cl8lhl0ku0008ekwe5d620dp3","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/async-replication-data-lose-case.png","slug":"async-replication-data-lose-case.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/lru-cache.png","slug":"lru-cache.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/lru.png","slug":"lru.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-caching-avalanche-solution.png","slug":"redis-caching-avalanche-solution.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-caching-avalanche.png","slug":"redis-caching-avalanche.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-caching-avoid-penetration.png","slug":"redis-caching-avoid-penetration.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-caching-penetration.png","slug":"redis-caching-penetration.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-cluster-split-brain.png","slug":"redis-cluster-split-brain.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-junior-inconsistent.png","slug":"redis-junior-inconsistent.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-master-slave-replication-detail.png","slug":"redis-master-slave-replication-detail.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-master-slave-replication.png","slug":"redis-master-slave-replication.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-master-slave.png","slug":"redis-master-slave.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/redis知识点整理/redis-single-thread-model.png","slug":"redis-single-thread-model.png","post":"cl8lhl0kw000cekwe9s337wt6","modified":0,"renderable":0},{"_id":"source/_posts/分库分表之后的id主键如何处理/database-id-sequence-step.png","slug":"database-id-sequence-step.png","post":"cl8lhl0kz000qekwe3a425ww3","modified":0,"renderable":0},{"_id":"source/_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-1.png","slug":"database-shard-method-1.png","post":"cl8lhl0l1000tekwed662bzd6","modified":0,"renderable":0},{"_id":"source/_posts/现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？/database-shard-method-2.png","slug":"database-shard-method-2.png","post":"cl8lhl0l1000tekwed662bzd6","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cl8lhl0kt0005ekweci6f6tye","category_id":"cl8lhl0kv0009ekwe6sjd1vea","_id":"cl8lhl0kx000hekwedqsmdq9g"},{"post_id":"cl8lhl0kv000aekwecdyhe5h4","category_id":"cl8lhl0kv0009ekwe6sjd1vea","_id":"cl8lhl0ky000jekwe68ul1lv8"},{"post_id":"cl8lhl0l3000vekwe35xsan66","category_id":"cl8lhl0kv0009ekwe6sjd1vea","_id":"cl8lhl0l40011ekweec63bord"},{"post_id":"cl8lhl0l3000xekwe3q9ueif7","category_id":"cl8lhl0kv0009ekwe6sjd1vea","_id":"cl8lhl0l40013ekwe8vlvaeij"}],"PostTag":[{"post_id":"cl8lhl0k60000ekwe39nf24oh","tag_id":"cl8lhl0kr0002ekwe4gok3jfq","_id":"cl8lhl0ku0007ekwegmnc7wcn"},{"post_id":"cl8lhl0kq0001ekweabkl0bvx","tag_id":"cl8lhl0ku0006ekwebq2maj8k","_id":"cl8lhl0kw000dekweajyeh8nj"},{"post_id":"cl8lhl0kt0005ekweci6f6tye","tag_id":"cl8lhl0kv000bekweawvc286n","_id":"cl8lhl0kx000gekwe6yrz6h3c"},{"post_id":"cl8lhl0ku0008ekwe5d620dp3","tag_id":"cl8lhl0kx000fekwe2p8123nh","_id":"cl8lhl0ky000lekwe9ys6ftk2"},{"post_id":"cl8lhl0ku0008ekwe5d620dp3","tag_id":"cl8lhl0kx000iekwe7jh27sxn","_id":"cl8lhl0ky000mekwe6lk22kmx"},{"post_id":"cl8lhl0kv000aekwecdyhe5h4","tag_id":"cl8lhl0ky000kekwe25k7710s","_id":"cl8lhl0ky000oekwefd3g25h0"},{"post_id":"cl8lhl0kw000cekwe9s337wt6","tag_id":"cl8lhl0ky000nekwe88wybx5g","_id":"cl8lhl0ky000pekwe4wqq4n2k"},{"post_id":"cl8lhl0kz000qekwe3a425ww3","tag_id":"cl8lhl0kx000fekwe2p8123nh","_id":"cl8lhl0l1000sekwe2whfazsk"},{"post_id":"cl8lhl0kz000qekwe3a425ww3","tag_id":"cl8lhl0kx000iekwe7jh27sxn","_id":"cl8lhl0l2000uekwe4wu90exc"},{"post_id":"cl8lhl0l1000rekweg53i5j2q","tag_id":"cl8lhl0kx000fekwe2p8123nh","_id":"cl8lhl0l3000wekweete884lb"},{"post_id":"cl8lhl0l1000rekweg53i5j2q","tag_id":"cl8lhl0kx000iekwe7jh27sxn","_id":"cl8lhl0l4000zekwea86p1mca"},{"post_id":"cl8lhl0l1000tekwed662bzd6","tag_id":"cl8lhl0kx000fekwe2p8123nh","_id":"cl8lhl0l40010ekwedbj4b6ii"},{"post_id":"cl8lhl0l1000tekwed662bzd6","tag_id":"cl8lhl0kx000iekwe7jh27sxn","_id":"cl8lhl0l40012ekweesu159cc"},{"post_id":"cl8lhl0l3000xekwe3q9ueif7","tag_id":"cl8lhl0ku0006ekwebq2maj8k","_id":"cl8lhl0l40014ekwecw132sd8"},{"post_id":"cl8lhl0l3000vekwe35xsan66","tag_id":"cl8lhl0l4000yekwe01g2349w","_id":"cl8lhl0l40015ekwe4qv32cjh"}],"Tag":[{"name":"ElasticSearch","_id":"cl8lhl0kr0002ekwe4gok3jfq"},{"name":"java","_id":"cl8lhl0ku0006ekwebq2maj8k"},{"name":"hexo","_id":"cl8lhl0kv000bekweawvc286n"},{"name":"数据库","_id":"cl8lhl0kx000fekwe2p8123nh"},{"name":"分库分表","_id":"cl8lhl0kx000iekwe7jh27sxn"},{"name":"微服务","_id":"cl8lhl0ky000kekwe25k7710s"},{"name":"redis","_id":"cl8lhl0ky000nekwe88wybx5g"},{"name":"限流","_id":"cl8lhl0l4000yekwe01g2349w"}]}}