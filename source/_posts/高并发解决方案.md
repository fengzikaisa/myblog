---
title: 高并发解决方案
date: 2022-10-18 15:03:18
tags:
---
高并发解决方案分享<!--more-->

## 什么是高并发
高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。
- 响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
- 吞吐量：单位时间内处理的请求数量。
- QPS：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
- 并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。

## 高并发解决方案汇总
- 扩容
水平扩容、垂直扩容
- 缓存
Redis、CDN等
- 队列
Kafka、RabitMQ、RocketMQ等
- 服务拆分
服务化与微服务Spring Cloud、Spring Boot
- 限流
Guava RateLimiter使用、常用限流算法
- 服务降级与服务熔断
服务降级的多重选择、Hystrix
- 数据库切库，分库分表
切库、分表、多数据源
- 高可用的一些手段
任务调度分布式elastic-job、xxl-job、监控报警机制、负载均衡、图片服务器分离、独立的搜索服务器

### 扩容

提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。
前者垂直扩展可以通过提升单机硬件性能，例如：增加CPU核数，升级更好的网卡，升级更好的硬盘，扩充硬盘容量，扩充系统内存；或者提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间。但单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是后者：水平扩展

互联网分层架构中，各层次水平扩展的实践又有所不同：

![高并发解决方案](扩容水平扩展.png)

##### 用户层可以通过“DNS轮询”的方式来进行水平扩展；
大多数域名注册商都支持对统一主机添加多条A记录，这就是DNS轮询，DNS服务器将解析请求按照A记录的顺序，随机分配到不同的IP上，这样就完成了简单的负载均衡。

DNS轮询的优点：

- 零成本：只是在DNS服务器上绑定几个A记录，域名注册商一般都免费提供解析服务；
- 部署简单：就是在网络拓扑进行设备扩增，然后在DNS服务器上添加记录。

DNS轮询的缺点：

- 可靠性低

假设一个域名DNS轮询多台服务器，如果其中的一台服务器发生故障，那么所有的访问该服务器的请求将不会有所回应，这是任何人都不愿意看到的。即使从DNS中去掉该服务器的IP，但在Internet上，各地区电信、网通等宽带接入商将众多的DNS存放在缓存中，以节省访问时间，DNS记录全部生效需要几个小时，甚至更久。所以，尽管DNS轮询在一定程度上解决了负载均衡问题，但是却存在可靠性不高的缺点。

- 负载分配不均匀（有，但不会有那么大的影响）

DNS负载均衡采用的是简单的轮询算法，不能区分服务器的差异，不能反映服务器的当前运行状态，不能做到为性能较好的服务器多分配请求，甚至会出现客户请求集中在某一台服务器上的情况。

DNS服务器是按照一定的层次结构组织的，本地DNS服务器会缓存已解析的域名到IP地址的映射，这会导致使用该DNS服务器的用户在一段时间内访问的是同一台Web服务器，导致Web服务器间的负载不均匀。此外，用户本地计算机也会缓存已解析的域名到IP地址的映射。当多个用户计算机都缓存了某个域名到IP地址的映射时，而这些用户又继续访问该域名下的网页，这时也会导致不同Web服务器间的负载分配不均匀。

负载不均匀可能导致的后果有：某几台服务器负荷很低，而另几台服务器负载很高、处理缓慢；配置高的服务器分配到的请求少，而配置低的服务器分配到的请求多。

**当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。**

##### 反向代理层可以通过nginx来进行水平扩展；

通过修改nginx.conf，可以设置多个web后端服务器。

**当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。**

##### 服务层可以通过服务连接池来进行水平扩展；

站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。

##### 数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；

在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。

> 各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。

### 缓存

##### 为什么用redis

- 因为快

##### Redis快的原因

- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。

- 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU；

- 使用多路I/O复用模型，非阻塞IO；

- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

**关于redis的更多问题可以看下这篇**[《redis知识点整理》](https://blog.iluwen.com/2022/09/28/redis%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/)

#### 什么是CDN

CDN的全称是Content Delivery Network, 即内容发布网络。简单来说，CDN 就是将静态的资源分发到，位于多个地理位置机房中的服务器上，CDN系统能够实时地根据网络流量和各节点的链接,负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上

#### 为什么用CDN，而不是分布式缓存。

一般来说，图片和视频的大小会在几兆到几百兆之间不等，如果我们的应用服务器和分布式缓存都部署在北京的机房里，这时一个杭州的用户要访问缓存中的一个视频，那这个视频文件就需要从北京传输到杭州，期间会经过多个公网骨干网络，延迟很高，会让用户感觉视频打开很慢，严重影响到用户的使用体验。

所以，静态资源访问的关键点是就近访问，即北京用户访问北京的数据，杭州用户访问杭州的数据，这样才可以达到性能的最优。

你可能会说：“那我们在杭州也自建一个机房，让用户访问杭州机房的数据就好了呀。”可用户遍布在全国各地，有些应用可能还有国外的用户，我们不可能在每个地域都自建机房，这样成本太高了。
另外，单个视频和图片等静态资源很大，并且访问量又极高，如果使用业务服务器和分布式缓存来承担这些流量，无论是对于内网还是外网的带宽都会是很大的考验。

### 队列

#### 什么是消息队列

消息队列（Message Queue）可以看成是存储数据的一个容器，可以用来平衡低速系统和高速系统处理任务时间差的工具。

##### 为什么用消息队列

- 流量削峰填谷（最主要的作用）
- 解耦
- 异步
- 最终一致性

**削峰**
- 传统模式：并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常
- 中间件模式：系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。

**解耦**
- 传统模式:系统间耦合性太强，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！
- 中间件模式：将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改

**异步**
- 传统模式：一些非必要的业务逻辑以同步的方式运行，太耗费时间。
- 中间件模式： 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度。

##### 消息队列缺点
- 系统可用性降低
- 系统复杂性增加

### 服务拆分

#### 一体化架构的优缺点

所谓“一体化架构”就是说所有的功能模块，都被打包到一个web工程中，然后部署到应用服务器上。

**优点**
只针对开发前期

- 开发简单直接，代码和项目集中式管理

- 只需要维护一个工程，节省维护系统运行的人力成本

- 排查问题方便，只需要排查这个应用进程就可以了，目标性强

**缺点**

- 数据库连接的扩容问题

- 代码冲突耦合，模块相互依赖（git版本控制管理员）

- 运维困难，构建编译部署缓慢
在项目初期，你的代码可能只有几千行，构建一次只需要一分钟，那么你可以很敏捷灵活地频繁上线变更修复问题。但是当你的系统扩充到几十万行，甚至上百万行代码的时候，一次构建的过程，包括编译、单元测试、打包和上传到正式环境，花费的时间可能达到十几分钟，并且，任何小的修改，都需要构建整个项目，上线变更的过程非常不灵活。

- 出现问题导致应用整体不可用

#### 微服务拆分的意义

- 将与业务无关的公用服务抽取出来，下沉成单独的服务。每一个服务的功能内聚，维护人员职责明确，增加了新的功能只需要测试自己的服务就可以了，而一旦服务出了问题，也可以通过服务熔断、降级的方式减少对于其他服务的影响

#### 微服务拆分原则

- 做到单一服务内部功能的高内聚，和低耦合：也就是说，每个服务只完成自己职责之内的任务，对于不是自己职责的功能，交给其它服务来完成
有用户服务和内容服务，用户信息中有“是否为认证用户”字段。
但是内容服务里有这么一段逻辑：如果用户认证字段等于 1，代表是认证用户，那么就把内容权重提升。
问题是，判断用户是否为认证用户的逻辑，应该内聚在用户服务内部，而不应该由内容服务判断，否则认证的逻辑一旦变更，内容服务也需要一同跟着变更，这就不满足高内聚、低耦合的要求了。
- 关注服务拆分的粒度，先粗略拆分，然后逐渐细化。
比如说，对于一个社区系统来说，你可以先把和用户关系相关的业务逻辑，都拆分到用户关系服务中，之后，再把比如黑名单的逻辑独立成黑名单服务。
- 拆分的过程，要尽量避免影响产品的日常功能迭代。也就是说，要一边做产品功能迭代，一边完成服务器拆分。即，我们的拆分只能在现有一体化系统的基础上，不断剥离业务独立部署。剥离的顺序，可以如下：
优先剥离比较独立的边界服务（比如短信服务、地理位置服务），从非核心的服务出发，减少拆分对现有业务的影响
当两个服务存在依赖关系时，优先拆分被依赖的服务
比方说，内容服务依赖于用户服务获取用户的基本信息，那么如果先把内容服务拆分出来，内容服务就会依赖于一体化架构中的用户模块，这样还是无法保证内容服务的快速部署能力
所以正确的做法是，你要理清服务之间的调用关系，比如说，内容服务会依赖用户服务获取用户信息，互动服务会依赖内容服务，所以要按照先用户服务，再内容服务，最后互动服务的顺序来进行拆分。
- 服务接口的定义要具备可扩展性
服务拆分之后，由于服务是以独立进程的方式部署，所以服务之间的通信，就不再是进程内部的方法调用，而是跨进程的网络通信了。在这种通信模式下需要注意，服务接口的定义要具备可扩展性，否则在服务变更时，会造成意想不到的错误。
比如，服务接口的参数类型最好是封装类，这样如果增加参数，就不必变更参数的签名，只需要在类中添加字段就可以了

### 限流

#### 什么是限流

在高并发系统中，限流通常指的是：对高并发访问或者请求进行限速或者对一个时间内的请求进行限速来保护我们的系统，一旦达到系统的限速规则（比如系统限制的请求速度），则可以采用下面的方式来处理这些请求。

- 拒绝服务（友好提示或者跳转到错误页面）
- 排队或等待（比如秒杀系统）
- 服务降级（返回默认的兜底数据）

#### 限流常用算法

- 计数器（固定窗口算法）
假设1min内服务器的负载能力为100，因此一个周期的访问量限制在100，然而在第一个周期的最后5秒和下一个周期的开始5秒时间段内，分别涌入100的访问量，虽然没有超过每个周期的限制量，但是整体上10秒内已达到200的访问量，已远远超过服务器的负载能力，由此可见，计数器算法方式限流对于周期比较长的限流，存在很大的弊端。

- 滑动窗口算法
滑动窗口算法是将时间周期分为n个小周期，分别记录每个小周期内的访问次数 ，并且根据时间滑动删除过期的小周期。
如下图，假设时间周期为1min，将1min再分割成2个小周期，统计每个小周期的访问数量，则可以看到，第一个时间周期内访问数量为75，第二个时间周期内访问数量为100，超过100的数量被限流掉了。
![高并发解决方案](滑动窗口算法.png)
由此可见，当滑动窗口格子划分得越多，那么滑动窗口的滚动就越平滑，限流的统计就越精确。可以很好的解决固定窗口的流动问题。

- 漏桶算法
漏桶算法是将访问请求放入漏桶中，当请求达到限流值，则进行丢弃（触发限流策略）。无论有多少请求，请求的速率有多大，都按照固定的速率流出，对应到系统中就是按照固定的速率处理请求。超过漏桶容量的直接抛弃。
![高并发解决方案](漏桶算法.jpg)

- 令牌桶算法
令牌桶其实和漏桶的原理类似，令牌桶按固定的速率往桶里放入令牌，并且只要能从桶里取出令牌就能通过，令牌桶支持突发流量的快速处理。
![高并发解决方案](令牌桶算法.jpg)

> 令牌桶和漏桶区别
> 主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。

### 服务降级与服务熔断

#### 什么是熔断

当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，**进而熔断该节点微服务的调用，快速返回错误的响应信息。**检测到该节点微服务调用响应正常后恢复调用链路。
例如：A服务调用 B服务的某个功能，由于网络不稳定问题，或者 B服务卡机，导致功能时间超长。如果这样的次数很多。我们就可以直接将 B服务段路了（A不再请求 B接口），凡是调用 B得直接返回降级数据，不必等待 B的超长执行。这样 B的故障问题，就不会级联影响到 A服务。

#### 什么是降级
服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理，或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。**说白了，就是尽可能的把系统资源让给优先级高的服务。**
例如：整个网站处于流量高峰期，服务器压力剧增，根据当前业务情况及流量，对一些服务和页面进行由策略的降级[停止服务，所有的调用直接返回降级数据]。以此缓解服务器资源的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户得到正确的对应。

#### 熔断和降级的区别

**相同点：**
- 为了保证集群大部分服务的可用性和可靠性，防止崩溃，牺牲小我
- 用户最终都是体验到某个功能不可用

**不同点：**
- 熔断是被调用方故障，触发的系统主动规则
- 降级是基于全局的考虑，通知一些正常服务，释放资源

**推荐使用阿里的Sentinel，关于sentinel的介绍可以看这篇文章**[《Sentinel还是Hystrix》](https://blog.iluwen.com/2022/09/29/sentinel%E8%BF%98%E6%98%AFhystrix/)

### 数据库切库，分库分表

**关于分库分表的更多信息可以看以下几篇文章**
[《分库分表》](https://blog.iluwen.com/2022/09/28/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/)
[《分库分表之后的id主键如何处理》](https://blog.iluwen.com/2022/09/28/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B9%8B%E5%90%8E%E7%9A%84id%E4%B8%BB%E9%94%AE%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/)
[《现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上》](https://blog.iluwen.com/2022/09/28/%E7%8E%B0%E5%9C%A8%E6%9C%89%E4%B8%80%E4%B8%AA%E6%9C%AA%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%EF%BC%8C%E6%9C%AA%E6%9D%A5%E8%A6%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%89%8D%E5%8F%AF%E4%BB%A5%E8%AE%A9%E7%B3%BB%E7%BB%9F%E4%BB%8E%E6%9C%AA%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2%E5%88%B0%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B8%8A%EF%BC%9F/)
[《可以动态扩容缩容的分库分表方案》](https://blog.iluwen.com/2022/09/28/%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88/)


## 如何设计一个秒杀系统

**秒杀系统场景特点**
- 秒杀时大量用户会在同一时间同时进行抢购，网站瞬时访问流量激增。
- 秒杀一般是访问请求数量远远大于库存数量，只有少部分用户能够秒杀成功。
- 秒杀业务流程比较简单，一般就是下订单减库存。

**秒杀架构设计理念**
- 限流： 鉴于只有少部分用户能够秒杀成功，所以要限制大部分流量，只允许少部分流量进入服务后端。

- 削峰：对于秒杀系统瞬时会有大量用户涌入，所以在抢购一开始会有很高的瞬间峰值。高峰值流量是压垮系统很重要的原因，所以如何把瞬间的高流量变成一段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰的常用的方法有利用缓存和消息中间件等技术。

- 异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。

- 内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。

- 可拓展：当然如果我们想支持更多用户，更大的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓展机器就好了。像淘宝、京东等双十一活动时会增加大量机器应对交易高峰。

**设计思路**

将请求拦截在系统上游，降低下游压力：秒杀系统特点是并发量极大，但实际秒杀成功的请求数量却很少，所以如果不在前端拦截很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。 
充分利用缓存：利用缓存可极大提高系统读写速度。 
充分消息队列：消息队列可以削峰，将拦截大量并发请求，这也是一个异步处理过程，后台业务根据自己的处理能力，从消息队列中主动的拉取请求消息进行业务处理。

**前端方案**

- 页面静态化：将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 
- 秒杀链接加盐
- 禁止重复提交：用户提交之后按钮置灰，禁止重复提交 
- 用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流

**后端方案**

- 服务端控制器层(网关层)
对于我们的秒杀链接的非法攻击请求，比如：每秒进行1000次刷新请求，肯定不是人为的，或者需要携带令牌的请求并未携带令牌，伪造请求过来，就需要识别这种非法攻击请求进行拦截，拦截的地方一般设置在网关层，使得我们进入网关以后的请求都是正常的动态请求

- 限制uid（UserID）访问频率：
我们上面拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。

- 服务层
上面只拦截了一部分访问请求，当秒杀的用户量很大时，即使每个用户只有一个请求，到服务层的请求数量还是很大。比如我们有100W用户同时抢100台手机，服务层并发请求压力至少为100W。
（1）采用消息队列缓存请求：既然服务层知道库存只有100台手机，那完全没有必要把100W个请求都传递到数据库啊，那么可以先把这些请求都写到消息队列缓存一下，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。
（2）利用缓存应对读请求：对类似于12306等购票业务，是典型的读多写少业务，大部分请求是查询请求，所以可以利用缓存分担数据库压力。
（3）利用缓存应对写请求：缓存也是可以应对写请求的，比如我们就可以把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。

- 数据库层
数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。
经过上边的拦截，真正到达后台的请求已经不多了，一般情况下mysql完全可以搞定了，当然我们也可以在数据库层面有一些措施
（1）增加数据库连接池连接数
（2）调大数据库缓存
（3）尽量使用细粒度的锁，如使用mysql自带的乐观锁机制
（4）数据库可以进行拆分，分库分表
（5）业务方的数据批量定时同步到数据库

